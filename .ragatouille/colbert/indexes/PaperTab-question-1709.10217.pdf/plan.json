{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "The First Evaluation of Chinese Human-Computer Dialogue Technology Wei-Nan Zhang\u2020, Zhigang Chen\u2021, Wanxiang Che\u2020, Guoping Hu\u2021, Ting Liu\u2020 \u2020Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, Harbin, China \u2021Joint Laboratory of HIT and iFLYTEK, iFLYTEK Research, Hefei, China {wnzhang, car, tliu}@ir.hit.edu.cn, {zgchen, gphu}@i\ufb02ytek.com Abstract In this paper, we introduce the \ufb01rst evaluation of Chinese human-computer dialogue technology. We detail the evaluation scheme, tasks, metrics and how to collect and annotate the data for training, developing and test. The evaluation includes two tasks, namely user intent classi\ufb01cation and online testing of task-oriented dialogue. To consider the different sources of the data for training and developing, the \ufb01rst task can also be divided into two sub tasks. Both the two tasks are coming from the real problems when using the applications developed by industry. The evaluation data is provided by the iFLYTEK Corporation.",
            "To consider the different sources of the data for training and developing, the \ufb01rst task can also be divided into two sub tasks. Both the two tasks are coming from the real problems when using the applications developed by industry. The evaluation data is provided by the iFLYTEK Corporation. Meanwhile, in this paper, we publish the evaluation results to present the current performance of the participants in the two tasks of Chinese human-computer dialogue technology. Moreover, we analyze the existing problems of human-computer dialogue as well as the evaluation scheme itself. Keywords: Chinese dialogue evaluation, user intent classi\ufb01cation, online task-oriented dialogue test, evaluation data 1. Introduction Recently, human-computer dialogue has been emerged as a hot topic, which has attracted the attention of both academia and industry.",
            "Keywords: Chinese dialogue evaluation, user intent classi\ufb01cation, online task-oriented dialogue test, evaluation data 1. Introduction Recently, human-computer dialogue has been emerged as a hot topic, which has attracted the attention of both academia and industry. In research, the natural language understanding (NLU), dialogue management (DM) and natural language generation (NLG) have been promoted by the technologies of big data and deep learning (Shang et al., 2015; Serban et al., 2016a; Serban et al., 2016b; Li et al., 2015; Xing et al., 2016; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2016; Wen et al., 2015b). Following the development of machine reading comprehension (Cui et al., 2016; Hermann et al., 2015; Kadlec et al., 2016; Liu et al., 2017; Wang et al., 2017; Cui et al., 2017), the NLU technology has made great progress.",
            "The develop- ment of DM technology is from rule-based approach and supervised learning based approach to reinforcement learn- ing based approach (Young et al., 2013). The NLG technol- ogy is through pattern-based approach, sentence planning approach and end-to-end deep learning approach (Mairesse and Young, 2014; Mairesse et al., 2010; Wen et al., 2015a). In application, there are massive products that are based on the technology of human-computer dialogue, such as Apple Siri1, Amazon Echo2, Microsoft Cortana3, Facebook Mes- senger4 and Google Allo5 etc. Although the blooming of human-computer dialogue tech- nology in both academia and industry, how to evaluate a dialogue system, especially an open domain chit-chat sys- tem, is still an open question. Figure 1 presents a brief comparison of the open domain chit-chat system and the task-oriented dialogue system. From Figure 1, we can see that it is quite different between the open domain chit-chat system and the task-oriented di- alogue system.",
            "Figure 1 presents a brief comparison of the open domain chit-chat system and the task-oriented dialogue system. From Figure 1, we can see that it is quite different between the open domain chit-chat system and the task-oriented di- alogue system. For the open domain chit-chat system, as it has no exact goal in a conversation, given an input mes- 1https:\/\/www.apple.com\/ios\/siri\/ 2https:\/\/en.wikipedia.org\/wiki\/Amazon Echo 3https:\/\/www.microsoft.com\/en-us\/windows\/cortana 4https:\/\/en.wikipedia.org\/wiki\/Facebook Messenger 5https:\/\/allo.google.com\/ Figure 1: A brief comparison of the open domain chit-chat system and the task-oriented dialogue system. sage, the responses can be various. For example, for the input message \u201cHow is it going today?\u201d, the responses can be \u201cI\u2019m \ufb01ne!\u201d, \u201cNot bad.\u201d, \u201cI feel so depressed!\u201d, \u201cWhat a bad day!\u201d, etc. There may be in\ufb01nite number of responses for an open domain messages.",
            "There may be in\ufb01nite number of responses for an open domain messages. Hence, it is dif\ufb01cult to con- struct a gold standard (usually a reference set) to evaluate a response which is generated by an open domain chit-chat system. For the task-oriented system, although there are some objective evaluation metrics, such as the number of turns in a dialogue6, the ratio of task completion7, etc., there is no gold standard for automatically evaluating two (or more) dialogue systems when considering the satisfac- tion of the human and the \ufb02uency of the generated dialogue. To promote the development of the evaluation technology for dialogue systems, especially considering the language characteristics of Chinese, we organize the \ufb01rst evaluation 6The number of utterances in a task-completed dialogue. Given a same task, the less number of turns, the better of the dia- logue system. 7The number of completed tasks divided by the total number of tasks. arXiv:1709.10217v2  [cs.CL]  2 Dec 2019",
            "Input message Intent category \u4f60\u597d\u554a\uff0c\u5f88\u9ad8\u5174\u89c1\u5230\u4f60\uff01 \u95f2\u804a\u7c7b Hello, nice to meet you! Chit-chat \u6211\u60f3\u8ba2\u4e00\u5f20\u53bb\u5317\u4eac\u7684\u673a\u7968 \u4efb\u52a1\u578b\uff08\u8ba2\u673a\u7968\uff09 I want to book an air ticket to Beijing. Task-oriented dialogue (Booking air tickets) \u6211\u60f3\u627e\u4e00\u5bb6\u4e94\u9053\u53e3\u9644\u8fd1\u4fbf\u5b9c\u5e72\u51c0\u7684\u5feb\u6377\u9152\u5e97 \u4efb\u52a1\u578b\uff08\u8ba2\u9152\u5e97\uff09 I want to book a neat and low-priced inn near Wudaokou. Task-oriented dialogue (Booking hotels) Table 1: An example of user intent with category information. of Chinese human-computer dialogue technology. In this paper, we will present the evaluation scheme and the re- leased corpus in detail. The rest of this paper is as follows. In Section 2, we will brie\ufb02y introduce the \ufb01rst evaluation of Chinese human- computer dialogue technology, which includes the descrip- tions and the evaluation metrics of the two tasks.",
            "The rest of this paper is as follows. In Section 2, we will brie\ufb02y introduce the \ufb01rst evaluation of Chinese human- computer dialogue technology, which includes the descrip- tions and the evaluation metrics of the two tasks. We then present the evaluation data and \ufb01nal results in Section 3 and 4 respectively, following the conclusion and acknowledge- ments in the last two sections. 2. The First Evaluation of Chinese Human-Computer Dialogue Technology The First Evaluation of Chinese Human-Computer Dia- logue Technology includes two tasks, namely user in- tent classi\ufb01cation and online testing of task-oriented di- alogue. 2.1. Task 1: User Intent Classi\ufb01cation In using of human-computer dialogue based applications, human may have various intent, for example, chit-chatting, asking questions, booking air tickets, inquiring weather, etc. Therefore, after receiving an input message (text or ASR result) from a user, the \ufb01rst step is to classify the user intent into a speci\ufb01c domain for further processing. Table 1 shows an example of user intent with category information.",
            "Therefore, after receiving an input message (text or ASR result) from a user, the \ufb01rst step is to classify the user intent into a speci\ufb01c domain for further processing. Table 1 shows an example of user intent with category information. In task 1, there are two top categories, namely, chit-chat and task-oriented dialogue. The task-oriented dialogue also includes 30 sub categories. In this evaluation, we only con- sider to classify the user intent in single utterance. It is worth noting that besides the released data for training and developing, we also allow to collect external data for training and developing. To considering that, the task 1 is indeed includes two sub tasks. One is a closed evaluation, in which only the released data can be used for training and developing. The other is an open evaluation that allow to collect external data for training and developing. For task 1, we use F1-score as evaluation metric. 2.2. Task 2: Online Testing of Task-oriented Dialogue For the task-oriented dialogue systems, the best way for evaluation is to use the online human-computer dialogue.",
            "For task 1, we use F1-score as evaluation metric. 2.2. Task 2: Online Testing of Task-oriented Dialogue For the task-oriented dialogue systems, the best way for evaluation is to use the online human-computer dialogue. After \ufb01nishing an online human-computer dialogue with a dialogue system, the human then manually evaluate the system by using the metrics of user satisfaction degree, dialogue \ufb02uency, etc. Therefore, in the task 2, we use an online testing of task-oriented dialogue for dialogue U \u6709\u5230\u5317\u4eac\u7684\u8f6f\u5367\u706b\u8f66\u7968\u5417\uff1f Are there any soft berth tickets to Beijing? R \u8bf7\u95ee\u60a8\u8981\u4ece\u54ea\u91cc\u51fa\u53d1\uff1f Where do you leave from? U \u54c8\u5c14\u6ee8 Harbin. R \u60a8\u8981\u8ba2\u54ea\u5929\u7684\u5462\uff1f When will you leave? U \u660e\u5929\u5427 Tomorrow. R \u53d1\u8f66\u65f6\u95f4\u5462\uff1f What about the departure time? U \u665a\u4e0a\u5427\uff0c\u6b63\u597d\u7761\u89c9\u3002 Evening is okay, just sleep. R \u4e0a\u94fa\u8fd8\u662f\u4e0b\u94fa\uff1f Do you want an upper or lower berth?",
            "R \u53d1\u8f66\u65f6\u95f4\u5462\uff1f What about the departure time? U \u665a\u4e0a\u5427\uff0c\u6b63\u597d\u7761\u89c9\u3002 Evening is okay, just sleep. R \u4e0a\u94fa\u8fd8\u662f\u4e0b\u94fa\uff1f Do you want an upper or lower berth? U \u90fd\u884c\u3002 Either is okay. R \u4ee5\u4e0b\u662f\u4e3a\u60a8\u67e5\u8be2\u5230\u7684\u8f66\u7968\u4fe1\u606f\u3002 The tickets information is as following. U \u8c22\u8c22\uff0c\u518d\u89c1\u3002 Thanks, see you. R \u4e0d\u5ba2\u6c14\uff0c\u518d\u89c1\u3002 You\u2019re welcome. Goodbye. Table 2: An example of the task-oriented human-computer dialogue. systems. For a human tester, we will give a complete intent with an initial sentence, which is used to start the online human-computer dialogue. Table 2 shows an example of the task-oriented human-computer dialogue. Here \u201cU\u201d and \u201cR\u201d denote user and robot respectively.",
            "systems. For a human tester, we will give a complete intent with an initial sentence, which is used to start the online human-computer dialogue. Table 2 shows an example of the task-oriented human-computer dialogue. Here \u201cU\u201d and \u201cR\u201d denote user and robot respectively. The complete intent is as following: \u201c\u67e5\u8be2\u660e\u5929\u4ece\u54c8\u5c14\u6ee8\u5230\u5317\u4eac\u7684\u665a\u95f4\u8f6f\u5367\u706b\u8f66\u7968\uff0c \u4e0a\u4e0b\u94fa\u5747\u53ef\u3002 Inquire the soft berth ticket at tomorrow evening, from Harbin to Beijing, either upper or lower berth is okay.\u201d In task 2, there are three categories. They are \u201cair tickets\u201d, \u201ctrain tickets\u201d and \u201chotel\u201d. Correspondingly, there are three type of tasks. All the tasks are in the scope of the three categories. However, a complete user intent may include more than one task. For example, a user may \ufb01rst inquiring the air tickets. However, due to the high price, the user decide to buy a train tickets. Furthermore, the user may",
            "also need to book a hotel room at the destination. We use manual evaluation for task 2. For each system and each complete user intent, the initial sentence, which is used to start the dialogue, is the same. The tester then be- gin to converse to each system. A dialogue is \ufb01nished if the system successfully returns the information which the user inquires or the number of dialogue turns is larger than 30 for a single task. For building the dialogue systems of par- ticipants, we release an example set of complete user intent and three data \ufb01les of \ufb02ight, train and hotel in JSON format. There are \ufb01ve evaluation metrics for task 2 as following. \u2022 Task completion ratio: The number of completed tasks divided by the number of total tasks. \u2022 User satisfaction degree: There are \ufb01ve scores -2, - 1, 0, 1, 2, which denote very dissatis\ufb01ed, dissatis\ufb01ed, neutral, satis\ufb01ed and very satis\ufb01ed, respectively.",
            "\u2022 User satisfaction degree: There are \ufb01ve scores -2, - 1, 0, 1, 2, which denote very dissatis\ufb01ed, dissatis\ufb01ed, neutral, satis\ufb01ed and very satis\ufb01ed, respectively. \u2022 Response \ufb02uency: There are three scores -1, 0, 1, which indicate non\ufb02uency, neutral, \ufb02uency. \u2022 Number of dialogue turns: The number of utterances in a task-completed dialogue. \u2022 Guidance ability for out of scope input8: There are two scores 0, 1, which represent able to guide or un- able to guide. For the number of dialogue turns, we have a penalty rule that for a dialogue task, if the system cannot return the re- sult (or accomplish the task) in 30 turns, the dialogue task is end by force. Meanwhile, if a system cannot accomplish a task in less than 30 dialogue turns, the number of dialogue turns is set to 30. 3.",
            "Meanwhile, if a system cannot accomplish a task in less than 30 dialogue turns, the number of dialogue turns is set to 30. 3. Evaluation Data In the evaluation, all the data for training, developing and test is provided by the iFLYTEK Corporation9. For task 1, as the descriptions in Section 2.1., the two top categories are chit-chat (chat in Table 3) and task-oriented dialogue. Meanwhile, the task-oriented dialogue also in- cludes 30 sub categories. Actually, the task 1 is a 31 cate- gories classi\ufb01cation task. In task 1, besides the data we re- leased for training and developing, we also allow the partic- ipants to extend the training and developing corpus. Hence, there are two sub tasks for the task 1. One is closed test, which means the participants can only use the released data for training and developing. The other is open test, which allows the participants to explore external corpus for train- ing and developing. Note that there is a same test set for both the closed test and the open test.",
            "One is closed test, which means the participants can only use the released data for training and developing. The other is open test, which allows the participants to explore external corpus for train- ing and developing. Note that there is a same test set for both the closed test and the open test. For task 2, we release 11 examples of the complete user intent and 3 data \ufb01le, which includes about one month of \ufb02ight, hotel and train information, for participants to build their dialogue systems. The current date for online test is set to April 18, 2017. If the tester says \u201ctoday\u201d, the systems developed by the participants should understand that he\/she indicates the date of April 18, 2017. 8During the dialogue, the testers may inquire the information that is not existing in the data \ufb01les. These inquiry inputs are called out of scope inputs. 9http:\/\/www.i\ufb02ytek.com\/en\/index.html 4. Evaluation Results There are 74 participants who are signing up the evalua- tion. The \ufb01nal number of participants is 28 and the number of submitted systems is 43.",
            "9http:\/\/www.i\ufb02ytek.com\/en\/index.html 4. Evaluation Results There are 74 participants who are signing up the evalua- tion. The \ufb01nal number of participants is 28 and the number of submitted systems is 43. Table 4 and 5 show the eval- uation results of the closed test and open test of the task 1 respectively. Due to the space limitation, we only present the top 5 results of task 1. We will add the complete lists of the evaluation results in the version of full paper. Note that for task 2, there are 7 submitted systems. How- ever, only 4 systems can provide correct results or be con- nected in a right way at the test phase. Therefore, Table 6 shows the complete results of the task 2. 5. Conclusion In this paper, we introduce the \ufb01rst evaluation of Chinese human-computer dialogue technology. In detail, we \ufb01rst present the two tasks of the evaluation as well as the evalua- tion metrics. We then describe the released data for evalua- tion.",
            "5. Conclusion In this paper, we introduce the \ufb01rst evaluation of Chinese human-computer dialogue technology. In detail, we \ufb01rst present the two tasks of the evaluation as well as the evalua- tion metrics. We then describe the released data for evalua- tion. Finally, we also show the evaluation results of the two tasks. As the evaluation data is provided by the iFLYTEK Corporation from their real online applications, we believe that the released data will further promote the research of human-computer dialogue and \ufb01ll the blank of the data on the two tasks. Acknowledgements We would like to thank the Social Media Processing (SMP) committee of Chinese Information Processing Society of China. We thank all the participants of the \ufb01rst evalua- tion of Chinese human-computer dialogue technology. We also thank the testers from the voice resource department of the iFLYTEK Corporation for their effort to the online real-time human-computer dialogue test and of\ufb02ine dia- logue evaluation.",
            "We also thank the testers from the voice resource department of the iFLYTEK Corporation for their effort to the online real-time human-computer dialogue test and of\ufb02ine dia- logue evaluation. We thank Lingzhi Li, Yangzi Zhang, Ji- aqi Zhu and Xiaoming Shi from the research center for so- cial computing and information retrieval for their support on the data annotation, establishing the system testing en- vironment and the communication to the participants and help connect their systems to the testing environment. This paper is supported by National Key Basic Research Program of China (No. 2014CB340503) and NSFC (No. 61502120), the Fundamental Research Funds for the Cen- tral Universities(30620170037). Reference Cui, Y., Liu, T., Chen, Z., Wang, S., and Hu, G. (2016). Consensus attention-based neural networks for chinese reading comprehension. In Proceedings of COLING 2016, the 26th International Conference on Computa- tional Linguistics: Technical Papers, pages 1777\u20131786, Osaka, Japan.",
            "(2016). Consensus attention-based neural networks for chinese reading comprehension. In Proceedings of COLING 2016, the 26th International Conference on Computa- tional Linguistics: Technical Papers, pages 1777\u20131786, Osaka, Japan. Cui, Y., Chen, Z., Wei, S., Wang, S., Liu, T., and Hu, G. (2017). Attention-over-attention neural networks for reading comprehension. In Proceedings of the 55th An- nual Meeting of the Association for Computational Lin- guistics (Volume 1: Long Papers), pages 593\u2013602. Asso- ciation for Computational Linguistics. Hermann, K. M., Kocisky, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman, M., and Blunsom, P. (2015). Teach- ing machines to read and comprehend. In Advances in",
            "app bus calc chat cinemas contacts cookbook datetime email epg \ufb02ight Train 36 24 24 456 24 30 269 18 24 107 62 Dev 18 8 8 114 10 10 88 6 8 36 21 Test 18 8 8 50 8 10 90 6 8 36 21 Sum 72 40 40 662 42 50 447 30 40 179 104 health lottery map match message music news novel poetry radio riddle Train 55 24 68 24 63 66 58 24 402 24 34 Dev 19 8 23 8 21 22 19 8 34 8 11 Test 18 8 23 8 21 22 19 8 34 8 11 Sum 92 40 114 40 105 110 96 40 470 40 56 schedule stock telephone train translation tvchannel video weather website Total # Train 29 71 63 70 61 71 182 66 54 2,",
            "583 Dev 9 24 21 23 21 23 60 22 18 729 Test 10 24 21 23 20 24 61 22 18 688 Sum 48 119 105 116 102 118 303 110 90 4,000 Table 3: The statistics of the released data for task 1.",
            "000 Table 3: The statistics of the released data for task 1. Ranking Participant F1 score 1 \u534e\u5357\u519c\u4e1a\u5927\u5b66\u53e3\u8bed\u5bf9\u8bdd\u7cfb\u7edf\u7814\u7a76\u5ba4 0.9391 Spoken Dialogue System Lab, South China Agricultural University 2 \u4e49\u8bed\u667a\u80fd\u79d1\u6280\uff08\u4e0a\u6d77\uff09\u6709\u9650\u516c\u53f8 0.9288 DeepBrain Corporation 3 \u5c71\u897f\u5927\u5b66\u8ba1\u7b97\u673a\u4e0e\u4fe1\u606f\u6280\u672f\u5b66\u9662 0.9089 School of Computer & Information Technology, Shanxi University 4 \u5317\u4eac\u90ae\u7535\u5927\u5b66\u667a\u80fd\u79d1\u5b66\u4e0e\u6280\u672f\u4e2d\u5fc3 0.9082 Intelligent science and technology center, Beijing University of Posts and Telecommunications 5 \u54c8\u5c14\u6ee8\u5de5\u4e1a\u5927\u5b66(\u6df1\u5733) 0.9028 Harbin Institute of Technology (Shenzhen) Table 4: Top 5 results of the closed test of the task 1.",
            "Ranking Participant F1 score 1 \u534e\u5357\u519c\u4e1a\u5927\u5b66\u53e3\u8bed\u5bf9\u8bdd\u7cfb\u7edf\u7814\u7a76\u5ba4 0.9414 Spoken Dialogue System Lab, South China Agricultural University 2 \u4e49\u8bed\u667a\u80fd\u79d1\u6280\uff08\u4e0a\u6d77\uff09\u6709\u9650\u516c\u53f8 0.9288 DeepBrain Corporation 3 \u4e2d\u56fd\u79d1\u5b66\u9662\u81ea\u52a8\u5316\u7814\u7a76\u6240-\u51fa\u95e8\u95ee\u95ee\u8bed\u8a00\u667a\u80fd\u4e0e\u4eba\u673a\u4ea4\u4e92\u8054\u5408\u5b9e\u9a8c\u5ba4 0.9258 Institute of automation, Chinese Academy of Sciences 4 \u5e7f\u4e1c\u5916\u8bed\u5916\u8d38\u5927\u5b66 0.9255 Guangdong University of Foreign Studies 5 \u5c71\u897f\u5927\u5b66\u8ba1\u7b97\u673a\u4e0e\u4fe1\u606f\u6280\u672f\u5b66\u9662 0.9123 School of Computer & Information Technology, Shanxi University Table 5: Top 5 results of the open test of the task 1. Neural Information Processing Systems, pages 1693\u2013 1701. Kadlec, R., Schmid, M., Bajgar, O., and Kleindienst, J. (2016). Text understanding with the attention sum reader network.",
            "Neural Information Processing Systems, pages 1693\u2013 1701. Kadlec, R., Schmid, M., Bajgar, O., and Kleindienst, J. (2016). Text understanding with the attention sum reader network. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 908\u2013918, Berlin, Germany, Au- gust. Association for Computational Linguistics. Li, J., Galley, M., Brockett, C., Gao, J., and Dolan, B. (2015). A diversity-promoting objective function for neural conversation models. NAACL. Li, J., Monroe, W., Ritter, A., and Dan, J. (2016). Deep re- inforcement learning for dialogue generation. EMNLP. Liu, T., Cui, Y., Yin, Q., Zhang, W.-N., Wang, S., and Hu, G. (2017). Generating and exploiting large-scale pseudo training data for zero pronoun resolution.",
            "EMNLP. Liu, T., Cui, Y., Yin, Q., Zhang, W.-N., Wang, S., and Hu, G. (2017). Generating and exploiting large-scale pseudo training data for zero pronoun resolution. In Pro- ceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 102\u2013111, Vancouver, Canada, July. Association for Computational Linguistics. Mairesse, F. and Young, S. (2014). Stochastic language generation in dialogue using factored language models.",
            "Ranking Participant Ratio Satisfaction Fluency Turns Guide 1 \u6df1\u601d\u8003\u4eba\u5de5\u667a\u80fd\u673a\u5668\u4eba\u79d1\u6280\uff08\u5317\u4eac\uff09\u6709\u9650\u516c\u53f8 0.3175 64.53 0 -1 2 iDeepMind Arti\ufb01cial Intelligence 2 \u4e0a\u6d77\u8461\u8404\u7eac\u5ea6\u79d1\u6280\u6709\u9650\u516c\u53f8 0.1905 72.28 -1 1 3 Shanghai Putao Technology Co., Ltd. 3 \u5317\u4eac\u90ae\u7535\u5927\u5b66\u4fe1\u606f\u4e0e\u901a\u4fe1\u5de5\u7a0b\u5b66\u9662 0.1905 78.72 0 1 3 School of Information and Communication Engineering Beijing University of Posts and Telecommunications 4 \u4e2d\u56fd\u79d1\u5b66\u9662\u81ea\u52a8\u5316\u7814\u7a76\u6240 0.1111 71.39 -2 -1 3 \u51fa\u95e8\u95ee\u95ee\u8bed\u8a00\u667a\u80fd\u4e0e\u4eba\u673a\u4ea4\u4e92\u8054\u5408\u5b9e\u9a8c\u5ba4 Institute of automation, Chinese Academy of Sciences Table 6: The results of the task 2.",
            "Ratio, Satisfaction, Fluency, Turns and Guide indicate the task completion ratio, user satisfaction degree, response \ufb02uency, number of dialogue turns and guidance ability for out of scope input respectively. Computational Linguistics, 40(4):763\u2013799. Mairesse, F., , M., Jurcicek, Ek, F., Keizer, S., Thomson, B., Yu, K., and Young, S. (2010). Phrase-based statisti- cal language generation using graphical models and ac- tive learning. In ACL, pages 1552\u20131561. Serban, I. V., Sordoni, A., Bengio, Y., Courville, A., and Pineau, J. (2016a). Building end-to-end dialogue sys- tems using generative hierarchical neural network mod- els. Computer Science. Serban, I. V., Sordoni, A., Lowe, R., Charlin, L., Pineau, J., Courville, A., and Bengio, Y. (2016b). A hierarchi- cal latent variable encoder-decoder model for generating dialogues.",
            "Serban, I. V., Sordoni, A., Lowe, R., Charlin, L., Pineau, J., Courville, A., and Bengio, Y. (2016b). A hierarchi- cal latent variable encoder-decoder model for generating dialogues. Shang, L., Lu, Z., and Li, H. (2015). Neural respond- ing machine for short-text conversation. In ACL, pages 1577\u20131586. Vinyals, O. and Le, Q. (2015). A neural conversational model. Computer Science. Wang, W., Yang, N., Wei, F., Chang, B., and Zhou, M. (2017). Gated self-matching networks for reading com- prehension and question answering. In Proceedings of the 55th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), volume 1, pages 189\u2013198.",
            "(2017). Gated self-matching networks for reading com- prehension and question answering. In Proceedings of the 55th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), volume 1, pages 189\u2013198. Wen, T. H., Gasic, M., Kim, D., Mrksic, N., Su, P. H., Vandyke, D., and Young, S. (2015a). Stochastic lan- guage generation in dialogue using recurrent neural net- works with convolutional sentence reranking. SIGDial. Wen, T. H., Gasic, M., Mrksic, N., Su, P. H., Vandyke, D., and Young, S. (2015b). Semantically conditioned lstm- based natural language generation for spoken dialogue systems. EMNLP. Wen, T.-H., Ga\u02c7si\u00b4c, M., Mrk\u02c7si\u00b4c, N., Rojas-Barahona, L. M., Su, P.-H., Vandyke, D., and Young, S.",
            "EMNLP. Wen, T.-H., Ga\u02c7si\u00b4c, M., Mrk\u02c7si\u00b4c, N., Rojas-Barahona, L. M., Su, P.-H., Vandyke, D., and Young, S. (2016). Multi- domain neural network language generation for spoken dialogue systems. In NAACL, pages 120\u2013129. Xing, C., Wu, W., Wu, Y., Liu, J., Huang, Y., Zhou, M., and Ma, W. Y. (2016). Topic augmented neural response generation with a joint attention mechanism. Young, S., Gasic, M., Thomson, B., and Williams, J. D. (2013). Pomdp-based statistical spoken dialog systems: A review. Proceedings of the IEEE, pages 1160\u20131179."
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-1709.10217.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 5207.000030517578,
    "avg_doclen_est": 167.96774291992188
}
