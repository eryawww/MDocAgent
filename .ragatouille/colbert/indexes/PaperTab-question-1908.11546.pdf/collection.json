[
  "Modeling Multi-Action Policy for Task-Oriented Dialogues Lei Shu, Hu Xu, Bing Liu University of Illinois at Chicago {lshu3, hxu48, liub}@uic.edu Piero Molino Uber AI piero@uber.com Abstract Dialogue management (DM) plays a key role in the quality of the interaction with the user in a task-oriented dialogue sys- tem. In most existing approaches, the agent predicts only one DM policy ac- tion per turn. This signi\ufb01cantly limits the expressive power of the conversational agent and introduces unwanted turns of in- teractions that may challenge users\u2019 pa- tience. Longer conversations also lead to more errors and the system needs to be more robust to handle them. In this pa- per, we compare the performance of sev- eral models on the task of predicting mul- tiple acts for each turn. A novel pol- icy model is proposed based on a recur- rent cell called gated Continue-Act-Slots (gCAS) that overcomes the limitations of the existing models.",
  "A novel pol- icy model is proposed based on a recur- rent cell called gated Continue-Act-Slots (gCAS) that overcomes the limitations of the existing models. Experimental results show that gCAS1 outperforms other ap- proaches.2 1 Introduction In a task-oriented dialogue system, the dialogue manager policy module predicts actions usually in terms of dialogue acts and domain speci\ufb01c slots. It is a crucial component that in\ufb02uences the ef- \ufb01ciency (e.g., the conciseness and smoothness) of the communication between the user and the agent. Both supervised learning (SL) (Stent, 2002; Williams et al., 2017a; Williams and Zweig, 2016; Henderson et al., 2005, 2008) and reinforcement learning (RL) approaches (Walker, 2000; Young et al., 2007; Gasic and Young, 2014; Williams et al., 2017b; Su et al., 2017) have been adopted 1The code is available at https://leishu02.",
  "github.io/ 2To appear in EMNLP 2019 user msg Hi! I\u2019m looking for good thriller. Are there any playing right now? agent msg Yes, there are! The Witch, The Other Side of the Door, and The Boy are all thrillers. Would you like to \ufb01nd tickets for a showing for any of them? agent acts inform(moviename=The Witch, The Other Side of the Door, The Boy; genre=thriller) multiple choice(moviename) Table 1: Dialogue example. to learn policies. SL learns a policy to predict acts given the dialogue state. Recent work (Wen et al., 2017; Liu and Lane, 2018) also used SL as pre-training for RL to mitigate the sam- ple inef\ufb01ciency of RL approaches and to reduce the number of interactions. Sequence2Sequence (Seq2Seq) (Sutskever et al., 2014) approaches have also been adopted in user simulators to pro- duce user acts (Gur et al., 2018).",
  "Sequence2Sequence (Seq2Seq) (Sutskever et al., 2014) approaches have also been adopted in user simulators to pro- duce user acts (Gur et al., 2018). These ap- proaches typically assume that the agent can only produce one act per turn through classi\ufb01cation. Generating only one act per turn signi\ufb01cantly lim- its what an agent can do in a turn and leads to lengthy dialogues, making tracking of state and context throughout the dialogue harder. An exam- ple in Table 1 shows how the agent can produce both an inform and a multiple choice act, reducing the need for additional turns. The use of multiple actions has previously been used in interaction managers that keep track of the \ufb02oor (who is speaking right now) (Raux and Esk\u00b4enazi, 2007; Khouzaimi et al., 2015; Hastie et al., 2013, among others), but the option of gen- erating multiple acts simultaneously at each turn for dialogue policy has been largely ignored, and only explored in simulated scenarios without real data (Chandramohan and Pietquin, 2010).",
  "This task can be cast as a multi-label classi\ufb01ca- tion problem (if the sequential dependency among the acts is ignored) or as a sequence generation one as shown in Table 2. In this paper, we introduce a novel policy model to output multiple actions per turn (called multi- act), generating a sequence of tuples and expand- arXiv:1908.11546v1  [cs.CL]  30 Aug 2019",
  "RNN RNN RNN RNN Encoder Decoder <go>  C <go>  A <go>  S  <continue> inform {moviename, genre} <continue> multiple_choice {moviename} <stop> <pad> {} Dialogue State Figure 1: CAS decoder: at each step, a tuple of (continue, act, slots) is produced. The KB vector k regarding the queried result from knowledge base is not shown for brevity. ing agents\u2019 expressive power. Each tuple is de- \ufb01ned as (continue, act, slots), where continue in- dicates whether to continue or stop producing new acts, act is an act type (e.g., inform or request), and slots is a set of slots (names) associated with the current act type. Correspondingly, a novel decoder (Figure 1) is proposed to produce such sequences. Each tuple is generated by a cell called gated Continue Act Slots (gCAS, as in Figure 2), which is composed of three sequentially connected gated units handling the three components of the tuple. This decoder can generate multi-acts in a double recurrent manner (Tay et al., 2018).",
  "Each tuple is generated by a cell called gated Continue Act Slots (gCAS, as in Figure 2), which is composed of three sequentially connected gated units handling the three components of the tuple. This decoder can generate multi-acts in a double recurrent manner (Tay et al., 2018). We compare this model with baseline classi\ufb01ers and sequence generation models and show that it consistently outperforms them. 2 Methodology The proposed policy network adopts an encoder- decoder architecture (Figure 1). The input to the encoder is the current-turn dialogue state, which follows Li et al. (2018)\u2019s de\ufb01nition. It contains policy actions from the previous turn, user dia- logue acts from the current turn, user requested slots, the user informed slots, the agent requested slots and agent proposed slots. We treat the dia- logue state as a sequence and adopt a GRU (Cho et al., 2014) to encode it. The encoded dialogue state is a sequence of vectors E = (e0, . . . , el) and the last hidden state is hE.",
  "We treat the dia- logue state as a sequence and adopt a GRU (Cho et al., 2014) to encode it. The encoded dialogue state is a sequence of vectors E = (e0, . . . , el) and the last hidden state is hE. The CAS de- coder recurrently generates tuples at each step. It takes hE as initial hidden state h0. At each de- coding step, the input contains the previous (con- tinue, act, slots) tuple (ct\u22121, at\u22121, st\u22121). An ad- ditional vector k containing the number of results from the knowledge base (KB) query and the cur- rent turn number is given as input.",
  "An ad- ditional vector k containing the number of results from the knowledge base (KB) query and the cur- rent turn number is given as input. The output of the decoder at each step is a tuple (c, a, s), where c \u2208{\u27e8continue\u27e9, \u27e8stop\u27e9, \u27e8pad\u27e9}, a \u2208A (one act ct-1 at-1 st-1 gate ht-1 ct at-1 st-1 gate at act unit  st-1 gate st slots unit  ht ct-1 at-1 st-1 continue\u00a0  unit Figure 2: The gated CAS recurrent cell contains three units: continue unit, act unit and slots unit. The three units use a gating mechanism and are sequentially connected. The KB vector k is not shown for brevity. from the act set), and s \u2282S (a subset from the slot set). 2.1 gCAS Cell As shown in Figure 2, the gated CAS cell contains three sequentially connected units for outputting continue, act, and slots respectively.",
  "from the act set), and s \u2282S (a subset from the slot set). 2.1 gCAS Cell As shown in Figure 2, the gated CAS cell contains three sequentially connected units for outputting continue, act, and slots respectively. The Continue unit maps the previous tuple (ct\u22121, at\u22121, st\u22121) and the KB vector k into xc t. The hidden state from the previous step ht\u22121 and xc t are inputs to a GRUc unit that produces output gc t and hidden state hc t. Finally, gc t is used to pre- dict ct through a linear projection and a softmax. xc t = W c x[ct\u22121, at\u22121, st\u22121, k] + bc x, gc t, hc t = GRUc(xc t, ht\u22121), P(ct) = softmax(W c g gc t + bc g), Lc = \u2212 X t log P(ct). (1) The Act unit maps the tuple (ct, at\u22121, st\u22121) and the KB vector k into xa t .",
  "(1) The Act unit maps the tuple (ct, at\u22121, st\u22121) and the KB vector k into xa t . The hidden state from the continue cell hc t and xa t are inputs to a GRUa unit that produces output ga t and hidden state ha t . Finally, ga t is used to predict at through a linear projection and a softmax. xa t = W a x [ct, at\u22121, st\u22121, k] + ba x, ga t , ha t = GRUa(xa t , hc t), P(at) = softmax(W a g ga t + ba g), La = \u2212 X t log P(at). (2) The Slots unit maps the tuple (ct, at, st\u22121) and the KB vector k into xs t. The hidden state from the act cell ha t and xs t are inputs to a GRUs unit that produces output gs t and hidden state hs t. Finally, ga t is used to predict st through a linear projection and",
  "annotation inform(moviename=The Witch, The Other Side of the Door, The Boy; genre=thriller) multiple choice(moviename) classi\ufb01cation inform+moviename, inform+genre, multiple choice+moviename sequence \u2018inform\u2019 \u2018(\u2019 \u2018moviename\u2019 \u2018=\u2019 \u2018;\u2019 \u2018genre\u2019 \u2018=\u2019 \u2018)\u2019 \u2018multiple choice\u2019 \u2018(\u2019 \u2018moviename\u2019 \u2018)\u2019 \u2018\u27e8eos\u27e9\u2019 cas sequence (\u27e8continue\u27e9, inform, {moviename, genre}) (\u27e8continue\u27e9, multiple choice, {moviename}) (\u27e8stop\u27e9, \u27e8pad\u27e9, {}) Table 2: Multiple dialogue act format in different architectures. domain total train valid test acts slots pairs movie 2888 1445 433 1010 11 29 90 taxi 3093 1548 463 1082 11 23 63 restaurant 4101 2051 615 1435 11 31 91 Table 3: Dataset: train, validation and test split, and the count of distinct acts, slots and act-slot pairs.",
  "domain & speaker 1 act 2 acts 3 acts 4 acts movie user 9130 1275 106 11 movie agent 5078 4982 427 33 taxi user 10544 762 50 8 taxi agent 7855 3301 200 8 restaurant user 12726 1672 100 3 restaurant agent 10333 3755 403 10 Table 4: Dialogue act counts by turn. a sigmoid. Let zi t be the i-th slot\u2019s ground truth. xs t = W s x[ct, at, st\u22121, k] + bs x, gs t , hs t = GRUs(xs t, ha t ), st = sigmoid(W s g gs t + bs g), Ls = \u2212 X t |S| X i=0 zi t log si t + (1 \u2212zi t) log \u00001 \u2212si t \u0001 . (3) The overall loss is the sum of the losses of the three units: L = Lc + La + Ls 3 Experiments The experiment dataset comes from Microsoft Re- search (MSR) 3.",
  "(3) The overall loss is the sum of the losses of the three units: L = Lc + La + Ls 3 Experiments The experiment dataset comes from Microsoft Re- search (MSR) 3. It contains three domains: movie, taxi, and restaurant. The total count of dialogues per domain and train/valid/test split is reported in Table 3. At every turn both user and agent acts are annotated, we use only the agent side as tar- gets in our experiment. The acts are ordered in the dataset (each output sentence aligns with one act). The size of the sets of acts, slots, and act-slot pairs are also listed in Table 3. Table 4 shows the count of turns with multiple act annotations, which amounts to 23% of the dataset. We use MSR\u2019s di- alogue management code and knowledge base to obtain the state at each turn and use it as input to every model.",
  "Table 4 shows the count of turns with multiple act annotations, which amounts to 23% of the dataset. We use MSR\u2019s di- alogue management code and knowledge base to obtain the state at each turn and use it as input to every model. 3https://github.com/xiul-msr/e2e_ dialog_challenge Entity F1 Success F1 movie taxi restaurant movie taxi restaurant Classi\ufb01cation 34.02 49.71 28.23 70.41 84.45 39.97 Seq2Seq 39.95 63.12 60.21 77.82 75.09 55.70 Copy Seq2Seq 28.04 62.95 59.14 77.59 74.58 58.74 CAS 48.02 59.16 54.70 76.81 78.89 65.18 gCAS 50.86 64.00 60.35 77.95 81.17 71.52 Table 5: Entity F1 and Success F1 at dialogue level. 3.1 Evaluation Metrics We evaluate the performance at the act, frame and task completion level.",
  "3.1 Evaluation Metrics We evaluate the performance at the act, frame and task completion level. For a frame to be correct, both the act and all the slots should match the ground truth. We report precision, recall, F1 score of turn-level acts and frames. For task comple- tion evaluation, Entity F1 score and Success F1 score (Lei et al., 2018) are reported. The Entity F1 score, differently from the entity match rate in state tracking, compares the slots requested by the agent with the slots the user informed about and that were used to perform the KB query. We use it to measure agent performance in requesting infor- mation. The Success F1 score compares the slots provided by the agent with the slots requested by the user. We use it to measure the agent perfor- mance in providing information. Critical slots and Non-critical slots: By \u2018non- critical\u2019, we mean slots that the user informs the system about by providing their values and thus it is not critical for the system to provide them in the output. Table 1 shows an example, with the genre slot provided by the user and the system repeat- ing it in its answer.",
  "Table 1 shows an example, with the genre slot provided by the user and the system repeat- ing it in its answer. Critical slots refers to slots that the system must provide like moviename in the Table 1 example. Although non-critical slots do not impact task completion directly, they may in\ufb02uence the output quality by enriching the dia- logue state and helping users understand the sys- tem\u2019s utterance correctly. Furthermore, given the same dialog state, utterances offering non-critical slots or not offering them can both be present in the dataset, as they are optional. This makes the prediction of those slots more challenging for the system. To provide a more detailed analysis, we report the precision, recall, F1 score of turn-level",
  "Act Frame movie taxi restaurant movie taxi restaurant method P R F1 P R F1 P R F1 P R F1 P R F1 P R F1 classi\ufb01cation 84.19 50.24 62.93 92.20 55.48 69.27 79.71 33.94 47.60 63.91 18.39 28.56 65.87 44.31 52.98 49.63 12.32 19.74 Seq2Seq 73.44 73.62 73.53 77.52 69.29 73.17 65.66 66.01 65.83 42.88 24.81 31.43 57.12 50.32 53.51 39.97 25.40 31.06 Copy Seq2Seq 67.56 73.61 70.46 73.99 69.21 71.52 64.93 65.69 65.31 41.90 23.12 29.80 51.66 50.23 50.93 36.96 27.",
  "56 73.61 70.46 73.99 69.21 71.52 64.93 65.69 65.31 41.90 23.12 29.80 51.66 50.23 50.93 36.96 27.22 31.35 CAS 70.46 76.08 73.16 79.85 72.54 76.02 65.40 72.43 68.73 43.12 31.60 36.47 51.66 54.29 52.94 33.72 25.45 29.01 gCAS 73.08 75.78 74.41 79.47 75.39 77.37 68.30 74.39 71.22 42.24 35.50 38.58 53.77 56.24 54.98 36.86 32.41 34.49 Table 6: Precision (P), Recall (R) and F1score (F1) of turn-level acts and frames.",
  "24 35.50 38.58 53.77 56.24 54.98 36.86 32.41 34.49 Table 6: Precision (P), Recall (R) and F1score (F1) of turn-level acts and frames. example 1 example 2 groundtruth request(date; starttime) inform(restaurantname=; starttime =) multiple choice(restaurantname) classi\ufb01cation request+date [] Seq2Seq \u2018request\u2019 \u2018(\u2019 \u2018date\u2019 \u2018;\u2019 \u2018starttime\u2019 \u2018)\u2019 \u2018inform\u2019 \u2018(\u2019 \u2018restaurantname\u2019 \u2018=\u2019 \u2018)\u2019 \u2018multiple choice\u2019 \u2018=\u2019 \u2018restaurantname\u2019 \u2018)\u2019 Copy Seq2Seq \u2018request\u2019 \u2018(\u2019 \u2018date\u2019 \u2018=\u2019 \u2018)\u2019 \u2018inform\u2019 \u2018(\u2019 \u2018restaurantname\u2019 \u2018=\u2019 \u2018;\u2019 \u2018;\u2019, \u2018;\u2019, \u2018=\u2019, \u2018;\u2019 \u2018starttime\u2019 \u2018=\u2019 \u2018)\u2019 CAS request {} inform {restaurantname} gCAS request {date; starttime} inform {restaurantname} multiple choice{restaurantname} Table 7: Examples of predicted dialogue acts in the restaurant domain.",
  "for all slots, critical slots and non-critical slots of the inform act. 3.2 Baseline We compare \ufb01ve methods on the multi-act task. Classi\ufb01cation replicates the MSR challenge (Li et al., 2018) policy network architecture: two fully connected layers. We replace the last activation from softmax to sigmoid in order to predict prob- abilities for each act-slot pair. It is equivalent to binary classi\ufb01cation for each act-slot pair and the loss is the sum of the binary cross-entropy of all of them. Seq2Seq (Sutskever et al., 2014) encodes the dialogue state as a sequence, and decodes agent acts as a sequence with attention (Bahdanau et al., 2015). Copy Seq2Seq (Gu et al., 2016) adds a copy mechanism to Seq2Seq, which allows copying words from the encoder input. CAS adopts a single GRU (Cho et al., 2014) for decoding and uses three different fully connected layers for mapping the output of the GRU to con- tinue, act and slots.",
  "CAS adopts a single GRU (Cho et al., 2014) for decoding and uses three different fully connected layers for mapping the output of the GRU to con- tinue, act and slots. For each step in the sequence of CAS tuples, given the output of the GRU, con- tinue, act and slot predictions are obtained by sep- arate heads, each with one fully connected layer. The hidden state of the GRU and the predictions at the previous step are passed to the cell at the next step connecting them sequentially. gCAS uses our proposed recurrent cell which contains separate continue, act and slots unit that are sequentially connected. The classi\ufb01cation architecture has two fully connected layers of size 128, and the remaining models have a hidden size of 64 and a teacher- forcing rate of 0.5. Seq2Seq and Copy Seq2Seq use a beam search with beam size 10 during in- ference. CAS and gCAS do not adopt a beam search since their inference steps are much less than Seq2Seq methods. All models use Adam op- timizer (Kingma and Ba, 2015) with a learning rate of 0.001.",
  "CAS and gCAS do not adopt a beam search since their inference steps are much less than Seq2Seq methods. All models use Adam op- timizer (Kingma and Ba, 2015) with a learning rate of 0.001. 3.3 Result and Error Analysis As shown in Table 5, gCAS outperforms all other methods on Entity F1 in all three domains. Com- pared to Seq2Seq, the performance advantage of gCAS in the taxi and restaurant domains is small, while it is more evident in the movie domain. The reason is that in the movie domain the propor- tion of turns with multiple acts is higher (52%), while in the other two domains it is lower (30%). gCAS also outperforms all other models in terms of Success F1 in the movie and restaurant domain but is outperformed by the classi\ufb01cation model in the taxi domain. The reason is that in the taxi domain, the agent usually informs the user at the last turn, while in all previous turns the agent usu- ally requests information from the user. It is easy for the classi\ufb01cation model to over\ufb01t this pattern.",
  "The reason is that in the taxi domain, the agent usually informs the user at the last turn, while in all previous turns the agent usu- ally requests information from the user. It is easy for the classi\ufb01cation model to over\ufb01t this pattern. The advantage of gCAS in the restaurant domain is much more evident: the agent\u2019s inform act usu- ally has multiple slots (see example 2 in Table 7) and this makes classi\ufb01cation and sequence gener- ation harder, but gCAS multi-label slots decoder handles it easily. Table 6 shows the turn-level acts and frame pre- diction performance. CAS and gCAS outperform all other models in acts prediction in terms of F1 score. The main reason is that CAS and gCAS out- put a tuple at each recurrent step, which makes for",
  "All Slots Non-critical slots movie taxi restaurant movie taxi restaurant method P R F1 P R F1 P R F1 P R F1 P R F1 P R F1 classi\ufb01cation 67.90 21.48 32.64 73.52 72.66 73.08 45.16 12.71 19.84 62.98 13.39 22.08 43.91 60.03 50.72 33.61 11.15 16.75 Seq2Seq 53.25 29.54 38.00 64.09 74.32 68.83 42.36 17.73 25.00 47.90 13.95 21.61 64.15 48.45 55.20 35.28 12.95 18.94 Copy Seq2Seq 52.78 28.43 36.95 56.92 74.06 64.37 38.15 22.38 28.21 40.45 12.48 19.07 45.95 55.46 50.26 34.",
  "78 28.43 36.95 56.92 74.06 64.37 38.15 22.38 28.21 40.45 12.48 19.07 45.95 55.46 50.26 34.90 19.11 24.70 CAS 63.61 33.16 43.59 61.90 80.39 69.94 51.12 22.57 31.31 56.21 26.96 36.44 43.03 68.03 52.72 37.31 15.87 22.27 gCAS 54.75 38.70 45.35 62.31 79.76 69.96 44.20 29.65 35.49 48.23 36.68 41.67 44.35 62.15 51.77 31.26 29.60 30.41 Table 8: P, R and F1 of turn-level inform all slots and non-critical slots.",
  "65 35.49 48.23 36.68 41.67 44.35 62.15 51.77 31.26 29.60 30.41 Table 8: P, R and F1 of turn-level inform all slots and non-critical slots. Critical Slots movie taxi restaurant method P R F1 P R F1 P R F1 Classi\ufb01cation 70.29 29.13 41.19 85.18 75.90 80.27 55.66 13.76 22.07 Seq2Seq 55.08 44.26 49.08 64.08 80.97 71.54 46.24 20.97 28.86 Copy Seq2Seq 57.54 43.49 49.54 59.49 78.83 67.81 40.11 24.59 30.49 CAS 69.59 39.02 50.00 68.15 83.57 75.08 59.93 27.10 37.32 gCAS 61.89 40.62 49.04 67.48 84.28 74.95 61.35 29.69 40.01 Table 9: P, R and F1 of turn-level inform critical slots.",
  "shorter sequences that are easier to generate com- pared to the long sequences of Seq2Seq (example 2 in Table 7). The classi\ufb01cation method has a good precision score, but a lower recall score, suggest- ing it has problems making granular decisions (ex- ample 2 in Table 7). At the frame level, gCAS still outperforms all other methods. The performance difference between CAS and gCAS on frames be- comes much more evident, suggesting that gCAS is more capable of predicting slots that are consis- tent with the act. This \ufb01nding is also consistent with their Entity F1 and Success F1 performance. However, gCAS\u2019s act-slot pair performance is far from perfect. The most common failure case is on non-critical slots (like \u2018genre\u2019 in the example in Table 2): gCAS does not predict them, while it predicts the critical ones (like \u2018moviename\u2019 in the example in Table 2). Table 7 shows predictions of all methods from two emblematic examples. Example 1 is a fre- quent single-act multi-slots agent act.",
  "Table 7 shows predictions of all methods from two emblematic examples. Example 1 is a fre- quent single-act multi-slots agent act. Example 2 is a complex multi-act example. The baseline classi\ufb01cation method can predict frequent pairs in the dataset, but cannot predict any act in the complex example. The generated sequences of Copy Seq2Seq and Seq2Seq show that both mod- els struggle in following the syntax. CAS cannot predict slots correctly even if the act is common in the dataset. gCAS returns a correct prediction for Example 1, but for Example 2 gCAS cannot predict \u2018starttime\u2019, which is a non-critical slot. Tables 8 and 9 show the results of all slots, criti- cal slots and non-critical slots under the inform act. gCAS performs better than the other methods on all slots in the movie and restaurant domains. The reason why classi\ufb01cation performs the best here in the taxi domain is the same as the Success F1. In the taxi domain, the agent usually informs the user at the last turn.",
  "gCAS performs better than the other methods on all slots in the movie and restaurant domains. The reason why classi\ufb01cation performs the best here in the taxi domain is the same as the Success F1. In the taxi domain, the agent usually informs the user at the last turn. The non-critical slots are also re- peated frequently in the taxi domain, which makes their prediction easier. gCAS\u2019s performance is close to other methods on critical-slots. The rea- son is that the inform act is mostly the \ufb01rst act in multi-act and critical slots are usually frequent in the data. All methods can predict them well. In the movie and restaurant domains, the inform act usually appears during the dialogue and there are many optional non-critical slots that can ap- pear (see Table 3, movie and restaurant domains have more slots and pairs than the taxi domain). gCAS can better predict the non-critical slots than other methods. However, the overall performance on non-critical slots is much worse than critical slots since their appearances are optional and in- consistent in the data.",
  "gCAS can better predict the non-critical slots than other methods. However, the overall performance on non-critical slots is much worse than critical slots since their appearances are optional and in- consistent in the data. 4 Conclusion and Future Work In this paper, we introduced a multi-act dialogue policy model motivated by the need for a richer interaction between users and conversation agents. We studied classi\ufb01cation and sequence generation methods for this task, and proposed a novel recur- rent cell, gated CAS, which allows the decoder to output a tuple at each step. Experimental results showed that gCAS is the best performing model for multi-act prediction. The CAS decoder and the gCAS cell can also be used in a user simulator and gCAS can be applied in the encoder. A few directions for improvement have also been identi- \ufb01ed: 1) improving the performance on non-critical slots, 2) tuning the decoder with RL, 3) text gener- ation from gCAS. We leave them as future work. Acknowledgments We would like to express our special thanks to Alexandros Papangelis and Gokhan Tur for their support and contribution.",
  "We leave them as future work. Acknowledgments We would like to express our special thanks to Alexandros Papangelis and Gokhan Tur for their support and contribution. We also would like to thank Xiujun Li for his help on dataset preparation",
  "and Jane Hung for her valuable comments. Bing Liu is partially supported by the NSF grant IIS- 1910424 and a research gift from Northrop Grum- man. References Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2015. Neural machine translation by jointly learning to align and translate. In International Con- ference on Learning Representations, San Diego, California, USA. Senthilkumar Chandramohan and Olivier Pietquin. 2010. User and noise adaptive dialogue manage- ment using hybrid system actions. In Spoken Dia- logue Systems for Ambient Environments, Springer, pages 13\u201324. Kyunghyun Cho, Bart van Merrienboer, C\u00b8 aglar G\u00a8ulc\u00b8ehre, Dzmitry Bahdanau, Fethi Bougares, Hol- ger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In EMNLP. ACL, pages 1724\u20131734. Milica Gasic and Steve J. Young.",
  "2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In EMNLP. ACL, pages 1724\u20131734. Milica Gasic and Steve J. Young. 2014. Gaussian pro- cesses for pomdp-based dialogue manager optimiza- tion. IEEE/ACM Transactions on Audio, Speech, and Language Processing 22:28\u201340. Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O. K. Li. 2016. Incorporating copying mechanism in sequence-to-sequence learning. In ACL (1). The As- sociation for Computer Linguistics. Izzeddin Gur, Dilek Z. Hakkani-Tur, Gokhan Tur, and Pararth Shah. 2018. User modeling for task oriented dialogues. 2018 IEEE Spoken Language Technology Workshop (SLT) pages 900\u2013906.",
  "Izzeddin Gur, Dilek Z. Hakkani-Tur, Gokhan Tur, and Pararth Shah. 2018. User modeling for task oriented dialogues. 2018 IEEE Spoken Language Technology Workshop (SLT) pages 900\u2013906. Helen F. Hastie, Marie-Aude Aufaure, Panos Alex- opoulos, Heriberto Cuay\u00b4ahuitl, Nina Dethlefs, Milica Gasic, James Henderson, Oliver Lemon, Xingkun Liu, Peter Mika, Nesrine Ben Mustapha, Verena Rieser, Blaise Thomson, Pirros Tsiakoulis, and Yves Vanrompay. 2013. Demonstration of the parlance system: a data-driven incremental, spoken dialogue system for interactive search. In SIGDIAL Conference. James Henderson, Oliver Lemon, and Kallirroi Georgila. 2005. Hybrid reinforcement/supervised learning for dialogue policies from communicator data. In IJCAI workshop on knowledge and rea- soning in practical dialogue systems. Citeseer, pages 68\u201375.",
  "2005. Hybrid reinforcement/supervised learning for dialogue policies from communicator data. In IJCAI workshop on knowledge and rea- soning in practical dialogue systems. Citeseer, pages 68\u201375. James Henderson, Oliver Lemon, and Kallirroi Georgila. 2008. Hybrid reinforcement/supervised learning of dialogue policies from \ufb01xed data sets. Computational Linguistics 34(4):487\u2013511. Hatim Khouzaimi, Romain Laroche, and Fabrice Lef`evre. 2015. Turn-taking phenomena in incre- mental dialogue systems. In EMNLP. Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In Interna- tional Conference on Learning Representations, San Diego, California, USA. Wenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun Ren, Xiangnan He, and Dawei Yin. 2018. Sequic- ity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures. In ACL.",
  "Wenqiang Lei, Xisen Jin, Min-Yen Kan, Zhaochun Ren, Xiangnan He, and Dawei Yin. 2018. Sequic- ity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures. In ACL. Xiujun Li, Sarah Panda, Jingjing Liu, and Jianfeng Gao. 2018. Microsoft dialogue challenge: Building end-to-end task-completion dialogue systems. vol- ume abs/1807.11125. Bing Liu and Ian Lane. 2018. End-to-end learning of task-oriented dialogs. In Proceedings of the NAACL-HLT. Antoine Raux and Maxine Esk\u00b4enazi. 2007. A multi- layer architecture for semi-synchronous event- driven dialogue management. 2007 IEEE Workshop on Automatic Speech Recognition and Understand- ing (ASRU) pages 514\u2013519. Amanda J Stent. 2002. A conversation acts model for generating spoken dialogue contributions. Com- puter Speech & Language 16(3-4):313\u2013352.",
  "2007 IEEE Workshop on Automatic Speech Recognition and Understand- ing (ASRU) pages 514\u2013519. Amanda J Stent. 2002. A conversation acts model for generating spoken dialogue contributions. Com- puter Speech & Language 16(3-4):313\u2013352. Pei-Hao Su, Pawel Budzianowski, Stefan Ultes, Mil- ica Gasic, and Steve J. Young. 2017. Sample- ef\ufb01cient actor-critic reinforcement learning with su- pervised data for dialogue management. In Kris- tiina Jokinen, Manfred Stede, David DeVault, and Annie Louis, editors, Proceedings of the 18th An- nual SIGdial Meeting on Discourse and Dialogue, Saarbr\u00a8ucken, Germany, August 15-17, 2017. Asso- ciation for Computational Linguistics, pages 147\u2013 157. Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural net- works. In NIPS. pages 3104\u20133112.",
  "Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural net- works. In NIPS. pages 3104\u20133112. Yi Tay, Anh Tuan Luu, and Siu Cheung Hui. 2018. Recurrently controlled recurrent networks. In Ad- vances in Neural Information Processing Systems. pages 4736\u20134748. Marilyn A. Walker. 2000. An application of reinforce- ment learning to dialogue strategy selection in a spo- ken dialogue system for email. J. Artif. Intell. Res. 12:387\u2013416. Tsung-Hsien Wen, Yishu Miao, Phil Blunsom, and Steve J. Young. 2017. Latent intention dialogue models. In ICML. PMLR, volume 70 of Proceed- ings of Machine Learning Research, pages 3732\u2013 3741.",
  "Jason D. Williams, Kavosh Asadi, and Geoffrey Zweig. 2017a. Hybrid code networks: practical and ef\ufb01- cient end-to-end dialog control with supervised and reinforcement learning. In ACL (1). Association for Computational Linguistics, pages 665\u2013677. Jason D. Williams, Kavosh Asadi, and Geoffrey Zweig. 2017b. Hybrid code networks: practical and ef\ufb01- cient end-to-end dialog control with supervised and reinforcement learning. In ACL. Jason D Williams and Geoffrey Zweig. 2016. End- to-end lstm-based dialog control optimized with su- pervised and reinforcement learning. arXiv preprint arXiv:1606.01269 . Steve J. Young, Jost Schatzmann, Karl Weilhammer, and Hui Ye. 2007. The hidden information state ap- proach to dialog management. 2007 IEEE Interna- tional Conference on Acoustics, Speech and Signal Processing - ICASSP \u201907 4:IV\u2013149\u2013IV\u2013152."
]