{
  "config":{
    "query_token_id":"[unused0]",
    "doc_token_id":"[unused1]",
    "query_token":"[Q]",
    "doc_token":"[D]",
    "ncells":null,
    "centroid_score_threshold":null,
    "ndocs":null,
    "load_index_with_mmap":false,
    "index_path":null,
    "index_bsize":32,
    "nbits":4,
    "kmeans_niters":20,
    "resume":false,
    "pool_factor":1,
    "clustering_mode":"hierarchical",
    "protected_tokens":0,
    "similarity":"cosine",
    "bsize":64,
    "accumsteps":1,
    "lr":0.00001,
    "maxsteps":400000,
    "save_every":null,
    "warmup":20000,
    "warmup_bert":null,
    "relu":false,
    "nway":64,
    "use_ib_negatives":true,
    "reranker":false,
    "distillation_alpha":1.0,
    "ignore_scores":false,
    "model_name":null,
    "query_maxlen":32,
    "attend_to_mask_tokens":false,
    "interaction":"colbert",
    "dim":128,
    "doc_maxlen":256,
    "mask_punctuation":true,
    "checkpoint":"colbert-ir/colbertv2.0",
    "triples":"/future/u/okhattab/root/unit/experiments/2021.10/downstream.distillation.round2.2_score/round2.nway6.cosine.ib/examples.64.json",
    "collection":[
      "Harnessing Cognitive Features for Sarcasm Detection Abhijit Mishra\u2020, Diptesh Kanojia\u2020,\u2663, Seema Nagar \u22c6, Kuntal Dey\u22c6, Pushpak Bhattacharyya\u2020 \u2020Indian Institute of Technology Bombay, India \u2663IITB-Monash Research Academy, India \u22c6IBM Research, India \u2020{abhijitmishra, diptesh, pb}@cse.iitb.ac.in \u22c6{senagar3, kuntadey}@in.ibm.com Abstract In this paper, we propose a novel mecha- nism for enriching the feature vector, for the task of sarcasm detection, with cogni- tive features extracted from eye-movement patterns of human readers. Sarcasm detec- tion has been a challenging research prob- lem, and its importance for NLP applica- tions such as review summarization, dia- log systems and sentiment analysis is well recognized. Sarcasm can often be traced to incongruity that becomes apparent as the full sentence unfolds. This presence of incongruity- implicit or explicit- affects the way readers eyes move through the text.",
      "Sarcasm can often be traced to incongruity that becomes apparent as the full sentence unfolds. This presence of incongruity- implicit or explicit- affects the way readers eyes move through the text. We observe the difference in the be- haviour of the eye, while reading sarcastic and non sarcastic sentences. Motivated by this observation, we augment traditional linguistic and stylistic features for sarcasm detection with the cognitive features ob- tained from readers eye movement data. We perform statistical classi\ufb01cation using the enhanced feature set so obtained. The augmented cognitive features improve sar- casm detection by 3.7% (in terms of F- score), over the performance of the best reported system. 1 Introduction Sarcasm is an intensive, indirect and complex con- struct that is often intended to express contempt or ridicule 1. Sarcasm, in speech, is multi-modal, involving tone, body-language and gestures along with linguistic artifacts used in speech. Sarcasm in text, on the other hand, is more restrictive when it comes to such non-linguistic modalities. This makes recognizing textual sarcasm more challeng- ing for both humans and machines.",
      "Sarcasm in text, on the other hand, is more restrictive when it comes to such non-linguistic modalities. This makes recognizing textual sarcasm more challeng- ing for both humans and machines. 1The Free Dictionary Sarcasm detection plays an indispensable role in applications like online review summarizers, di- alog systems, recommendation systems and senti- ment analyzers. This makes automatic detection of sarcasm an important problem. However, it has been quite dif\ufb01cult to solve such a problem with traditional NLP tools and techniques. This is apparent from the results reported by the survey from Joshi et al. (2016). The following discussion brings more insights into this. Consider a scenario where an online reviewer gives a negative opinion about a movie through sarcasm: \u201cThis is the kind of movie you see be- cause the theater has air conditioning\u201d. It is dif- \ufb01cult for an automatic sentiment analyzer to as- sign a rating to the movie and, in the absence of any other information, such a system may not be able to comprehend that prioritizing the air-conditioning facilities of the theater over the movie experience indicates a negative sentiment towards the movie.",
      "It is dif- \ufb01cult for an automatic sentiment analyzer to as- sign a rating to the movie and, in the absence of any other information, such a system may not be able to comprehend that prioritizing the air-conditioning facilities of the theater over the movie experience indicates a negative sentiment towards the movie. This gives an intuition to why, for sarcasm detection, it is necessary to go beyond textual analysis. We aim to address this problem by exploiting the psycholinguistic side of sarcasm detection, us- ing cognitive features extracted with the help of eye-tracking. A motivation to consider cogni- tive features comes from analyzing human eye- movement trajectories that supports the conjec- ture: Reading sarcastic texts induces distinctive eye movement patterns, compared to literal texts. The cognitive features, derived from human eye movement patterns observed during reading, in- clude two primary feature types: 1. Eye movement characteristic features of readers while reading given text, comprising gaze-\ufb01xaions (i.e,longer stay of gaze on a vi- sual object), forward and backward saccades (i.e., quick jumping of gaze between two po- sitions of rest).",
      "Eye movement characteristic features of readers while reading given text, comprising gaze-\ufb01xaions (i.e,longer stay of gaze on a vi- sual object), forward and backward saccades (i.e., quick jumping of gaze between two po- sitions of rest). arXiv:1701.05574v1  [cs.CL]  19 Jan 2017",
      "2. Features constructed using the statistical and deeper structural information contained in graph, created by treating words as vertices and saccades between a pair of words as edges. The cognitive features, along with textual fea- tures used in best available sarcasm detectors, are used to train binary classi\ufb01ers against given sar- casm labels. Our experiments show signi\ufb01cant im- provement in classi\ufb01cation accuracy over the state of the art, by performing such augmentation. Feasibility of Our Approach Since our method requires gaze data from human readers to be available, the methods practicability becomes questionable. We present our views on this below. Availability of Mobile Eye-trackers Availability of inexpensive embedded eye-trackers on hand-held devices has come close to reality now. This opens avenues to get eye-tracking data from inexpensive mobile devices from a huge population of online readers non-intrusively, and derive cognitive features to be used in predic- tive frameworks like ours. For instance, Co- gisen: (http://www.sencogi.com) has a patent (ID: EP2833308-A1) on \u201ceye-tracking using inexpen- sive mobile web-cams\u201d.",
      "For instance, Co- gisen: (http://www.sencogi.com) has a patent (ID: EP2833308-A1) on \u201ceye-tracking using inexpen- sive mobile web-cams\u201d. Applicability Scenario We believe, mobile eye-tracking modules could be a part of mobile applications built for e-commerce, online learning, gaming etc. where automatic analysis of online reviews calls for better solutions to detect linguistic nuances like sarcasm. To give an example, let\u2019s say a book gets different reviews on Amazon. Our system could watch how read- ers read the review using mobile eye-trackers, and thereby, decide whether the text contains sarcasm or not. Such an application can horizontally scale across the web and will help in improving auto- matic classi\ufb01cation of online reviews. Since our approach seeks human mediation, one might be tempted to question the approach of re- lying upon eye-tracking, an indirect indicator, in- stead of directly obtaining man-made annotations.",
      "Since our approach seeks human mediation, one might be tempted to question the approach of re- lying upon eye-tracking, an indirect indicator, in- stead of directly obtaining man-made annotations. We believe, asking a large number of internet au- dience to annotate/give feedback on each and ev- ery sentence that they read online, following a set of annotation instructions, will be extremely intru- sive and may not be responded well. Our system, on the other hand, can be seamlessly integrated into existing applications and as the eye-tracking process runs in the background, users will not be interrupted in the middle of the reading. This, thus, offers a more natural setting where human mediation can be availed without intervention. Getting Users\u2019 Consent for Eye-tracking Eye-tracking technology has already been uti- lized by leading mobile technology developers (like Samsung) to facilitate richer user experiences through services like Smart-scroll (where a user\u2019s eye movement determines whether a page has to be scrolled or not) and Smart-lock (where user\u2019s gaze position decides whether to lock the screen or not).",
      "The growing interest of users in us- ing such services takes us to a promising situa- tion where getting users\u2019 consent to record eye- movement patterns will not be dif\ufb01cult, though it is yet not the current state of affairs. Disclaimer: In this work, we focus on detect- ing sarcasm in non-contextual and short-text set- tings prevalent in product reviews and social me- dia. Moreover, our method requires eye-tracking data to be available in the test scenario. 2 Related Work Sarcasm, in general, has been the focus of re- search for quite some time. In one of the pio- neering works Jorgensen et al. (1984) explained how sarcasm arises when a \ufb01gurative meaning is used opposite to the literal meaning of the utter- ance. In the word of Clark and Gerrig (1984), sar- casm processing involves canceling the indirectly negated message and replacing it with the impli- cated one. Giora (1995), on the other hand, de- \ufb01ne sarcasm as a mode of indirect negation that re- quires processing of both negated and implicated messages.",
      "Giora (1995), on the other hand, de- \ufb01ne sarcasm as a mode of indirect negation that re- quires processing of both negated and implicated messages. Ivanko and Pexman (2003) de\ufb01ne sar- casm as a six tuple entity consisting of a speaker, a listener, Context, Utterance, Literal Proposition and Intended Proposition and study the cognitive aspects of sarcasm processing. Computational linguists have previously ad- dressed this problem using rule based and sta- tistical techniques, that make use of : (a) Un- igrams and Pragmatic features (Carvalho et al., 2009; Gonz\u00b4alez-Ib\u00b4anez et al., 2011; Barbieri et al., 2014; Joshi et al., 2015) (b) Stylistic patterns (Davidov et al., 2010) and patterns related to situa- tional disparity (Riloff et al., 2013) and (c) Hastag",
      "interpretations (Liebrecht et al., 2013; Maynard and Greenwood, 2014). Most of the previously done work on sar- casm detection uses distant supervision based techniques (ex: leveraging hashtags) and stylis- tic/pragmatic features (emoticons, laughter ex- pressions such as \u201clol\u201d etc). But, detecting sarcasm in linguistically well-formed structures, in absence of explicit cues or information (like emoticons), proves to be hard using such linguis- tic/stylistic features alone. With the advent of sophisticated eye- trackers and electro/magneto-encephalographic (EEG/MEG) devices, it has been possible to delve deep into the cognitive underpinnings of sarcasm understanding. Filik (2014), using a series of eye-tracking and EEG experiments try to show that for unfamiliar ironies, the literal interpretation would be computed \ufb01rst. They also show that a mismatch with context would lead to a re-interpretation of the statement, as being ironic. Camblin et al. (2007) show that in multi-sentence passages, discourse congruence has robust effects on eye movements.",
      "They also show that a mismatch with context would lead to a re-interpretation of the statement, as being ironic. Camblin et al. (2007) show that in multi-sentence passages, discourse congruence has robust effects on eye movements. This also implies that disrupted processing occurs for dis- course incongruent words, even though they are perfectly congruous at the sentence level. In our previous work (Mishra et al., 2016), we augment cognitive features, derived from eye-movement patterns of readers, with textual features to detect whether a human reader has realized the presence of sarcasm in text or not. The recent advancements in the literature dis- cussed above, motivate us to explore gaze-based cognition for sarcasm detection. As far as we know, our work is the \ufb01rst of its kind. 3 Eye-tracking Database for Sarcasm Analysis Sarcasm often emanates from incongruity (Camp- bell and Katz, 2012), which enforces the brain to reanalyze it (Kutas and Hillyard, 1980). This, in turn, affects the way eyes move through the text.",
      "This, in turn, affects the way eyes move through the text. Hence, distinctive eye-movement patterns may be observed in the case of successful processing of sarcasm in text in contrast to literal texts. This hypothesis forms the crux of our method for sarcasm detection and we validate this using our previously released freely available sarcasm dataset2 (Mishra et al., 2016) enriched with gaze 2http://www.c\ufb01lt.iitb.ac.in/cognitive-nlp \u00b5 S \u03c3 S \u00b5 NS \u03c3 NS t p P1 319 145 196 97 14.1 5.84E-39 P2 415 192 253 130 14.0 1.71E-38 P3 322 173 214 160 9.5 3.74E-20 P4 328 170 191 96 13.9 1.89E-37 P5 291 151 183 76 11.9 2.75E-28 P6 230 118 136 84 13.2 6.",
      "74E-20 P4 328 170 191 96 13.9 1.89E-37 P5 291 151 183 76 11.9 2.75E-28 P6 230 118 136 84 13.2 6.79E-35 P7 488 268 252 141 15.3 3.96E-43 Table 1: T-test statistics for average \ufb01xation dura- tion time per word (in ms) for presence of sarcasm (represented by S) and its absence (NS) for partic- ipants P1-P7. information. 3.1 Document Description The database consists of 1,000 short texts, each having 10-40 words. Out of these, 350 are sar- castic and are collected as follows: (a) 103 sen- tences are from two popular sarcastic quote web- sites3, (b) 76 sarcastic short movie reviews are manually extracted from the Amazon Movie Cor- pus (Pang and Lee, 2004) by two linguists.",
      "(c) 171 tweets are downloaded using the hashtag #sar- casm from Twitter. The 650 non-sarcastic texts are either downloaded from Twitter or extracted from the Amazon Movie Review corpus. The sentences do not contain words/phrases that are highly topic or culture speci\ufb01c. The tweets were normalized to make them linguistically well formed to avoid dif\ufb01culty in interpreting social media lingo. Every sentence in our dataset carries positive or negative opinion about speci\ufb01c \u201caspects\u201d. For example, the sentence \u201cThe movie is extremely well cast\u201d has positive sentiment about the aspect \u201ccast\u201d. The annotators were seven graduate students with science and engineering background, and possess good English pro\ufb01ciency. They were given a set of instructions beforehand and are ad- vised to seek clari\ufb01cations before they proceed. The instructions mention the nature of the task, annotation input method, and necessity of head movement minimization during the experiment. 3.2 Task Description The task assigned to annotators was to read sen- tences one at a time and label them with with binary labels indicating the polarity (i.e., posi- tive/negative).",
      "3.2 Task Description The task assigned to annotators was to read sen- tences one at a time and label them with with binary labels indicating the polarity (i.e., posi- tive/negative). Note that, the participants were not 3http://www.sarcasmsociety.com, http://www.themarysue.com/funny-amazon-reviews",
      "instructed to annotate whether a sentence is sar- castic or not., to rule out the Priming Effect (i.e., if sarcasm is expected beforehand, processing incon- gruity becomes relatively easier (Gibbs, 1986)). The setup ensures its \u201cecological validity\u201d in two ways: (1) Readers are not given any clue that they have to treat sarcasm with special attention. This is done by setting the task to polarity annotation (instead of sarcasm detection). (2) Sarcastic sen- tences are mixed with non sarcastic text, which does not give prior knowledge about whether the forthcoming text will be sarcastic or not. The eye-tracking experiment is conducted by following the standard norms in eye-movement research (Holmqvist et al., 2011). At a time, one sentence is displayed to the reader along with the \u201caspect\u201d with respect to which the an- notation has to be provided.",
      "The eye-tracking experiment is conducted by following the standard norms in eye-movement research (Holmqvist et al., 2011). At a time, one sentence is displayed to the reader along with the \u201caspect\u201d with respect to which the an- notation has to be provided. While reading, an SR-Research Eyelink-1000 eye-tracker (monocu- lar remote mode, sampling rate 500Hz) records several eye-movement parameters like \ufb01xations (a long stay of gaze) and saccade (quick jumping of gaze between two positions of rest) and pupil size. The accuracy of polarity annotation varies be- tween 72%-91% for sarcastic texts and 75%-91% for non-sarcastic text, showing the inherent dif- \ufb01culty of sentiment annotation, when sarcasm is present in the text under consideration. An- notation errors may be attributed to: (a) lack of patience/attention while reading, (b) issues related to text comprehension, and (c) confu- sion/indecisiveness caused due to lack of context. For our analysis, we do not discard the incor- rect annotations present in the database.",
      "For our analysis, we do not discard the incor- rect annotations present in the database. Since our system eventually aims to involve online read- ers for sarcasm detection, it will be hard to segre- gate readers who misinterpret the text. We make a rational assumption that, for a particular text, most of the readers, from a fairly large popula- tion, will be able to identify sarcasm. Under this assumption, the eye-movement parameters, aver- aged across all readers in our setting, may not be signi\ufb01cantly distorted by a few readers who would have failed to identify sarcasm. This assumption is applicable for both regular and multi-instance based classi\ufb01ers explained in section 6. 4 Analysis of Eye-movement Data We observe distinct behavior during sarcasm read- ing, by analyzing the \u201c\ufb01xation duration on the text\u201d (also referred to as \u201cdwell time\u201d in the lit-     Word ID Time ( miliseconds) P1 P2 P3 S2: The lead actress is terrible and I cannot be convinced she is supposed  to be some forensic genius.",
      "S1: I'll always cherish the original misconception I had of you.. Figure 1: Scanpaths of three participants for two negatively polar sentences sentence S1 and S2. Sentence S1 is sarcastic but S2 is not. erature) and \u201cscanpaths\u201d of the readers. 4.1 Variation in the Average Fixation Duration per Word Since sarcasm in text can be expected to induce cognitive load, it is reasonable to believe that it would require more processing time (Ivanko and Pexman, 2003). Hence, \ufb01xation duration nor- malized over total word count should usually be higher for a sarcastic text than for a non-sarcastic one. We observe this for all participants in our dataset, with the average \ufb01xation duration per word for sarcastic texts being at least 1.5 times more than that of non-sarcastic texts. To test the statistical signi\ufb01cance, we conduct a two- tailed t-test (assuming unequal variance) to com- pare the average \ufb01xation duration per word for sar- castic and non-sarcastic texts.",
      "To test the statistical signi\ufb01cance, we conduct a two- tailed t-test (assuming unequal variance) to com- pare the average \ufb01xation duration per word for sar- castic and non-sarcastic texts. The hypothesized mean difference is set to 0 and the error tolerance limit (\u03b1) is set to 0.05. The t-test analysis, pre- sented in Table 1, shows that for all participants, a statistically signi\ufb01cant difference exists between the average \ufb01xation duration per word for sar- casm (higher average \ufb01xation duration) and non- sarcasm (lower average \ufb01xation duration). This af\ufb01rms that the presence of sarcasm affects the du- ration of \ufb01xation on words. It is important to note that longer \ufb01xations may also be caused by other linguistic subtleties (such as dif\ufb01cult words, ambiguity and syntacti- cally complex structures) causing delay in com- prehension, or occulomotor control problems forc- ing readers to spend time adjusting eye-muscles.",
      "So, an elevated average \ufb01xation duration per word may not suf\ufb01ciently indicate the presence of sar- casm. But we would also like to share that, for our",
      "I will always cherish the original mis- conception I had of you Figure 2: Saliency graph of participant P1 for the sentence I will always cherish the original miscon- ception I had of you. dataset, when we considered readability (Flesch readability ease-score (Flesch, 1948)), number of words in a sentence and average character per word along with the sarcasm label as the predic- tors of average \ufb01xation duration following a linear mixed effect model (Barr et al., 2013), sarcasm la- bel turned out to be the most signi\ufb01cant predictor with a maximum slope. This indicates that average \ufb01xation duration per word has a strong connection with the text being sarcastic, at least in our dataset. We now analyze scanpaths to gain more in- sights into the sarcasm comprehension process. 4.2 Analysis of Scanpaths Scanpaths are line-graphs that contain \ufb01xations as nodes and saccades as edges; the radii of the nodes represent the \ufb01xation duration. A scanpath corresponds to a participant\u2019s eye-movement pat- tern while reading a particular sentence.",
      "4.2 Analysis of Scanpaths Scanpaths are line-graphs that contain \ufb01xations as nodes and saccades as edges; the radii of the nodes represent the \ufb01xation duration. A scanpath corresponds to a participant\u2019s eye-movement pat- tern while reading a particular sentence. Figure 1 presents scanpaths of three participants for the sar- castic sentence S1 and the non-sarcastic sentence S2. The x-axis of the graph represents the se- quence of words a reader reads, and the y-axis rep- resents a temporal sequence in milliseconds. Consider a sarcastic text containing incongru- ous phrases A and B. Our qualitative scanpath- analysis reveals that scanpaths with respect to sar- casm processing have two typical characteristics. Often, a long regression - a saccade that goes to a previously visited segment - is observed when a reader starts reading B after skimming through A. In a few cases, the \ufb01xation duration on A and B are signi\ufb01cantly higher than the average \ufb01xation duration per word.",
      "In sentence S1, we see long and multiple regressions from the two incongru- ous phrases \u201cmisconception\u201d and \u201ccherish\u201d, and a few instances where phrases \u201calways cherish\u201d and \u201coriginal misconception\u201d are \ufb01xated longer than usual. Such eye-movement behaviors are not seen for S2. Though sarcasm induces distinctive scanpaths like the ones depicted in Figure 1 in the observed examples, presence of such patterns is not suf\ufb01- cient to guarantee sarcasm; such patterns may also possibly arise from literal texts. We believe that a combination of linguistic features, readability of text and features derived from scanpaths would help discriminative machine learning models learn sarcasm better. 5 Features for Sarcasm Detection We describe the features used for sarcasm detec- tion in Table 2. The features enlisted under lex- ical,implicit incongruity and explicit incongruity are borrowed from various literature (predomi- nantly from Joshi et al. (2015)). These features are essential to separate sarcasm from other forms semantic incongruity in text (for example ambi- guity arising from semantic ambiguity or from metaphors). Two additional textual features viz.",
      "(2015)). These features are essential to separate sarcasm from other forms semantic incongruity in text (for example ambi- guity arising from semantic ambiguity or from metaphors). Two additional textual features viz. readability and word count of the text are also taken under consideration. These features are used to reduce the effect of text hardness and text length on the eye-movement patterns. 5.1 Simple Gaze Based Features Readers\u2019 eye-movement behavior, characterized by \ufb01xations, forward saccades, skips and regres- sions, can be directly quanti\ufb01ed by simple statis- tical aggregation (i.e., either computing features for individual participants and then averaging or performing a multi-instance based learning as ex- plained in section 6). Since these eye-movement attributes relate to the cognitive process in reading (Rayner and Sereno, 1994), we consider these as features in our model. Some of these features have been reported by Mishra et al. (2016) for modeling sarcasm understandability of readers.",
      "Since these eye-movement attributes relate to the cognitive process in reading (Rayner and Sereno, 1994), we consider these as features in our model. Some of these features have been reported by Mishra et al. (2016) for modeling sarcasm understandability of readers. However, as far as we know, these features are being introduced in NLP tasks like textual sarcasm detection for the \ufb01rst time. The values of these features are believed to increase with the increase in the degree of sur- prisal caused by incongruity in text (except skip count, which will decrease). 5.2 Complex Gaze Based Features For these features, we rely on a graph structure, namely \u201csaliency graphs\u201d, derived from eye-gaze information and word sequences in the text. Constructing Saliency Graphs: For each reader and each sentence, we construct a \u201csaliency graph\u201d, representing the reader\u2019s atten-",
      "Subcategory Feature Name Type Intent Category: Textual Sarcasm Features, Source: Joshi et. al. Lexical Presence of Unigrams (UNI) Boolean Unigrams in the training corpus Punctuations (PUN) Real Count of punctuation marks Implicit In- congruity Implicit Incongruity (IMP) Boolean Incongruity of extracted implicit phrases (Rilof et.al, 2013) Explicit Incongruity (EXP) Integer Number of times a word follows a word of opposite po- larity Largest Pos/Neg Subsequence (LAR) Integer Length of the largest series of words with polarities un- changed Explicit Positive words (+VE) Integer Number of positive words Incongruity Negative words (-VE) Integer Number of negative words Lexical Polarity (LP) Integer Sentence polarity found by supervised logistic regres- sion Category: Cognitive Features. We introduce these features for sarcasm detection. Readability (RED) Real Flesch Readability Ease (Flesch, 1948) score of the sen- tence Textual Number of Words (LEN) Integer Number of words in the sentence Avg.",
      "We introduce these features for sarcasm detection. Readability (RED) Real Flesch Readability Ease (Flesch, 1948) score of the sen- tence Textual Number of Words (LEN) Integer Number of words in the sentence Avg. Fixation Duration (FDUR) Real Sum of \ufb01xation duration divided by word count Avg. Fixation Count (FC) Real Sum of \ufb01xation counts divided by word count Avg. Saccade Length (SL) Real Sum of saccade lengths (measured by number of words) divided by word count Simple Regression Count (REG) Real Total number of gaze regressions Gaze Skip count (SKIP) Real Number of words skipped divided by total word count Based Count of regressions from second half to \ufb01rst half of the sentence (RSF) Real Number of regressions from second half of the sentence to the \ufb01rst half of the sentence (given the sentence is divided into two equal half of words) Largest Regression Position (LREG) Real Ratio of the absolute position of the word from which a regression with the largest amplitude (number of pixels) is observed,",
      "to the total word count of sentence Edge density of the saliency gaze graph (ED) Real Ratio of the number of directed edges to vertices in the saliency gaze graph (SGG) Fixation Duration at Left/Source (F1H, F1S) Real Largest weighted degree (LWD) and second largest weighted degree (SWD) of the SGG considering the \ufb01x- ation duration of word i of edge Eij Complex Fixation Duration at Right/Target (F2H, F2S) Real LWD and SWD of the SGG considering the \ufb01xation du- ration of word j of edge Eij Gaze Forward Saccade Word Count of Source (PSH, PSS) Real LWD and SWD of the SGG considering the number of forward saccades between words i and j of an edge Eij Based Forward Saccade Word Count of Des- tination (PSDH, PSDS) Real LWD and SWD of the SGG considering the total dis- tance (word count) of forward saccades between words i and j of an edge Eij Regressive Saccade Word Count of Source (RSH,",
      "PSDS) Real LWD and SWD of the SGG considering the total dis- tance (word count) of forward saccades between words i and j of an edge Eij Regressive Saccade Word Count of Source (RSH, RSS) Real LWD and SWD of the SGG considering the number of regressive saccades between words i and j of an edge Eij Regressive Saccade Word Count of Destination (RSDH, RSDS) Real LWD and SWD of the SGG considering the total distance (word count) of regressive saccades between words i and j of an edge Eij Table 2: The complete set of features used in our system. tion characteristics. A saliency graph for a sen- tence S for a reader R, represented as G = (V, E), is a graph with vertices (V ) and edges (E) where each vertex v \u2208V corresponds to a word in S (may not be unique) and there exists an edge e \u2208E between vertices v1 and v2 if R performs at least one saccade between the words correspond- ing to v1 and v2.",
      "Figure 2 shows an example of a saliency graph.A saliency graph may be weighted, but not necessarily connected, for a given text (as there may be words in the given text with no \ufb01xation on them). The \u201ccomplex\u201d gaze features derived from saliency graphs are also motivated by the theory of incongruity. For instance, Edge Density of a saliency graph increases with the number of dis- tinct saccades, which could arise from the com- plexity caused by presence of sarcasm. Similarly, the highest weighted degree of a graph is expected to be higher, if the node corresponds to a phrase, incongruous to some other phrase in the text. 6 The Sarcasm Classi\ufb01er We interpret sarcasm detection as a binary clas- si\ufb01cation problem. The training data constitutes",
      "Features P(1) P(-1) P(avg) R(1) R(-1) R(avg) F(1) F(-1) F(avg) Kappa Multi Layered Neural Network Unigram 53.1 74.1 66.9 51.7 75.2 66.6 52.4 74.6 66.8 0.27 Sarcasm (Joshi et. al.)",
      "al.) 59.2 75.4 69.7 51.7 80.6 70.4 55.2 77.9 69.9 0.33 Gaze 62.4 76.7 71.7 54 82.3 72.3 57.9 79.4 71.8 0.37 Gaze+Sarcasm 63.4 75 70.9 48 84.9 71.9 54.6 79.7 70.9 0.34 N\u00a8aive Bayes Unigram 45.6 82.4 69.4 81.4 47.2 59.3 58.5 60 59.5 0.24 Sarcasm (Joshi et. al.)",
      "al.) 46.1 81.6 69.1 79.4 49.5 60.1 58.3 61.6 60.5 0.25 Gaze 57.3 82.7 73.8 72.9 70.5 71.3 64.2 76.1 71.9 0.41 Gaze+Sarcasm 46.7 82.1 69.6 79.7 50.5 60.8 58.9 62.5 61.2 0.26 Original system by Riloff et.al. : Rule Based with implicit incongruity Ordered 60 30 49 50 39 46 54 34 47 0.10 Unordered 56 28 46 40 42 41 46 33 42 0.16 Original system by Joshi et.al. : SVM with RBF Kernel Sarcasm (Joshi et. al.)",
      ": SVM with RBF Kernel Sarcasm (Joshi et. al.) 73.1 69.4 70.7 22.6 95.5 69.8 34.5 80.4 64.2 0.21 SVM Linear: with default parameters Unigram 56.5 77 69.8 58.6 75.5 69.5 57.5 76.2 69.6 0.34 Sarcasm (Joshi et. al.)",
      "al.) 59.9 78.7 72.1 61.4 77.6 71.9 60.6 78.2 72 0.39 Gaze 65.9 75.9 72.4 49.7 86 73.2 56.7 80.6 72.2 0.38 Gaze+Sarcasm 63.7 79.5 74 61.7 80.9 74.1 62.7 80.2 74 0.43 Multi Instance Logistic Regression: Best Performing Classi\ufb01er Gaze 65.3 77.2 73 53 84.9 73.8 58.5 80.8 73.1 0.41 Gaze+Sarcasm 62.5 84 76.5 72.6 76.7 75.3 67.2 80.2 75.7 0.47 Table 3: Classi\ufb01cation results for different feature combinations.",
      "P\u2192Precision, R\u2192Recall, F\u2192F\u02d9score, Kappa\u2192Kappa statistics show agreement with the gold labels. Subscripts 1 and -1 correspond to sar- casm and non-sarcasm classes respectively. Sentence Gold Sarcasm Gaze Gaze+Sarcasm 1. I would like to live in Manchester, England. The transition between Manch- ester and death would be unnoticeable. S NS S S 2. Helped me a lot with my panic attacks. I took 6 mg a day for almost 20 years. Can\u2019t stop of course but it makes me feel very comfortable. NS S NS NS 3. Forgot to bring my headphones to the gym this morning, the music they play in this gym pumps me up so much! S S NS NS 4. Best show on satellite radio!! No doubt about it. The little doggy company has nothing even close. NS S NS S Table 4: Example test-cases with S and NS representing labels for sarcastic and not-sarcastic respectively. 994 examples created using our eye-movement database for sarcasm detection.",
      "No doubt about it. The little doggy company has nothing even close. NS S NS S Table 4: Example test-cases with S and NS representing labels for sarcastic and not-sarcastic respectively. 994 examples created using our eye-movement database for sarcasm detection. To check the ef- fectiveness of our feature set, we observe the per- formance of multiple classi\ufb01cation techniques on our dataset through a strati\ufb01ed 10-fold cross val- idation. We also compare the classi\ufb01cation accu- racy of our system and the best available systems proposed by Riloff et al. (2013) and Joshi et al. (2015) on our dataset.",
      "We also compare the classi\ufb01cation accu- racy of our system and the best available systems proposed by Riloff et al. (2013) and Joshi et al. (2015) on our dataset. Using Weka (Hall et al., 2009) and LibSVM (Chang and Lin, 2011) APIs, we implement the following classi\ufb01ers: \u2022 N\u00a8aive Bayes classi\ufb01er \u2022 Support Vector Machines (Cortes and Vap- nik, 1995) with default hyper-paramaters \u2022 Multilayer Feed Forward Neural Network \u2022 Multi Instance Logistic Regression (MILR) (Xu and Frank, 2004) 6.1 Results Table 3 shows the classi\ufb01cation results consider- ing various feature combinations for different clas- si\ufb01ers and other systems. These are: \u2022 Unigram (with principal components of uni- gram feature vectors), \u2022 Sarcasm (the feature-set reported by Joshi et al.",
      "These are: \u2022 Unigram (with principal components of uni- gram feature vectors), \u2022 Sarcasm (the feature-set reported by Joshi et al. (2015) subsuming unigram features and features from other reported systems) \u2022 Gaze (the simple and complex cognitive fea- tures we introduce, along with readability and word count features), and \u2022 Gaze+Sarcasm (the complete set of features).",
      "70 80 90 100 60 65 70 75 Training data % Avg. F-Score 70 80 90 100 0.2 0.4 Training data % Avg. Kappa (a) (b) Unigrams Gaze Sarcasm Sarcasm+Gaze Figure 3: Effect of training data size on classi\ufb01ca- tion in terms of (a) F-score and (b) Kappa statistics 20 40 60 80 100 RED *RDSH* *ED* *FC* *PSS* *RSH* *PSH* +VE *F1S* *SKIP* *SL* *F1H* *RSS* IMP *F2S* UNI LEN *F2H* *LREG* *FDUR* *RDSH* *ED* *FC* *PSS* *RSH* *PSH* *F1S* *SKIP* *SL* *F1H* *RSS* *F2S* *F2H* *LREG* *FDUR* X: Avg.",
      "Merit (Chi-squared) Y: Features 20 40 60 80 *RSDH* *RSDS* *ED* *PSS* *FC* *RSH* *F1S* *PSH* *SKIP* +VE *SL* *RSS* *F1H* *F2S* IMP *F2H* UNI LEN *LREG* *FDUR* *RSDH* *RSDS* *ED* *PSS* *FC* *RSH* *F1S* *PSH* *SKIP* *SL* *RSS* *F1H* *F2S* *F2H* *LREG* *FDUR* X: Avg. Merit (InfoGain) Y: Features Figure 4: Signi\ufb01cance of features observed by ranking the features using Attribute Evaluation based on Information Gain and Attribute Evalu- ation based on Chi-squared test. The length of the bar corresponds to the average merit of the feature. Features marked with * are gaze features. For all regular classi\ufb01ers, the gaze features are averaged across participants and augmented with linguistic and sarcasm related features.",
      "The length of the bar corresponds to the average merit of the feature. Features marked with * are gaze features. For all regular classi\ufb01ers, the gaze features are averaged across participants and augmented with linguistic and sarcasm related features. For the MILR classi\ufb01er, the gaze features derived from each participant are augmented with linguistic fea- tures and thus, a multi instance \u201cbag\u201d of features is formed for each sentence in the training data. This multi-instance dataset is given to an MILR clas- si\ufb01er, which follows the standard multi instance assumption to derive class-labels for each bag. For all the classi\ufb01ers, our feature combination outperforms the baselines (considering only uni- gram features) as well as (Joshi et al., 2015), with the MILR classi\ufb01er getting an F-score improve- ment of 3.7% and Kappa difference of 0.08. We also achieve an improvement of 2% over the base- line, using SVM classi\ufb01er, when we employ our feature set.",
      "We also achieve an improvement of 2% over the base- line, using SVM classi\ufb01er, when we employ our feature set. We also observe that the gaze fea- tures alone, also capture the differences between sarcasm and non-sarcasm classes with a high- precision but a low recall. To see if the improvement obtained is statisti- cally signi\ufb01cant over the state-of-the art system with textual sarcasm features alone, we perform McNemar test. The output of the SVM classi\ufb01er using only linguistic features used for sarcasm de- tection by Joshi et al. (2015) and the output of the MILR classi\ufb01er with the complete set of features are compared, setting threshold \u03b1 = 0.05. There was a signi\ufb01cant difference in the classi\ufb01er\u2019s accu- racy with p(two-tailed) = 0.02 with an odds-ratio of 1.43, showing that the classi\ufb01cation accuracy improvement is unlikely to be observed by chance in 95% con\ufb01dence interval.",
      "6.2 Considering Reading Time as a Cognitive Feature along with Sarcasm Features One may argue that, considering simple measures of reading effort like \u201creading time\u201d as cognitive feature instead of the expensive eye-tracking fea- tures for sarcasm detection may be a cost-effective solution. To examine this, we repeated our ex- periments with \u201creading time\u201d considered as the only cognitive feature, augmented with the tex- tual features. The F-scores of all the classi\ufb01ers turn out to be close to that of the classi\ufb01ers con- sidering sarcasm feature alone and the difference in the improvement is not statistically signi\ufb01cant (p > 0.05). One the other hand, F-scores with gaze features are superior to the F-scores when reading time is considered as a cognitive feature. 6.3 How Effective are the Cognitive Features We examine the effectiveness of cognitive features on the classi\ufb01cation accuracy by varying the input training data size. To examine this, we create a",
      "strati\ufb01ed (keeping the class ratio constant) random train-test split of 80%:20%. We train our classi\ufb01er with 100%, 90%, 80% and 70% of the training data with our whole feature set, and the feature combination from Joshi et al. (2015). The good- ness of our system is demonstrated by improve- ments in F-score and Kappa statistics, shown in Figure 3. We further analyze the importance of features by ranking the features based on (a) Chi squared test, and (b) Information Gain test, using Weka\u2019s attribute selection module. Figure 4 shows the top 20 ranked features produced by both the tests. For both the cases, we observe 16 out of top 20 fea- tures to be gaze features. Further, in each of the cases, Average Fixation Duration per Word and Largest Regression Position are seen to be the two most signi\ufb01cant features. 6.4 Example Cases Table 4 shows a few example cases from the ex- periment with strati\ufb01ed 80%-20% train-test split.",
      "6.4 Example Cases Table 4 shows a few example cases from the ex- periment with strati\ufb01ed 80%-20% train-test split. \u2022 Example sentence 1 is sarcastic, and requires extra-linguistic knowledge (about poor living conditions at Manchester). Hence, the sar- casm detector relying only on textual features is unable to detect the underlying incongruity. However, our system predicts the label suc- cessfully, possibly helped by the gaze fea- tures. \u2022 Similarly, for sentence 2, the false sense of presence of incongruity (due to phrases like \u201cHelped me\u201d and \u201cCan\u2019t stop\u201d) affects the system with only linguistic features. Our sys- tem, though, performs well in this case also. \u2022 Sentence 3 presents a false-negative case where it was hard for even humans to get the sarcasm. This is why our gaze features (and subsequently the complete set of features) ac- count for erroneous prediction. \u2022 In sentence 4, gaze features alone false- indicate presence of incongruity, whereas the system predicts correctly when gaze and lin- guistic features are taken together.",
      "This is why our gaze features (and subsequently the complete set of features) ac- count for erroneous prediction. \u2022 In sentence 4, gaze features alone false- indicate presence of incongruity, whereas the system predicts correctly when gaze and lin- guistic features are taken together. From these examples, it can be inferred that, only gaze features would not have suf\ufb01ced to rule out the possibility of detecting other forms of in- congruity that do not result in sarcasm. 6.5 Error Analysis Errors committed by our system arise from mul- tiple factors, starting from limitations of the eye- tracker hardware to errors committed by linguis- tic tools and resources. Also, aggregating vari- ous eye-tracking parameters to extract the cogni- tive features may have caused information loss in the regular classi\ufb01cation setting. 7 Conclusion In the current work, we created a novel frame- work to detect sarcasm, that derives insights from human cognition, that manifests over eye move- ment patterns. We hypothesized that distinctive eye-movement patterns, associated with reading sarcastic text, enables improved detection of sar- casm.",
      "7 Conclusion In the current work, we created a novel frame- work to detect sarcasm, that derives insights from human cognition, that manifests over eye move- ment patterns. We hypothesized that distinctive eye-movement patterns, associated with reading sarcastic text, enables improved detection of sar- casm. We augmented traditional linguistic fea- tures with cognitive features obtained from read- ers\u2019 eye-movement data in the form of simple gaze-based features and complex features derived from a graph structure. This extended feature-set improved the success rate of the sarcasm detector by 3.7%, over the best available system. Using cognitive features in an NLP Processing system like ours is the \ufb01rst proposal of its kind. Our general approach may be useful in other NLP sub-areas like sentiment and emotion anal- ysis, text summarization and question answering, where considering textual clues alone does not prove to be suf\ufb01cient. We propose to augment this work in future by exploring deeper graph and gaze features.",
      "Our general approach may be useful in other NLP sub-areas like sentiment and emotion anal- ysis, text summarization and question answering, where considering textual clues alone does not prove to be suf\ufb01cient. We propose to augment this work in future by exploring deeper graph and gaze features. We also propose to develop models for the purpose of learning complex gaze feature rep- resentation, that accounts for the power of indi- vidual eye movement patterns along with the ag- gregated patterns of eye movements. Acknowledgments We thank the members of CFILT Lab, especially Jaya Jha and Meghna Singh, and the students of IIT Bombay for their help and support. References [Barbieri et al.2014] Francesco Barbieri, Horacio Sag- gion, and Francesco Ronzano. 2014. Modelling sarcasm in twitter, a novel approach. ACL 2014, page 50. [Barr et al.2013] Dale J Barr, Roger Levy, Christoph Scheepers, and Harry J Tily. 2013. Random ef- fects structure for con\ufb01rmatory hypothesis testing:",
      "Keep it maximal. Journal of memory and language, 68(3):255\u2013278. [Camblin et al.2007] C. Christine Camblin, Peter C. Gordon, and Tamara Y. Swaab. 2007. The inter- play of discourse congruence and lexical association during sentence processing: Evidence from {ERPs} and eye tracking. Journal of Memory and Language, 56(1):103 \u2013 128. [Campbell and Katz2012] John D Campbell and Al- bert N Katz. 2012. Are there necessary conditions for inducing a sense of sarcastic irony? Discourse Processes, 49(6):459\u2013480. [Carvalho et al.2009] Paula Carvalho, Lu\u00b4\u0131s Sarmento, M\u00b4ario J Silva, and Eug\u00b4enio De Oliveira. 2009. Clues for detecting irony in user-generated contents: oh...!! it\u2019s so easy;-). In Proceedings of the 1st inter- national CIKM workshop on Topic-sentiment analy- sis for mass opinion, pages 53\u201356. ACM.",
      "2009. Clues for detecting irony in user-generated contents: oh...!! it\u2019s so easy;-). In Proceedings of the 1st inter- national CIKM workshop on Topic-sentiment analy- sis for mass opinion, pages 53\u201356. ACM. [Chang and Lin2011] Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1\u201327:27. Software available at http://www.csie.ntu.edu.tw/\u223ccjlin/libsvm. [Clark and Gerrig1984] Herbert H Clark and Richard J Gerrig. 1984. On the pretense theory of irony. [Cortes and Vapnik1995] Corinna Cortes and Vladimir Vapnik. 1995. Support-vector networks. Machine learning, 20(3):273\u2013297. [Davidov et al.2010] Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.",
      "1995. Support-vector networks. Machine learning, 20(3):273\u2013297. [Davidov et al.2010] Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010. Semi-supervised recognition of sarcastic sentences in twitter and amazon. In Pro- ceedings of the Fourteenth Conference on Computa- tional Natural Language Learning, pages 107\u2013116. Association for Computational Linguistics. [Filik2014] Hartmut; Wallington Katie; Page Jemma Filik, Ruth; Leuthold. 2014. Testing theories of irony processing using eye-tracking and erps. Jour- nal of Experimental Psychology: Learning, Mem- ory, and Cognition, 40(3):811\u2013828. [Flesch1948] Rudolph Flesch. 1948. A new read- ability yardstick. Journal of applied psychology, 32(3):221. [Gibbs1986] Raymond W. Gibbs. 1986. Compre- hension and memory for nonliteral utterances: The problem of sarcastic indirect requests.",
      "1948. A new read- ability yardstick. Journal of applied psychology, 32(3):221. [Gibbs1986] Raymond W. Gibbs. 1986. Compre- hension and memory for nonliteral utterances: The problem of sarcastic indirect requests. Acta Psycho- logica, 62(1):41 \u2013 57. [Giora1995] Rachel Giora. 1995. On irony and nega- tion. Discourse processes, 19(2):239\u2013264. [Gonz\u00b4alez-Ib\u00b4anez et al.2011] Roberto Gonz\u00b4alez- Ib\u00b4anez, Smaranda Muresan, and Nina Wacholder. 2011. Identifying sarcasm in twitter: a closer look. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 581\u2013586. Association for Computational Linguistics. [Hall et al.2009] Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten.",
      "Association for Computational Linguistics. [Hall et al.2009] Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The weka data mining software: an update. ACM SIGKDD explorations newsletter, 11(1):10\u201318. [Holmqvist et al.2011] Kenneth Holmqvist, Marcus Nystr\u00a8om, Richard Andersson, Richard Dewhurst, Halszka Jarodzka, and Joost Van de Weijer. 2011. Eye tracking: A comprehensive guide to methods and measures. Oxford University Press. [Ivanko and Pexman2003] Stacey L Ivanko and Penny M Pexman. 2003. Context incongruity and irony processing. Discourse Processes, 35(3):241\u2013279. [Jorgensen et al.1984] Julia Jorgensen, George A Miller, and Dan Sperber. 1984. Test of the mention theory of irony. Journal of Experimental Psychology: General, 113(1):112.",
      "[Jorgensen et al.1984] Julia Jorgensen, George A Miller, and Dan Sperber. 1984. Test of the mention theory of irony. Journal of Experimental Psychology: General, 113(1):112. [Joshi et al.2015] Aditya Joshi, Vinita Sharma, and Pushpak Bhattacharyya. 2015. Harnessing context incongruity for sarcasm detection. Proceedings of 53rd Annual Meeting of the Association for Compu- tational Linguistics, Beijing, China, page 757. [Joshi et al.2016] Aditya Joshi, Pushpak Bhat- tacharyya, and Mark James Carman. 2016. Automatic sarcasm detection: A survey. CoRR, abs/1602.03426. [Kutas and Hillyard1980] Marta Kutas and Steven A Hillyard. 1980. Reading senseless sentences: Brain potentials re\ufb02ect semantic incongruity. Science, 207(4427):203\u2013205.",
      "[Kutas and Hillyard1980] Marta Kutas and Steven A Hillyard. 1980. Reading senseless sentences: Brain potentials re\ufb02ect semantic incongruity. Science, 207(4427):203\u2013205. [Liebrecht et al.2013] Christine Liebrecht, Florian Kunneman, and Antal van den Bosch. 2013. The perfect solution for detecting sarcasm in tweets# not. WASSA 2013, page 29. [Maynard and Greenwood2014] Diana Maynard and Mark A Greenwood. 2014. Who cares about sar- castic tweets? investigating the impact of sarcasm on sentiment analysis. In Proceedings of LREC. [Mishra et al.2016] Abhijit Mishra, Diptesh Kanojia, and Pushpak Bhattacharyya. 2016. Predicting read- ers\u2019 sarcasm understandability by modeling gaze be- havior. In Proceedings of AAAI. [Pang and Lee2004] Bo Pang and Lillian Lee. 2004.",
      "2016. Predicting read- ers\u2019 sarcasm understandability by modeling gaze be- havior. In Proceedings of AAAI. [Pang and Lee2004] Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the 42nd annual meeting on As- sociation for Computational Linguistics, page 271. Association for Computational Linguistics. [Rayner and Sereno1994] Keith Rayner and Sara C Sereno. 1994. Eye movements in reading: Psy- cholinguistic studies.",
      "[Riloff et al.2013] Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalindra De Silva, Nathan Gilbert, and Rui- hong Huang. 2013. Sarcasm as contrast between a positive sentiment and negative situation. In EMNLP, pages 704\u2013714. [Xu and Frank2004] Xin Xu and Eibe Frank. 2004. Logistic regression and boosting for labeled bags of instances. In Advances in knowledge discovery and data mining, pages 272\u2013281. Springer."
    ],
    "queries":"/future/u/okhattab/data/MSMARCO/queries.train.tsv",
    "index_name":"PaperTab-question-1701.05574.pdf",
    "overwrite":false,
    "root":".ragatouille/",
    "experiment":"colbert",
    "index_root":null,
    "name":"2025-05/17/10.22.50",
    "rank":0,
    "nranks":1,
    "amp":true,
    "gpus":1,
    "avoid_fork_if_possible":false
  },
  "num_chunks":1,
  "num_partitions":1024,
  "num_embeddings":10209,
  "avg_doclen":170.15,
  "RAGatouille":{
    "index_config":{
      "index_type":"PLAID",
      "index_name":"PaperTab-question-1701.05574.pdf"
    }
  }
}