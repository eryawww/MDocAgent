{
  "config":{
    "query_token_id":"[unused0]",
    "doc_token_id":"[unused1]",
    "query_token":"[Q]",
    "doc_token":"[D]",
    "ncells":null,
    "centroid_score_threshold":null,
    "ndocs":null,
    "load_index_with_mmap":false,
    "index_path":null,
    "index_bsize":32,
    "nbits":4,
    "kmeans_niters":20,
    "resume":false,
    "pool_factor":1,
    "clustering_mode":"hierarchical",
    "protected_tokens":0,
    "similarity":"cosine",
    "bsize":64,
    "accumsteps":1,
    "lr":0.00001,
    "maxsteps":400000,
    "save_every":null,
    "warmup":20000,
    "warmup_bert":null,
    "relu":false,
    "nway":64,
    "use_ib_negatives":true,
    "reranker":false,
    "distillation_alpha":1.0,
    "ignore_scores":false,
    "model_name":null,
    "query_maxlen":32,
    "attend_to_mask_tokens":false,
    "interaction":"colbert",
    "dim":128,
    "doc_maxlen":256,
    "mask_punctuation":true,
    "checkpoint":"colbert-ir/colbertv2.0",
    "triples":"/future/u/okhattab/root/unit/experiments/2021.10/downstream.distillation.round2.2_score/round2.nway6.cosine.ib/examples.64.json",
    "collection":[
      "\"How May I Help You?\": Modeling Twitter Customer Service Conversations Using Fine-Grained Dialogue Acts Shereen Oraby\u2217, Pritam Gundecha\u2020, Jalal Mahmud\u2020, Mansurul Bhuiyan\u2020, Rama Akkiraju\u2020 \u2217University of California, Santa Cruz \u2020IBM Research, Almaden soraby@ucsc.edu, {psgundec | jumahmud | akkiraju}@us.ibm.com, mansurul.bhuiyan@ibm.com ABSTRACT Given the increasing popularity of customer service dialogue on Twitter, analysis of conversation data is essential to under- stand trends in customer and agent behavior for the purpose of automating customer service interactions. In this work, we develop a novel taxonomy of \ufb01ne-grained \u201cdialogue acts\u201d frequently observed in customer service, showcasing acts that are more suited to the domain than the more generic existing taxonomies. Using a sequential SVM-HMM model, we model conversation \ufb02ow, predicting the dialogue act of a given turn in real-time. We characterize differences between customer and agent behavior in Twitter customer service conversations, and investigate the effect of testing our system on different customer service industries.",
      "Using a sequential SVM-HMM model, we model conversation \ufb02ow, predicting the dialogue act of a given turn in real-time. We characterize differences between customer and agent behavior in Twitter customer service conversations, and investigate the effect of testing our system on different customer service industries. Finally, we use a data-driven approach to predict important conversation outcomes: cus- tomer satisfaction, customer frustration, and overall problem resolution. We show that the type and location of certain di- alogue acts in a conversation have a signi\ufb01cant effect on the probability of desirable and undesirable outcomes, and present actionable rules based on our \ufb01ndings. The patterns and rules we derive can be used as guidelines for outcome-driven auto- mated customer service platforms. ACM Classi\ufb01cation Keywords H.5.2. User Interfaces: Natural Language Author Keywords Dialogue; Conversation Modeling; Twitter; Customer Service INTRODUCTION The need for real-time, ef\ufb01cient, and reliable customer service has grown in recent years. Twitter has emerged as a popular medium for customer service dialogue, allowing customers to make inquiries and receive instant live support in the public domain.",
      "Twitter has emerged as a popular medium for customer service dialogue, allowing customers to make inquiries and receive instant live support in the public domain. In order to provide useful information to customers, IUI 2017, March 13-16, 2017, Limassol, Cyprus ACM ISBN 978-1-4503-2138-9. DOI: http://dx.doi.org/10.1145/3025171.3025191 agents must \ufb01rst understand the requirements of the conver- sation, and offer customers the appropriate feedback. While this may be feasible at the level of a single conversation for a human agent, automatic analysis of conversations is essential for data-driven approaches towards the design of automated customer support agents and systems. Analyzing the dialogic structure of a conversation in terms of the \u201cdialogue acts\u201d used, such as statements or questions, can give important meta-information about conversation \ufb02ow and content, and can be used as a \ufb01rst step to developing automated agents.",
      "Analyzing the dialogic structure of a conversation in terms of the \u201cdialogue acts\u201d used, such as statements or questions, can give important meta-information about conversation \ufb02ow and content, and can be used as a \ufb01rst step to developing automated agents. Traditional dialogue act taxonomies used to label turns in a conversation are very generic, in order to allow for broad coverage of the majority of dialogue acts pos- sible in a conversation [6, 15, 30]. However, for the purpose of understanding and analyzing customer service conversa- tions, generic taxonomies fall short. Table 1 shows a sample customer service conversation between a human agent and customer on Twitter, where the customer and agent take al- ternating \u201cturns\u201d to discuss the problem. As shown from the dialogue acts used at each turn, simply knowing that a turn is a Statement or Request, as is possible with generic taxonomies, is not enough information to allow for automated handling or response to a problem. We need more \ufb01ne-grained dialogue acts, such as Informative Statement, Complaint, or Request for Information to capture the speaker\u2019s intent, and act ac- cordingly.",
      "We need more \ufb01ne-grained dialogue acts, such as Informative Statement, Complaint, or Request for Information to capture the speaker\u2019s intent, and act ac- cordingly. Likewise, turns often include multiple overlapping dialogue acts, such that a multi-label approach to classi\ufb01cation is often more informative than a single-label approach. Dialogue act prediction can be used to guide automatic re- sponse generation, and to develop diagnostic tools for the \ufb01ne-tuning of automatic agents. For example, in Table 1, the customer\u2019s \ufb01rst turn (Turn 1) is categorized as a Complaint, Negative Expressive Statement, and Sarcasm, and the agent\u2019s response (Turn 2) is tagged as a Request for Information, Yes- No Question, and Apology. Prediction of these dialogue acts in a real-time setting can be leveraged to generate appropriate automated agent responses to similar situations. Additionally, important patterns can emerge from analysis of the \ufb01ne-grained acts in a dialogue in a post-prediction setting.",
      "Prediction of these dialogue acts in a real-time setting can be leveraged to generate appropriate automated agent responses to similar situations. Additionally, important patterns can emerge from analysis of the \ufb01ne-grained acts in a dialogue in a post-prediction setting. For example, if an agent does not follow-up with certain ac- tions in response to a customer\u2019s question dialogue act, this could be found to be a violation of a best practice pattern. arXiv:1709.05413v1  [cs.CL]  15 Sep 2017",
      "Turn# Speaker Tweet Relevant Dialogue Acts 1 Customer Love my new SMASHED Amiibo box for Mega Man! Priority mail here, guys! /s <link> Complaint, Negative Expres- sive Statement, Sarcasm 2 Agent That\u2019s disappointing! Truly sorry. Is the actual <item> damaged? Request Info, Yes-No Question, Apology 3 Customer No, however, I am a collector and I keep them in their boxes. Negative Answer, Informative Statement 4 Agent I understand. Would you like the item to be exchanged? Acknowledgement, Yes-No Question, Offer 5 Customer Support If possible, yes. I\u2019ve never made a return, though. Af\ufb01rmative Answer, Informa- tive Statement 6 Agent How did you purchase the item? Did your local store assisted with this order? Open Question, Request Info, Yes-No Question 7 Customer Support Online. As far as I know this came straight to my house through the website. Informative Statement 8 Agent If the same item is available at your local store, you may exchange it there. If not, you may call <number>.",
      "As far as I know this came straight to my house through the website. Informative Statement 8 Agent If the same item is available at your local store, you may exchange it there. If not, you may call <number>. Informative Statement, Sugges- tion 9 Customer Support Thanks, I\u2019ll try it later. Thanks Table 1: Example Twitter Customer Service Conversation By analyzing large numbers of dialogue act sequences corre- lated with speci\ufb01c outcomes, various rules can be derived, i.e. \u201cContinuing to request information late in a conversation often leads to customer dissatisfaction.\u201d This can then be codi\ufb01ed into a best practice pattern rules for automated systems, such as \u201cA request for information act should be issued early in a conversation, followed by an answer, informative statement, or apology towards the end of the conversation.\u201d In this work, we are motivated to predict the dialogue acts in conversations with the intent of identifying problem spots that can be addressed in real-time, and to allow for post- conversation analysis to derive rules about conversation out- comes indicating successful/unsuccessful interactions, namely, customer satisfaction, customer frustration, and problem reso- lution.",
      "We focus on analysis of the dialogue acts used in cus- tomer service conversations as a \ufb01rst step to fully automating the interaction. We address various different challenges: dia- logue act annotated data is not available for customer service on Twitter, the task of dialogue act annotation is subjective, existing taxonomies do not capture the \ufb01ne-grained informa- tion we believe is valuable to our task, and tweets, although concise in nature, often consist of overlapping dialogue acts to characterize their full intent. The novelty of our work comes from the development of our \ufb01ne-grained dialogue act taxon- omy and multi-label approach for act prediction, as well as our analysis of the customer service domain on Twitter. Our goal is to offer useful analytics to improve outcome-oriented conversational systems. We \ufb01rst expand upon previous work and generic dialogue act taxonomies, developing a \ufb01ne-grained set of dialogue acts for customer service, and conducting a systematic user study to identify these acts in a dataset of 800 conversations from four Twitter customer service accounts (i.e. four different companies in the telecommunication, electronics, and insur- ance industries).",
      "four different companies in the telecommunication, electronics, and insur- ance industries). We then aim to understand the conversation \ufb02ow between customers and agents using our taxonomy, so we develop a real-time sequential SVM-HMM model to pre- dict our \ufb01ne-grained dialogue acts while a conversation is in progress, using a novel multi-label scheme to classify each turn. Finally, using our dialogue act predictions, we classify conversations based on the outcomes of customer satisfac- tion, frustration, and overall problem resolution, then provide actionable guidelines for the development of automated cus- tomer service systems and intelligent agents aimed at desired customer outcomes [1, 31]. We begin with a discussion of related work, followed by an overview of our methodology. Next, we describe our conver- sation modeling framework, and explain our outcome analysis experiments, to show how we derive useful patterns for design- ing automated customer service agents. Finally, we present conclusions and directions for future work.",
      "Next, we describe our conver- sation modeling framework, and explain our outcome analysis experiments, to show how we derive useful patterns for design- ing automated customer service agents. Finally, we present conclusions and directions for future work. RELATED WORK Developing computational speech and dialogue act models has long been a topic of interest [3, 23, 27, 29], with re- searchers from many different backgrounds studying human conversations and developing theories around conversational analysis and interpretation on intent. Modern intelligent con- versational [1, 31] and dialogue systems draw principles from many disciplines, including philosophy, linguistics, computer science, and sociology. In this section, we describe relevant previous work on speech and dialogue act modeling, general conversation modeling on Twitter, and speech and dialogue act modeling of customer service in other data sources. Previous work has explored speech act modeling in different domains (as a predecessor to dialogue act modeling). Zhang et al. present work on recognition of speech acts on Twitter, following up with a study on scalable speech act recognition given the dif\ufb01culty of obtaining labeled training data [36].",
      "Previous work has explored speech act modeling in different domains (as a predecessor to dialogue act modeling). Zhang et al. present work on recognition of speech acts on Twitter, following up with a study on scalable speech act recognition given the dif\ufb01culty of obtaining labeled training data [36]. They use a simple taxonomy of four main speech acts (State- ment, Question, Suggestion, Comment, and a Miscellaneous category). More recently, Vosoughi et al. develop [34] a speech act classi\ufb01er for Twitter, using a modi\ufb01cation of the taxonomy de\ufb01ned by Searle in 1975, including six acts they observe to commonly occur on Twitter: Assertion, Recommen- dation Expression, Question, Request, again plus a Miscella- neous category. They describe good features for speech act classi\ufb01cation and the application of such a system to detect stories on social media [33]. In this work, we are interested",
      "in the dialogic characteristics of Twitter conversations, rather than speech acts in stand-alone tweets. Different dialogue act taxonomies have been developed to characterize conversational acts. Core and Allen present the Dialogue Act Marking in Several Layers (DAMSL), a standard for discourse annotation that was developed in 1997 [6]. The taxonomy contains a total of 220 tags, divided into four main categories: communicative status, information level, forward- looking function, and backward-looking function. Jurafsky, Shriberg, and Biasca develop a less \ufb01ne-grained taxonomy of 42 tags based on DAMSL [15]. Stolcke et al. employ a similar set for general conversation [30], citing that \u201ccontent- and task-related distinctions will always play an important role in effective DA [Dialogue Act] labeling.\u201d Many researchers have tackled the task of developing different speech and dialogue act taxonomies and coding schemes [5, 18, 28, 32]. For the purposes of our own research, we require a set of dialogue acts that is more closely representative of customer service domain interactions - thus we expand upon previously de\ufb01ned taxonomies and develop a more \ufb01ne-grained set.",
      "For the purposes of our own research, we require a set of dialogue acts that is more closely representative of customer service domain interactions - thus we expand upon previously de\ufb01ned taxonomies and develop a more \ufb01ne-grained set. Modeling general conversation on Twitter has also been a topic of interest in previous work. Honeycutt and Herring study conversation and collaboration on Twitter using individ- ual tweets containing \u201c@\u201d mentions [11]. Ritter et al. explore unsupervised modeling of Twitter conversations, using cluster- ing methods on a corpus of 1.3 million Twitter conversations to de\ufb01ne a model of transitional \ufb02ow between in a general Twitter dialogue [26]. While these approaches are relevant to understanding the nature of interactions on Twitter, we \ufb01nd that the customer service domain presents its own interesting characteristics that are worth exploring further. The most related previous work has explored speech and di- alogue act modeling in customer service, however, no previ- ous work has focused on Twitter as a data source.",
      "The most related previous work has explored speech and di- alogue act modeling in customer service, however, no previ- ous work has focused on Twitter as a data source. In 2005, Ivanovic uses an abridged set of 12 course-grained dialogue acts (detailed in the Taxonomy section) to describe interac- tions between customers and agents in instant messaging chats [12, 14], leading to a proposal on response suggestion using the proposed dialogue acts [13]. Follow-up work using the taxonomy selected by Ivanovic comes from Kim et al., where they focus on classifying dialogue acts in both one-on-one and multi-party live instant messaging chats [16, 17]. These works are similar to ours in the nature of the problem addressed, but we use a much more \ufb01ne-grained taxonomy to de\ufb01ne the inter- actions possible in the customer service domain, and focus on Twitter conversations, which are unique in their brevity and the nature of the public interactions. The most similar work to our own is that of Herzig et al. on classifying emotions in customer support dialogues on Twitter [9].",
      "The most similar work to our own is that of Herzig et al. on classifying emotions in customer support dialogues on Twitter [9]. They explore how agent responses should be tailored to the detected emotional response in customers, in order to improve the quality of service agents can provide. Rather than focusing on emotional response, we seek to model the dialogic structure and intents of the speakers using dialogue acts, with emotion included as features in our model, to characterize the emotional intent within each act. METHODOLOGY The underlying goal of this work is to show how a well-de\ufb01ned taxonomy of dialogue acts can be used to summarize seman- tic information in real-time about the \ufb02ow of a conversation to derive meaningful insights into the success/failure of the interaction, and then to develop actionable rules to be used in automating customer service interactions. We focus on the customer service domain on Twitter, which has not previously been explored in the context of dialogue act classi\ufb01cation. In this new domain, we can provide meaningful recommenda- tions about good communicative practices, based on real data. Our methodology pipeline is shown in Figure 1. Figure 1: Methodology Pipeline 1.",
      "In this new domain, we can provide meaningful recommenda- tions about good communicative practices, based on real data. Our methodology pipeline is shown in Figure 1. Figure 1: Methodology Pipeline 1. Taxonomy De\ufb01nition and Data Collection: We expand on previous work by de\ufb01ning a taxonomy of \ufb01ne-grained dialogue acts suited to the customer service domain, and use this taxonomy to gather annotations for customer service conversations on Twitter. 2. Conversation Modeling: We develop an SVM-HMM model to identify the different dialogue acts in a customer service conversation, in a real-time setting, and using a novel multi-label approach to capture different dialogic intents contained in a single turn. We compare the per- formance of the model under different settings to better understand differences between customer and agent behav- ior. 3.",
      "We compare the per- formance of the model under different settings to better understand differences between customer and agent behav- ior. 3. Conversation Outcome Analysis: We use our model to provide actionable recommendations for the development of automated customer service systems, answering ques- tions such as, \u201cWhat is the correlation between conversa- tion \ufb02ow in terms of the dialogue acts used, and overall customer satisfaction, frustration, and problem resolution?\u201d, and \u201cWhat rules can we include in automated systems to promote successful interactions with customers?\u201d TAXONOMY DEFINITION As described in the related work, the taxonomy of 12 acts to classify dialogue acts in an instant-messaging scenario, developed by Ivanovic in 2005, has been used by previous work when approaching the task of dialogue act classi\ufb01ca- tion for customer service [12, 13, 14, 16, 17]. The dataset used consisted of eight conversations from chat logs in the MSN Shopping Service (around 550 turns spanning around 4,500 words) [14]. The conversations were gathered by ask- ing \ufb01ve volunteers to use the platform to inquire for help regarding various hypothetical situations (i.e.",
      "The dataset used consisted of eight conversations from chat logs in the MSN Shopping Service (around 550 turns spanning around 4,500 words) [14]. The conversations were gathered by ask- ing \ufb01ve volunteers to use the platform to inquire for help regarding various hypothetical situations (i.e. buying an item for someone) [14]. The process of selection of tags to de- velop the taxonomy, beginning with the 42 tags from the DAMSL set [6], involved removing tags inappropriate for",
      "Proposed Fine-Grained Dialogue Act Taxonomy Greeting Opening Closing Statement Informative Expressive Positive Expressive Negative Complaint Offer Help Suggest Action Promise Sarcasm Other Request Request Help Request Info Other Question Yes-No Question Wh- Question Open Question Answer Yes-Answer No-Answer Response-Ack Other Social Act Thanks Apology Downplayer Figure 2: Proposed Fine-Grained Dialogue Act Taxonomy for Customer Service written text, and collapsing sets of tags into a more coarse- grained label [12]. The \ufb01nal taxonomy consists of the fol- lowing 12 dialogue acts (sorted by frequency in the dataset): Statement (36%), Thanking (14.7%), Yes-No Question (13.9%), Response-Acknowledgement (7.2%), Request (5.9%), Open- Question (5.3%), Yes-Answer (5.1%), Conventional-Closing (2.9%), No-Answer (2.5%), Conventional-Opening (2.3%), Expressive (2.3%) and Downplayer (1.9%).",
      "For the purposes of our own research, focused on customer service on Twitter, we found that the course-grained nature of the taxonomy presented a natural shortcoming in terms of what information could be learned by performing classi\ufb01cation at this level. We observe that while having a smaller set of dialogue acts may be helpful for achieving good agreement between annotators (Ivanovic cites kappas of 0.87 between the three expert annotators using this tag set on his data [12]), it is unable to offer deeper semantic insight into the speci\ufb01c intent behind each act for many of the categories. For example, the Statement act, which comprises the largest percentage (36% of turns), is an extremely broad category that fails to provide useful information from an analytical perspective. Likewise, the Request category also does not specify any intent behind the act, and leaves much room for improvement. For this reason, and motivated by previous work seeking to develop dialogue act taxonomies appropriate for different do- mains [14, 16], we convert the list of dialogue acts presented by the literature into a hierarchical taxonomy, shown in Fig- ure 2.",
      "For this reason, and motivated by previous work seeking to develop dialogue act taxonomies appropriate for different do- mains [14, 16], we convert the list of dialogue acts presented by the literature into a hierarchical taxonomy, shown in Fig- ure 2. We \ufb01rst organize the taxonomy into six high-level dialogue acts: Greeting, Statement, Request, Question, Answer, and Social Act. Then, we update the taxonomy using two main steps: restructuring and adding additional \ufb01ne-grained acts. \u2022 We restructure 10 of the acts into our higher-level cate- gories: Conventional Opening and Conventional Closing into Greeting; Expressive into Statement (further dividing it into Expressive Positive and Expressive Negative); Yes-No Question and Open Question into Question; Yes-Answer, No Answer, and Response-Ack into Answer; and Thanking and Downplayer into Social Act. \u2022 Next, we add \ufb01ne-grained acts to the two very broad cat- egories of Statement and Request.",
      "\u2022 Next, we add \ufb01ne-grained acts to the two very broad cat- egories of Statement and Request. We add Giving Infor- mation, Complaint, Offer Help, Suggest Action, Promise, Sarcasm, and Other categories to Statement, and Request Help, Request Info, and Other categories to Request. We base our changes upon the taxonomy used by Ivanovic and Kim et al. in their work on instant messaging chat dialogues [14, 16], but also on general dialogue acts observed in the customer service domain, including complaints and sugges- tions. Our taxonomy does not make any speci\ufb01c restrictions on which party in the dialogue may perform each act, but we do observe that some acts are far more frequent (and sometimes non-existent) in usage, depending on whether the customer or agent is the speaker (for example, the Statement Complaint category never shows up in Agent turns). In order to account for gaps in available act selections for annotators, we include an Other act in the broadest categories. While our taxonomy \ufb01lls in many gaps from previous work in our domain, we do not claim to have handled coverage of all possible acts in this domain.",
      "In order to account for gaps in available act selections for annotators, we include an Other act in the broadest categories. While our taxonomy \ufb01lls in many gaps from previous work in our domain, we do not claim to have handled coverage of all possible acts in this domain. Our taxonomy allows us to more closely specify the intent and motivation behind each turn, and ultimately how to address different situations. DATA COLLECTION Given our taxonomy of \ufb01ne-grained dialogue acts that ex- pands upon previous work, we set out to gather annotations for Twitter customer service conversations. For our data collection phase, we begin with conversations from the Twitter customer service pages of four different com- panies,1 from the electronics, telecommunications, and insur- ance industries.2 We perform several forms of pre-processing to the conversations. We \ufb01lter out conversations if they contain more than one customer or agent speaker, do not have alternat- ing customer/agent speaking turns (single turn per speaker), 1We keep the names of the companies anonymous, replacing them with placeholders in our annotation tasks. 2The conversations were provided to us by Herzig et al. from the same pool used in their work [9].",
      "have less than 5 or more than 10 turns,3 have less than 70 words in total, and if any turn in the conversation ends in an ellipses followed by a link (indicating that the turn has been cut off due to length, and spans another tweet). Additionally, we remove any references to the company names (substituting with \u201cAgent\u201d), any references to customer usernames (sub- stituting with \u201cCustomer\u201d), and replacing and links or image references with <link> and <img> tokens. Using these \ufb01lters as pre-processing methods, we end up with a set of 800 conversations, spanning 5,327 turns. We conduct our annotation study on Amazon Mechanical Turk,4 presenting Turkers with Human Intelligence Tasks (henceforth, HITs) consisting of a single conversation between a customer and an agent. In each HIT, we present Turkers with a de\ufb01nition of each dialogue act, as well as a sample annotated dialogue for reference. For each turn in the conversation, we allow Turkers to select as many labels from our taxonomy as required to fully characterize the intent of the turn.",
      "In each HIT, we present Turkers with a de\ufb01nition of each dialogue act, as well as a sample annotated dialogue for reference. For each turn in the conversation, we allow Turkers to select as many labels from our taxonomy as required to fully characterize the intent of the turn. Additionally, annotators are asked three questions at the end of each conversation HIT, to which they could respond that they agreed, disagreed, or could not tell: \u2022 At any point in the conversation, does the customer seem frustrated? \u2022 By the end of the conversation, does the customer seem satis\ufb01ed? \u2022 By the end of the conversation, was the problem resolved (or will the parties continue the conversation)? We ask 5 Turkers to annotate each conversation HIT, and pay $0.20 per HIT. We \ufb01nd the list of \u201cmajority dialogue acts\u201d for each tweet by \ufb01nding any acts that have received majority-vote labels (at least 3 out of 5 judgements). It is important to note at this point that we make an important choice as to how we will handle dialogue act tagging for each turn.",
      "It is important to note at this point that we make an important choice as to how we will handle dialogue act tagging for each turn. We note that each turn may contain more than one dialogue act vital to carry its full meaning. Thus, we choose not to carry out a speci\ufb01c segmentation task on our tweets, contrary to previous work [21, 35], opting to characterize each tweet as a single unit composed of different, often overlapping, dialogue acts. Table 2 shows examples of tweets that receive majority vote on more than one label, where the act boundaries are overlapping and not necessarily distinguishable. Table 2: Sample Tweets with Overlapping Dialogue Acts 1 @Customer That\u2019s not what we like to hear. What\u2019s causing u to feel this way? How can we turn this around for u? We\u2019re here to help. Statement Offer, Request for Info, Question Open 2 \u201cThanks @Agent for screwing me over again.",
      "What\u2019s causing u to feel this way? How can we turn this around for u? We\u2019re here to help. Statement Offer, Request for Info, Question Open 2 \u201cThanks @Agent for screwing me over again. Once I\u2019m done \ufb01guring out the problems you caused me, I\u2019ll be taking my services elsewhere.\u201d Statement Informative, Statement Complaint, Statement Sarcasm It is clear that the lines differentiating these acts are not very well de\ufb01ned, and that segmentation would not necessarily aid 3The lower bound was set to allow for at least 2 turns per speaker, and the upper-bound was selected after \ufb01nding that 93% of the con- versations had 10 or fewer turns 4http://www.mturk.com Table 3: Dialogue Act Agreement in Fleiss-\u03ba Bins (from Landis and Koch, 1977) Agreement Dialogue Acts Slight (0.01-0.20) Statement Other, Answer Response Ack, Request Other Fair (0.21-0.40) Statement Sarcasm, Answer Other, Statement Promise, Greeting Closing, Question Open, State- ment Expressive Pos.",
      "Moderate (0.41-0.60) Statement Complaint, Question Wh-, Social Act Downplayer, Statement Offer, Request Info, State- ment Info, Request Help, Statement Expressive Neg. Substantial (0.61-0.80) Greeting Opening, Question Yes-No, Answer Yes, Answer No, Statement Suggestion Almost Perfect (0.81-1.00) Social Act Apology, Social Act Thanks in clearly separating out each intent. For these reasons, and due to the overall brevity of tweets in general, we choose to avoid the overhead of requiring annotators to provide segment boundaries, and instead ask for all appropriate dialogue acts. Annotation Results Figure 3 shows the distribution of the number of times each dialogue act in our taxonomy is selected a majority act by the annotators (recall that each turn is annotated by 5 anno- tators). From the distribution, we see that the largest class is Statement Info which is part of the majority vote list for 2,152 of the 5,327 total turns, followed by Request Info, which appears in 1,088 of the total turns.",
      "From the distribution, we see that the largest class is Statement Info which is part of the majority vote list for 2,152 of the 5,327 total turns, followed by Request Info, which appears in 1,088 of the total turns. Although Statement Infor- mative comprises the largest set of majority labels in the data (as did Statement in Ivanovic\u2019s distribution), we do observe that other \ufb01ne-grained categories of Statement occur in the most frequent labels as well, including Statement Complaint, Figure 3: Distribution of Annotated Dialogue Act Labels",
      "Table 4: Detailed Distribution of Top 12 Fine-Grained Dialogue Acts Derived From Annotations Tag Example % of Turns (5,327) % of Annot. (10,343) Statement Informative The signal came back last night [...] 40.3 20.8 Request Information Can you send us [...]? 20.4 10.5 Statement Complaint Staff didn\u2019t honor online info, was dismissive [...] 17.3 8.9 Question Yes-No Have you tried for availability at [...] 13.7 7.0 Statement Expressive Neg. I don\u2019t trust places that do bad installations [...] 12.0 6.2 Statement Suggestion Let\u2019s try clearing the cache <link> [...] 10.7 5.5 Answer (Other) Depends on the responder [...] 10.5 5.4 Social Act Apology I\u2019m sorry for the trouble [...] 8.8 4.5 Social Act Thanks Thanks for the help [...] 8.8 4.5 Question Wh- Why was that?",
      "8.5 4.4 Statement Offer We can always double check the account [...] 8.1 4.1 Question Open How come I can\u2019t get a [...] quote online? 6.4 3.3 (All Other Acts) 2.7 14.3 Statement Expressive Negative, and Statement Suggestion \u2013 giving more useful information as to what form of statement is most frequently occurring. We \ufb01nd that 147 tweets receive no majority label (i.e. no single act received 3 or more votes out of 5). At the tail of the distribution, we see less frequent acts, such as Statement Sarcasm, Social Act Downplayer, Statement Promise, Greeting Closing, and Request Other. It is also inter- esting to note that both opening and closing greetings occur infrequently in the data \u2013 which is understandable given the nature of Twitter conversation, where formal greeting is not generally required. Table 4 shows a more detailed summary of the distribution of our top 12 dialogue acts according to the annotation exper- iments, as presented by Ivanovic [12].",
      "Table 4 shows a more detailed summary of the distribution of our top 12 dialogue acts according to the annotation exper- iments, as presented by Ivanovic [12]. Since each turn has an overlapping set of labels, the column % of Turns (5,327) represents what fraction of the total 5,327 turns contain that dialogue act label (these values do not sum to 1, since there is overlap). To give a better sense of the percentage appearance of each dialogue act class in terms of the total number of anno- tated labels given, we also present column % of Annotations (10,343) (these values are percentages). We measure agreement in our annotations using a few different techniques. Since each item in our annotation experiments allows for multiple labels, we \ufb01rst design an agreement mea- sure that accounts for how frequently each annotator selects the acts that agree with the majority-selected labels for the turns they annotated.",
      "We measure agreement in our annotations using a few different techniques. Since each item in our annotation experiments allows for multiple labels, we \ufb01rst design an agreement mea- sure that accounts for how frequently each annotator selects the acts that agree with the majority-selected labels for the turns they annotated. To calculate this for each annotator, we \ufb01nd the number of majority-selected acts for each conversa- tion they annotated (call this MAJ), and the number of subset those acts that they selected (call this SUBS), and \ufb01nd the ratio (SUBS/MAJ). We use this ratio to systematically \ufb01ne-tune our set of annotators by running our annotation in four batches, restricting our pool of annotators to those that have above a 0.60 ratio of agreement with the majority from the previous batch, as a sort of quality assurance test. We also measure Fleiss\u2019 Kappa [7] agreement between annotators in two ways: \ufb01rst by normalizing our annotation results into binary-valued items indicating annotators\u2019 votes for each label contain within each turn.",
      "We also measure Fleiss\u2019 Kappa [7] agreement between annotators in two ways: \ufb01rst by normalizing our annotation results into binary-valued items indicating annotators\u2019 votes for each label contain within each turn. We \ufb01nd an average Fleiss-\u03ba = 0.528 for the full dataset, including all turn-and-label items, representing mod- erate agreement on the 24-label problem. We also calculate the Fleiss-\u03ba values for each label, and use the categories de\ufb01ned by Landis and Koch to bin our speech acts based on agreement [20]. As shown in Table 3, we \ufb01nd that the per-label agreement varies from \u201calmost perfect\u201d agreement of \u03ba = 0.871 for lexically de\ufb01ned categories such as Apology and Thanks, with only slight agreement of \u03ba = 0.01 \u22120.2 for less clearly-de\ufb01ned categories, such as Statement (Other), Answer Response Acknowledgement and Request (Other).",
      "For the conversation-level questions, we calculate the agreement across the \u201cAgree\u201d label for all annotators, \ufb01nding an aver- age Fleiss-\u03ba = 0.595, with question-level results of \u03ba = 0.624 for customer satisfaction, \u03ba = 0.512 for problem resolution, and \u03ba = 0.384 for customer frustration. These results suggest room for improvement for further development of the taxon- omy, to address problem areas for annotators and remedy areas of lower agreement. Motivation for Multi-Label Classi\ufb01cation We test our hypothesis that tweet turns are often characterized by more than one distinct dialogue act label by measuring the percentage overlap between frequent pairs of labels. Of the 5,327 turns annotated, across the 800 conversations, we \ufb01nd that 3,593 of those turns (67.4%) contained more than one majority-act label. Table 5 shows the distribution percentage of the most frequent pairs.",
      "Of the 5,327 turns annotated, across the 800 conversations, we \ufb01nd that 3,593 of those turns (67.4%) contained more than one majority-act label. Table 5 shows the distribution percentage of the most frequent pairs. Table 5: Distribution of the 10 Most Frequent Dialogue Act Pairs for Turns with More Than 1 Label (3,593) Dialogue Act Pair % of Turns (statement_info, answer_other) 13.74 (statement_expr_neg, statement_complaint) 12.71 (statement_info, statement_complaint) 12.10 (request_info, question_yesno) 9.18 (request_info, question_wh) 8.26 (statement_offer, request_info) 5.17 (statement_info, statement_expr_neg) 4.81 (request_info, socialact_apology) 4.75 (statement_info, statement_suggestion) 4.39 For example, we observe that answering with informative statements is the most frequent pair, followed by complaints coupled with negative sentiment or informative statements. We also observe that requests are usually formed as questions, but also co-occur frequently with apologies.",
      "We also observe that requests are usually formed as questions, but also co-occur frequently with apologies. This experiment validates our intuition that the majority of turns do contain",
      "more than a single label, and motivates our use of a multi- label classi\ufb01cation method for characterizing each turn in the conversation modeling experiments we present in the next section. CONVERSATION MODELING In this section, we describe the setup and results of our con- versational modeling experiments on the data we collected using our \ufb01ne-grained taxonomy of customer service dialogue acts. We begin with an overview of the features and classes used, followed by our experimental setup and results for each experiment performed.",
      "We begin with an overview of the features and classes used, followed by our experimental setup and results for each experiment performed. Features The following list describes the set of features used for our dialogue act classi\ufb01cation tasks: \u2022 Word/Punctuation: binary bag-of-word unigrams, binary existence of a question mark, binary existence of an excla- mation mark in a turn \u2022 Temporal: response time of a turn (time in seconds elapsed between the posting time of the previous turn and that of the current turn) \u2022 Second-Person Reference: existence of an explicit second- person reference in the turn (you, your, you\u2019re) \u2022 Emotion: count of words in each of the 8 emotion classes from the NRC emotion lexicon [22] (anger, anticipation, disgust, fear, joy, negative, positive, sadness, surprise, and trust) \u2022 Dialogue: lexical indicators in the turn: opening greetings (hi, hello, greetings, etc), closing greetings (bye, goodbye), yes-no questions (turns with questions starting with do, did, can, could, etc), wh- questions (turns with questions starting with who, what, where, etc), thanking (thank*), apology (sorry, apolog*), yes-answer, and no-answer Classes Table 6 shows the division of classes we use for each of our experiments.",
      "We select our classes using the distribution of annotations we observe in our data collection phase (see Table 4), selecting the top 12 classes as candidates. While iteratively selecting the most frequently-occurring classes helps to ensure that classes with the most data are represented in our experiments, it also introduces the problem of including classes that are very well-de\ufb01ned lexically, and may not require learning for classi\ufb01cation, such as Social Act Apology and Social Act Thanking in the \ufb01rst 10-Class set. For this reason, we call this set 10-Class (Easy), and also exper- iment using a 10-Class (Hard) set, where we add in the next two less-de\ufb01ned and more semantically rich labels, such as Statement Offer and Question Open. When using each set of classes, a turn is either classi\ufb01ed as one of the classes in the set, or it is classi\ufb01ed as \u201cother\u201d (i.e. any of the other classes). We discuss our experiments in more detail and comment on performance differences in the experiment section.",
      "any of the other classes). We discuss our experiments in more detail and comment on performance differences in the experiment section. Table 6: Dialogue Acts Used in Each Set of Experiments Name Dialogue Acts 6 Class Statement Informative Request Information Statement Complaint Question Yes-No Statement Expressive Negative (All Other Acts) 8 Class 6-Class + Statement Suggestion Statement Answer Other 10-Class 8-Class + (Easy) Social Act Apology Social Act Thanks 10-Class 8-Class + (Hard) Statement Offer Question Open Experiments Following previous work on conversation modeling [9], we use a sequential SVM-HMM (using the SVMHMM toolkit [2]) for our conversation modeling experiments. We hypothesize that a sequential model is most suited to our dialogic data, and that we will be able to concisely capture conversational attributes such as the order in which dialogue acts often occur (i.e. some Answer act after Question a question act, or Apology acts after Complaints).",
      "We hypothesize that a sequential model is most suited to our dialogic data, and that we will be able to concisely capture conversational attributes such as the order in which dialogue acts often occur (i.e. some Answer act after Question a question act, or Apology acts after Complaints). We note that with default settings for a sequence of length N, an SVM-HMM model will be able to re\ufb01ne its answers for any turn xi as information becomes available for turns xi+1...N. However, we opt to design our classi\ufb01er under a real-time setting, where turn-by-turn classi\ufb01cation is required without future knowledge or adaptation of prediction at any given stage. In our setup, turns are predicted in a real-time setting to fairly model conversation available to an intelligent agent in a conversational system. At any point, a turn xi is predicted using information from turns x1...i, and where a prediction is not changed when new information is available. We test our hypothesis by comparing our real-time sequential SVM-HMM model to non-sequential baselines from the NLTK [4] and Scikit-Learn [24] toolkits.",
      "We test our hypothesis by comparing our real-time sequential SVM-HMM model to non-sequential baselines from the NLTK [4] and Scikit-Learn [24] toolkits. We use our selected feature set (described above) to be generic enough to apply to both our sequential and non-sequential models, in order to allow us to fairly compare performance. We shuf\ufb02e and divide our data into 70% for training and development (560 conversations, using 10-fold cross-validation for parameter tuning), and hold out 30% of the data (240 conversations) for test. Motivated by the prevalent overlap of dialogue acts, we con- duct our learning experiments using a multi-label setup. For each of the sets of classes, we conduct binary classi\ufb01cation task for each label: for each N-class classi\ufb01cation task, a turn is labeled as either belonging to the current label, or not (i.e. \u201cother\u201d). In this setup, each turn is assigned a binary value for each label (i.e.",
      "\u201cother\u201d). In this setup, each turn is assigned a binary value for each label (i.e. for the 6-class experiment, each turn receives a value of 0/1 for each indicating whether the classi\ufb01er pre- dicts it to be relevant to the each of the 6 labels). Thus, for each N-class experiment, we end up with N binary labels, for example, whether the turn is a Statement Informative or Other, Request Information or Other, etc.",
      "We aggregate the N binary predictions for each turn, then compare the resultant prediction matrix for all turns to our majority-vote ground-truth labels, where at least 3 out of 5 annotators have selected a label to be true for a given turn. The dif\ufb01culty of the task increases as the number of classes N increases, as there are more classi\ufb01cations done for each turn (i.e., for the 6-class problem, there are 6 classi\ufb01cation tasks per turn, while for the 8-class problem, there are 8, etc). Due to the inherent imbalance of label-distribution in the data (shown in Figure 3), we use weighted F-macro to calculate our \ufb01nal scores for each feature set (which \ufb01nds the average of the metrics for each label, weighted by the number of true instances for that label) [24]. Non-Sequential Baselines vs. Sequential SVM-HMM Our \ufb01rst experiment sets out to compare the use of a non- sequential classi\ufb01cation algorithm versus a sequential model for dialogue act classi\ufb01cation on our dataset.",
      "Non-Sequential Baselines vs. Sequential SVM-HMM Our \ufb01rst experiment sets out to compare the use of a non- sequential classi\ufb01cation algorithm versus a sequential model for dialogue act classi\ufb01cation on our dataset. We experiment with the default Naive Bayes (NB) and Linear SVC algorithms from Scikit-Learn [24], comparing with our sequential SVM- HMM model. We test each classi\ufb01er on each of our four class sets, reporting weighted F-macro for each experiment. Figure 4 shows the results of the experiments. Figure 4: Plot of Non-Sequential Baselines vs. Sequential SVM-HMM Model From this experiment, we observe that our sequential SVM- HMM outperforms each non-sequential baseline, for each of the four class sets. We select the sequential SVM-HMM model for our preferred model for subsequent experiments. We observe that while performance may be expected to drop as the number of classes increases, we instead get a spike in performance for the 10-Class (Easy) setting.",
      "We select the sequential SVM-HMM model for our preferred model for subsequent experiments. We observe that while performance may be expected to drop as the number of classes increases, we instead get a spike in performance for the 10-Class (Easy) setting. This increase occurs due to the addition of the lexically well-de\ufb01ned classes of Statement Apology and Statement Thanks, which are much simpler for our model to predict. Their addition results in a performance boost, comparable to that of the simpler 6-Class problem. When we remove the two well-de\ufb01ned classes and add in the next two broader dialogue act classes of Statement Offer and Question Open (as de\ufb01ned by the 10-Class (Hard) set), we observe a drop in performance, and an overall result comparable to our 8-Class problem. This result is still strong, since the number of classes has increased, but the overall performance does not drop. We also observe that while NB and LinearSVC have the same performance trend for the smaller number of classes, Linear SVC rapidly improves in performance as the number of classes increases, following the same trend as SVM-HMM.",
      "We also observe that while NB and LinearSVC have the same performance trend for the smaller number of classes, Linear SVC rapidly improves in performance as the number of classes increases, following the same trend as SVM-HMM. The small- est margin of difference between SVM-HMM and Linear SVC also occurs at the 10-Class (Easy) setting, where the addition of highly-lexical classes makes for a more differentiable set of turns. Customer-Only vs. Agent-Only Turns Our next experiment tests the differences in performance when training and testing our real-time sequential SVM-HMM model using only a single type of speaker\u2019s turns (i.e. only Customer or only Agent turns). Figure 5 shows the relative performance of using only speaker-speci\ufb01c turns, versus our standard results using all turns. We observe that using Customer-only turns gives us lower pre- diction performance than using both speakers\u2019 turns, but that Agent-only turns actually gives us higher performance.",
      "Figure 5 shows the relative performance of using only speaker-speci\ufb01c turns, versus our standard results using all turns. We observe that using Customer-only turns gives us lower pre- diction performance than using both speakers\u2019 turns, but that Agent-only turns actually gives us higher performance. Since agents are put through training on how to interact with cus- tomers (often using templates), agent behavior is signi\ufb01cantly more predictable than customer behavior, and it is easier to predict agent turns even without utilizing any customer turn information (which is more varied, and thus more dif\ufb01cult to predict). We again observe a boost in performance at out 10-Class (Easy) set, due to the inclusion of lexically well-de\ufb01ned classes. Notably, we achieve best performance for the 10- Class (Easy) set using only agent turns, where the use of the Apology and Thanks classes are both prevalent and predictable. Figure 5: Plot of Both Speaker Turns vs. Only Cus- tomer/Agent Turns for Sequential SVM-HMM",
      "Company-Wise vs Company-Independent Evaluation In our \ufb01nal experiment, we explore the changes in performance we get by splitting the training and test data based on company domain. We compare this performance with our standard setup for SVM-HMM from our baseline experiments (Figure 4), where our train-test data splitting is company-independent (i.e. all conversations are randomized, and no information is used to differentiate different companies or domains). To recap, our data consists of conversations from four companies from three different industrial domains (one from the telecommunication domain, two from the electronics domain, and one from the insurance domain). We create four different versions of our 6-class real-time sequential SVM-HMM, where we train on the data from three of the companies, and test on the remaining company. We present our \ufb01ndings in Table 7.",
      "We create four different versions of our 6-class real-time sequential SVM-HMM, where we train on the data from three of the companies, and test on the remaining company. We present our \ufb01ndings in Table 7. Table 7: Company-Wise vs Company-Independent Evaluation for 6-Class Sequential SVM-HMM Experimental Setup Weighted Company-Wise F-Measure Train/Test Fold Size Test-Electronics-1, Train Rest 0.632 493 / 307 Test-Electronics-2, Train Rest 0.599 592 / 208 Test-Telecom, Train Rest 0.585 604 / 196 Test-Insurance, Train Rest 0.523 711 / 89 Company-Independent 0.658 - From the table, we see that our real-time model achieves best prediction results when we use one of the electronics companies in the test fold, even though the number of training samples is smallest in these cases. On the other hand, when we assign insurance company in the test fold, our model\u2019s prediction performance is comparatively low.",
      "On the other hand, when we assign insurance company in the test fold, our model\u2019s prediction performance is comparatively low. Upon further investigation, we \ufb01nd that customer-agent conversations in the telecommunication and electronics domains are more similar than those in the insurance domain. Our \ufb01ndings show that our model is robust to different domains as our test set size increases, and that our more generic, company-independent experiment gives us better performance than any domain-speci\ufb01c experiments. CONVERSATION OUTCOME ANALYSIS Given our observation that Agent turns are more pre- dictable, and that we achieve best performance in a company- independent setting, we question whether the training that agents receive is actually reliable in terms of resulting in over- all \u201csatis\ufb01ed customers\u201d, regardless of company domain. Ulti- mately, our goal is to discover whether we can use the insight we derive from our predicted dialogue acts to better inform conversational systems aimed at offering customer support. Our next set of experiments aims to show the utility of our real-time dialogue act classi\ufb01cation as a method for summa- rizing semantic intent in a conversation into rules that can be used to guide automated systems.",
      "Our next set of experiments aims to show the utility of our real-time dialogue act classi\ufb01cation as a method for summa- rizing semantic intent in a conversation into rules that can be used to guide automated systems. Classifying Problem Outcomes We conduct three supervised classi\ufb01cation experiments to bet- ter understand full conversation outcome, using the default Linear SVC classi\ufb01er in Scikit-Learn [24] (which gave us our best baseline for the dialogue classi\ufb01cation task). Each classi\ufb01cation experiments centers around one of three prob- lem outcomes: customer satisfaction, problem resolution, and customer frustration. For each outcome, we remove any con- versation that did not receive majority consensus for a label, or received majority vote of \u201ccan\u2019t tell\u201d. Our \ufb01nal conversa- tion sets consist of 216 satis\ufb01ed and 500 unsatis\ufb01ed customer conversations, 271 resolved and 425 unresolved problem con- versations, and 534 frustrated and 229 not frustrated customer conversations. We retain the inherent imbalance in the data to match the natural distribution observed.",
      "We retain the inherent imbalance in the data to match the natural distribution observed. The clear excess of consensus of responses that indicate negative outcomes fur- ther motivates us to understand what sorts of dialogic patterns results in such outcomes. We run the experiment for each conversation outcome using 10-fold cross-validation, under each of our four class settings: 6-Class, 8-Class, 10-Class (Easy), and 10-Class (Hard). The \ufb01rst feature set we use is Best_Features (from the original dialogue act classi\ufb01cation experiments), which we run as a baseline. Our second feature set is our Dialogue_Acts predictions for each turn \u2013 we choose the most probable dialogue act predic- tion for each turn using our dialogue act classi\ufb01cation frame- work to avoid sparsity. In this way, for each class size N, each conversation is converted into a vector of N (up to 10) features that describe the most strongly associated dialogue act from the dialogue act classi\ufb01cation experiments for each turn, and the corresponding turn number.",
      "In this way, for each class size N, each conversation is converted into a vector of N (up to 10) features that describe the most strongly associated dialogue act from the dialogue act classi\ufb01cation experiments for each turn, and the corresponding turn number. For example, a conversation feature vector may look as follows: \uf8ee \uf8ef\uf8f0 statement_complaint : turn_1 request_info : turn_2 ... greeting_closing : turn_N \uf8f9 \uf8fa\uf8fb Thus, our classi\ufb01er can then learn patterns based on these features (for example, that speci\ufb01c acts appearing at the end of a conversation are strong indicators of customer satisfaction) that allow us to derive rules about successful/unsuccessful interactions. Figure 6 shows the results of our binary classi\ufb01cation ex- periments for each outcome. For each experiment, the Best_Features set is constant over each class size, while the Dialogue_Act features are affected by class size (since the predicted act for each turn will change based on the set of acts available for that class size).",
      "For each experiment, the Best_Features set is constant over each class size, while the Dialogue_Act features are affected by class size (since the predicted act for each turn will change based on the set of acts available for that class size). Our \ufb01rst observation is that we achieve high performance on the binary classi\ufb01cation task, reaching F-measures of 0.70, 0.65, and 0.83 for the satisfac- tion, resolution, and frustration outcomes, respectively. Also, we observe that the performance of our predicted dialogue act features is comparable to that of the much larger set of best features for each label (almost identical in the case of frustration). In more detail, we note interesting differences comparing the performance of the small set of dialogue act features that \u201csummarize\u201d the large, sparse set of best features for each label, as a form of data-driven feature selection. For satisfaction, we see that the best feature set outperforms the dialogue acts for",
      "(a) Satisfaction Outcome (b) Resolution Outcome (c) Frustration Outcome Figure 6: Plot of Dialogue Act Features vs. Best Feature Sets for Satisfaction, Resolution, and Frustration Outcomes each class set except for 10-Class (Easy), where the dialogue acts are more effective. The existence of the very lexically well-de\ufb01ned Social Act Thanking and Social Act Apology classes makes the dialogue acts ideal for summarization. In the case of problem resolution, we see that the performance of the dialogue acts approaches that of the best feature set as the number of classes increases, showing that the dialogue features are able to express the full intent of the turns well, even at more dif\ufb01cult class settings. Finally, for the frustration experiment, we observe negligible different between the best features and dialogue act features, and very high classi\ufb01cation results overall. Actionable Rules for Automated Customer Support While these experiments highlight how we can use dialogue act predictions as a means to greatly reduce feature sparsity and predict conversation outcome, our main aim is to gain good insight from the use of the dialogue acts to inform and automate customer service interactions.",
      "Actionable Rules for Automated Customer Support While these experiments highlight how we can use dialogue act predictions as a means to greatly reduce feature sparsity and predict conversation outcome, our main aim is to gain good insight from the use of the dialogue acts to inform and automate customer service interactions. We conduct deeper analysis by taking a closer look at the most informative dia- logue act features in each experiment. Table 8 shows the most informative features and weights for each of our three conversation outcomes. To help guide our analysis, we divide the features into positions based on where they occur in the conversation: start (turns 1-3), middle (turns 4-6), and end (turns 7-10). Desirable outcomes (customers that are satis\ufb01ed/not frustrated and resolved problems) are shown at the top rows of the table, and undesirable outcomes (unsatis\ufb01ed/frustrated customers and unresolved problems) are shown at the bottom rows. Our analysis helps zone in on how the use of certain dialogue acts may be likely to result in different outcomes.",
      "Our analysis helps zone in on how the use of certain dialogue acts may be likely to result in different outcomes. The weights we observe vary in the amount of insight provided: for exam- ple, offering extra help at the end of a conversation, or thanking the customer yields more satis\ufb01ed customers, and more re- solved problems (with ratios of above 6:1). However, some outcomes are much more subtle: for example, asking yes-no questions early-on in a conversation is highly associated with problem resolution (ratio 3:1), but asking them at the end of a conversation has as similarly strong association with unsatis- \ufb01ed customers. Giving elaborate answers that are not a simple af\ufb01rmative, negative, or response acknowledgement (i.e. An- swer (Other)) towards the middle of a conversation leads to satis\ufb01ed customers that are not frustrated. Likewise, request- ing information towards the end of a conversation (implying that more information is still necessary at the termination of the dialogue) leads to unsatis\ufb01ed and unresolved customers, with ratios of at least 4:1.",
      "Likewise, request- ing information towards the end of a conversation (implying that more information is still necessary at the termination of the dialogue) leads to unsatis\ufb01ed and unresolved customers, with ratios of at least 4:1. By using the feature weights we derive from using our pre- dicted dialogue acts in our outcome classi\ufb01cation experiments, we can thus derive data-driven patterns that offer useful in- sight into good/bad practices. Our goal is to then use these rules as guidelines, serving as a basis for automated response planning in the customer service domain. For example, these rules can be used to recommend certain dialogue act responses given the position in a conversation, and based previous turns. This information, derived from correlation with conversation outcomes, gives a valuable addition to conversational \ufb02ow for intelligent agents, and is more useful than canned responses. CONCLUSIONS In this paper, we explore how we can analyze dialogic trends in customer service conversations on Twitter to offer insight into good/bad practices with respect to conversation outcomes. We design a novel taxonomy of \ufb01ne-grained dialogue acts, tai- lored for the customer service domain, and gather annotations for 800 Twitter conversations.",
      "We design a novel taxonomy of \ufb01ne-grained dialogue acts, tai- lored for the customer service domain, and gather annotations for 800 Twitter conversations. We show that dialogue acts are often semantically overlapping, and conduct multi-label supervised learning experiments to predict multiple appro- priate dialogue act labels for each turn in real-time, under varying class sizes. We show that our sequential SVM-HMM model outperforms all non-sequential baselines, and plan to continue our exploration of other sequential models including Conditional Random Fields (CRF) [19] and Long Short-Term Memory (LSTM) [10], as well as of dialogue modeling using different Markov Decision Process (MDP) [25] models such as the Partially-Observed MDP (POMDP) [8]. We establish that agents are more predictable than customers in terms of the dialogue acts they utilize, and set out to un- derstand whether the conversation strategies agents employ are well-correlated with desirable conversation outcomes. We conduct binary classi\ufb01cation experiments to analyze how our predicted dialogue acts can be used to classify conversations",
      "Table 8: Most Informative Dialogue Act Features and Derivative Actionable Insights, by Conversation Outcome Dialogue Act Example Position Outcome Weight Offering more help We can contact you if you like. Please DM us your info. End Satis\ufb01ed 13.25 Resolved 8.72 Thanking Thanks for your reply! We\u2019re happy to hear your issue End Satis\ufb01ed 8.58 has been taken care of. Resolved 6.77 Answer (Other) You can view our available selection of iPhone 6 Start Satis\ufb01ed 3.46 cases here <link> :) Not Frustrated 3.5 Apology I do apologize for the inconvenience. Please provide me with the cross streets and zip code, so I can look into this for you. Mid Satis\ufb01ed 3.31 Suggestion Oh that\u2019s odd! Let\u2019s start by power cycling Start Resolved 5.98 your console: <link> Not Frustrated 3.52 Question Yes-No I\u2019m sorry if you were unable to speak with a manager. Start Resolved 3.30 Are there any questions I can assist you with?",
      "Let\u2019s start by power cycling Start Resolved 5.98 your console: <link> Not Frustrated 3.52 Question Yes-No I\u2019m sorry if you were unable to speak with a manager. Start Resolved 3.30 Are there any questions I can assist you with? Not Frustrated 3.39 Statement Info I\u2019m so sorry you were given con\ufb02icting info. The discounted iphone 6 starts at $199.99 with a new 2-year contract. Start Not Frustrated 4.29 Suggestion We do not DM, but you can send the details to End Unsatis\ufb01ed 5.45 twitter@[agent].com - we should be able to look into this. Unresolved 5.98 Request Info Please DM us your name, state, and policy number so we can End Unsatis\ufb01ed 4.32 have someone review your policy for discounts. Unresolved 5.30 Question Yes-No Hmm, does the messaging showing match any of those on this page: <link>? End Unsatis\ufb01ed 3.19 Complaint Well what I received last night was not high quality service.",
      "Unresolved 5.30 Question Yes-No Hmm, does the messaging showing match any of those on this page: <link>? End Unsatis\ufb01ed 3.19 Complaint Well what I received last night was not high quality service. End Unsatis\ufb01ed 3.00 Especially for what I pay. You will be hearing from me. Mid Frustrated 8.56 Apology I\u2019m sorry to hear about this. Have you checked your spam mail? Start Frustrated 2.92 Statement Info No, normally you\u2019re supposed to receive them within minutes. End Frustrated 5.35 Expressive Neg. I reinstated online. Just mad was told would not be cancelled, and it happened anyway. Mid Unresolved 2.58 as ending in customer satisfaction, customer frustration, and problem resolution. We observe interesting correlations be- tween the dialogue acts agents use and the outcomes, offering insights into good/bad practices that are more useful for creat- ing context-aware automated customer service systems than generating canned response templates. Future directions for this work revolve around the integration of the insights derived in the design of automated customer service systems.",
      "Future directions for this work revolve around the integration of the insights derived in the design of automated customer service systems. To this end, we aim to improve the taxonomy and annotation design by consulting domain-experts and using annotator feedback and agreement information, derive more powerful features for dialogue act prediction, and automate ranking and selection of best-practice rules based on domain requirements for automated customer service system design. REFERENCES 1. James Allen, George Ferguson, and Amanda Stent. 2001. An architecture for more realistic conversational systems. In Proceedings of the 6th international conference on Intelligent user interfaces. ACM, 1\u20138. 2. Yasemin Altun, Ioannis Tsochantaridis, and Thomas Hofmann. 2003. Hidden Markov Support Vector Machines. (2003). 3. J. L. Austin. 1962. How to do things with words. Harvard University Press, Cambridge. 4. Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python (1st ed.). O\u2019Reilly Media, Inc. 5.",
      "1962. How to do things with words. Harvard University Press, Cambridge. 4. Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python (1st ed.). O\u2019Reilly Media, Inc. 5. Harry Bunt, Jan Alexandersson, Jean Carletta, Jae-Woong Choe, Alex Chengyu Fang, Koiti Hasida, Kiyong Lee, Volha Petukhova, Andrei Popescu-Belis, Laurent Romary, Claudia Soria, and David Traum. 2010. Towards an ISO standard for dialogue act annotation. Seventh conference on International Language Resources and Evaluation (LREC\u201910) (2010), 2548\u20132555. 6. Mark G Core and James Allen. 1997. Coding dialogs with the DAMSL annotation scheme. In AAAI fall symposium on communicative action in humans and machines, Vol. 56. Boston, MA. 7. J.L. Fleiss and others. 1971. Measuring nominal scale agreement among many raters.",
      "In AAAI fall symposium on communicative action in humans and machines, Vol. 56. Boston, MA. 7. J.L. Fleiss and others. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin 76, 5 (1971), 378\u2013382. 8. Milica Gasic, Catherine Breslin, Matthew Henderson, Dongho Kim, Martin Szummer, Blaise Thomson, Pirros Tsiakoulis, and Steve Young. 2013. POMDP-based dialogue manager adaptation to extended domains. In Proceedings of the SIGDIAL 2013 Conference. Association for Computational Linguistics, Association for Computational Linguistics, Metz, France, 214\u2013222. 9. Jonathan Herzig, Guy Feigenblat, Michal Shmueli-Scheuer, David Konopnicki, Anat Rafaeli, Daniel Altman, and David Spivak. 2016. Classifying Emotions in Customer Support Dialogues in Social Media. In Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue.",
      "2016. Classifying Emotions in Customer Support Dialogues in Social Media. In Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue. Association for Computational Linguistics, Los Angeles, 64\u201373. 10. Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long Short-Term Memory. Neural Comput. 9, 8 (Nov. 1997), 1735\u20131780.",
      "11. Courtenay Honeycutt and Susan C. Herring. 2009. Beyond Microblogging: Conversation and Collaboration via Twitter. In Proceedings of the Forty-Second Hawai\u2019i International Conference on System Sciences (HICSS-42). Los Alamitos, CA. IEEE Computer Society, Los Alamitos, CA, USA, 1\u201310. 12. Edward Ivanovic. 2005. Dialogue act tagging for instant messaging chat sessions. Proceedings of the ACL Student Research Workshop on - ACL \u201905 June (2005), 79. 13. Edward Ivanovic. 2006. Using Dialogue Acts to Suggest Responses in Support Services via Instant Messaging. Technology (2006), 159\u2013160. 14. Edward Ivanovic. 2008. Automatic instant messaging dialogue using statistical models and dialogue acts. Masters Research thesis (2008). 15. D. Jurafsky, E. Shriberg, and D. Biasca. 1997. Switchboard-DAMSL Labeling Project Coder\u2019s Manual, Draft 13.",
      "Masters Research thesis (2008). 15. D. Jurafsky, E. Shriberg, and D. Biasca. 1997. Switchboard-DAMSL Labeling Project Coder\u2019s Manual, Draft 13. Technical Report 97-02, University of Colorado, Institute of Cognitive Science. Boulder, CO. (1997). 16. Su Nam Kim, Lawrence Cavedon, and Timothy Baldwin. 2012a. Classifying Dialogue Acts in Multi-party Live Chats. 26th Paci\ufb01c Asia Conference on Language, Information and Computation (2012), 463\u2013472. 17. Su Nam Kim, Lawrence Cavedon, and Timothy Baldwin. 2012b. Classifying Dialogue Acts in One-on-one Live Chats. 26th Paci\ufb01c Asia Conference on Language, Information and Computation October (2012), 463\u2013472. 18. Tina Kl\u00fcwer, Hans Uszkoreit, and Feiyu Xu. 2010. Using syntactic and semantic based relations for dialogue act recognition.",
      "18. Tina Kl\u00fcwer, Hans Uszkoreit, and Feiyu Xu. 2010. Using syntactic and semantic based relations for dialogue act recognition. Proceedings of COLING 2010 August (2010), 570\u2013578. 19. John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proceedings of the Eighteenth International Conference on Machine Learning (ICML \u201901). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 282\u2013289. 20. J. Richard Landis and Gary G. Koch. 1977. The Measurement of Observer Agreement for Categorical Data. Biometrics 33, 1 (1977). 21. Ramesh Manuvinakurike, Maike Paetzel, Cheng Qu, David Schlangen, and David DeVault. 2016. Toward incremental dialogue act segmentation in fast-paced interactive dialogue systems.",
      "Biometrics 33, 1 (1977). 21. Ramesh Manuvinakurike, Maike Paetzel, Cheng Qu, David Schlangen, and David DeVault. 2016. Toward incremental dialogue act segmentation in fast-paced interactive dialogue systems. In Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue. Association for Computational Linguistics, Los Angeles, 252\u2013262. 22. Saif M. Mohammad and Peter D. Turney. 2010. Emotions Evoked by Common Words and Phrases: Using Mechanical Turk to Create an Emotion Lexicon. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text (CAAGET \u201910). Association for Computational Linguistics, Stroudsburg, PA, USA, 26\u201334. 23. R. A. Morelli, J. D. Bronzino, and J. W. Goethe. 1991. A computational speech-act model of human-computer conversations.",
      "Association for Computational Linguistics, Stroudsburg, PA, USA, 26\u201334. 23. R. A. Morelli, J. D. Bronzino, and J. W. Goethe. 1991. A computational speech-act model of human-computer conversations. In Bioengineering Conference, 1991., Proceedings of the 1991 IEEE Seventeenth Annual Northeast. 263\u2013264. 24. F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12 (2011), 2825\u20132830. 25. Martin L. Puterman. 1994. Markov Decision Processes: Discrete Stochastic Dynamic Programming (1st ed.).",
      "Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12 (2011), 2825\u20132830. 25. Martin L. Puterman. 1994. Markov Decision Processes: Discrete Stochastic Dynamic Programming (1st ed.). John Wiley & Sons, Inc., New York, NY, USA. 26. Alan Ritter, Colin Cherry, and Bill Dolan. 2010. Unsupervised Modeling of Twitter Conversations. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics, Los Angeles, California, 172\u2013180. 27. H. Sacks and G. Jefferson. 1992. Lectures on Conversation. Number v. 1 in Harvey Sacks : Lectures on Conversation. Blackwell. 28. Amanda Schiffrin. 2005. Modelling Speech Acts in Conversational Discourse. May (2005). 29. J. R. Searle. 1975. Language Mind and Knowledge Minnesota Studies.",
      "Blackwell. 28. Amanda Schiffrin. 2005. Modelling Speech Acts in Conversational Discourse. May (2005). 29. J. R. Searle. 1975. Language Mind and Knowledge Minnesota Studies. in the Philosophy of Science chapter A Taxonomy of Illocutionary Acts. University of Minnesota Press. 30. Andreas Stolcke, Klaus Ries, Noah Coccaro, Elizabeth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul Taylor, Rachel Martin, C.V. Ess-Dykema, and Marie Meteer. 2000. Dialogue act modeling for automatic tagging and recognition of conversational speech. Computational linguistics 26, 3 (2000), 339\u2013373. 31. Ming Sun, Yun-Nung Chen, and Alexander I Rudnicky. 2016. An intelligent assistant for high-level task understanding. In Proceedings of the 21st International Conference on Intelligent User Interfaces. ACM, 169\u2013174. 32. Gokhan Tur, Umit Guz, and Dilek Hakkani-T\u00fcr.",
      "2016. An intelligent assistant for high-level task understanding. In Proceedings of the 21st International Conference on Intelligent User Interfaces. ACM, 169\u2013174. 32. Gokhan Tur, Umit Guz, and Dilek Hakkani-T\u00fcr. 2006. Model adaptation for dialog act tagging. 2006 IEEE ACL Spoken Language Technology Workshop, SLT 2006, Proceedings (2006), 94\u201397. 33. Soroush Vosoughi and Deb Roy. 2013. A Semi-automatic Method for Ef\ufb01cient Detection of Stories on Social Media. (2013), 2013\u20132016. 34. Soroush Vosoughi and Deb Roy. 2016. Tweet acts: A speech act classi\ufb01er for twitter. arXiv preprint arXiv:1605.05156 (2016).",
      "35. Elina Zarisheva and Tatjana Schef\ufb02er. 2015. Dialog Act Annotation for Twitter Conversations. September (2015), 114\u2013123. 36. Renxian Zhang, Dehong Gao, and Wenjie Li. 2011. What Are Tweeters Doing: Recognizing Speech Acts in Twitter. Analyzing Microtext (2011), 86\u201391."
    ],
    "queries":"/future/u/okhattab/data/MSMARCO/queries.train.tsv",
    "index_name":"PaperTab-question-1709.05413.pdf",
    "overwrite":false,
    "root":".ragatouille/",
    "experiment":"colbert",
    "index_root":null,
    "name":"2025-05/17/10.22.50",
    "rank":0,
    "nranks":1,
    "amp":true,
    "gpus":1,
    "avoid_fork_if_possible":false
  },
  "num_chunks":1,
  "num_partitions":1024,
  "num_embeddings":13879,
  "avg_doclen":177.9358974359,
  "RAGatouille":{
    "index_config":{
      "index_type":"PLAID",
      "index_name":"PaperTab-question-1709.05413.pdf"
    }
  }
}