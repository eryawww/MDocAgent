{
  "config":{
    "query_token_id":"[unused0]",
    "doc_token_id":"[unused1]",
    "query_token":"[Q]",
    "doc_token":"[D]",
    "ncells":null,
    "centroid_score_threshold":null,
    "ndocs":null,
    "load_index_with_mmap":false,
    "index_path":null,
    "index_bsize":32,
    "nbits":4,
    "kmeans_niters":20,
    "resume":false,
    "pool_factor":1,
    "clustering_mode":"hierarchical",
    "protected_tokens":0,
    "similarity":"cosine",
    "bsize":64,
    "accumsteps":1,
    "lr":0.00001,
    "maxsteps":400000,
    "save_every":null,
    "warmup":20000,
    "warmup_bert":null,
    "relu":false,
    "nway":64,
    "use_ib_negatives":true,
    "reranker":false,
    "distillation_alpha":1.0,
    "ignore_scores":false,
    "model_name":null,
    "query_maxlen":32,
    "attend_to_mask_tokens":false,
    "interaction":"colbert",
    "dim":128,
    "doc_maxlen":256,
    "mask_punctuation":true,
    "checkpoint":"colbert-ir/colbertv2.0",
    "triples":"/future/u/okhattab/root/unit/experiments/2021.10/downstream.distillation.round2.2_score/round2.nway6.cosine.ib/examples.64.json",
    "collection":[
      "Marrying Universal Dependencies and Universal Morphology Arya D. McCarthy1, Miikka Silfverberg2, Ryan Cotterell1, Mans Hulden2, and David Yarowsky1 1Johns Hopkins University 2University of Colorado Boulder {arya,rcotter2,yarowsky}@jhu.edu {miikka.silfverberg,mans.hulden}@colorado.edu Abstract The Universal Dependencies (UD) and Uni- versal Morphology (UniMorph) projects each present schemata for annotating the mor- phosyntactic details of language. Each project also provides corpora of annotated text in many languages\u2014UD at the token level and UniMorph at the type level. As each cor- pus is built by different annotators, language- speci\ufb01c decisions hinder the goal of universal schemata. With compatibility of tags, each project\u2019s annotations could be used to validate the other\u2019s. Additionally, the availability of both type- and token-level resources would be a boon to tasks such as parsing and homograph disambiguation.",
      "With compatibility of tags, each project\u2019s annotations could be used to validate the other\u2019s. Additionally, the availability of both type- and token-level resources would be a boon to tasks such as parsing and homograph disambiguation. To ease this interoperability, we present a deterministic mapping from Uni- versal Dependencies v2 features into the Uni- Morph schema. We validate our approach by lookup in the UniMorph corpora and \ufb01nd a macro-average of 64.13% recall. We also note incompatibilities due to paucity of data on ei- ther side. Finally, we present a critical evalu- ation of the foundations, strengths, and weak- nesses of the two annotation projects. 1 Introduction The two largest standardized, cross-lingual datasets for morphological annotation are provided by the Universal Dependencies (UD; Nivre et al., 2017) and Universal Morphology (UniMorph; Sylak- Glassman et al., 2015; Kirov et al., 2018) projects. Each project\u2019s data are annotated according to its own cross-lingual schema, prescribing how fea- tures like gender or case should be marked.",
      "Each project\u2019s data are annotated according to its own cross-lingual schema, prescribing how fea- tures like gender or case should be marked. The schemata capture largely similar information, so one may want to leverage both UD\u2019s token-level treebanks and UniMorph\u2019s type-level lookup tables and unify the two resources. This would permit a leveraging of both the token-level UD treebanks and the type-level UniMorph tables of paradigms. Unfortunately, neither resource perfectly realizes Figure 1: Example of annotation disagreement in UD between two languages on translations of one phrase, reproduced from Malaviya et al. (2018). The \ufb01nal word in each, \u201crefrescante\u201d, is not in\ufb02ected for gender: It has the same surface form whether masculine or feminine. Only in Portuguese, it is annotated as masculine to re- \ufb02ect grammatical concord with the noun it modi\ufb01es. its schema. On a dataset-by-dataset basis, they in- corporate annotator errors, omissions, and human decisions when the schemata are underspeci\ufb01ed; one such example is in Figure 1.",
      "its schema. On a dataset-by-dataset basis, they in- corporate annotator errors, omissions, and human decisions when the schemata are underspeci\ufb01ed; one such example is in Figure 1. A dataset-by-dataset problem demands a dataset- by-dataset solution; our task is not to translate a schema, but to translate a resource. Starting from the idealized schema, we create a rule-based tool for converting UD-schema annotations to UniMorph annotations, incorporating language- speci\ufb01c post-edits that both correct infelicities and also increase harmony between the datasets them- selves (rather than the schemata). We apply this conversion to the 31 languages with both UD and UniMorph data, and we report our method\u2019s recall, showing an improvement over the strategy which just maps corresponding schematic features to each other. Further, we show similar downstream per- formance for each annotation scheme in the task of morphological tagging. arXiv:1810.06743v1  [cs.CL]  15 Oct 2018",
      "This tool enables a synergistic use of UniMorph and Universal Dependencies, as well as teasing out the annotation discrepancies within and across projects. When one dataset disobeys its schema or disagrees with a related language, the \ufb02aws may not be noticed except by such a methodological dive into the resources. When the maintainers of the resources ameliorate these \ufb02aws, the resources move closer to the goal of a universal, cross-lingual inventory of features for morphological annotation. The contributions of this work are: \u2022 We detail a deterministic mapping from UD morphological annotations to UniMorph. Language-speci\ufb01c edits of the tags in 31 lan- guages increase harmony between converted UD and existing UniMorph data (\u00a75). \u2022 We provide an implementation of this map- ping and post-editing, which replaces the UD features in a CoNLL-U \ufb01le with UniMorph features.1 \u2022 We demonstrate that downstream perfor- mance tagging accuracy on UD treebanks is similar, whichever annotation schema is used (\u00a77).",
      "\u2022 We provide an implementation of this map- ping and post-editing, which replaces the UD features in a CoNLL-U \ufb01le with UniMorph features.1 \u2022 We demonstrate that downstream perfor- mance tagging accuracy on UD treebanks is similar, whichever annotation schema is used (\u00a77). \u2022 We provide a partial inventory of missing at- tributes or annotation inconsistencies in both UD and UniMorph, a guidepost for strength- ening and harmonizing each resource. 2 Background: Morphological In\ufb02ection Morphological in\ufb02ection is the act of altering the base form of a word (the lemma, represented in fixed-width type) to encode morphosyntac- tic features. As an example from English, prove takes on the form \u201cproved\u201d to indicate that the ac- tion occurred in the past. (We will represent all surface forms in quotation marks.) The process oc- curs in the majority of the world\u2019s widely-spoken languages, typically through meaningful af\ufb01xes. The breadth of forms created by in\ufb02ection creates a challenge of data sparsity for natural language pro- cessing: The likelihood of observing a particular word form diminishes.",
      "The process oc- curs in the majority of the world\u2019s widely-spoken languages, typically through meaningful af\ufb01xes. The breadth of forms created by in\ufb02ection creates a challenge of data sparsity for natural language pro- cessing: The likelihood of observing a particular word form diminishes. A classic result in psycholinguistics (Berko, 1958) shows that in\ufb02ectional morphology is a fully productive process. Indeed, it cannot be that hu- mans simply have the equivalent of a lookup table, 1Available at https://www.github.com/ unimorph/ud-compatibility. Simple label Form PTB tag Present, 3rd singular \u201cproves\u201d VBZ Present, other \u201cprove\u201d VBP Past \u201cproved\u201d VBD Past participle \u201cproven\u201d VBN Present participle \u201cproving\u201d VBG Table 1: In\ufb02ected forms of the English verb prove, along with their Penn Treebank tags where they store the in\ufb02ected forms for retrieval as the syntactic context requires. Instead, there needs to be a mental process that can generate properly in\ufb02ected words on demand.",
      "Instead, there needs to be a mental process that can generate properly in\ufb02ected words on demand. Berko (1958) showed this insightfully through the \u201cwug\u201d-test, an experi- ment where she forced participants to correctly in- \ufb02ect out-of-vocabulary lemmata, such as the novel noun wug. Certain features of a word do not vary depending on its context: In German or Spanish where nouns are gendered, the word for onion will always be grammatically feminine. Thus, to prepare for later discussion, we divide the morphological features of a word into two categories: the modi\ufb01able in- \ufb02ectional features and the \ufb01xed lexical features. A part of speech (POS) is a coarse syntactic category (like \u201cverb\u201d) that begets a word\u2019s partic- ular menu of lexical and in\ufb02ectional features. In English, verbs express no gender, and adjectives do not re\ufb02ect person or number. The part of speech dictates a set of in\ufb02ectional slots to be \ufb01lled by the surface forms.",
      "In English, verbs express no gender, and adjectives do not re\ufb02ect person or number. The part of speech dictates a set of in\ufb02ectional slots to be \ufb01lled by the surface forms. Completing these slots for a given lemma and part of speech gives a paradigm: a mapping from slots to surface forms. Regular En- glish verbs have \ufb01ve slots in their paradigm (Long, 1957), which we illustrate for the verb prove, us- ing simple labels for the forms in Table 1. A morphosyntactic schema prescribes how lan- guage can be annotated\u2014giving stricter categories than our simple labels for prove\u2014and can vary in the level of detail provided. Part of speech tags are an example of a very coarse schema, ig- noring details of person, gender, and number. A slightly \ufb01ner-grained schema for English is the Penn Treebank tagset (Marcus et al., 1993), which includes signals for English morphology. For in- stance, its VBZ tag pertains to the specially in- \ufb02ected 3rd-person singular, present-tense verb form (e.g.",
      "For in- stance, its VBZ tag pertains to the specially in- \ufb02ected 3rd-person singular, present-tense verb form (e.g. \u201cproves\u201d in Table 1). If the tag in a schema is detailed enough that it exactly speci\ufb01es a slot in a paradigm, it is",
      "called a morphosyntactic description (MSD).2 These descriptions require varying amounts of de- tail: While the English verbal paradigm is small enough to \ufb01t on a page, the verbal paradigm of the Northeast Caucasian language Archi can have over 1,500,000 slots (Kibrik, 1998). 3 Two Schemata, Two Philosophies Unlike the Penn Treebank tags, the UD and Uni- Morph schemata are cross-lingual and include a fuller lexicon of attribute-value pairs, such as PER- SON: 1. Each was built according to a different set of principles. UD\u2019s schema is constructed bottom- up, adapting to include new features when they\u2019re identi\ufb01ed in languages. UniMorph, conversely, is top-down: A cross-lingual survey of the literature of morphological phenomena guided its design. UniMorph aims to be linguistically complete, con- taining all known morphosyntactic attributes. Both schemata share one long-term goal: a total inven- tory for annotating the possible morphosyntactic features of a word.",
      "UniMorph aims to be linguistically complete, con- taining all known morphosyntactic attributes. Both schemata share one long-term goal: a total inven- tory for annotating the possible morphosyntactic features of a word. 3.1 Universal Dependencies The Universal Dependencies morphological schema comprises part of speech and 23 additional attributes (also called features in UD) annotating meaning or syntax, as well as language-speci\ufb01c attributes. In order to ensure consistent annotation, attributes are included into the general UD schema if they occur in several corpora. Language-speci\ufb01c attributes are used when only one corpus annotates for a speci\ufb01c feature. The UD schema seeks to balance language- speci\ufb01c and cross-lingual concerns. It annotates for both in\ufb02ectional features such as case and lexi- cal features such as gender. Additionally, the UD schema annotates for features which can be inter- preted as derivational in some languages.",
      "It annotates for both in\ufb02ectional features such as case and lexi- cal features such as gender. Additionally, the UD schema annotates for features which can be inter- preted as derivational in some languages. For ex- ample, the Czech UD guidance uses a COLL value for the NUMBER feature to denote mass nouns (for example, \u201dlidstvo\u201d \u201dhumankind\u201d from the root \u201dlid\u201d \u201dpeople\u201d).3 UD represents a confederation of datasets (see, e.g., Dirix et al., 2017) annotated with dependency relationships (which are not the focus of this work) and morphosyntactic descriptions. Each dataset 2Other sources will call this a morphological tag or bundle. We avoid the former because of the analogy to POS tagging; a morphological tag is not atomic. 3Note that NUMBER: COLL does not actually \ufb01gure in the Czech corpus. is an annotated treebank, making it a resource of token-level annotations. The schema is guided by these treebanks, with feature names chosen for rele- vance to native speakers.",
      "3Note that NUMBER: COLL does not actually \ufb01gure in the Czech corpus. is an annotated treebank, making it a resource of token-level annotations. The schema is guided by these treebanks, with feature names chosen for rele- vance to native speakers. (In \u00a73.2, we will contrast this with UniMorph\u2019s treatment of morphosyntac- tic categories.) The UD datasets have been used in the CoNLL shared tasks (Zeman et al., 2017, 2018 to appear). 3.2 UniMorph In the Universal Morphological Feature Schema (UniMorph schema, Sylak-Glassman, 2016), there are at least 212 values, spread across 23 attributes. It identi\ufb01es some attributes that UD excludes like information structure and deixis, as well as pro- viding more values for certain attributes, like 23 different noun classes endemic to Bantu languages. As it is a schema for marking morphology, its part of speech attribute does not have POS values for punctuation, symbols, or miscellany (PUNCT, SYM, and X in Universal Dependencies).",
      "As it is a schema for marking morphology, its part of speech attribute does not have POS values for punctuation, symbols, or miscellany (PUNCT, SYM, and X in Universal Dependencies). Like the UD schema, the decomposition of a word into its lemma and MSD is directly compara- ble across languages. Its features are informed by a distinction between universal categories, which are widespread and psychologically \u201creal\u201d to speak- ers; and comparative concepts, only used by lin- guistic typologists to compare languages (Haspel- math, 2010). Additionally, it strives for identity of meaning across languages, not simply similarity of terminology. As a prime example, it does not regularly label a dative case for nouns, for reasons explained in depth by Haspelmath (2010).4 The UniMorph resources for a language con- tain complete paradigms extracted from Wiktionary (Kirov et al., 2016, 2018). Word types are anno- tated to form a database, mapping a lemma\u2013tag pair to a surface form. The schema is explained in detail in Sylak-Glassman (2016).",
      "Word types are anno- tated to form a database, mapping a lemma\u2013tag pair to a surface form. The schema is explained in detail in Sylak-Glassman (2016). It has been used in the SIGMORPHON shared task (Cotterell et al., 2016) and the CoNLL\u2013SIGMORPHON shared tasks (Cot- terell et al., 2017, 2018). Several components of the UniMorph schema have been adopted by UD.5 4\u201cThe Russian Dative, the Korean Dative, and the Turkish Dative are similar enough to be called by the same name, but there are numerous differences between them and they cannot be simply equated with each other. Clearly, their nature is not captured satisfactorily by saying that they are instantiations of a crosslinguistic category \u2018dative\u2019.\u201d (Haspelmath, 2010) 5http://universaldependencies.org/v2/ features.html#comparison-with-unimorph",
      "Schema Annotation UD VERB MOOD=IND|NUMBER=SING|PERSON=3|TENSE=IMP|VERBFORM=FIN UniMorph V;IND;PST;1;SG;IPFV V;IND;PST;3;SG;IPFV Table 2: Attested annotations for the Spanish verb form \u201cmandaba\u201d \u201cI/he/she/it commanded\u201d. Note that UD separates the part of speech from the remainder of the morphosyntactic description. In each schema, order of the values is irrelevant. 3.3 Similarities in the annotation While the two schemata annotate different features, their annotations often look largely similar. Con- sider the attested annotation of the Spanish word \u201cmandaba\u201d \u201c(I/he/she/it) commanded\u201d. Table 2 shows that these annotations share many attributes.",
      "3.3 Similarities in the annotation While the two schemata annotate different features, their annotations often look largely similar. Con- sider the attested annotation of the Spanish word \u201cmandaba\u201d \u201c(I/he/she/it) commanded\u201d. Table 2 shows that these annotations share many attributes. Some conversions are straightforward: VERB to V, MOOD=IND to IND, NUMBER=SING to SG, and PERSON=3 to 3.6 One might also suggest mapping TENSE=IMP to IPFV, though this crosses semantic categories: IPFV represents the imper- fective aspect, whereas TENSE=IMP comes from imperfect, the English name often given to Span- ish\u2019s pasado continuo form. The imperfect is a verb form which combines both past tense and im- perfective aspect. UniMorph chooses to split this into the atoms PST and IPFV, while UD uni\ufb01es them according to the familiar name of the tense. 4 UD treebanks and UniMorph tables Prima facie, the alignment task may seem trivial. But we\u2019ve yet to explore the humans in the loop. This conversion is a hard problem because we\u2019re operating on idealized schemata.",
      "4 UD treebanks and UniMorph tables Prima facie, the alignment task may seem trivial. But we\u2019ve yet to explore the humans in the loop. This conversion is a hard problem because we\u2019re operating on idealized schemata. We\u2019re actually annotating human decisions\u2014and human mistakes. If both schemata were perfectly applied, their over- lapping attributes could be mapped to each other simply, in a cross-lingual and totally general way. Unfortunately, the resources are imperfect realiza- tions of their schemata. The cross-lingual, cross- resource, and within-resource problems that we\u2019ll note mean that we need a tailor-made solution for each language. Showcasing their schemata, the Universal De- pendencies and UniMorph projects each present 6The curious reader may wonder why there are two rows of UniMorph annotation for \u201cmandaba\u201d, each with a different recorded person. The word displays syncretism, meaning that a single form realizes multiple MSDs. UniMorph chooses to mark these separately for the sake of its decomposable representation.",
      "The word displays syncretism, meaning that a single form realizes multiple MSDs. UniMorph chooses to mark these separately for the sake of its decomposable representation. As this ambiguity is systematic and pervasive in the language, one can imagine a uni\ufb01ed paradigm slot V;IND;PST;{1/3};SG;IPFV (Baerman et al., 2005). large, annotated datasets. UD\u2019s v2.1 release (Nivre et al., 2017) has 102 treebanks in 60 languages. The large resource, constructed by independent parties, evinces problems in the goal of a universal inven- tory of annotations. Annotators may choose to omit certain values (like the coerced gender of refres- cante in Figure 1), and they may disagree on how a linguistic concept is encoded. (See, e.g., Haspel- math\u2019s (2010) description of the dative case.) Ad- ditionally, many of the treebanks \u201cwere created by fully- or semi-automatic conversion from treebanks with less comprehensive annotation schemata than UD\u201d (Malaviya et al., 2018).",
      "Ad- ditionally, many of the treebanks \u201cwere created by fully- or semi-automatic conversion from treebanks with less comprehensive annotation schemata than UD\u201d (Malaviya et al., 2018). For instance, the Spanish word \u201cvas\u201d \u201cyou go\u201d is incorrectly labeled GENDER: FEM|NUMBER: PL because it ends in a character sequence which is common among feminine plural nouns. (Nevertheless, the part of speech \ufb01eld for \u201cvas\u201d is correct.) UniMorph\u2019s development is more centralized and pipelined.7 In\ufb02ectional paradigms are scraped from Wiktionary, annotators map positions in the scraped data to MSDs, and the mapping is automat- ically applied to all of the scraped paradigms. Be- cause annotators handle languages they are familiar with (or related ones), realization of the schema is also done on a language-by-language basis. Fur- ther, the scraping process does not capture lexical aspects that are not in\ufb02ected, like noun gender in many languages. The schema permits inclusion of these details; their absence is an artifact of the data collection process.",
      "Fur- ther, the scraping process does not capture lexical aspects that are not in\ufb02ected, like noun gender in many languages. The schema permits inclusion of these details; their absence is an artifact of the data collection process. Finally, UniMorph records only exist for nouns, verbs, and adjectives, though the schema is broader than these categories. For these reasons, we treat the corpora as imper- fect realizations of the schemata. Moreover, we contend that ambiguity in the schemata leave the door open to allow for such imperfections. With no strict guidance, it\u2019s natural that annotators would take different paths. Nevertheless, modulo annota- 7This centralization explains why UniMorph tables exist for only 49 languages, or 50 when counting the Norwegian Nynorsk and Bokm\u02daal writing forms separately.",
      "tegarg latme-ye bad-i be ba:q-e man zad. Hail damage-EZ bad-INDEF PAR to garden-EZ 1.S beat-PST. \u201cThe hail caused bad damage to my garden.\u201d or \u201cThe hail damaged my garden badly.\u201d Figure 2: Transliterated Persian with a gloss and translation from Karimi-Doostan (2011), annotated in a Persian- speci\ufb01c schema. The light verb construction \u201clatme zadan\u201d (\u201cto damage\u201d) has been spread across the sentence. Multiword constructions like this are a challenge for word-level tagging schemata. tor disagreement, we assume that within a partic- ular corpus, one word form will always be consis- tently annotated. Three categories of annotation dif\ufb01culty are missing values, language-speci\ufb01c attributes, and multiword expressions. Missing values In both schemata, irrelevant at- tributes are omitted for words to which they do not pertain. For instance, an English verb is not labeled GENDER=NULL; the GENDER attribute is simply excluded from the annotation, making the human-readable representations compact.",
      "Missing values In both schemata, irrelevant at- tributes are omitted for words to which they do not pertain. For instance, an English verb is not labeled GENDER=NULL; the GENDER attribute is simply excluded from the annotation, making the human-readable representations compact. Unfortu- nately, in both resources, even relevant attributes are intentionally omitted. A verb\u2019s positiveness, activeness, or \ufb01niteness can be taken as implicit, and it will be omitted arbitrarily on a language-by- language basis. For instance, in our example in Table 2 only UD tags Spanish \ufb01nite verbs: VERB- FORM=FIN. Not only UniMorph makes such eli- sions: we note that neither resource marks verb forms as active\u2014an action entirely permitted by the schemata. This is one source of discrepancy, both between the projects and across languages within a project, but it is straightforward to harmo- nize.",
      "Not only UniMorph makes such eli- sions: we note that neither resource marks verb forms as active\u2014an action entirely permitted by the schemata. This is one source of discrepancy, both between the projects and across languages within a project, but it is straightforward to harmo- nize. Language-speci\ufb01c attributes UD records a set of features that are kept language-speci\ufb01c, includ- ing POSITION in Romanian, DIALECT in Rus- sian, and NUMVALUE in Czech and Arabic.8 Uni- Morph has (potentially in\ufb01nite) language-speci\ufb01c features LGSPEC1, LGSPEC2, ..., which are sparsely used but opaque when encountered. For instance, LGSPEC1 in Spanish distinguishes be- tween the two (semantically identical) forms of the imperfect subjunctive: the \u201c-se\u201d and \u201c-ra\u201d forms (e.g. \u201cestuviese\u201d and \u201cestuviera\u201d from \u201cestar\u201d \u201cto be\u201d). UD does not annotate the forms differently.",
      "\u201cestuviese\u201d and \u201cestuviera\u201d from \u201cestar\u201d \u201cto be\u201d). UD does not annotate the forms differently. If a language has multiple language-speci\ufb01c at- 8The complete list is at http:// universaldependencies.org/v2/features. html#inventory-of-features-that-will- stay-language-specific tributes, their order is not prescribed by the Uni- Morph schema, and separate notes that explain the use of such tags must accompany datasets. Multiword expressions A \ufb01nal imperfection is how to represent multiword constructions. Both UD and UniMorph are word-level annotations, es- pousing what has alternately been called the lexi- cal integrity principle (Chomsky, 1970; Bresnan and Mchombo, 1995) or word-based morphol- ogy (Aronoff, 1976, 2007; Spencer, 1991). Un- fortunately, not all morphological manifestations occur at the level of individual words. The Farsi (Persian) light verb construction illustrates the de\ufb01ciency (see Karimi-Doostan, 2011).",
      "Un- fortunately, not all morphological manifestations occur at the level of individual words. The Farsi (Persian) light verb construction illustrates the de\ufb01ciency (see Karimi-Doostan, 2011). Farsi ex- presses many actions by pairing a light verb (one with little meaning) with a noun that gives a con- crete meaning. The example in Figure 2 uses the light verb construction \u201clatme zadan\u201d (\u201cto dam- age\u201d). The parts of the verb construction are sep- arated in the sentence, seeming to require a mor- phosyntactic parse. When attempting to annotate these constructs, neither schema provides guidance. In languages where these occur, language-speci\ufb01c decisions are made. It should be noted that multi- word expressions are a general challenge to natural language processing, not speci\ufb01cally morphology (Sag et al., 2002). 5 A Deterministic Conversion In our work, the goal is not simply to translate one schema into the other, but to translate one re- source (the imperfect manifestation of the schema) to match the other.",
      "5 A Deterministic Conversion In our work, the goal is not simply to translate one schema into the other, but to translate one re- source (the imperfect manifestation of the schema) to match the other. The differences between the schemata and discrepancies in annotation mean that the transformation of annotations from one schema to the other is not straightforward. Two naive options for the conversion are a lookup table of MSDs and a lookup table of the individual attribute-value pairs which comprise the MSDs. The former is untenable: the table of all UD feature combinations (including null features, excluding language-speci\ufb01c attributes) would have",
      "2.445 \u00d7 1017 entries. Of course, most combina- tions won\u2019t exist, but this gives a sense of the table\u2019s scale. Also, it doesn\u2019t leverage the factorial nature of the annotations: constructing the table would re- quire a massive duplication of effort. On the other hand, attribute-value lookup lacks the \ufb02exibility to show how a pair of values interacts. Neither approach would handle language- and annotator- speci\ufb01c tendencies in the corpora. Our approach to converting UD MSDs to Uni- Morph MSDs begins with the attribute-value lookup, then amends it on a language-speci\ufb01c ba- sis. Alterations informed by the MSD and the word form, like insertion, substitution, and dele- tion, increase the number of agreeing annotations. They are critical for work that examines the MSD monolithically instead of feature-by-feature (e.g. Belinkov et al., 2017; Cotterell and Heigold, 2017): Without exact matches, converting the individual tags becomes hollow.",
      "They are critical for work that examines the MSD monolithically instead of feature-by-feature (e.g. Belinkov et al., 2017; Cotterell and Heigold, 2017): Without exact matches, converting the individual tags becomes hollow. Beginning our process, we relied on documen- tation of the two schemata to create our initial, language-agnostic mapping of individual values. This mapping has 140 pairs in it. Because the map- ping was derived purely from the schemata, it is a useful approximation of how well the schemata match up. We note, however, that the mapping does not handle idiosyncrasies like the many uses of \u201cdative\u201d or features which are represented in UniMorph by argument templates: possession and ergative\u2013absolutive argument marking. The initial step of our conversion is using this mapping to populate a proposed UniMorph MSD. As shown in \u00a77, the initial proposal is often frus- tratingly de\ufb01cient. Thus we introduce the post- edits.",
      "The initial step of our conversion is using this mapping to populate a proposed UniMorph MSD. As shown in \u00a77, the initial proposal is often frus- tratingly de\ufb01cient. Thus we introduce the post- edits. To concoct these, we looked into UniMorph corpora for these languages, compared these to the conversion outputs, and then sought to bring the conversion outputs closer to the annotations in the actual UniMorph corpora. When a form and its lemma existed in both corpora, we could directly inspect how the annotations differed. Our process of iteratively re\ufb01ning the conversion implies a ta- ble which exactly maps any combination of UD MSD and its related values (lemma, form, etc.) to a UniMorph MSD, though we do not store the table explicitly. Some conversion rules we\u2019ve created must be applied before or after others. These sequential de- pendencies provide conciseness. Our post-editing procedure operates on the initial MSD hypothesis as follows: 1.",
      "to a UniMorph MSD, though we do not store the table explicitly. Some conversion rules we\u2019ve created must be applied before or after others. These sequential de- pendencies provide conciseness. Our post-editing procedure operates on the initial MSD hypothesis as follows: 1. First, we collect all arguments relating to a possessor or an ergative\u2013absolutive lan- guage\u2019s argument agreement, because Uni- Morph represents both categories as a single templatic value. 2. We discard any values that UniMorph doesn\u2019t annotate for a particular part of speech, like gender and number in French verb participles, or German noun genders. 3. We make MSD additions when they are unam- biguously implied by the resources, like PFV to accompany PST in Spanish \u201cpasado sim- ple\u201d, but PST to accompany IPFV in Spanish \u201cpasado continuo\u201d. 4.",
      "3. We make MSD additions when they are unam- biguously implied by the resources, like PFV to accompany PST in Spanish \u201cpasado sim- ple\u201d, but PST to accompany IPFV in Spanish \u201cpasado continuo\u201d. 4. We also incorporate \ufb01xes using information outside of the MSD like the LGSPEC1 tag for Spanish\u2019s \u201c-ra\u201d forms, as described in \u00a74, and other language-speci\ufb01c corrections, like mapping the various dative cases to the cross- lingually comparable case annotations used in UniMorph. What we left out We did, however, reject certain changes that would increase harmony between the resources. Usually, this decision was made when the UniMorph syntax or tagset was not obeyed, such as in the case of made-up tags for Basque ar- guments (instead of the template mentioned above) or the use of idiopathic colons (:) instead of semi- colons (;) as separators in Farsi. Other instances were linguistically motivated. UD acknowledges Italian imperatives, but UniMorph does not have any in its table. We could largely alter these to have subjunctive labels, but to ill effect.",
      "Other instances were linguistically motivated. UD acknowledges Italian imperatives, but UniMorph does not have any in its table. We could largely alter these to have subjunctive labels, but to ill effect. A third reason to be conservative in our rules was cases of under-speci\ufb01cation: If a participle is not marked as past or present in UD, but both exist in UniMorph, we could unilaterally assign all to the majority cat- egory and increase recall. This would pollute the data with fallacious features, so we leave these cases under-speci\ufb01ed. In other words, we do not add new values that cannot be unequivocally in- ferred from the existing data. Output The Universal Dependencies data are presented in the CoNLL-U format.9 Each sentence 9http://universaldependencies.org/ format.html",
      "is represented in tabular form to organize annota- tions like lemmas, parts of speech, and dependen- cies of each word token. The MSDs are held in a column called FEATS. Our MSD conversion tool produces a CoNLL-U \ufb01le whose FEATS column now contains a UniMorph-style MSD. For more straightforward interface with UniMorph, the fea- ture bundle includes the part of speech tag. As the POS column of the CONLL-U \ufb01le is preserved, this can easily be stripped from the FEATS column, depending on use case. Why not a learned mapping? One can imagine learning the UniMorph MSD corresponding to a UD dataset\u2019s MSD by a set-to-set translation model like IBM Model 1 (Brown et al., 1993). Unfortu- nately, statistical (and especially neural) machine translation generalizes in unreliable ways. Our goal is a straightforward, easily manipulable and exten- sible conversion that prioritizes correctness over coverage.",
      "Unfortu- nately, statistical (and especially neural) machine translation generalizes in unreliable ways. Our goal is a straightforward, easily manipulable and exten- sible conversion that prioritizes correctness over coverage. 6 Experiments We evaluate our tool on two tasks: Intrinsic assessment: Once we convert UD MSDs to UniMorph MSDs, how many of the converted ones are attested in UniMorph\u2019s paradigm tables. Extrinsic assessment: Whether performance on a downstream task is comparable when using pre- and post-conversion MSDs. To be clear, our scope is limited to the schema conversion. Future work will explore NLP tasks that exploit both the created token-level UniMorph data and the existing type-level UniMorph data. Data We draw our input data from the UD v2.1 treebanks (Nivre et al., 2017). When multiple tree- banks exist for a language, we select the one with a basic name, e.g. \u201cSpanish\u201d instead of \u201cSpanish- AnCora\u201d. We leave the construction of additional converters to future work, and we invite the com- munity to participate in designing the mappings for all UD treebanks.",
      "\u201cSpanish\u201d instead of \u201cSpanish- AnCora\u201d. We leave the construction of additional converters to future work, and we invite the com- munity to participate in designing the mappings for all UD treebanks. UniMorph modi\ufb01es its language packs individually instead of offering versioned re- leases. Our UniMorph lookup tables are the latest versions at the time of writing.10 There are 31 lan- guages which possess both a UD and a UniMorph corpus. 10As of 19 June 2018, the latest modi\ufb01cation to a UniMorph language resource was to Finnish on 3 August 2017. 6.1 Intrinsic evaluation We transform all UD data to the UniMorph. We compare the simple lookup-based transformation to the one with linguistically informed post-edits on all languages with both UD and UniMorph data. We then evaluate the recall of MSDs without partial credit. Calculating recall Because the UniMorph tables only possess annotations for verbs, nouns, adjec- tives, or some combination, we can only examine performance for these parts of speech.",
      "We then evaluate the recall of MSDs without partial credit. Calculating recall Because the UniMorph tables only possess annotations for verbs, nouns, adjec- tives, or some combination, we can only examine performance for these parts of speech. We consider two words to be a match if their form and lemma are present in both resources. Syncretism allows a single surface form to realize multiple MSDs (Spanish \u201cmandaba\u201d can be \ufb01rst- or third-person), so we de\ufb01ne success as the computed MSD match- ing any of the word\u2019s UniMorph MSDs. This gives rise to an equation for recall: of the word\u2013lemma pairs found in both resources, how many of their UniMorph-converted MSDs are present in the Uni- Morph tables? Why no held-out test set? Our problem here is not a learning problem, so the question is ill-posed. There is no training set, and the two resources for a given language make up a test set. The quality of our model\u2014the conversion tool\u2014comes from how well we encode prior knowledge about the relation- ship between the UD and UniMorph corpora.",
      "There is no training set, and the two resources for a given language make up a test set. The quality of our model\u2014the conversion tool\u2014comes from how well we encode prior knowledge about the relation- ship between the UD and UniMorph corpora. 6.2 Extrinsic evaluation If the UniMorph-converted treebanks perform dif- ferently on downstream tasks, then they convey different information. This signals a failure of the conversion process. As a downstream task, we choose morphological tagging, a critical step to leveraging morphological information on new text. We evaluate taggers trained on the transformed UD data, choosing eight languages randomly from the intersection of UD and UniMorph resources. We report the macro-averaged F1 score of attribute- value pairs on a held-out test set, with of\ufb01cial train/validation/test splits provided in the UD tree- banks. As a reference point, we also report tagging accuracy on those languages\u2019 untransformed data. We use the state-of-the-art morphological tagger of Malaviya et al. (2018).",
      "As a reference point, we also report tagging accuracy on those languages\u2019 untransformed data. We use the state-of-the-art morphological tagger of Malaviya et al. (2018). It is a factored con- ditional random \ufb01eld with potentials for each at- tribute, attribute pair, and attribute transition. The potentials are computed by neural networks, pre- dicting the values of each attribute jointly but not",
      "monolithically. Inference with the potentials is per- formed approximately by loopy belief propagation. We use the authors\u2019 hyperparameters. We note a minor implementation detail for the sake of reproducibility. The tagger exploits explicit guidance about the attribute each value pertains to. The UniMorph schema\u2019s values are globally unique, but their attributes are not explicit. For ex- ample, the UniMorph MASC denotes a masculine gender. We amend the code of Malaviya et al. to incorporate attribute identi\ufb01ers for each UniMorph value. 7 Results We present the intrinsic task\u2019s recall scores in Ta- ble 3. Bear in mind that due to annotation errors in the original corpora (like the \u201cvas\u201d example from \u00a74), the optimal score is not always 100%. Some shortcomings of recall come from irremediable an- notation discrepancies. Largely, we are hamstrung by differences in choice of attributes to annotate. When one resource marks gender and the other marks case, we can\u2019t infer the gender of the word purely from its surface form.",
      "Some shortcomings of recall come from irremediable an- notation discrepancies. Largely, we are hamstrung by differences in choice of attributes to annotate. When one resource marks gender and the other marks case, we can\u2019t infer the gender of the word purely from its surface form. The resources them- selves would need updating to encode the relevant morphosyntactic information. Some languages had a very low number of overlapping forms,11 and no tag matches or near-matches between them: Ara- bic, Hindi, Lithuanian, Persian, and Russian. A full list of observed, irremediable discrepancies is presented alongside the codebase. There are three other transformations for which we note no improvement here. Because of the prob- lem in Basque argument encoding in the UniMorph dataset\u2014which only contains verbs\u2014we note no improvement in recall on Basque. Irish also does not improve: UD marks gender on nouns, while UniMorph marks case. Adjectives in UD are also underspeci\ufb01ed. The verbs, though, are already cor- rect with the simple mapping.",
      "Irish also does not improve: UD marks gender on nouns, while UniMorph marks case. Adjectives in UD are also underspeci\ufb01ed. The verbs, though, are already cor- rect with the simple mapping. Finally, with Dutch, the UD annotations are impoverished compared to the UniMorph annotations, and missing attributes cannot be inferred without external knowledge. For the extrinsic task, the performance is reason- ably similar whether UniMorph or UD; see Table 4. A large \ufb02uctuation would suggest that the two an- notations encode distinct information. On the con- trary, the similarities suggest that the UniMorph- mapped MSDs have similar content. We recognize 11Fewer than 250 overlapping form\u2013lemma pairs. The other languages had overlaps in the thousands. Language CSV Post-editing Ar 0.00 - Bg 34.61 87.88 Ca 23.23 99.78 Cs 0.48 81.71 Da 1.55 4.70 De 17.20 60.81 En 42.17 90.10 Es 17.20 97.",
      "61 87.88 Ca 23.23 99.78 Cs 0.48 81.71 Da 1.55 4.70 De 17.20 60.81 En 42.17 90.10 Es 17.20 97.86 Eu 0.00 0.00 Fa 0.00 - Fi 59.19 92.81 Fr 18.61 99.20 Ga 0.41 0.41 He 4.08 46.61 Hi 0.00 - Hu 15.46 24.94 It 22.32 94.89 La 11.73 64.25 Lt 0.00 - Lv 0.17 90.58 Nb 2.11 38.88 Nl 12.12 12.12 Nn 2.40 40.21 Pl 7.70 88.17 Pt 20.11 99.34 Ro 0.00 25.16 Ru 0.00 - Sl 37.57 90.27 Sv 13.20 83.44 Tr 0.00 65.14 Uk 4.06 96.",
      "70 88.17 Pt 20.11 99.34 Ro 0.00 25.16 Ru 0.00 - Sl 37.57 90.27 Sv 13.20 83.44 Tr 0.00 65.14 Uk 4.06 96.45 Ur 0.00 55.72 Table 3: Token-level recall when converting Universal Dependencies tags to UniMorph tags. CSV refers to the lookup-based system. Post-editing refers to the pro- posed method. Language UD F1 UniMorph F1 Da 90.58 92.59 Es 78.31 96.44 Fi 93.78 94.98 Lv 84.20 86.94 Pt 95.57 95.77 Ru 89.89 89.95 Bg 95.54 95.79 Sv 92.39 93.83 Table 4: Tagging F1 using UD sentences annotated with either original UD MSDs or UniMorph-converted MSDs",
      "that in every case, tagging F1 increased\u2014albeit by amounts as small as 0.16 points. This is in part due to the information that is lost in the conversion. UniMorph\u2019s schema does not indicate the type of pronoun (demonstrative, interrogative, etc.), and when lexical information is not recorded in Uni- Morph, we delete it from the MSD during trans- formation. On the other hand, UniMorph\u2019s atomic tags have more parts to guess, but they are often related. (E.g. IPFV always entails PST in Spanish.) Altogether, these forces seem to have little impact on tagging performance. 8 Related Work The goal of a tagset-to-tagset mapping of mor- phological annotations is shared by the Interset project (Zeman, 2008). Interset decodes features in the source corpus to a tag interlingua, then en- codes that into target corpus features. (The idea of an interlingua is drawn from machine translation, where a prevailing early mindset was to convert to a universal representation, then encode that repre- sentation\u2019s semantics in the target language.",
      "(The idea of an interlingua is drawn from machine translation, where a prevailing early mindset was to convert to a universal representation, then encode that repre- sentation\u2019s semantics in the target language. Our approach, by contrast, is a direct \ufb02ight from the source to the target.) Because UniMorph corpora are noisy, the encoding from the interlingua would have to be rewritten for each target. Further, de- coding the UD MSD into the interlingua cannot leverage external information like the lemma and form. The creators of HamleDT sought to harmonize dependency annotations among treebanks, similar to our goal of harmonizing across resources (Ze- man et al., 2014). The treebanks they sought to har- monize used multiple diverse annotation schemes, which the authors uni\ufb01ed under a single scheme. Petrov et al. (2012) present mappings into a coarse, \u201cuniversal\u201d part of speech for 22 languages. Working with POS tags rather than morphological tags (which have far more dimensions), their space of options to harmonize is much smaller than ours.",
      "Petrov et al. (2012) present mappings into a coarse, \u201cuniversal\u201d part of speech for 22 languages. Working with POS tags rather than morphological tags (which have far more dimensions), their space of options to harmonize is much smaller than ours. Our extrinsic evaluation is most in line with the paradigm of Wisniewski and Lacroix (2017) (and similar work therein), who compare syntac- tic parser performance on UD treebanks annotated with two styles of dependency representation. Our problem differs, though, in that the dependency rep- resentations express different relationships, while our two schemata vastly overlap. As our conver- sion is lossy, we do not appraise the learnability of representations as they did. In addition to using the number of extra rules as a proxy for harmony between resources, one could perform cross-lingual projection of morpho- logical tags (Dr\u00b4abek and Yarowsky, 2005; Kirov et al., 2017). Our approach succeeds even without parallel corpora.",
      "Our approach succeeds even without parallel corpora. 9 Conclusion and Future Work We created a tool for annotating Universal Depen- dencies CoNLL-U \ufb01les with UniMorph annota- tions. Our tool is ready to use off-the-shelf today, requires no training, and is deterministic. While under-speci\ufb01cation necessitates a lossy and imper- fect conversion, ours is interpretable. Patterns of mistakes can be identi\ufb01ed and ameliorated. The tool allows a bridge between resources an- notated in the Universal Dependencies and Uni- versal Morphology (UniMorph) schemata. As the Universal Dependencies project provides a set of treebanks with token-level annotation, while the UniMorph project releases type-level annotated ta- bles, the newfound compatibility opens up new experiments. A prime example of exploiting token- and type-level data is T\u00a8ackstr\u00a8om et al. (2013). That work presents a part-of-speech (POS) dictionary built from Wiktionary, where the POS tagger is also constrained to options available in their type- level POS dictionary, improving performance.",
      "(2013). That work presents a part-of-speech (POS) dictionary built from Wiktionary, where the POS tagger is also constrained to options available in their type- level POS dictionary, improving performance. Our transformation means that datasets are prepared for similar experiments with morphological tag- ging. It would also be reasonable to incorporate this tool as a subroutine to UDPipe (Straka and Strakov\u00b4a, 2017) and Udapi (Popel et al., 2017). We leave open the task of converting in the opposite direction, turning UniMorph MSDs into Universal Dependencies MSDs. Because our conversion rules are interpretable, we identify shortcomings in both resources, using each as validation for the other. We were able to \ufb01nd speci\ufb01c instances of incorrectly applied Uni- Morph annotation, as well as speci\ufb01c instances of cross-lingual inconsistency in both resources. These \ufb01ndings will harden both resources and bet- ter align them with their goal of universal, cross- lingual annotation.",
      "These \ufb01ndings will harden both resources and bet- ter align them with their goal of universal, cross- lingual annotation. Acknowledgments We thank Hajime Senuma and John Sylak- Glassman for early comments in devising the start- ing language-independent mapping from Universal Dependencies to UniMorph.",
      "References Mark Aronoff. 1976. Word formation in generative grammar. Linguistic Inquiry Monographs Cam- bridge, Mass., 1:1\u2013134. Mark Aronoff. 2007. In the beginning was the word. Language, 83(4):803\u2013830. Matthew Baerman, Dunstan Brown, Greville G Cor- bett, et al. 2005. The syntax-morphology interface: A study of syncretism, volume 109. Cambridge Uni- versity Press. Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. 2017. What do neural ma- chine translation models learn about morphology? In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 861\u2013872. Jean Berko. 1958. The child\u2019s learning of English mor- phology. Word, 14(2-3):150\u2013177. Joan Bresnan and Sam A. Mchombo. 1995.",
      "Jean Berko. 1958. The child\u2019s learning of English mor- phology. Word, 14(2-3):150\u2013177. Joan Bresnan and Sam A. Mchombo. 1995. The lexical integrity principle: Evidence from Bantu. Natural Language & Linguistic Theory, 13(2):181\u2013254. Peter F Brown, Vincent J Della Pietra, Stephen A Della Pietra, and Robert L Mercer. 1993. The mathemat- ics of statistical machine translation: Parameter esti- mation. Computational linguistics, 19(2):263\u2013311. Noam Chomsky. 1970. Remarks on nominalization. In R. Jacobs and P. Rosenbaum, editors, Reading in English Transformational Grammar, pages 184\u2013 221. Ginn and Co., Waltham. Ryan Cotterell and Georg Heigold. 2017. Cross- lingual character-level neural morphological tag- ging. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 748\u2013759.",
      "Ginn and Co., Waltham. Ryan Cotterell and Georg Heigold. 2017. Cross- lingual character-level neural morphological tag- ging. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 748\u2013759. Association for Computational Lin- guistics. Ryan Cotterell, Christo Kirov, John Sylak-Glassman, G\u00b4eraldine Walther, Ekaterina Vylomova, Arya D. McCarthy, Katharina Kann, Sebastian Mielke, Gar- rett Nicolai, Miikka Silfverberg, David Yarowsky, Jason Eisner, and Mans Hulden. 2018. The CoNLL\u2013 SIGMORPHON 2018 shared task: Universal mor- phological rein\ufb02ection. In Proceedings of the CoNLL\u2013SIGMORPHON 2018 Shared Task: Univer- sal Morphological Rein\ufb02ection, Brussels, Belgium. Association for Computational Linguistics.",
      "In Proceedings of the CoNLL\u2013SIGMORPHON 2018 Shared Task: Univer- sal Morphological Rein\ufb02ection, Brussels, Belgium. Association for Computational Linguistics. Ryan Cotterell, Christo Kirov, John Sylak-Glassman, G\u02d9eraldine Walther, Ekaterina Vylomova, Patrick Xia, Manaal Faruqui, Sandra K\u00a8ubler, David Yarowsky, Jason Eisner, et al. 2017. CoNLL- SIGMORPHON 2017 shared task: Universal mor- phological rein\ufb02ection in 52 languages. Proceed- ings of the CoNLL\u2013SIGMORPHON 2017 Shared Task: Universal Morphological Rein\ufb02ection, pages 1\u201330. Ryan Cotterell, Christo Kirov, John Sylak-Glassman, David Yarowsky, Jason Eisner, and Mans Hulden. 2016. The SIGMORPHON 2016 shared task\u2014 morphological rein\ufb02ection.",
      "Ryan Cotterell, Christo Kirov, John Sylak-Glassman, David Yarowsky, Jason Eisner, and Mans Hulden. 2016. The SIGMORPHON 2016 shared task\u2014 morphological rein\ufb02ection. In Proceedings of the 14th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 10\u201322. Peter Dirix, Liesbeth Augustinus, Daniel van Niekerk, and Frank Van Eynde. 2017. Universal dependen- cies for Afrikaans. In Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies, 22 May, Gothenburg Sweden, 135, pages 38\u201347. Link\u00a8oping University Electronic Press. Elliott Franco Dr\u00b4abek and David Yarowsky. 2005. In- duction of \ufb01ne-grained part-of-speech taggers via classi\ufb01er combination and crosslingual projection. In Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 49\u201356. Association for Computational Linguistics.",
      "2005. In- duction of \ufb01ne-grained part-of-speech taggers via classi\ufb01er combination and crosslingual projection. In Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 49\u201356. Association for Computational Linguistics. Martin Haspelmath. 2010. Comparative concepts and descriptive categories in crosslinguistic studies. Language, 86(3):663\u2013687. Gholamhossein Karimi-Doostan. 2011. Separability of light verb constructions in Persian. Studia Linguis- tica, 65(1):70\u201395. Aleksandr E. Kibrik. 1998. Archi (Caucasian\u2013 Daghestanian). Wiley Online Library. Christo Kirov, Ryan Cotterell, John Sylak-Glassman, G\u00b4eraldine Walther, Ekaterina Vylomova, Patrick Xia, Manaal Faruqui, Arya D. McCarthy, Sandra K\u00a8ubler, David Yarowsky, Jason Eisner, and Mans Hulden. 2018.",
      "2018. UniMorph 2.0: Universal Morphol- ogy. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA). Christo Kirov, John Sylak-Glassman, Rebecca Knowles, Ryan Cotterell, and Matt Post. 2017. A rich morphological tagger for English: Exploring the cross-linguistic tradeoff between morphology and syntax. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, volume 2, pages 112\u2013117. Christo Kirov, John Sylak-Glassman, Roger Que, and David Yarowsky. 2016. Very-large scale pars- ing and normalization of Wiktionary morphological paradigms. In LREC. Ralph B. Long. 1957. Paradigms for English verbs. Publications of the Modern Language Association of America, pages 359\u2013372.",
      "Very-large scale pars- ing and normalization of Wiktionary morphological paradigms. In LREC. Ralph B. Long. 1957. Paradigms for English verbs. Publications of the Modern Language Association of America, pages 359\u2013372. Chaitanya Malaviya, Matthew R. Gormley, and Gra- ham Neubig. 2018. Neural factor graph models for cross-lingual morphological tagging. In Proceed- ings of the 56th Annual Meeting of the Association",
      "for Computational Linguistics (Volume 1: Long Pa- pers), pages 2652\u20132662. Association for Computa- tional Linguistics. Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: The Penn Treebank. Computa- tional linguistics, 19(2):313\u2013330. Joakim Nivre, \u02c7Zeljko Agi\u00b4c, Lars Ahrenberg, Lene An- tonsen, Maria Jesus Aranzabe, Masayuki Asahara, Luma Ateyah, Mohammed Attia, Aitziber Atutxa, Liesbeth Augustinus, et al. 2017. Universal depen- dencies 2.1. LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics ( \u00b4UFAL), Faculty of Mathematics and Physics, Charles Uni- versity. Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset.",
      "Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Proceed- ings of the Eight International Conference on Lan- guage Resources and Evaluation (LREC\u201912), Istan- bul, Turkey. European Language Resources Associ- ation (ELRA). Martin Popel, Zden\u02d8ek \u02c7Zabokrtsk\u00b4y, and Martin Vojtek. 2017. Udapi: Universal API for universal depen- dencies. In Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017), pages 96\u2013101. Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Interna- tional Conference on Intelligent Text Processing and Computational Linguistics, pages 1\u201315. Springer. Andrew Spencer. 1991. Morphological theory: An in- troduction to word structure in generative grammar, volume 2. Basil Blackwell Oxford.",
      "Springer. Andrew Spencer. 1991. Morphological theory: An in- troduction to word structure in generative grammar, volume 2. Basil Blackwell Oxford. Milan Straka and Jana Strakov\u00b4a. 2017. Tokenizing, POS tagging, lemmatizing and parsing UD 2.0 with UDPipe. In Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Univer- sal Dependencies, pages 88\u201399, Vancouver, Canada. Association for Computational Linguistics. John Sylak-Glassman. 2016. The composition and use of the universal morphological feature schema (Uni- Morph schema). Technical report, Department of Computer Science, Johns Hopkins University. John Sylak-Glassman, Christo Kirov, David Yarowsky, and Roger Que. 2015. A language-independent fea- ture schema for in\ufb02ectional morphology.",
      "Technical report, Department of Computer Science, Johns Hopkins University. John Sylak-Glassman, Christo Kirov, David Yarowsky, and Roger Que. 2015. A language-independent fea- ture schema for in\ufb02ectional morphology. In Pro- ceedings of the 53rd Annual Meeting of the Associ- ation for Computational Linguistics and the 7th In- ternational Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 674\u2013 680, Beijing, China. Association for Computational Linguistics. Oscar T\u00a8ackstr\u00a8om, Dipanjan Das, Slav Petrov, Ryan Mc- Donald, and Joakim Nivre. 2013. Token and type constraints for cross-lingual part-of-speech tagging. Transactions of the Association for Computational Linguistics, 1:1\u201312. Guillaume Wisniewski and Oph\u00b4elie Lacroix. 2017. A systematic comparison of syntactic representations of dependency parsing.",
      "Transactions of the Association for Computational Linguistics, 1:1\u201312. Guillaume Wisniewski and Oph\u00b4elie Lacroix. 2017. A systematic comparison of syntactic representations of dependency parsing. In Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependen- cies (UDW 2017), pages 146\u2013152. Daniel Zeman. 2008. Reusable tagset conversion using tagset drivers. In LREC, volume 2008, pages 28\u201330. Daniel Zeman, Ond\u02c7rej Du\u02c7sek, David Mare\u02c7cek, Mar- tin Popel, Loganathan Ramasamy, Jan \u02c7St\u02c7ep\u00b4anek, Zden\u02c7ek \u02c7Zabokrtsk`y, and Jan Haji\u02c7c. 2014. Hamledt: Harmonized multi-language dependency treebank. Language Resources and Evaluation, 48(4):601\u2013 637.",
      "2014. Hamledt: Harmonized multi-language dependency treebank. Language Resources and Evaluation, 48(4):601\u2013 637. Daniel Zeman, Martin Popel, Milan Straka, Jan Ha- jic, Joakim Nivre, Filip Ginter, Juhani Luotolahti, Sampo Pyysalo, Slav Petrov, Martin Potthast, et al. 2017. CoNLL 2017 shared task: multilingual pars- ing from raw text to universal dependencies. Pro- ceedings of the CoNLL 2017 Shared Task: Multilin- gual Parsing from Raw Text to Universal Dependen- cies, pages 1\u201319."
    ],
    "queries":"/future/u/okhattab/data/MSMARCO/queries.train.tsv",
    "index_name":"PaperTab-question-1810.06743.pdf",
    "overwrite":false,
    "root":".ragatouille/",
    "experiment":"colbert",
    "index_root":null,
    "name":"2025-05/17/10.22.50",
    "rank":0,
    "nranks":1,
    "amp":true,
    "gpus":1,
    "avoid_fork_if_possible":false
  },
  "num_chunks":1,
  "num_partitions":1024,
  "num_embeddings":12173,
  "avg_doclen":187.2769230769,
  "RAGatouille":{
    "index_config":{
      "index_type":"PLAID",
      "index_name":"PaperTab-question-1810.06743.pdf"
    }
  }
}