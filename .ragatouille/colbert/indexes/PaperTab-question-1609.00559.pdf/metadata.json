{
  "config":{
    "query_token_id":"[unused0]",
    "doc_token_id":"[unused1]",
    "query_token":"[Q]",
    "doc_token":"[D]",
    "ncells":null,
    "centroid_score_threshold":null,
    "ndocs":null,
    "load_index_with_mmap":false,
    "index_path":null,
    "index_bsize":32,
    "nbits":4,
    "kmeans_niters":20,
    "resume":false,
    "pool_factor":1,
    "clustering_mode":"hierarchical",
    "protected_tokens":0,
    "similarity":"cosine",
    "bsize":64,
    "accumsteps":1,
    "lr":0.00001,
    "maxsteps":400000,
    "save_every":null,
    "warmup":20000,
    "warmup_bert":null,
    "relu":false,
    "nway":64,
    "use_ib_negatives":true,
    "reranker":false,
    "distillation_alpha":1.0,
    "ignore_scores":false,
    "model_name":null,
    "query_maxlen":32,
    "attend_to_mask_tokens":false,
    "interaction":"colbert",
    "dim":128,
    "doc_maxlen":256,
    "mask_punctuation":true,
    "checkpoint":"colbert-ir/colbertv2.0",
    "triples":"/future/u/okhattab/root/unit/experiments/2021.10/downstream.distillation.round2.2_score/round2.nway6.cosine.ib/examples.64.json",
    "collection":[
      "arXiv:1609.00559v2  [cs.CL]  27 May 2017 Improving Correlation with Human Judgments by Integrating Semantic Similarity with Second\u2013Order Vectors Bridget T. McInnes Department of Computer Science Virginia Commonwealth University Richmond, VA 23284 USA btmcinnes@vcu.edu Ted Pedersen Department of Computer Science University of Minnesota Duluth, MN 55812 USA tpederse@d.umn.edu Abstract Vector space methods that measure se- mantic similarity and relatedness often rely on distributional information such as co\u2013occurrence frequencies or statistical measures of association to weight the im- portance of particular co\u2013occurrences. In this paper, we extend these methods by incorporating a measure of semantic sim- ilarity based on a human curated taxon- omy into a second\u2013order vector represen- tation. This results in a measure of seman- tic relatedness that combines both the con- textual information available in a corpus\u2013 based vector space representation with the semantic knowledge found in a biomedical ontology.",
      "This results in a measure of seman- tic relatedness that combines both the con- textual information available in a corpus\u2013 based vector space representation with the semantic knowledge found in a biomedical ontology. Our results show that incorpo- rating semantic similarity into a second or- der co\u2013occurrence matrices improves cor- relation with human judgments for both similarity and relatedness, and that our method compares favorably to various dif- ferent word embedding methods that have recently been evaluated on the same refer- ence standards we have used. 1 Introduction Measures of semantic similarity and relatedness quantify the degree to which two concepts are similar (e.g., lung\u2013heart) or related (e.g., lung\u2013 bronchitis). Semantic similarity can be viewed as a special case of semantic relatedness \u2013 to be similar is one of many ways that a pair of con- cepts may be related.",
      "Semantic similarity can be viewed as a special case of semantic relatedness \u2013 to be similar is one of many ways that a pair of con- cepts may be related. The automated discovery of groups of semantically similar or related terms is critical to improving the retrieval (Rada et al., 1989) and clustering (Lin et al., 2007) of biomed- ical and clinical documents, and the develop- ment of biomedical terminologies and ontolo- gies (Bodenreider and Burgun, 2004). There is a long history in using distribu- tional methods to discover semantic similarity and relatedness (e.g., (Lin and Pantel, 2002; Reisinger and Mooney, 2010; Radinsky et al., 2011; Yih and Qazvinian, 2012)). These methods are all based on the distributional hypothesis, which holds that two terms that are distribu- tionally similar (i.e., used in the same context) will also be semantically similar (Harris, 1954; Weeds et al., 2004).",
      "These methods are all based on the distributional hypothesis, which holds that two terms that are distribu- tionally similar (i.e., used in the same context) will also be semantically similar (Harris, 1954; Weeds et al., 2004). Recently word embedding techniques such as word2vec (Mikolov et al., 2013) have become very popular. Despite the prominent role that neural networks play in many of these approaches, at their core they remain distributional techniques that typically start with a word by word co\u2013occurrence matrix, much like many of the more traditional approaches. However, despite these successes distributional methods do not perform well when data is very sparse (which is common). One possible solu- tion is to use second\u2013order co\u2013occurrence vec- tors (Sch\u00a8utze, 1992; Sch\u00a8utze, 1998). In this ap- proach the similarity between two words is not strictly based on their co\u2013occurrence frequencies, but rather on the frequencies of the other words which occur with both of them (i.e., second order co\u2013occurrences).",
      "In this ap- proach the similarity between two words is not strictly based on their co\u2013occurrence frequencies, but rather on the frequencies of the other words which occur with both of them (i.e., second order co\u2013occurrences). This approach has been shown to be successful in quantifying semantic relat- edness (Islam and Inkpen, 2006; Pedersen et al., 2007). However, while more robust in the face of sparsity, second\u2013order methods can result in sig- ni\ufb01cant amounts of noise, where contextual infor- mation that is overly general is included and does not contribute to quantifying the semantic related- ness between the two concepts. Our goal then is to discover methods that auto- matically reduce the amount of noise in a second\u2013 order co\u2013occurrence vector. We achieve this by incorporating pairwise semantic similarity scores",
      "derived from a taxonomy into our second\u2013order vectors, and then using these scores to select only the most semantically similar co\u2013occurrences (thereby reducing noise). We evaluate our method on two datasets that have been annotated in multiple ways. One has been annotated for both similarity and relatedness, and the other has been annotated for relatedness by two different types of experts (medical doctors and medical coders). Our results show that in- tegrating second order co\u2013occurrences with mea- sures of semantic similarity increases correlation with our human reference standards. We also com- pare our result to a number of other studies which have applied various word embedding methods to the same reference standards we have used. We \ufb01nd that our method often performs at a compara- ble or higher level than these approaches. These results suggest that our methods of integrating se- mantic similarity and relatedness values have the potential to improve performance of purely distri- butional methods. 2 Similarity and Relatedness Measures This section describes the similarity and related- ness measures we integrate in our second\u2013order co\u2013occurrence vectors. We use two taxonomies in this study, SNOMED\u2013CT and MeSH.",
      "2 Similarity and Relatedness Measures This section describes the similarity and related- ness measures we integrate in our second\u2013order co\u2013occurrence vectors. We use two taxonomies in this study, SNOMED\u2013CT and MeSH. SNOMED\u2013 CT (Systematized Nomenclature of Medicine Clin- ical Terms) is a comprehensive clinical terminol- ogy created for the electronic representation of clinical health information. MeSH (Medical Sub- ject Headings) is a taxonomy of biomedical terms developed for indexing biomedical journal arti- cles. We obtain SNOMED\u2013CT and MeSH via the Uni\ufb01ed Medical Language System (UMLS) Metathesaurus (version 2016AA). The Metathe- saurus contains approximately 2 million biomed- ical and clinical concepts from over 150 different terminologies that have been semi\u2013automatically integrated into a single source. Concepts in the Metathesaurus are connected largely by two types of hierarchical relations: parent/child (PAR/CHD) and broader/narrower (RB/RN).",
      "Concepts in the Metathesaurus are connected largely by two types of hierarchical relations: parent/child (PAR/CHD) and broader/narrower (RB/RN). 2.1 Similarity Measures Measures of semantic similarity can be classi\ufb01ed into three broad categories : path\u2013based, feature\u2013 based and information content (IC). Path\u2013based similarity measures use the structure of a taxon- omy to measure similarity \u2013 concepts positioned close to each other are more similar than those further apart. Feature\u2013based methods rely on set theoretic measures of overlap between features (union and intersection). The information content measures quantify the amount of information that a concept provides \u2013 more speci\ufb01c concepts have a higher amount of information content. 2.1.1 Path\u2013based Measures Rada et al. (1989) introduce the Conceptual Dis- tance measure. This measure is simply the length of the shortest path between two concepts (c1 and c2) in the MeSH hierarchy. Paths are based on broader than (RB) and narrower than (RN) re- lations.",
      "(1989) introduce the Conceptual Dis- tance measure. This measure is simply the length of the shortest path between two concepts (c1 and c2) in the MeSH hierarchy. Paths are based on broader than (RB) and narrower than (RN) re- lations. Caviedes and Cimino (2004) extends this measure to use parent (PAR) and child (CHD) re- lations. Our path measure is simply the recipro- cal of this shortest path value (Equation 1), so that larger values (approaching 1) indicate a high de- gree of similarity. path = 1 spath(c1, c2) (1) While the simplicity of path is appealing, it can be misleading when concepts are at different lev- els of speci\ufb01city. Two very general concepts may have the same path length as two very speci\ufb01c con- cepts. Wu and Palmer (1994) introduce a correc- tion to path that incorporates the depth of the con- cepts, and the depth of their Least Common Sub- sumer (LCS).",
      "Wu and Palmer (1994) introduce a correc- tion to path that incorporates the depth of the con- cepts, and the depth of their Least Common Sub- sumer (LCS). This is the most speci\ufb01c ancestor two concepts share. In this measure, similarity is twice the depth of the two concept\u2019s LCS divided by the product of the depths of the individual con- cepts (Equation 2). Note that if there are multiple LCSs for a pair of concepts, the deepest of them is used in this measure. wup = 2 \u2217depth(lcs(c1, c2)) depth(c1) + depth(c2) (2) Zhong et al. (2002) take a very similar approach and again scale the depth of the LCS by the sum of the depths of the two concepts (Equation 3), where m(c) = k\u2212depth(c). The value of k was set to 2 based on their recommendations.",
      "(2002) take a very similar approach and again scale the depth of the LCS by the sum of the depths of the two concepts (Equation 3), where m(c) = k\u2212depth(c). The value of k was set to 2 based on their recommendations. zhong = 2 \u2217m(lcs(c1, c2)) m(c1) + m(c2) (3) Pekar and Staab (2002) offer another variation on path, where the shortest path of the two con- cepts to the LCS is used, in addition to the shortest",
      "bath between the LCS and the root of the taxon- omy (Equation 4). pks = \u2212log spath(lcs(c1, c2), root) P x=c1,c2,root spath(lcs(c1, c2), x) (4) 2.1.2 Feature\u2013based Measures Feature\u2013based methods represent each concept as a set of features and then measure the overlap or sharing of features to measure similarity. In par- ticular, each concept is represented as the set of their ancestors, and similarity is a ratio of the in- tersection and union of these features. Maedche and Staab (2001) quantify the similar- ity between two concepts as the ratio of the inter- section over their union as shown in Equation 5. cmatch = |A(c1) T A(c2)| |A(c1) S A(c2)| (5) Batet et al.",
      "(2011) extend this by excluding any shared features (in the numerator) as shown in Equation 6. batet = \u2212log2(|A(c1) S A(c2)| \u2212|A(c1) T A(c2)| |A(c1) S A(c2)| ) (6) 2.1.3 Information Content Measures Information content is formally de\ufb01ned as the neg- ative log of the probability of a concept. The effect of this is to assign rare (low probability) concepts a high measure of information content, since the underlying assumption is that more speci\ufb01c con- cepts are less frequently used than more common ones. Resnik (1995) modi\ufb01ed this notion of informa- tion content in order to use it as a similarity mea- sure. He de\ufb01nes the similarity of two concepts to be the information content of their LCS (Equa- tion 7).",
      "Resnik (1995) modi\ufb01ed this notion of informa- tion content in order to use it as a similarity mea- sure. He de\ufb01nes the similarity of two concepts to be the information content of their LCS (Equa- tion 7). res = IC(lcs(c1, c2) = \u2212log(P(lcs(c1, c2))) (7) Jiang and Conrath (1997), Lin (1998), and Pirr\u00b4o and Euzenat (2010) extend res by incorpo- rating the information content of the individual concepts in various different ways. Lin (1998) de- \ufb01nes the similarity between two concepts as the ratio of information content of the LCS with the sum of the individual concept\u2019s information con- tent (Equation 8). Note that lin has the same form as wup and zhong, and is in effect using informa- tion content as a measure of speci\ufb01city (rather than depth). If there is more than one possible LCS, the LCS with the greatest IC is chosen.",
      "Note that lin has the same form as wup and zhong, and is in effect using informa- tion content as a measure of speci\ufb01city (rather than depth). If there is more than one possible LCS, the LCS with the greatest IC is chosen. lin = 2 \u2217IC(lcs(c1, c2)) IC(c1) + IC(c2) (8) Jiang and Conrath (1997) de\ufb01ne the distance between two concepts to be the sum of the infor- mation content of the two concepts minus twice the information content of the concepts\u2019 LCS. We modify this from a distance to a similarity mea- sure by taking the reciprocal of the distance (Equa- tion 9). Note that the denominator of jcn is very similar to the numerator of batet.",
      "We modify this from a distance to a similarity mea- sure by taking the reciprocal of the distance (Equa- tion 9). Note that the denominator of jcn is very similar to the numerator of batet. jcn = 1 IC(c1) + IC(c2) \u22122 \u2217IC(lcs(c1, c2)) (9) Pirr\u00b4o and Euzenat (2010) de\ufb01ne the similarity between two concepts as the information content of the two concept\u2019s LCS divided by the sum of their individual information content values mi- nus the information content of their LCS (Equa- tion 10). Note that batet can be viewed as a set\u2013 theoretic version of faith. faith = IC(lcs(c1, c2)) IC(c1) + IC(c2) \u2212IC(lcs(c1, c2)) (10) 2.2 Information Content The information content of a concept may be de- rived from a corpus (corpus\u2013based) or directly from a taxonomy (intrinsic\u2013based). In this work we focus on corpus\u2013based techniques.",
      "In this work we focus on corpus\u2013based techniques. For corpus\u2013based information content, we esti- mate the probability of a concept c by taking the sum of the probability of the concept P(c) and the probability its descendants P(d) (Equation 11). P(c\u2217) = P(c) + X d\u2208descendant(c) P(d) (11) The initial probabilities of a concept (P(c)) and its descendants (P(d)) are obtained by dividing the number of times each concept and descendant occurs in the corpus, and dividing that by the total numbers of concepts (N).",
      "Ideally the corpus from which we are estimating the probabilities of concepts will be sense\u2013tagged. However, sense\u2013tagging is a challenging problem in its own right, and it is not always possible to carry out reliably on larger amounts of text. In fact in this paper we did not use any sense\u2013tagging of the corpus we derived information content from. Instead, we estimated the probability of a con- cept by using the UMLSonMedline dataset. This was created by the National Library of Medicine and consists of concepts from the 2009AB UMLS and the counts of the number of times they oc- curred in a snapshot of Medline taken on 12 Jan- uary, 2009. These counts were obtained by using the Essie Search Engine (Ide et al., 2007) which queried Medline with normalized strings from the 2009AB MRCONSO table in the UMLS. The fre- quency of a CUI was obtained by aggregating the frequency counts of the terms associated with the CUI to provide a rough estimate of its frequency. The information content measures then use this in- formation to calculate the probability of a concept.",
      "The fre- quency of a CUI was obtained by aggregating the frequency counts of the terms associated with the CUI to provide a rough estimate of its frequency. The information content measures then use this in- formation to calculate the probability of a concept. Another alternative is the use of Intrinsic In- formation Content. It assess the informativeness of concept based on its placement within a tax- onomy by considering the number of incoming (ancestors) relative to outgoing (descendant) links (S\u00b4anchez et al., 2011) (Equation 12). IC(c) = \u2212log( |leaves(c)| |subsumers(c)| + 1 max leaves + 1 ) (12) where leaves are the number of descendants of concept c that are leaf nodes, subsumers are the number of concept c\u2019s ancestors and max leaves are the total number of leaf nodes in the taxonomy. 2.3 Relatedness Measures Lesk (1986) observed that concepts that are related should share more words in their respective de\ufb01- nitions than concepts that are less connected.",
      "2.3 Relatedness Measures Lesk (1986) observed that concepts that are related should share more words in their respective de\ufb01- nitions than concepts that are less connected. He was able to perform word sense disambiguation by identifying the senses of words in a sentence with the largest number of overlaps between their de\ufb01- nitions. An overlap is the longest sequence of one or more consecutive words that occur in both def- initions. Banerjee and Pedersen (2003) extended this idea to WordNet, but observed that WordNet glosses are often very short, and did not contain enough information to distinguish between mul- tiple concepts. Therefore, they created a super\u2013 gloss for each concept by adding the glosses of related concepts to the gloss of the concept itself (and then \ufb01nding overlaps). Patwardhan and Pedersen (2006) adapted this measure to second\u2013order co\u2013occurrence vectors. In this approach, a vector is created for each word in a concept\u2019s de\ufb01nition that shows which words co\u2013occur with it in a corpus. These word vectors are averaged to create a single co- occurrence vector for the concept.",
      "In this approach, a vector is created for each word in a concept\u2019s de\ufb01nition that shows which words co\u2013occur with it in a corpus. These word vectors are averaged to create a single co- occurrence vector for the concept. The similarity between the concepts is calculated by taking the cosine between the concepts second\u2013order vec- tors. Liu et al. (2012) modi\ufb01ed and extended this measure to be used to quantify the relatedness be- tween biomedical and clinical terms in the UMLS. The work in this paper can be seen as a further extension of Patwardhan and Pedersen (2006) and Liu et al. (2012). 3 Method In this section, we describe our second\u2013order simi- larity vector measure. This incorporates both con- textual information using the term pair\u2019s de\ufb01ni- tion and their pairwise semantic similarity scores derived from a taxonomy. There are two stages to our approach. First, a co\u2013occurrence matrix must be constructed.",
      "This incorporates both con- textual information using the term pair\u2019s de\ufb01ni- tion and their pairwise semantic similarity scores derived from a taxonomy. There are two stages to our approach. First, a co\u2013occurrence matrix must be constructed. Second, this matrix is used to construct a second\u2013order co\u2013occurrence vector for each concept in a pair of concepts to be mea- sured for relatedness. 3.1 Co\u2013occurrence Matrix Construction We build an m\u00d7n similarity matrix using an exter- nal corpus where the rows and columns represent words within the corpus and the element contains the similarity score between the row word and col- umn word using the similarity measures discussed above. If a word maps to more than one possi- ble sense, we use the sense that returns the highest similarity score. For this paper our external corpus was the NLM 2015 Medline baseline. Medline is a biblio- graphic database containing over 23 million ci- tations to journal articles in the biomedical do- main and is maintained by National Library of Medicine.",
      "For this paper our external corpus was the NLM 2015 Medline baseline. Medline is a biblio- graphic database containing over 23 million ci- tations to journal articles in the biomedical do- main and is maintained by National Library of Medicine. The 2015 Medline Baseline encom- passes approximately 5,600 journals starting from 1948 and contains 23,343,329 citations, of which 2,579,239 contain abstracts. In this work, we use Medline titles and abstracts from 1975 to present day. Prior to 1975, only 2% of the citations con- tained an abstract. We then calculate the similarity",
      "for each bigram in this dataset and include those that have a similarity score greater than a speci\ufb01ed threshold on these experiments. 3.2 Measure Term Pairs for Relatedness We obtain de\ufb01nitions for each of the two terms we wish to measure. Due to the sparsity and inconsistencies of the de\ufb01nitions in the UMLS, we not only use the de\ufb01nition of the term (CUI) but also include the de\ufb01nition of its related con- cepts. This follows the method proposed by Patwardhan and Pedersen (2006) for general En- glish and WordNet, and which was adapted for the UMLS and the medical domain by Liu et al. (2012). In particular we add the de\ufb01nitions of any concepts connected via a parent (PAR), child (CHD), RB (broader than), RN (narrower than) or TERM (terms associated with CUI) relation. All of the de\ufb01nitions for a term are combined into a single super\u2013gloss.",
      "All of the de\ufb01nitions for a term are combined into a single super\u2013gloss. At the end of this process we should have two super\u2013glosses, one for each term to be measured for relatedness. Next, we process each super\u2013gloss as follows: 1. We extract a \ufb01rst\u2013order co\u2013occurrence vector for each term in the super\u2013gloss from the co\u2013 occurrence matrix created previously. 2. We take the average of the \ufb01rst order co\u2013 occurrence vectors associated with the terms in a super\u2013gloss and use that to represent the meaning of the term. This is a second\u2013order co\u2013occurrence vector. 3. After a second\u2013order co\u2013occurrence vector has been constructed for each term, then we calculate the cosine between these two vec- tors to measure the relatedness of the terms. 4 Data We use two reference standards to evaluate the semantic similarity and relatedness measures 1. UMNSRS was annotated for both similarity and relatedness by medical residents. MiniMayoSRS was annotated for relatedness by medical doctors (MD) and medical coders (coder).",
      "4 Data We use two reference standards to evaluate the semantic similarity and relatedness measures 1. UMNSRS was annotated for both similarity and relatedness by medical residents. MiniMayoSRS was annotated for relatedness by medical doctors (MD) and medical coders (coder). In this section, we describe these data sets and describe a few of their differences. MiniMayoSRS: The MayoSRS, developed by Pakhomov et al. (2011), consists of 101 clinical term pairs whose relatedness was determined by 1http://www.people.vcu.edu/ btmcinnes/downloads.html nine medical coders and three physicians from the Mayo Clinic. The relatedness of each term pair was assessed based on a four point scale: (4.0) practically synonymous, (3.0) related, (2.0) marginally related and (1.0) unrelated. Mini- MayoSRS is a subset of the MayoSRS and con- sists of 30 term pairs on which a higher inter\u2013 annotator agreement was achieved. The average correlation between physicians is 0.68. The av- erage correlation between medical coders is 0.78.",
      "The average correlation between physicians is 0.68. The av- erage correlation between medical coders is 0.78. We evaluate our method on the mean of the physi- cian scores, and the mean of the coders scores in this subset in the same manner as reported by Pedersen et al. (2007). UMNSRS: The University of Minnesota Se- mantic Relatedness Set (UMNSRS) was devel- oped by Pakhomov et al. (2010), and consists of 725 clinical term pairs whose semantic similarity and relatedness was determined independently by four medical residents from the University of Min- nesota Medical School. The similarity and relat- edness of each term pair was annotated based on a continuous scale by having the resident touch a bar on a touch sensitive computer screen to indicate the degree of similarity or relatedness. The Intr- aclass Correlation Coef\ufb01cient (ICC) for the refer- ence standard tagged for similarity was 0.47, and 0.50 for relatedness.",
      "The Intr- aclass Correlation Coef\ufb01cient (ICC) for the refer- ence standard tagged for similarity was 0.47, and 0.50 for relatedness. Therefore, as suggested by Pakhomov and colleagues,we use a subset of the ratings consisting of 401 pairs for the similarity set and 430 pairs for the relatedness set which each have an ICC of 0.73. 5 Experimental Framework We conducted our experiments using the freely available open source software package UMLS::Similarity (McInnes et al., 2009) version 1.472. This package takes as input two terms (or UMLS concepts) and returns their similarity or relatedness using the measures discussed in Section 2. Correlation between the similarity measures and human judgments were estimated using Spear- man\u2019s Rank Correlation (\u03c1). Spearman\u2019s measures the statistical dependence between two variables to assess how well the relationship between the rankings of the variables can be described using a monotonic function. We used Fisher\u2019s r-to-z trans- formation (Fisher, 1915) to calculate the signi\ufb01- cance between the correlation results.",
      "We used Fisher\u2019s r-to-z trans- formation (Fisher, 1915) to calculate the signi\ufb01- cance between the correlation results. 2http://search.cpan.org/edist/UMLS-Similarity/",
      "6 Results and Discussion Table 1 shows the Spearman\u2019s Rank Correlation between the human scores from the four reference standards and the scores from the various mea- sures of similarity introduced in Section 2. Each class of measure is followed by the scores obtained when integrating our second order vector approach with these measures of semantic similarity. 6.1 Results Comparison The results for UMNSRS tagged for similarity (sim) and MiniMayoSRS tagged by coders show that all of the second-order similarity vector mea- sures (Integrated) except for vector-jcn obtain a higher correlation than the original measures. We found that vector-res and vector-faith obtain the highest correlations of all these results with hu- man judgments. For the UMNSRS dataset tagged for relatedness and MiniMayoSRS tagged by physicians (MD), the original vector measure obtains a higher cor- relation than our measure (Integrated) although the difference is not statistically signi\ufb01cant (p \u2264 0.2). In order to analyze and better understand these results, we \ufb01ltered the bigram pairs used to create the initial similarity matrix based on the strength of their similarity using the faith and the res measures.",
      "In order to analyze and better understand these results, we \ufb01ltered the bigram pairs used to create the initial similarity matrix based on the strength of their similarity using the faith and the res measures. Note that the faith measure holds to a 0 to 1 scale, while res ranges from 0 to an un- speci\ufb01ed upper bound that is dependent on the size of the corpus from which information content is estimated. As such we use a different range of threshold values for each measure. We discuss the results of this \ufb01ltering below. 6.2 Thresholding Experiments Table 2 shows the results of applying the threshold parameter on each of the reference standards using the res measure. For example, a threshold of 0 indicates that all of the bigrams were included in the similarity matrix; and a threshold of 1 indicates that only the bigram pairs with a similarity score greater than one were included. These results show that using a threshold cutoff of 2 obtains the highest correlation for the UMN- SRS dataset, and that a threshold cutoff of 4 ob- tains the highest correlation for the MiniMayoSRS dataset.",
      "These results show that using a threshold cutoff of 2 obtains the highest correlation for the UMN- SRS dataset, and that a threshold cutoff of 4 ob- tains the highest correlation for the MiniMayoSRS dataset. All of the results show an increase in correlation with human judgments when incorpo- rating a threshold cutoff over all of the original Table 1: Spearman\u2019s Correlation Results UMNSRS MiniMayoSRS Resident MD Coder sim rel relatedness Path path 0.52 0.28 0.35 0.45 wup 0.50 0.24 0.39 0.51 pks 0.49 0.25 0.38 0.50 zhong 0.50 0.25 0.42 0.50 Integrated vector-path 0.60 0.43 0.54 0.54 vector-wup 0.60 0.42 0.55 0.55 vector-pks 0.60 0.42 0.53 0.53 vector-zhong 0.58 0.41 0.54 0.53 Feature batet 0.",
      "60 0.42 0.55 0.55 vector-pks 0.60 0.42 0.53 0.53 vector-zhong 0.58 0.41 0.54 0.53 Feature batet 0.16 0.33 0.16 0.15 cmatch 0.33 0.17 0.35 0.35 Integrated vector-batet 0.59 0.43 0.53 0.51 vector-cmatch 0.60 0.43 0.54 0.55 IC res 0.49 0.26 0.36 0.47 lin 0.51 0.29 0.44 0.54 jcn 0.52 0.33 0.42 0.52 faith 0.51 0.29 0.43 0.54 Integrated vector-res 0.57 0.41 0.58 0.65 vector-lin 0.57 0.41 0.59 0.64 vector-jcn 0.42 0.15 0.26 0.",
      "43 0.54 Integrated vector-res 0.57 0.41 0.58 0.65 vector-lin 0.57 0.41 0.59 0.64 vector-jcn 0.42 0.15 0.26 0.41 vector-faith 0.59 0.42 0.58 0.63 Intrinsic IC ires 0.49 0.26 0.40 0.50 ilin 0.50 0.28 0.41 0.50 ijcn 0.51 0.29 0.39 0.50 ifaith 0.50 0.28 0.41 0.50 Integrated vector-ires 0.57 0.41 0.50 0.52 vector-ilin 0.57 0.41 0.55 0.59 vector-ijcn 0.50 0.41 0.54 0.54 vector-ifaith 0.58 0.42 0.58 0.64 Relatedness lesk 0.49 0.33 0.52 0.",
      "55 0.59 vector-ijcn 0.50 0.41 0.54 0.54 vector-ifaith 0.58 0.42 0.58 0.64 Relatedness lesk 0.49 0.33 0.52 0.56 o1vector 0.47 0.36 0.43 0.54 o2vector 0.54 0.45 0.63 0.59",
      "Table 2: Threshold Correlation with vector-res UMNSRS MiniMayoSRS T # bigrams sim rel MD coder 0 850,959 0.58 0.41 0.58 0.65 1 166,003 0.56 0.39 0.60 0.67 2 65,502 0.64 0.47 0.56 0.62 3 27,744 0.60 0.46 0.62 0.71 4 10,991 0.56 0.43 0.75 0.76 5 3,305 0.26 0.16 0.36 0.36 Table 3: Threshold Correlation with vector-faith # UMNSRS MiniMayoSRS T bigrams sim rel MD coder 0 838,353 0.59 0.42 0.58 0.63 0.1 197,189 0.58 0.41 0.57 0.63 0.2 121,839 0.58 0.41 0.58 0.",
      "353 0.59 0.42 0.58 0.63 0.1 197,189 0.58 0.41 0.57 0.63 0.2 121,839 0.58 0.41 0.58 0.63 0.3 71,353 0.63 0.46 0.54 0.55 0.4 45,335 0.64 0.48 0.50 0.51 0.5 29,734 0.66 0.49 0.49 0.53 0.6 19,347 0.65 0.49 0.52 0.56 0.7 11,946 0.64 0.48 0.53 0.55 0.8 7,349 0.64 0.49 0.53 0.56 0.9 4,731 0.62 0.49 0.53 0.57 measures.",
      "64 0.48 0.53 0.55 0.8 7,349 0.64 0.49 0.53 0.56 0.9 4,731 0.62 0.49 0.53 0.57 measures. The increase in the correlation for the UMNSRS tagged for similarity is statistically sig- ni\ufb01cant (p \u22640.05), however this is not the case for the UMNSRS tagged for relatedness nor for the MiniMayoSRS data. Similarly, Table 3 shows the results of apply- ing the threshold parameter (T) on each of the ref- erence standards using the faith measure. Al- though, unlike res whose scores are greater than or equal to 0 without an upper limit, the faith measure returns scores between 0 and 1 (inclu- sive). Therefore, here a threshold of 0 indicates that all of the bigrams were included in the sim- ilarity matrix; and a threshold of 0.1 indicates that only the bigram pairs with a similarity score greater than 0.1 were included.",
      "Therefore, here a threshold of 0 indicates that all of the bigrams were included in the sim- ilarity matrix; and a threshold of 0.1 indicates that only the bigram pairs with a similarity score greater than 0.1 were included. The results show an increase in accuracy for all of the datasets except for the MiniMayoSRS tagged for physi- cians. The increase in the results for the UMNSRS tagged for similarity and the MayoSRS is statisti- cally signi\ufb01cant (p \u22640.05). This is not the case for the UMNSRS tagged for relatedness nor the MiniMayoSRS. Overall, these results indicate that including only those bigrams that have a suf\ufb01ciently high similarity score increases the correlation results with human judgments, but what quanti\ufb01es as suf- \ufb01ciently high varies depending on the dataset and measure. 6.3 Comparison with Previous Work Recently, word embeddings (Mikolov et al., 2013) have become a popular method for measuring se- mantic relatedness in the biomedical domain.",
      "6.3 Comparison with Previous Work Recently, word embeddings (Mikolov et al., 2013) have become a popular method for measuring se- mantic relatedness in the biomedical domain. This is a neural network based approach that learns a representation of a word by word co\u2013occurrence matrix. The basic idea is that the neural net- work learns a series of weights (the hidden layer within the neural network) that either maximizes the probability of a word given its context, referred to as the continuous bag of words (CBOW) ap- proach, or that maximizes the probability of the context given a word, referred to as the Skip\u2013gram approach. These approaches have been used in nu- merous recent papers. Muneeb et al. (2015) trained both the Skip\u2013 gram and CBOW models over the PubMed Cen- tral Open Access (PMC) corpus of approximately 1.25 million articles. They evaluated the models on a subset of the UMNSRS data, removing word pairs that did not occur in their training corpus more than ten times. Chiu et al.",
      "They evaluated the models on a subset of the UMNSRS data, removing word pairs that did not occur in their training corpus more than ten times. Chiu et al. (2016) evaluated both the the Skip\u2013gram and CBOW models over the PMC corpus and PubMed. They also evaluated the models on a subset of the UMNSRS ignoring those words that did not appear in their training corpus. Pakhomov et al. (2016) trained CBOW model over three different types of corpora: clin- ical (clinical notes from the Fairview Health Sys- tem), biomedical (PMC corpus), and general En- glish (Wikipedia). They evaluated their method using a subset of the UMNSRS restricting to sin- gle word term pairs and removing those not found within their training corpus. Sajadi et al. (2015) trained the Skip\u2013gram model over CUIs identi\ufb01ed by MetaMap on the OHSUMED corpus, a collec- tion of 348,566 biomedical research articles.",
      "Sajadi et al. (2015) trained the Skip\u2013gram model over CUIs identi\ufb01ed by MetaMap on the OHSUMED corpus, a collec- tion of 348,566 biomedical research articles. They evaluated the method on the complete UMNSRS, MiniMayoSRS and the MayoSRS datasets; any subset information about the dataset was not ex- plicitly stated therefore we believe a direct com- parison may be possible. In addition, a previous work very closely related to ours is a retro\ufb01tting vector method proposed by Yu et al. (2016) that incorporates ontological in- formation into a vector representation by includ-",
      "Table 4: Comparison with Previous Work Method UMNSRS MayoSRS MiniMayoSRS Subsets Full (N=101) (N=29) sim rel sim (N=566) rel (N=587) rel MD coder avg vector\u2013res (ours) 0.64 (N=401) 0.49 (N=430) 0.59 0.48 0.51 0.75 0.76 0.76 vector\u2013faith (ours) 0.66 (N=401) 0.49 (N=430) 0.61 0.49 0.46 0.58 0.63 0.63 (Yu et al., 2016) 0.70 0.67 (Sajadi et al., 2015) 0.39 0.39 0.63 0.8 (Pakhomov et al., 2016) 0.62 (N=449) 0.58 (N=458) (Muneeb et al., 2015) 0.52 (N=462) 0.",
      "63 0.8 (Pakhomov et al., 2016) 0.62 (N=449) 0.58 (N=458) (Muneeb et al., 2015) 0.52 (N=462) 0.45 (N=465) (Chiu et al., 2016) 0.65 (N=UK) 0.60 (N=UK) ing semantically related words. In their measure, they \ufb01rst map a biomedical term to MeSH terms, and second build a word vector based on the doc- uments assigned to the respective MeSH term. They then retro\ufb01t the vector by including seman- tically related words found in the Uni\ufb01ed Medical Language System. They evaluate their method on the MiniMayoSRS dataset. Table 4 shows a comparison to the top corre- lation scores reported by each of these works on the respective datasets (or subsets) they evaluated their methods on. N refers to the number of term pairs in the dataset the authors report they eval- uated their method.",
      "Table 4 shows a comparison to the top corre- lation scores reported by each of these works on the respective datasets (or subsets) they evaluated their methods on. N refers to the number of term pairs in the dataset the authors report they eval- uated their method. The table also includes our top scoring results: the integrated vector-res and vector-faith. The results show that integrating se- mantic similarity measures into second\u2013order co\u2013 occurrence vectors obtains a higher or on\u2013par cor- relation with human judgments as the previous works reported results with the exception of the UMNSRS rel dataset. The results reported by Pakhomov et al. (2016) and Chiu et al. (2016) ob- tain a higher correlation although the results can not be directly compared because both works used different subsets of the term pairs from the UMN- SRS dataset. 7 Conclusion and Future Work We have presented a method for quantifying the similarity and relatedness between two terms that integrates pair\u2013wise similarity scores into second\u2013 order vectors. The goal of this approach is two\u2013 fold.",
      "7 Conclusion and Future Work We have presented a method for quantifying the similarity and relatedness between two terms that integrates pair\u2013wise similarity scores into second\u2013 order vectors. The goal of this approach is two\u2013 fold. First, we restrict the context used by the vector measure to words that exist in the biomed- ical domain, and second, we apply larger weights to those word pairs that are more similar to each other. Our hypothesis was that this combination would reduce the amount of noise in the vectors and therefore increase their correlation with hu- man judgments. We evaluated our method on datasets that have been manually annotated for relatedness and similarity and found evidence to support this hypothesis. In particular we dis- covered that guiding the creation of a second\u2013 order context vector by selecting term pairs from biomedical text based on their semantic similarity led to improved levels of correlation with human judgment. We also explored using a threshold cutoff to in- clude only those term pairs that obtained a suf- \ufb01ciently large level of similarity. We found that eliminating less similar pairs improved the over- all results (to a point). In the future, we plan to explore metrics to automatically determine the threshold cutoff appropriate for a given dataset and measure.",
      "We found that eliminating less similar pairs improved the over- all results (to a point). In the future, we plan to explore metrics to automatically determine the threshold cutoff appropriate for a given dataset and measure. We also plan to explore additional features that can be integrated with a second\u2013 order vector measure that will reduce the noise but still provide suf\ufb01cient information to quan- tify relatedness. We are particularly interested in approaches that learn word, phrase, and sentence embeddings from structured corpora such as lit- erature (Hill et al., 2016a) and dictionary entries (Hill et al., 2016b). Such embeddings could be in- tegrated into a second\u2013order vector or be used on their own. Finally, we compared our proposed method to other distributional approaches, focusing on those that used word embeddings. Our results showed that integrating semantic similarity mea- sures into second\u2013order co\u2013occurrence vectors ob- tains the same or higher correlation with human judgments as do various different word embed- ding approaches. However, a direct comparison was not possible due to variations in the subsets of the UMNSRS evaluation dataset used.",
      "However, a direct comparison was not possible due to variations in the subsets of the UMNSRS evaluation dataset used. In the future, we would not only like to conduct a direct comparison but also explore integrating semantic similarity into various kinds of word embeddings by training on pair\u2013wise values of semantic simi-",
      "larity as well as co\u2013occurrence statistics. References S. Banerjee and T. Pedersen. 2003. Extended gloss overlaps as a measure of semantic relatedness. In Proceedings of the Eighteenth International Joint Conference on Arti\ufb01cial Intelligence. Acapulco, Mexico, pages 805\u2013810. M. Batet, D. S\u00b4anchez, and A. Valls. 2011. An ontology-based measure to compute semantic sim- ilarity in biomedicine. Journal of biomedical infor- matics 44(1):118\u2013125. O. Bodenreider and A. Burgun. 2004. Aligning knowl- edge sources in the UMLS: methods, quantitative results, and applications. In Proceedings of the 11th World Congress on Medical Informatics (MED- INFO). San Fransico, CA, pages 327\u2013331. J.E. Caviedes and J.J. Cimino. 2004. Towards the development of a conceptual distance metric for the UMLS. Journal of Biomedical Informatics 37(2):77\u201385.",
      "J.E. Caviedes and J.J. Cimino. 2004. Towards the development of a conceptual distance metric for the UMLS. Journal of Biomedical Informatics 37(2):77\u201385. B. Chiu, G. Crichton, A. Korhonen, and S. Pyysalo. 2016. How to Train Good Word Embeddings for Biomedical NLP. In Proceedings of the 15th Work- shop on Biomedical Natural Language Processing. pages 166\u2013174. R.A. Fisher. 1915. Frequency distribution of the values of the correlation coef\ufb01cient in samples from an in- de\ufb01nitely large population. Biometrika pages 507\u2013 521. Z. Harris. 1954. Distributional structure. Word 10(23):146\u2013162. F. Hill, K. Cho, and A. Korhonen. 2016a. Learning distributed representations of sentences from unla- belled data. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.",
      "F. Hill, K. Cho, and A. Korhonen. 2016a. Learning distributed representations of sentences from unla- belled data. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Lin- guistics, San Diego, California, pages 1367\u20131377. F. Hill, K. Cho, A. Korhonen, and Y. Bengio. 2016b. Learning to understand phrases by embedding the dictionary. Transactions of the Association for Com- putational Linguistics 4:17\u201330. N.C. Ide, R.F. Loane, and D. Demner-Fushman. 2007. Essie: a concept-based search engine for structured biomedical text. Journal of the American Medical Informatics Association 14(3):253\u2013263. A. Islam and D. Inkpen. 2006. Second order co- occurrence pmi for determining the semantic simi- larity of words. In Proceedings of the International Conference on Language Resources and Evaluation, Genoa, Italy.",
      "A. Islam and D. Inkpen. 2006. Second order co- occurrence pmi for determining the semantic simi- larity of words. In Proceedings of the International Conference on Language Resources and Evaluation, Genoa, Italy. pages 1033\u20131038. J. Jiang and D. Conrath. 1997. Semantic similar- ity based on corpus statistics and lexical taxonomy. In Proceedings on International Conference on Re- search in Computational Linguistics. Tapei, Taiwan, pages 19\u201333. M. Lesk. 1986. Automatic sense disambiguation us- ing machine readable dictionaries: how to tell a pine cone from an ice cream cone. In Proceedings of the 5th Annual International Conference on Systems Documentation. Toronto, Canada, pages 24\u201326. D. Lin. 1998. An information-theoretic de\ufb01nition of similarity. In Intl Conf ML Proc.. San Francisco, CA, pages 296\u2013304. D. Lin and P. Pantel. 2002. Concept discovery from text.",
      "D. Lin. 1998. An information-theoretic de\ufb01nition of similarity. In Intl Conf ML Proc.. San Francisco, CA, pages 296\u2013304. D. Lin and P. Pantel. 2002. Concept discovery from text. In Proceedings of the 19th International Con- ference on Computational Linguistics (COLING- 02). Taipei, Taiwan, pages 577\u2013583. Y. Lin, W. Li, K. Chen, and Y. Liu. 2007. A document clustering and ranking system for exploring MED- LINE citations. Journal of the American Medical Informatics Association 14(5):651\u2013661. Y. Liu, B.T. McInnes, T. Pedersen, G. Melton-Meaux, and S. Pakhomov. 2012. Semantic relatedness study using second order co-occurrence vectors computed from biomedical corpora, UMLS and WordNet. In Proceedings of the 2nd ACM SIGHIT symposium on International health informatics. ACM, pages 363\u2013 372. A. Maedche and S. Staab.",
      "In Proceedings of the 2nd ACM SIGHIT symposium on International health informatics. ACM, pages 363\u2013 372. A. Maedche and S. Staab. 2001. Comparing ontologies-similarity measures and a comparison study. AIFB. B.T. McInnes, T. Pedersen, and S.V. Pakhomov. 2009. UMLS-Interface and UMLS-Similarity: Open source software for measuring paths and se- mantic similarity. In Proceedings of the Ameri- can Medical Informatics Association (AMIA) Sym- posium. San Fransico, CA, pages 431\u2013435. T. Mikolov, I. Sutskever, K. Chen, G.S. Corrado, and J. Dean. 2013. Distributed representations of words and phrases and their compositionality. In Ad- vances in neural information processing systems. pages 3111\u20133119. T.H. Muneeb, Sunil Sahu, and Ashish Anand. 2015.",
      "2013. Distributed representations of words and phrases and their compositionality. In Ad- vances in neural information processing systems. pages 3111\u20133119. T.H. Muneeb, Sunil Sahu, and Ashish Anand. 2015. Evaluating distributed word representations for cap- turing semantics of biomedical concepts. In Pro- ceedings of BioNLP 15. Association for Computa- tional Linguistics, Beijing, China, pages 158\u2013163. S. Pakhomov, B.T. McInnes, T. Adam, Y. Liu, T. Ped- ersen, and G.B. Melton. 2010. Semantic similar- ity and relatedness between clinical terms: An ex- perimental study. In Proceedings of the Ameri- can Medical Informatics Association (AMIA) Sym- posium. Washington, DC, pages 572\u2013576.",
      "S.V. Pakhomov, G. Finley, R. McEwan, Y. Wang, and G.B. Melton. 2016. Corpus domain effects on dis- tributional semantic modeling of medical terms \u2014 Bioinformatics \u2014 Oxford Academic. Bioinformat- ics 32:3635\u20133644. S.V.S. Pakhomov, T. Pedersen, B. McInnes, G.B. Melton, A. Ruggieri, and C.G. Chute. 2011. To- wards a framework for developing semantic relat- edness reference standards. Journal of Biomedical Informatics 44(2):251\u2013265. S. Patwardhan and T. Pedersen. 2006. Using WordNet- based context vectors to estimate the semantic re- latedness of concepts. In Proceedings of the EACL 2006 Workshop Making Sense of Sense - Bring- ing Computational Linguistics and Psycholinguis- tics Together. Trento, Italy, pages 1\u20138. T. Pedersen, S.V.S.",
      "In Proceedings of the EACL 2006 Workshop Making Sense of Sense - Bring- ing Computational Linguistics and Psycholinguis- tics Together. Trento, Italy, pages 1\u20138. T. Pedersen, S.V.S. Pakhomov, S. Patwardhan, and C.G. Chute. 2007. Measures of semantic similarity and relatedness in the biomedical domain. Journal of Biomedical Informatics 40(3):288\u2013299. V. Pekar and S. Staab. 2002. Taxonomy learning: Factoring the structure of a taxonomy into a se- mantic classi\ufb01cation decision. In Proceedings of the 19th International Conference on Computational Linguistics - Volume 1. Association for Computa- tional Linguistics, Stroudsburg, PA, USA, COLING \u201902, pages 1\u20137. G. Pirr\u00b4o and J. Euzenat. 2010. A feature and infor- mation theoretic framework for semantic similarity and relatedness. In The Semantic Web\u2013ISWC 2010, Springer, pages 615\u2013630.",
      "G. Pirr\u00b4o and J. Euzenat. 2010. A feature and infor- mation theoretic framework for semantic similarity and relatedness. In The Semantic Web\u2013ISWC 2010, Springer, pages 615\u2013630. R. Rada, H. Mili, E. Bicknell, and M. Blettner. 1989. Development and application of a metric on seman- tic nets. IEEE Transactions on Systems, Man, and Cybernetics 19(1):17\u201330. K. Radinsky, E. Agichtein, E. Gabrilovich, and S. Markovitch. 2011. A word at a time: computing word relatedness using temporal semantic analysis. In Proceedings of the 20th international conference on World wide web. ACM, pages 337\u2013346. J. Reisinger and R.J. Mooney. 2010. Multi-prototype vector-space models of word meaning. In Human Language Technologies: The 2010 Annual Confer- ence of the North American Chapter of the Associa- tion for Computational Linguistics.",
      "J. Reisinger and R.J. Mooney. 2010. Multi-prototype vector-space models of word meaning. In Human Language Technologies: The 2010 Annual Confer- ence of the North American Chapter of the Associa- tion for Computational Linguistics. Association for Computational Linguistics, pages 109\u2013117. P. Resnik. 1995. Using information content to evaluate semantic similarity in a taxonomy. In Proceedings of the 14th International Joint Conference on Arti\ufb01- cial Intelligence. Montreal, Canada, pages 448\u2013453. A. Sajadi, E.E. Milios, V. Ke\u02c7selj, and J.C.M. Janssen. 2015. Domain-speci\ufb01c semantic relatedness from Wikipedia structure: A case study in biomedical text. In Proceedings of the 16th International Con- ference on Computational Linguistics and Intelli- gent Text Processing (CICLing 2015)). Cairo, Egypt, pages 347\u2013360. D. S\u00b4anchez, M. Batet, and D. Isern. 2011.",
      "Cairo, Egypt, pages 347\u2013360. D. S\u00b4anchez, M. Batet, and D. Isern. 2011. Ontology-based information content computa- tion. Knowledge-Based Systems 24(2):297\u2013303. H. Sch\u00a8utze. 1992. Dimensions of meaning. In Pro- ceedings of the ACM/IEEE Conference on Super- computing. Minneapolis, MN, pages 787\u2013796. H. Sch\u00a8utze. 1998. Automatic word sense discrimina- tion. Computational Linguistics 24(1):97\u2013123. J. Weeds, D. Weir, and D. McCarthy. 2004. Character- ising measures of lexical distributional similarity. In Proceedings of the 20th international conference on Computational Linguistics. Association for Compu- tational Linguistics, page 1015. Z. Wu and M. Palmer. 1994. Verbs semantics and lex- ical selection. In Proceedings of the 32nd Meet- ing of Association of Computational Linguistics.",
      "Association for Compu- tational Linguistics, page 1015. Z. Wu and M. Palmer. 1994. Verbs semantics and lex- ical selection. In Proceedings of the 32nd Meet- ing of Association of Computational Linguistics. Las Cruces, NM, pages 133\u2013138. W. Yih and V. Qazvinian. 2012. Measuring word re- latedness using heterogeneous vector space models. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies. Association for Computational Linguistics, pages 616\u2013620. Z. Yu, T. Cohen, B. Wallace, E. Bernstam, and T. John- son. 2016. Retro\ufb01tting word vectors of mesh terms to improve semantic similarity measures. In Pro- ceedings of the Seventh International Workshop on Health Text Mining and Information Analysis. Asso- ciation for Computational Linguistics, Auxtin, TX, pages 43\u201351. J. Zhong, H. Zhu, J. Li, and Y. Yu.",
      "In Pro- ceedings of the Seventh International Workshop on Health Text Mining and Information Analysis. Asso- ciation for Computational Linguistics, Auxtin, TX, pages 43\u201351. J. Zhong, H. Zhu, J. Li, and Y. Yu. 2002. Conceptual graph matching for semantic search. In Proceedings of the 10th International Conference on Conceptual Structures. pages 92\u2013106."
    ],
    "queries":"/future/u/okhattab/data/MSMARCO/queries.train.tsv",
    "index_name":"PaperTab-question-1609.00559.pdf",
    "overwrite":false,
    "root":".ragatouille/",
    "experiment":"colbert",
    "index_root":null,
    "name":"2025-05/17/10.22.50",
    "rank":0,
    "nranks":1,
    "amp":true,
    "gpus":1,
    "avoid_fork_if_possible":false
  },
  "num_chunks":1,
  "num_partitions":1024,
  "num_embeddings":10648,
  "avg_doclen":171.7419354839,
  "RAGatouille":{
    "index_config":{
      "index_type":"PLAID",
      "index_name":"PaperTab-question-1609.00559.pdf"
    }
  }
}