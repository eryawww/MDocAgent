[
  "Constructing a Natural Language Inference Dataset using Generative Neural Networks Janez Starca,\u2217, Dunja Mladeni\u00b4ca aJo\u02c7zef Stefan Institute and Jo\u02c7zef Stefan International Postgraduate School, Jamova 39, 1000 Ljubljana, Slovenia Abstract Natural Language Inference is an important task for Natural Language Understanding. It is concerned with classifying the logical relation between two sentences. In this paper, we propose several text generative neural networks for generating text hypothesis, which allows construction of new Natural Language Inference datasets. To evaluate the models, we propose a new metric \u2013 the accuracy of the classi\ufb01er trained on the generated dataset. The accuracy obtained by our best generative model is only 2.7% lower than the accuracy of the classi\ufb01er trained on the original, human crafted dataset. Furthermore, the best generated dataset combined with the original dataset achieves the highest accuracy. The best model learns a mapping embedding for each training example. By comparing various metrics we show that datasets that obtain higher ROUGE or METEOR scores do not necessarily yield higher classi\ufb01cation accuracies.",
  "Furthermore, the best generated dataset combined with the original dataset achieves the highest accuracy. The best model learns a mapping embedding for each training example. By comparing various metrics we show that datasets that obtain higher ROUGE or METEOR scores do not necessarily yield higher classi\ufb01cation accuracies. We also provide analysis of what are the characteristics of a good dataset including the distinguishability of the generated datasets from the original one. Keywords: natural language inference, natural language generation, machine learning, dataset construction, generative neural network, recurrent neural network 1. Introduction The challenge in Natural Language Inference (NLI), also known as Recognizing Textual Entailment (RTE), is to correctly decide whether a sentence (referred to as a premise) entails or contradicts or is neutral in respect to another sentence (a hypothesis). This classi\ufb01cation task requires various natural language comprehension skills. In this paper, we are focused on the following natural language generation task based on NLI. Given the premise the goal is to generate a stream of hypotheses that comply with the label (entailment, contradiction or neutral). In addition to reading capabilities this task also requires language generation capabilities.",
  "In this paper, we are focused on the following natural language generation task based on NLI. Given the premise the goal is to generate a stream of hypotheses that comply with the label (entailment, contradiction or neutral). In addition to reading capabilities this task also requires language generation capabilities. The Stanford Natural Language Inference (SNLI) Corpus (Bowman et al., 2015a) is a NLI dataset that contains over a half a million examples. The size of the dataset is su\ufb03cient to train powerful neural networks. Several successful classi\ufb01cation neural networks have already been proposed (Rockt\u00a8aschel et al., 2016; Wang and Jiang, 2016; Cheng et al., 2016; Parikh et al., 2016). In this paper, we utilize SNLI to train generative neural networks. Each example in the dataset consist of two human-written sentences, a premise and a hypothesis, and a corresponding label that describes the relationship between them. Few examples are presented in Table 1. The proposed generative networks are trained to generate a hypothesis given a premise and a label, which allow us to construct new, unseen examples.",
  "Few examples are presented in Table 1. The proposed generative networks are trained to generate a hypothesis given a premise and a label, which allow us to construct new, unseen examples. Some generative models are build to generate a single optimal response given the input. Such models have been applied to machine translation (Sutskever et al., 2014), image caption generation(Xu et al., 2015), or dialogue systems (Serban et al., 2016a). Another type of \u2217Corresponding author Email addresses: janez.starc@ijs.si (Janez Starc), dunja.mladenic@ijs.si (Dunja Mladeni\u00b4c) Preprint submitted to Elsevier February 26, 2022 arXiv:1607.06025v2  [cs.AI]  27 Mar 2017",
  "Premise Hypothesis Label A person throwing a yellow ball in the air. The ball sails through the air entailment A person throwing a yellow ball in the air. The person throws a square contradiction A person throwing a yellow ball in the air. The ball is heavy neutral Table 1: Three NLI examples from SNLI. generative models are autoencoders that generate a stream of random samples from the original distribution. For instance, autoencoders have been used to generate text (Bowman et al., 2015b; Li et al., 2015), and images (Goodfellow et al., 2014). In our setting we combine both approaches to generate a stream of random responses (hypotheses) that comply with the input (premise, label). But what is a good stream of hypotheses? We argue that a good stream contains diverse, comprehensible, accurate and non-trivial hypotheses. A hypothesis is comprehensible if it is grammatical and semantically makes sense. It is accurate if it clearly expresses the relationship (signi\ufb01ed by the label) with the premise.",
  "We argue that a good stream contains diverse, comprehensible, accurate and non-trivial hypotheses. A hypothesis is comprehensible if it is grammatical and semantically makes sense. It is accurate if it clearly expresses the relationship (signi\ufb01ed by the label) with the premise. Finally, it is non-trivial if it is not trivial to determine the relationship (label) between the hypothesis and premise. For instance, given a premise \u201dA man drives a red car\u201d and label entailment, the hypothesis \u201dA man drives a car\u201d is more trivial than \u201dA person is sitting in a red vehicle\u201d. The next question is how to automatically measure the quality of generated hypotheses. One way is to use metrics that are standard in text generation tasks, for instance ROUGE(Lin, 2004), BLEU(Papineni et al., 2002), METEOR(Denkowski and Lavie, 2014). These metrics estimate the similarity between the generated text and the original reference text. In our task they can be used by comparing the generated and reference hypotheses with the same premise and label.",
  "These metrics estimate the similarity between the generated text and the original reference text. In our task they can be used by comparing the generated and reference hypotheses with the same premise and label. The main issue of these metrics is that they penalize the diversity since they penalize the generated hypotheses that are dissimilar to the reference hypothesis. An alternative metric is to use a NLI classi\ufb01er to test the generated hypothesis if the input label is correct in respect to the premise. A perfect classi\ufb01er would not penalize diverse hypotheses and would reward accurate and (arguably to some degree) comprehensible hypotheses. However, it would not reward non-trivial hypotheses. Non-trivial examples are essential in a dataset for training a capable machine learning model. Further- more, we make the following hypothesis. A good dataset for training a NLI classi\ufb01er consists of a variety of accurate, non-trivial and comprehensible examples. Based on this hypothesis, we propose the following approach for evaluation of generative models, which is also presented in Figure 1. First, the generative model is trained on the original training dataset.",
  "Based on this hypothesis, we propose the following approach for evaluation of generative models, which is also presented in Figure 1. First, the generative model is trained on the original training dataset. Then, the premise and label from an example in the original dataset are taken as the input to the generative model to generate a new random hypothesis. The generated hypothesis is combined with the premise and the label to form a new unseen example. This is done for every example in the original dataset to construct a new dataset. Next, a classi\ufb01er is trained on the new dataset. Finally, the classi\ufb01er is evaluated on the original test set. The accuracy of the classi\ufb01er is the proposed quality metric for the generative model. It can be compared to the accuracy of the classi\ufb01er trained on the original training set and tested on the original test set. The generative models learn solely from the original training set to regenerate the dataset. Thus, the model learns the distribution of the original dataset. Furthermore, the generated dataset is just a random sample from the estimated distribution.",
  "The generative models learn solely from the original training set to regenerate the dataset. Thus, the model learns the distribution of the original dataset. Furthermore, the generated dataset is just a random sample from the estimated distribution. To determine how well did the generative model learn the distribution, we observe how close does the accuracy of the classi\ufb01er trained on the generated dataset approach the accuracy of classi\ufb01er trained on the original dataset. Our \ufb02agship generative network EmbedDecoder works in a similar fashion as the encoder-decoder networks, where the encoder is used to transform the input into a low-dimensional latent representation, from which the decoder reconstructs the input. The di\ufb00erence is that EmbedDecoder consists only of the decoder, and the latent representation is learned as an embedding for each training example separately. In 2",
  "Original Dataset Generative Model learns from Generated Dataset generates Original Classi\ufb01er learns from, tested on New Classi\ufb01er learns from tested on accuracy compared Figure 1: Evaluation of NLI generative models. Note that both datasets are split on training test and validation sets. our models, the latent representation represents the mapping between the premise and the label on one side and the hypothesis on the other side. Our main contributions are i) a novel generative neural network, which consist of the decoder that learns a mapping embedding for each training example separately, ii) a procedure for generating NLI datasets automatically, iii) and a novel evaluation metric for NLI generative models \u2013 the accuracy of the classi\ufb01er trained on the generated dataset. In Section 2 we present the related work. In Section 3 the considered neural networks are presented. Besides the main generative networks, we also present classi\ufb01cation and discriminative networks, which are used for evaluation. The results are presented in Section 5, where the generative models are evaluated and compared. From the experiments we can see that the best dataset was generated by the attention-based model EmbedDecoder.",
  "The results are presented in Section 5, where the generative models are evaluated and compared. From the experiments we can see that the best dataset was generated by the attention-based model EmbedDecoder. The classi\ufb01er on this dataset achieved accuracy of 78.5%, which is 2.7% less than the accuracy achieved on the original dataset. We also investigate the in\ufb02uence of latent dimensionality on the performance, compare di\ufb00erent evaluation metrics, and provide deeper insights of the generated datasets. The conclusion is presented in Section 6. 2. Related Work NLI has been the focal point of Recognizing Textual Entailment (RTE) Challenges, where the goal is to determine if the premise entails the hypothesis or not1. The proposed approaches for RTE include bag-of-words matching approach (Glickman et al., 2005), matching predicate argument structure approach (MacCartney et al., 2006) and logical inference approach (Bos and Markert, 2006; Tatu and Moldovan, 2006). Another rule-based inference approach was proposed by Bar-Haim et al. (2015).",
  "Another rule-based inference approach was proposed by Bar-Haim et al. (2015). This approach allows generation of new hypotheses by transforming parse trees of the premise while maintaining entailment. Hickl et al. (2006) proposes an approach for constructing training datasets by extracting sentences from news articles that tend to be in an entailment relationship. After SNLI dataset was released several neural network approaches for NLI classi\ufb01cation have emerged. (Rockt\u00a8aschel et al., 2016; Wang and Jiang, 2016; Cheng et al., 2016; Parikh et al., 2016). The state-of-the-art model (Parikh et al., 2016) achieves 86.6% accuracy on the SNLI dataset. A similar generation approach to ours was proposed by Kolesnyk et al. (2016), The goal of this work is generating entailment inference chains, where only examples with entailment label are used.",
  "A similar generation approach to ours was proposed by Kolesnyk et al. (2016), The goal of this work is generating entailment inference chains, where only examples with entailment label are used. Natural Lanuguage Generation (NLG) is a task of generating natural language from a structured form such as knowledge base or logic form (Wen et al., 2015; Mairesse et al., 2010; Belz, 2008). The input in our 1The task is designed as a 2-class classi\ufb01cation problem, while the SNLI dataset is constructed for a 3-class classi\ufb01cation task. 3",
  "task is unstructured text (premise) and label. On the other side of this spectrum, there are tasks that deal solely with unstructured text, like machine translation (Koehn, 2009; Bahdanau et al., 2014; Luong et al., 2015), summarization (Clarke and Lapata, 2008; Rush et al., 2015) and conversational dialogue systems (Serban et al., 2016a; Banchs and Li, 2012). Another recently popular task is generating captions from images (Vinyals et al., 2015; Socher et al., 2014). With the advancement of deep learning, many neural network approaches have been introduced for generating sequences. The Recurrent Neural Network Language Model (RNNLM) (Mikolov et al., 2010) is one of the simplest neural architectures for generating text. The approach was extended by (Sutskever et al., 2014), which use encoder-decoder architecture to generate a sequence from the input sequence.",
  "The approach was extended by (Sutskever et al., 2014), which use encoder-decoder architecture to generate a sequence from the input sequence. The Hierarchical Recurrent Encoder-Decoder (HRED) architecture (Serban et al., 2016a) generates sequences from several input sequences. These models o\ufb00er very little variety of output sequences. It is obtained by modeling the output distribution of the language model. To introduce more variety, models based on variational autoencoder (VAE)(Kingma and Welling, 2013) have been proposed. These models use stochastic random variables as a source of variety. In (Bowman et al., 2015b) a latent variable is used to initial the RNN that generates sentences, while the variational recurrent neural network (VRNN) (Chung et al., 2015) models the dependencies between latent variables across subsequent steps of RNN. The Latent Variable Hierarchical Recurrent Encoder-Decoder (VHRED) (Serban et al., 2016b) extends the HRED by incorporating latent variables, which are learned similarly than in VAE.",
  "The Latent Variable Hierarchical Recurrent Encoder-Decoder (VHRED) (Serban et al., 2016b) extends the HRED by incorporating latent variables, which are learned similarly than in VAE. The latent variables are, like in some of our models, used to represent the mappings between sequences. Conditional variational autoencoders (CVAEs) (Yan et al., 2015) were used to generate images from continuous visual attributes. These attributes are conditional information that is fed to the models, like the discrete label is in our models. As recognized by (Reiter and Belz, 2009), the evaluation metrics of text-generating models fall into three categories: manual evaluation, automatic evaluation metrics, task-based evaluation. In evaluation based on human judgment each generated textual example is inspected manually. The automatic evaluation metrics, like ROUGE, BLEU and METEOR, compare human texts and generated texts. (Elliott and Keller, 2014) shows METEOR has the strongest correlation with human judgments in image description evaluation. The last category is task-based evaluation, where the impact of the generated texts on a particular task is measured.",
  "(Elliott and Keller, 2014) shows METEOR has the strongest correlation with human judgments in image description evaluation. The last category is task-based evaluation, where the impact of the generated texts on a particular task is measured. This type of evaluation usually involves costly and lengthy human involvement, like measuring the e\ufb00ectiveness of smoking-cessation letters (Reiter et al., 2003). On the other hand, the task in our evaluation, the NLI classi\ufb01cation, is automatic. In (Hodosh et al., 2013) ranking was used as an automatic task-based evaluation for associating images with captions. 3. Models In this section, we present several neural networks used in the experiments. We start with variants of Recurrent Neural Networks, which are essential layers in all our models. Then, we present classi\ufb01cation networks, which are needed in evaluation of generative neural networks presented in the following section. Next, we present how to use generative networks to generate hypothesis. Finally, we present discriminative networks, which are used for evaluation and analysis of the hypotheses. The premise W p = wp 1wp 2 .",
  "Next, we present how to use generative networks to generate hypothesis. Finally, we present discriminative networks, which are used for evaluation and analysis of the hypotheses. The premise W p = wp 1wp 2 . . . wp M and hypothesis W h = wh 1wh 2 . . . wh N are represented with word embed- dings Xp = xp 1xp 2 . . . xp M and Xh = xh 1xh 2 . . . xh N respectively. Each x is a e-dimensional vector that represents the corresponding word, M is the length of premise, and N is the length of hypothesis. The labels (entail- ment, contradiction, neutral) are represented by a 3-dimensional vector Y l if the label is the output of the model, or L if the label is the input to the model. 3.1. Recurrent Neural Networks The Recurrent Neural Networks (RNNs) are neural networks suitable for processing sequences. They are the basic building block in all our networks.",
  "3.1. Recurrent Neural Networks The Recurrent Neural Networks (RNNs) are neural networks suitable for processing sequences. They are the basic building block in all our networks. We use two variants of RNNs \u2013 Long short term memory (LSTM) network (Hochreiter and Schmidhuber, 1997) and an attention-based extension of LSTM, the mLSTM (Wang and Jiang, 2016). The LSTM tends to learn long-term dependencies better than vanilla RNNs. The input to the LSTM is a sequence of vectors X = x1x2 . . . xn, and the output is a sequence of 4",
  "vectors H = h1h2 . . . hn. At each time point t, input gate it, forget gate ft, output gate ot, cell state Ct and one output vector ht are calculated. it = \u03c3(Wixt + Uiht\u22121 + bi) (1) ft = \u03c3(Wfxt + Ufht\u22121 + bf) (2) ot = \u03c3(Woxt + Uoht\u22121 + bo) (3) Ct = ft \u2299Ct\u22121 + it \u2299tanh(Wcxt + Ucht\u22121 + bc) (4) ht = ot \u2299tanh(Ct), (5) where \u03c3 is a sigmoid function, \u2299is the element-wise multiplication operator, W \u2208Rd\u00d7e and U \u2208Rd\u00d7d are parameter matrices, b \u2208Rd parameter vectors, e is the input vector dimension, and d is the output vector dimension. The vectors C0 and h0 are set to zero in the standard setting, however, in some cases in our models, they are set to a value that is the result of previous layers.",
  "The vectors C0 and h0 are set to zero in the standard setting, however, in some cases in our models, they are set to a value that is the result of previous layers. The mLSTM is an attention-based model with two input sequences \u2013 premise and hypothesis in case of NLI. Each word of the premise is matched against each word of the hypothesis to \ufb01nd the soft alignment between the sentences. The mLSTM is based on LSTM in such a way that it remembers the important matches and forgets the less important. The input to the LSTM inside the mLSTM at each time step is x\u2032 t = [at, xh t ], where at is an attention vector that represents the weighted sum of premise sequence, where the weights present the degree to which each token of the premise is aligned with the t-th token of the hypothesis xh t , and [\u2217, \u2217] is the concatenation operator. More details about mLSTM are presented in (Wang and Jiang, 2016). 3.2. Classi\ufb01cation model The classi\ufb01cation model predicts the label of the example given the premise and the hypothesis.",
  "More details about mLSTM are presented in (Wang and Jiang, 2016). 3.2. Classi\ufb01cation model The classi\ufb01cation model predicts the label of the example given the premise and the hypothesis. We use the mLSTM-based model proposed by (Wang and Jiang, 2016). The architecture of the model is presented in Figure 2. The embeddings of the premise Xp and hypothesis Xh are the input to the \ufb01rst two LSTMs to obtain the hidden states of the premise Hp and hypothesis Hh. Hp = LSTM (Xp) Hh = LSTM (Xh) (6) All the hidden states in our models are d-dimensional unless otherwise noted. The hidden states Hp and Hh are the input to the mLSTM layer. The output of mLSTM are hidden states Hm, although only the last state hm N is further used. A fully connected layer transforms it into a 3-dimensional vector, on top of which softmax function is applied to obtain the probabilities Y l of labels. Y l = Softmax(Dense3(hm N)), (7) where Densex represents the fully connected layer, whose output size is x.",
  "A fully connected layer transforms it into a 3-dimensional vector, on top of which softmax function is applied to obtain the probabilities Y l of labels. Y l = Softmax(Dense3(hm N)), (7) where Densex represents the fully connected layer, whose output size is x. 3.3. Generative models The goal of the proposed generative models, is to generate a diverse stream of hypotheses given the premise and the label. In this section, we present four variants of generative models, two variants of EmbedDecoder model presented in Figure 3a, and two variants of EncoderDecoder model presented in Figure 3b. 5",
  "Xp = xp 1xp 2 . . . xp M LSTM Hp = hp 1hp 2 . . . hp M Xh = xh 1xh 2 . . . xh N LSTM Hh = hh 1hh 2 . . . hh N mLSTM hm N Y l Figure 2: NLI classi\ufb01cation model Z Decoder 0-Hypo Premise Label Hypo (a) EmbedDecoder model Z Decoder 0-Hypo Premise Label Hypo Encoder Hypo Premise Label (b) EncoderDecoder model Figure 3: Generative models architecture. The rounded boxes represent trainable parameters, blue boxes are inputs, green boxes are outputs and the orange box represents the mapping embeddings. 0-Hypo denotes the shifted <null>-started hypothesis. Note that in EncoderDecoder model the latent representation Z is just a hidden layer, while in EmebedDecoder it is a trainable parameter matrix. 6",
  "All models learn a latent representation Z that represents the mapping between the premise and the label on one side, and the hypothesis on the other side. The EmbedDecoder models learn the latent rep- resentation by learning an embedding of the mapping for each training example separately. The embedding for i-th training example Z(i) is a z-dimensional trainable parameter vector. Consequentely, Z \u2208Rn\u00d7z is a parameter matrix of all embeddings, where n is the number of training examples. On the other hand, in EncoderDecoder models latent representation is the output of the decoder. The EmbedDecoder models are trained to predict the next word of the hypothesis given the previous words of hypothesis, the premise, the label, and the latent representation of the example. \u03b8\u22c6, Z\u22c6= arg max \u03b8,Z n X i=1 d(W h(i)) X k=1 log p(wh(i) k |wh(i) k\u22121 . . . wh(i) 1 , W p(i), L(i), Z(i), \u03b8) (8) where \u03b8 represent parameters other than Z, and d(W h(i)) is the length of the hypothesis W h(i).",
  ". . wh(i) 1 , W p(i), L(i), Z(i), \u03b8) (8) where \u03b8 represent parameters other than Z, and d(W h(i)) is the length of the hypothesis W h(i). The AttEmbedDecoder, presented in Figure 4, is attention based variant of EmbedDecoder. The same mLSTM layer is used as in classi\ufb01cation model. However, the initial cell state C0 of mLSTM is constructed from the latent vector and the label input. C0 = Densed([Z(i), L]) (9) For the sake of simplifying the notation, we dropped the superscript (i) from the equations, except in Z(i), where we explicitly want to state that the embedding vector is used. The premise and the hypothesis are \ufb01rst processed by LSTM and then fed into the mLSTM, like in the classi\ufb01cation model, however here the hypothesis is shifted. The \ufb01rst word of the hypothesis input is an empty token <null>, symbolizing the empty input sequence when predicting the \ufb01rst word.",
  "The \ufb01rst word of the hypothesis input is an empty token <null>, symbolizing the empty input sequence when predicting the \ufb01rst word. The output of the mLSTM is a hidden state Hm, where each hm represents an output word. To obtain the probabilities for all the words in the vocabulary yh k for the position k in the output sequence, hm k is \ufb01rst transformed into a vocabulary-sized vector, then the softmax function is applied. yh k = softmax(DenseV (hm k )), (10) where V is the size of the vocabulary. But, due to the large size of the vocabulary, a two-level hierarchical softmax (Goodman, 2001) was used instead of a regular softmax to reduce the number of parameters updated during each training step. yh k = hsoftmax(hm k ) (11) In the training step, the last output word yh N+1 is set to <null>, while in the generating step, it is ignored. In the EmbedDecoder model without attention, BaseEmbedDecoder, the mLSTM is replaced by a regular LSTM. The input to this LSTM is the shifted hypothesis.",
  "In the EmbedDecoder model without attention, BaseEmbedDecoder, the mLSTM is replaced by a regular LSTM. The input to this LSTM is the shifted hypothesis. But, here the premise is provided through the initial cell state C0. Speci\ufb01cally, last hidden state of the premise is merged with class input and the latent representation, then fed to the LSTM. C0 = Densed\u2032([Z(i), L, hp M]) (12) In order to not lose information d\u2032 was picked to be equal to sum of the sizes of Z(i), L and hp M. Thus, d\u2032 = f + 3 + d. Since the size of C0 is d\u2032, the output vectors of the LSTM are also the size of d\u2032. We also present two variants of EncoderDecoder models, a regular one BaseEncodeDecoder, and a regularized one VarEncoderDecoder, which is based on Variational Bayesian approach. As presented in Figure 3b, all the information (premise, hypothesis, label) is available to the encoder, whose output is the latent representation Z. On the other hand, the decoder is provided with the same premise and label, but the hypothesis is shifted.",
  "As presented in Figure 3b, all the information (premise, hypothesis, label) is available to the encoder, whose output is the latent representation Z. On the other hand, the decoder is provided with the same premise and label, but the hypothesis is shifted. This forces the encoder to learn to encode only the missing information \u2013 the mapping between premise-label pair and the hypothesis. The encoder has a similar structure as the classi\ufb01cation model in Figure 2. Except that the label is connected to the initial cell state of the mLSTM 7",
  "C0 = Densed(L), (13) and the output of mLSTM hm N is transformed into latent representation Z Z = Densez(hm N). (14) The decoder is the same as in EmbedDecoder. The VarEncoderDecoder models is based on Variational Autoencoder from (Kingma and Welling, 2013). Instead of using single points for latent representation as in all previous models, the latent represen- tation in VarEncoderDecoder is presented as a continuous variable Z \u223cN(Z\u00b5, Z\u03c3). Thus, the mappings are presented as a soft elliptical regions in the latent space, instead of a single points, which forces the model to \ufb01ll up the latent space (Bowman et al., 2015b). Both Z\u00b5 and Z\u03c3 are calculated form the output of the encoder using two di\ufb00erent fully connected layers. Z\u00b5 = Densez(hm N), Z\u03c3 = Densez(hm N).",
  "Both Z\u00b5 and Z\u03c3 are calculated form the output of the encoder using two di\ufb00erent fully connected layers. Z\u00b5 = Densez(hm N), Z\u03c3 = Densez(hm N). To sample from the distribution the reparametrization trick is applied Z = Z\u00b5 + Z\u03c3 \u2299\u03f5, \u03f5 \u223cN(0, I) (15) When training, a single sample is generated per example to generate Z. As in (Kingma and Welling, 2013), the following regularization term is added to the loss function 1 2(1 + log(Z2 \u03c3) \u2212Z2 \u00b5 \u2212Z2 \u03c3). (16) 3.4. Generating hypotheses In the generation phase only decoder of a trained generative model is used. It generates a hypothesis given the premise, label, and a randomly selected latent vector Z(\u2217) . A single word is generated in each step, and it becomes the hypothesis input in the next step. xh k = embedding(arg max yh k) (17) We also used beam search to optimize hypothesis generation.",
  "A single word is generated in each step, and it becomes the hypothesis input in the next step. xh k = embedding(arg max yh k) (17) We also used beam search to optimize hypothesis generation. Similarly as in (Sutskever et al., 2014), a small number of hypotheses are generated given a single input, then the best is selected. In k-beam search, in each time step k best partial hypotheses are expanded by all the words in the vocabulary producing kV partial hypothesis. Out of these k best partial hypotheses are selected for the next step according to the joint probability of each partial hypothesis. Thus, when k is 1, the procedure is the same as the one presented in Eq 17. The generation ends when <null> symbol is encountered or maximum hypothesis length is reached2. The random latent vector Z(\u2217) is selected randomly from a normal distribution N(0, \u03c3), where \u03c3 is the standard deviation of Z. 2In beam search mode the process stops when all k hypotheses reach the <null> symbol or maximum hypothesis length is reached 8",
  "Xp = xp 1xp 2 . . . xp M LSTM Hp = hp 1hp 2 . . . hp M Xh = <null>xh 1xh 2 . . . xh N LSTM Hh = hh 1hh 2 . . . hh N+1 mLSTM . Z(i) Xl Hm = hm 1 xm 2 . . . hm N+1 Hierachical Softmax Y h = yh 1 yh 2 . . . yh N+1 Figure 4: AttEmbedDecoder model 3.5. Discriminative model The discriminative model is used to measure the distinguishability between the original human written sentences and the generated ones. Higher error rate of the model means that the generative distribution is similar to the original distribution, which is one of the goals on the generative model.",
  "Discriminative model The discriminative model is used to measure the distinguishability between the original human written sentences and the generated ones. Higher error rate of the model means that the generative distribution is similar to the original distribution, which is one of the goals on the generative model. The model is based on Generative Adversarial Nets (Goodfellow et al., 2014), where in a single network the generative part tires to trick the discriminative part by generating images that are similar to the original images, and the discriminative part tries to distinguish between the original and generated images. Due to the discreteness of words (the output of our generative model) it is di\ufb03cult to connect both the discriminative and generative part in a single di\ufb00erentiable network, thus we construct them separately. The generative models have already been de\ufb01ned in Section 3.3. Here we de\ufb01ne the discriminative model.",
  "The generative models have already been de\ufb01ned in Section 3.3. Here we de\ufb01ne the discriminative model. The discriminative model D takes sequence X and process it with LSTM and fully connected layer D(X) = \u03c3(Dense1(LSTM (X)) (18) In the training step, one original sequence Xoriginal and one generated sequence Xgenerated are processed by the discriminative model. The optimization function maximizes the following objective log(D(Xoriginal)) + log(1 \u2212D(Xgenerated)) (19) In the testing step, the discriminative model predicts correctly if D(Xoriginal) > D(Xgenerated) (20) 4. Dataset Generation To construct a new dataset, \ufb01rst a generative model is trained on the training set of the original dataset. Then, a new dataset is constructed by generating a new hypotheses with a generative model. The premises and labels from the examples of the original dataset are taken as an input for the generative model. The new hypotheses replace the training hypotheses in the new dataset. Next, the classi\ufb01er, presented in Section 3.2, is trained on the generated dataset.",
  "The premises and labels from the examples of the original dataset are taken as an input for the generative model. The new hypotheses replace the training hypotheses in the new dataset. Next, the classi\ufb01er, presented in Section 3.2, is trained on the generated dataset. The accuracy of the new classi\ufb01er is the main metric for evaluating the quality of the generated dataset. 9",
  "4.1. Experiment details All the experiments are performed on the SNLI dataset. There are 549,367 examples in the dataset, divided into training, development and test set. Both the development and test set contain around 10.000 examples. Some examples are labeled with \u2019-\u2019, which means there was not enough consensus on them. These examples are excluded. Also, to speed up the computation we excluded examples, which have the premise longer than 25 words, or the hypothesis longer than 15 words. There were still 92.5% remaining examples. Both premises and hypothesis were padded with <null> symbols (empty words), so that all premises consisted of 25 words, and all hypotheses consisted of 15 tokens. We use 50-dimensional word vectors3 trained with GloVe (Pennington et al., 2014). For words with- out pretrained embeddings, the embeddings are randomly selected from the normal distribution. Word embeddings are not updated during training. For optimization Adam method (Kingma and Ba, 2014) was used with suggested hyperparameters4. Classi\ufb01cation models are trained until the loss on the validation set does not improve for three epochs.",
  "Word embeddings are not updated during training. For optimization Adam method (Kingma and Ba, 2014) was used with suggested hyperparameters4. Classi\ufb01cation models are trained until the loss on the validation set does not improve for three epochs. The model with best validation loss is retained. Generative models are trained for 20 epochs, since it turned out that none of the stopping criteria were useful. With each generative model a new dataset is created. The new dataset consists of training set, which is generated using examples from the original training set, and a development set, which is generated from the original development set. The beam size for beam search was set to 1. The details of the decision are presented in Section 5.1. Some datasets were constructed by \ufb01ltering the generated datasets according to various thresholds. Thus, the generated datasets were constructed to contain enough examples, so that the \ufb01ltered datasets had at least the number of examples as the original dataset. In the end, all the datasets were trimmed down to the size of the original dataset by selecting the samples sequentially from the beginning until the dataset had the right size.",
  "In the end, all the datasets were trimmed down to the size of the original dataset by selecting the samples sequentially from the beginning until the dataset had the right size. Also, the datasets were \ufb01ltered so that each of the labels was represented equally. All the models, including classi\ufb01cation and discriminative models, were trained with hidden dimension d set to 150, unless otherwise noted. Our implementation is accessible at http://github.com/jstarc/nli_generation. It is based on li- braries Keras5 and Theano(Theano Development Team, 2016). 5. Results First, the classi\ufb01cation model OrigClass was trained on the original dataset. This model was then used throughout the experiments for \ufb01ltering the datasets, comparison, etc. Notice that we have assumed OrigClass to be ground truth for the purpose of our experiments. However, the accuracy of this model on the original test set was 81.3%, which is less than 86.1%, which was attained by mLSTM (d=150) model in (Wang and Jiang, 2016).",
  "However, the accuracy of this model on the original test set was 81.3%, which is less than 86.1%, which was attained by mLSTM (d=150) model in (Wang and Jiang, 2016). Both models are very similar, including the experimental settings, however ours was trained and evaluated on a slightly smaller dataset. 5.1. Preliminary evaluation Several AttEmbedDecoder models with various latent dimensions z \u2208[2, 4, 8, 16, 32, 1476] were \ufb01rst trained and then used to generate new datasets. A couple of generated examples are presented in Table 2. Figure 5 shows the accuracies of the generated development datasets evaluated by the OrigClass. The maximum accuracy of 64.2% was achieved by EmbedDecoder (z=2), and the accuracy is decreasing with the number of dimensions in the latent variable.",
  "Figure 5 shows the accuracies of the generated development datasets evaluated by the OrigClass. The maximum accuracy of 64.2% was achieved by EmbedDecoder (z=2), and the accuracy is decreasing with the number of dimensions in the latent variable. The analysis for each label shows that the accuracy of contradiction and neutral labels is quite stable, while the accuracy of the entailment examples drops 3http://nlp.stanford.edu/data/glove.6B.zip 4As suggested in (Kingma and Ba, 2014) \u03b21 is set to 0.9 and beta2 is set to 0.999. 5http://keras.io 6Latent dimension z = 147 is the largest dimension so that there is no reduction in dimensionality in Equation 9, therefore z + c = d, where c is the number of labels. 10",
  "Premise A person throwing a yellow ball in the air. z = 2 neutral Someone is playing basketball. contradiction A person is sleeping in a chair. entailment A person is throwing a ball z = 8 neutral The person has a yellow ball going to the game. contradiction The person is sitting in the bleachers. entailment A person is playing with a ball. z = 147 neutral A person is trying to get home from give a ball. contradiction A person is reading a bank from london. entailment A person is throwing a ball up. Premise Two women in bathing suits climb rock piles by the ocean. z = 2 neutral Two women are climbing rocks in the ocean on a sunny day. contradiction The women are playing basketball. entailment Two women are climbing. z = 8 neutral Two young women in bathing suits are friends contradiction Two women naked. entailment The girls looking at the water. z = 147 neutral Two women are looking at the lagoon in front of a calm shore. contradiction Two women are gossiping on a sandy beach.",
  "entailment The girls looking at the water. z = 147 neutral Two women are looking at the lagoon in front of a calm shore. contradiction Two women are gossiping on a sandy beach. entailment A group of women are climbing wood in the ocean. Table 2: Generated examples to illustrate the proposed appraoch. signi\ufb01cantly with latent dimensionality. One reason for this is that the hypothesis space of the entailment label is smaller than the spaces of other two labels. Thus, when the dimensionality is higher, more creative examples are generated, and these examples less often comply with the entailment label. Since none of the generated datasets\u2019 accuracies is as high as the accuracy of the OrigClass on the original test set, we used OrigClass to \ufb01lter the datasets subject to various prediction thresholds. The examples from the generated dataset were classi\ufb01ed by OrigClass and if the probability of the label of the example exceeded the threshold t \u2208[0.0, 0.3, 0.6, 0.9], then the example was retained.",
  "The examples from the generated dataset were classi\ufb01ed by OrigClass and if the probability of the label of the example exceeded the threshold t \u2208[0.0, 0.3, 0.6, 0.9], then the example was retained. For each \ufb01ltered dataset a classi\ufb01er was trained. Figure 6a shows the accuracies of these classi\ufb01ers on the original test set. Filtering out the examples that have incorrect labels (according to the OrigClass) improves the accuracy of the classi\ufb01er. However, if the threshold is set too high, the accuracy drops, since the dataset contains examples that are too trivial. Figure 6b, which represents the accuracy of classi\ufb01ers on their corresponding generated development sets, further shows the trade-o\ufb00between the accuracy and triviality of the examples. The classi\ufb01ers trained on datasets with low latent dimension or high \ufb01ltering threshold have higher accuracies. Notice that the training dataset and test dataset were generated by the same generative model.",
  "The classi\ufb01ers trained on datasets with low latent dimension or high \ufb01ltering threshold have higher accuracies. Notice that the training dataset and test dataset were generated by the same generative model. The un\ufb01ltered datasets have been evaluated with \ufb01ve other metrics besides classi\ufb01cation accuracy. The results are presented in Figure 7. The whole \ufb01gure shows the e\ufb00ect of latent dimensionality of the models on di\ufb00erent metrics. The main purpose of the \ufb01gure is not show absolute values for each of the metrics, but to compare the metrics\u2019 curves to the curve of our main metric, the accuracy of the classi\ufb01er. The \ufb01rst metric \u2013 Premise-Hypothesis Distance \u2013 represents the average Jaccard distance between the premise and the generated hypothesis. Datasets generated with low latent dimensions have hypotheses more similar to premises, which indicates that the generated hypotheses are more trivial and less diverse than hypothesis generated with higher latent dimensions. We also evaluated the models with standard language generation metrics ROUGE-L and METEOR. The metrics are negatively correlated with the accuracy of the classi\ufb01er.",
  "We also evaluated the models with standard language generation metrics ROUGE-L and METEOR. The metrics are negatively correlated with the accuracy of the classi\ufb01er. We believe this is because the two metrics reward hypotheses that are similar to their reference (original) hypothesis. However, the classi\ufb01er is better if trained on more diverse hypotheses. 11",
  "2 4 8 16 32 147 Latent Dimension 0.3 0.4 0.5 0.6 0.7 0.8 0.9 Accuracy% Accuracies of datasets All Neutral Contradiction Entailment Figure 5: Accuracies of the un\ufb01ltered generated datasets classi\ufb01ed by OrigClass. A dataset was generated for each generative model with di\ufb00erent latent dimension z \u2208[2, 4, 8, 16, 32, 147]. For each dataset the examples were classi\ufb01ed with OrigClass. The predicted labels were taken as a golden truth and were compared to the labels of the generated dataset to measure its accuracy. The accuracies were measured for all the labels together and for each label separately.",
  "For each dataset the examples were classi\ufb01ed with OrigClass. The predicted labels were taken as a golden truth and were compared to the labels of the generated dataset to measure its accuracy. The accuracies were measured for all the labels together and for each label separately. 2 4 8 16 32 147 Latent Dimension 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 Accuracy% Classifiers evaluated on original data 0.0 0.3 0.6 0.9 (a) Accuracies of classi\ufb01ers evaluated on the original test set 2 4 8 16 32 147 Latent Dimension 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 Accuracy% Classifiers evaluated on generated data 0.0 0.3 0.6 0.9 (b) Accuracies of classi\ufb01ers evaluated on generated devel- opment sets Figure 6: Accuracies of classi\ufb01ers trained on the generated dataset and tested on the original test set and the generated development sets.",
  "A dataset was generated for each generative model with di\ufb00erent latent dimension z \u2208[2, 4, 8, 16, 32, 147]. From these un\ufb01ltered datasets new datasets were created by \ufb01ltering according to various prediction thresholds (0.0, 0.3, 0.6, 0.9), which also represent chart lines. A classi\ufb01er was trained on each of the datasets. Each point represents the accuracy of a single classi\ufb01er. The classi\ufb01ers were evaluated on the original test set in Figure 6a. Each classi\ufb01er was evaluated on its corresponding generated development set in Figure 6b. 12",
  "The next metric is the log-likelihood of hypotheses in the development set. This metric is the negative of the training loss function. The log-likelihood improves with dimensionality since it is easier to \ufb01t the hypotheses in the training step having more dimensions. Consequently, the hypothesis in the generating step are more con\ufb01dent \u2013 they have lower log-likelihood. The last metric \u2013 discriminative error rate \u2013 is calculated with the discriminative model. The model is trained on the hypotheses from the un\ufb01ltered generated dataset on one side and the original hypotheses on the other side. Error rate is calculated on the (generated and original) development sets. Higher error rate indicates that it is more di\ufb03cult for discriminative model to distinguish between the generated and the original hypotheses, which suggests that the original generating distribution and the distribution of the generative model are more similar. The discriminative model detects that low dimensional generative models generate more trivial examples as also indicated by the distance between premise and hypotheses. On the other hand, it also detects the hypotheses of high dimensional models, which more frequently contain grammatic or semantic errors.",
  "The discriminative model detects that low dimensional generative models generate more trivial examples as also indicated by the distance between premise and hypotheses. On the other hand, it also detects the hypotheses of high dimensional models, which more frequently contain grammatic or semantic errors. There is a positive correlation between the discriminative error rate and the accuracy of the classi- \ufb01er. This observation led us to the experiment, where the generated dataset was \ufb01ltered according to the prediction probability of the discriminative model. Two disjoint \ufb01ltered datasets were created. One with hypotheses that had high probability that they come from the original distribution and the other one with low probability. However, the accuracies of classi\ufb01ers trained on these datasets were very similar to the accuracy of the classi\ufb01er on the un\ufb01ltered dataset. Similar test was also done with the log-likelihood metric. The examples with higher log-likelihood had similar performance than the ones with lower log-likelihood. This also lead us to set the size of the beam to 1. Also, the run time of generating hypothesis is O(b), where b is beam size.",
  "The examples with higher log-likelihood had similar performance than the ones with lower log-likelihood. This also lead us to set the size of the beam to 1. Also, the run time of generating hypothesis is O(b), where b is beam size. Thus, with lower beam sizes much more hypotheses can be generated. To accept the hypothesis from Section 1 we have shown that a quality dataset requires accurate exam- ples by showing that \ufb01ltering the dataset with the original classi\ufb01er improves the performance (Figure 6a). Next, we have shown that non-trivial examples are also required. If the \ufb01ltering threshold is set too high, these examples are excluded, and the accuracy drops. Also, the more trivial examples are produced by low-dimensional models, which is indicated by lower premise-hypothesis distances, and lower discriminative error rate (Figure 7). Finally, a quality dataset requires more comprehensible examples. The high dimen- sional models produce less comprehensible hypotheses. They are detected by the discriminative model (see discriminator error rate in Figure 7). 5.2.",
  "Finally, a quality dataset requires more comprehensible examples. The high dimen- sional models produce less comprehensible hypotheses. They are detected by the discriminative model (see discriminator error rate in Figure 7). 5.2. Other models We also compared AttEmbedDecoder model to all other models. Table 3 presents the results. For all the models the latent dimension z is set to 8, as it was previously shown to be one of the best dimensions. For all the models the number of total parameters is relatively high, however only a portion of parameters get updated each time. The AttEmbedDecoder model was the best model according to our main metric \u2013 the accuracy of the classi\ufb01er trained on the generated dataset. The hidden dimension d of the BaseEmbedDecoder was selected so that the model was comparable to AttEmbedDecoder in terms of the number of parameters \u03b8\u2217. The accuracies of classi\ufb01ers generated by BaseEmbedDecoder are still lower than the accuracies of classi\ufb01ers generated by AttEmbedDecoder, which shows that the attention mechanism helps the models. Table 4 shows the performance of generated datasets compared to the original one.",
  "The accuracies of classi\ufb01ers generated by BaseEmbedDecoder are still lower than the accuracies of classi\ufb01ers generated by AttEmbedDecoder, which shows that the attention mechanism helps the models. Table 4 shows the performance of generated datasets compared to the original one. The best generated dataset was generated by AttEmbedDecoder. The accuracy of its classi\ufb01er is only 2.7 % lower than the accuracy of classi\ufb01er generated on the original human crafted dataset. The comparison of the best generated dataset to the original dataset shows that the datasets had only 0.06% of identical examples. The average length of the hypothesis was 7.97 and 8.19 in the original dataset and in the generated dataset, respectively. In another experiment the generated dataset and the original dataset were merged to train a new classi\ufb01er. Thus, the merged dataset contained twice as many examples as other datasets. The accuracy of this classi\ufb01er was 82.0%, which is 0.8 % better than the classi\ufb01er trained solely on the original training set.",
  "Thus, the merged dataset contained twice as many examples as other datasets. The accuracy of this classi\ufb01er was 82.0%, which is 0.8 % better than the classi\ufb01er trained solely on the original training set. However, the lowest average loss is achieved by the classi\ufb01er trained on the original dataset. 13",
  "2 4 8 16 32 147 Latent Dimension 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.80 0.81 Premise-Hypothesis Distance 2 4 8 16 32 147 Latent Dimension 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 ROUGE-L 2 4 8 16 32 147 Latent Dimension 0.80 0.75 0.70 0.65 0.60 0.55 0.50 0.45 0.40 0.35 Log-likelihood 2 4 8 16 32 147 Latent Dimension 0.115 0.120 0.125 0.130 0.135 0.140 0.145 0.150 0.155 METEOR 2 4 8 16 32 147 Latent Dimension 0.08 0.10 0.12 0.",
  "120 0.125 0.130 0.135 0.140 0.145 0.150 0.155 METEOR 2 4 8 16 32 147 Latent Dimension 0.08 0.10 0.12 0.14 0.16 Discriminator Error Rate 2 4 8 16 32 147 Latent Dimension 0.56 0.58 0.60 0.62 0.64 0.66 Classifier Accuracy Figure 7: Comparison of un\ufb01ltered generated datasets using various metrics. Each dataset was generated by a model with a di\ufb00erent latent dimension, then each metric was applied on each dataset. For metrics other than classi\ufb01er accuracy and discriminator error rate, the metric was applied on each example and the average was calculated for each dataset. 14",
  "Model z d |\u03b8total| |\u03b8\u2217| acc@0.0 acc@0.6 acc-data nll disc-er EncoderDecoder 8 150 6.4M 1.1M 43.4 72.4 57.5 1.00 0.01 VaeEncoderDecoder 8 150 6.4M 1.1M 58.6 77.9 48.0 0.77 1.9 BaseEmbedDecoder 8 226 13M 580K 65.0 77.7 56.3 0.73 14.0 AttEmbedDecoder 8 150 11M 581K 65.7 78.5 56.8 0.69 14.8 Table 3: Comparison of generative models. Column |\u03b8total| is the total number of trainable parameters. Column |\u03b8\u2217| represents the number of parameters that are updated with each training example. Thus, hierarchical softmax and latent representation parameters are excluded from this measure.",
  "Column |\u03b8total| is the total number of trainable parameters. Column |\u03b8\u2217| represents the number of parameters that are updated with each training example. Thus, hierarchical softmax and latent representation parameters are excluded from this measure. Columns acc@0.0 and acc@0.6 represent the accuracy of the classi\ufb01er trained on the un\ufb01ltered dataset and on the dataset \ufb01ltered with threshold 0.6, respectively. Column acc-data presents the accuracy of the un\ufb01ltered development dataset evaluated by OrigClass. Column nll presents the negative log-likelihood of the un\ufb01ltered development dataset. The error rates of the discriminative models are presented by disc-er. Dataset loss accuracy% EncoderDecoder 1.563 72.4 VaeEncoderDecoder 1.174 77.9 BaseEmbedDecoder 1.095 77.7 AttEmbedDecoder 0.970 78.5 Original Dataset 0.475 81.2 Original Dataset + AttEmbedDecoder 0.486 82.0 Table 4: The performance of classi\ufb01ers trained on the original and generated datasets.",
  "The classi\ufb01ers were tested on original test set. The generated datasets were generated by the models from Table 3. The generated datasets were \ufb01ltered with threshold 0.6. 5.3. Qualitative evaluation We also did a qualitative evaluation of the generated hypothesis. Hypotheses are mostly grammatically sound. Sometimes the models incorrectly use inde\ufb01nite articles, for instance \u201dan phone\u201d, or possessive pronouns \u201da man uses her umbrella\u201d. These may be due to the fact the system must learn the right inde\ufb01nite article for every word separately. On the other hand, the models sometimes generate hypotheses that showcase more advanced grammatical patterns. For instance, hypothesis \u201dThe man and woman have a cake for their family\u201d shows that the model can correctly use plural in a non-trivial setting. Generative neural networks have a tendency to repeat words, which sometimes make sentences meaningless, like \u201dA cup is drinking from a cup of co\ufb00ee\u201d or even ungrammatical, like \u201dSeveral people in a car car\u201d. As shown previously the larger is the latent dimension more creative hypotheses are generated. However, with more creativity semantic errors emerge.",
  "As shown previously the larger is the latent dimension more creative hypotheses are generated. However, with more creativity semantic errors emerge. Some hypotheses are correct, just unlikely to be written by a human, like \u201dA shirtless man is holding a guitar with a woman and a woman\u201d. Others present improbable events, like \u201dThe girls were sitting in the park watching tv\u201d, or even impossible events, for instance \u201dThe child is waiting for his wife\u201d. This type of errors arise because the models have not learned enough common sense logic. Finally, there are hypotheses, which make no sense. For instance, \u201dTwo women with grassy beach has no tennis equipment\u201d. On the contrary, the models are able to generate some non-trivial hypotheses. From the original premise \u201dA band performing with a girl singing and a guy next to her singing as well while playing the guitar\u201d, the model has generated some hypotheses that do not contain concepts explicitly found in the premise. For instance, \u201dPeople are playing instruments\u201d (entailment), \u201dThe band was entirely silent\u201d (contradiction), or \u201dThe girl is playing at the concert\u201d (neutral).",
  "For instance, \u201dPeople are playing instruments\u201d (entailment), \u201dThe band was entirely silent\u201d (contradiction), or \u201dThe girl is playing at the concert\u201d (neutral). Regarding the compliance of the hypotheses with the label and premise, we observed that many generated hypotheses are not complying with the label, however they would be a very good example with a di\ufb00erent label. For instance, the generated hypotheses represent entailment instead of contradiction. This also explains why the accuracy of the generated dataset measured by the original classi\ufb01er is low in Figure 5. On the other hand, the models generate examples that are more ambiguous and not as clear as those in the original dataset. These examples are harder to classify even for a human. For instance, the relationship between premise \u201dA kid hitting a baseball in a baseball \ufb01eld\u201d and hypothesis \u201dThe baseball player is trying to get the ball\u201d can be either interpreted either as an entailment if verb get is intepreted as not to miss or 15",
  "Dev. set Sample Gen. Model Disc. Model Human Disc. Model Human AttEmbedDecoder 14.0 - 14.0 22.5 VaeEncoderDecoder 1.9 - 2.0 11.5 Table 5: Discrimination error rate on the development set and a sample of 200 examples, evaluated by the discriminative model and human evaluator contradiction if get is intepreted as possess. For a deeper insight into generated hypothesis more examples are presented in Appendix A. The gap between the discriminative error rates (disc-er) of EncoderDecoder models and EmbedDe- coder models in Table 3 is signi\ufb01cant. To further investigate, the same experiment was performed again by a human evaluator and the discriminative model. This time on a sample of 200 examples. To recap, both the model and human were asked to select the generated hypothesis given a random original and generated hypothesis without knowing which one is which. Human evaluation con\ufb01rms that AttEmbedDecoder hypotheses are more di\ufb03cult to separate from the original one than the hypotheses of VaeEncoderDecoder. Table 5 presents the results.",
  "Human evaluation con\ufb01rms that AttEmbedDecoder hypotheses are more di\ufb03cult to separate from the original one than the hypotheses of VaeEncoderDecoder. Table 5 presents the results. The discriminative model discriminates better than the human evaluator. This may be due to the fact that the discriminative model has learned from a large training set, while the human was not shown any training examples. Human evaluation has shown that generated hypotheses are positively recognized if they contain a grammatical or semantic error. But even if the generated hypothesis does not contain these errors, it sometimes reveals itself by not being as sophisticated as the original example. On the other hand, the discriminative model does not always recognize these discrepancies. It relies more on the di\ufb00erences in distributions learned form a big training set. The true number of non-distinguishable examples may be even higher than indicated by the human discriminator error rate since the human may have correctly guessed some of the examples he could not distinguish. 6. Conclusion In this paper, we have proposed several generative neural networks for generating hypothesis using NLI dataset.",
  "The true number of non-distinguishable examples may be even higher than indicated by the human discriminator error rate since the human may have correctly guessed some of the examples he could not distinguish. 6. Conclusion In this paper, we have proposed several generative neural networks for generating hypothesis using NLI dataset. To evaluate these models we propose the accuracy of classi\ufb01er trained on the generated dataset as the main metric. The best model achieved 78.5% accuracy, which is only 2.7% less than the accuracy of the classi\ufb01er trained on the original human written dataset, while the best dataset combined with the original dataset has achieved the highest accuracy. This model learns a decoder and a mapping embedding for each training example. It outperforms the more standard encoder-decoder networks. Although more parameters are needed to be trained, less are updated on each batch. We have also shown that the attention mechanism improves the model. The analysis has con\ufb01rmed our hypothesis that a good dataset contains accurate, non-trivial and comprehensible examples. To further examine the quality of generated hypothesis, they were compared against the original human written hypotheses.",
  "We have also shown that the attention mechanism improves the model. The analysis has con\ufb01rmed our hypothesis that a good dataset contains accurate, non-trivial and comprehensible examples. To further examine the quality of generated hypothesis, they were compared against the original human written hypotheses. The discriminative evaluation shows that in 22.5% of cases the human evaluator incorrectly distinguished between the original and the generated hypothesis. The discriminative model was actually better in distinguishing. We have also compared the accuracy of classi\ufb01er to other metrics. The standard text generation metrics ROUGE and METEOR do not indicate if a generated dataset is good for training a classi\ufb01er. To obtain higher accuracies of the generated datasets, they need to be \ufb01ltered, because the generative models produce examples, whose label is not always accurate. Thus, we propose for future work incorporating the classi\ufb01er into the generative model, in a similar fashion that it was done on images by (Lamb et al., 2016). This network could also include the discriminative model to generate examples from a distribution that is more similar to the original training distribution.",
  "This network could also include the discriminative model to generate examples from a distribution that is more similar to the original training distribution. Finally, constructing a dataset requires a lot of intensive manual work that mainly consists of writing text with some creativity. To extend the original dataset human users could just validate or correct the generated examples. On top of that we would like to develop active learning methods to identify incorrect generated examples that would most improve the dataset if corrected. 16",
  "Acknowledgements This work was supported by the Slovenian Research Agency and the ICT Programme of the EC under XLike (ICT-STREP-288342) and XLime (FP7-ICT-611346). References References Bahdanau, D., Cho, K., and Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473. Banchs, R. E. and Li, H. (2012). Iris: a chat-oriented dialogue system based on the vector space model. In Proceedings of the ACL 2012 System Demonstrations, pages 37\u201342. Association for Computational Linguistics. Bar-Haim, R., Dagan, I., and Berant, J. (2015). Knowledge-based textual inference via parse-tree transformations. Journal of Arti\ufb01cial Intelligence Research, 54(1):1\u201357. Belz, A. (2008). Automatic generation of weather forecast texts using comprehensive probabilistic generation-space models. Natural Language Engineering, 14(04):431\u2013455.",
  "Journal of Arti\ufb01cial Intelligence Research, 54(1):1\u201357. Belz, A. (2008). Automatic generation of weather forecast texts using comprehensive probabilistic generation-space models. Natural Language Engineering, 14(04):431\u2013455. Bos, J. and Markert, K. (2006). When logical inference helps determining textual entailment (and when it doesn\u2019t). In Proceedings of the Second PASCAL RTE Challenge, page 26. Bowman, S. R., Angeli, G., Potts, C., and Manning, C. D. (2015a). A large annotated corpus for learning natural language infer- ence. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics. Bowman, S. R., Vilnis, L., Vinyals, O., Dai, A. M., Jozefowicz, R., and Bengio, S. (2015b). Generating sentences from a continuous space. arXiv preprint arXiv:1511.06349.",
  "(2015b). Generating sentences from a continuous space. arXiv preprint arXiv:1511.06349. Cheng, J., Dong, L., and Lapata, M. (2016). Long short-term memory-networks for machine reading. arXiv preprint arXiv:1601.06733. Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A. C., and Bengio, Y. (2015). A recurrent latent variable model for sequential data. In Advances in neural information processing systems, pages 2980\u20132988. Clarke, J. and Lapata, M. (2008). Global inference for sentence compression: An integer linear programming approach. Journal of Arti\ufb01cial Intelligence Research, 31:399\u2013429. Denkowski, M. and Lavie, A. (2014). Meteor universal: Language speci\ufb01c translation evaluation for any target language. In Proceedings of the EACL 2014 Workshop on Statistical Machine Translation. Elliott, D. and Keller, F.",
  "Denkowski, M. and Lavie, A. (2014). Meteor universal: Language speci\ufb01c translation evaluation for any target language. In Proceedings of the EACL 2014 Workshop on Statistical Machine Translation. Elliott, D. and Keller, F. (2014). Comparing automatic evaluation measures for image description. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: Short Papers, volume 452, page 457. Glickman, O., Dagan, I., and Koppel, M. (2005). Web based probabilistic textual entailment. In Proceedings of the 1st Pascal Challenge Workshop, pages 33\u201336. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative adversarial nets. In Advances in Neural Information Processing Systems, pages 2672\u20132680. Goodman, J. (2001). Classes for fast maximum entropy training.",
  "(2014). Generative adversarial nets. In Advances in Neural Information Processing Systems, pages 2672\u20132680. Goodman, J. (2001). Classes for fast maximum entropy training. In Acoustics, Speech, and Signal Processing, 2001. Proceed- ings.(ICASSP\u201901). 2001 IEEE International Conference on, volume 1, pages 561\u2013564. IEEE. Hickl, A., Williams, J., Bensley, J., Roberts, K., Rink, B., and Shi, Y. (2006). Recognizing textual entailment with lcc\u2019s groundhog system. In Proceedings of the Second PASCAL Challenges Workshop. Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8):1735\u20131780. Hodosh, M., Young, P., and Hockenmaier, J. (2013). Framing image description as a ranking task: Data, models and evaluation metrics.",
  "Neural computation, 9(8):1735\u20131780. Hodosh, M., Young, P., and Hockenmaier, J. (2013). Framing image description as a ranking task: Data, models and evaluation metrics. Journal of Arti\ufb01cial Intelligence Research, 47:853\u2013899. Kingma, D. P. and Ba, J. (2014). Adam: A method for stochastic optimization. Proceedings of the 3rd International Conference on Learning Representations (ICLR). Kingma, D. P. and Welling, M. (2013). Auto-encoding variational bayes. In Proceedings of the 2nd International Conference on Learning Representations (ICLR), number 2014. Koehn, P. (2009). Statistical machine translation. Cambridge University Press. Kolesnyk, V., Rockt\u00a8aschel, T., and Riedel, S. (2016). Generating natural language inference chains. arXiv preprint arXiv:1606.01404.",
  "Statistical machine translation. Cambridge University Press. Kolesnyk, V., Rockt\u00a8aschel, T., and Riedel, S. (2016). Generating natural language inference chains. arXiv preprint arXiv:1606.01404. Lamb, A., Dumoulin, V., and Courville, A. (2016). Discriminative regularization for generative models. arXiv preprint arXiv:1602.03220. Li, J., Luong, T., and Jurafsky, D. (2015). A hierarchical neural autoencoder for paragraphs and documents. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1106\u20131115, Beijing, China. Association for Computational Linguistics. Lin, C.-Y. (2004). Rouge: A package for automatic evaluation of summaries. In Text summarization branches out: Proceedings of the ACL-04 workshop, volume 8. Barcelona, Spain.",
  "Association for Computational Linguistics. Lin, C.-Y. (2004). Rouge: A package for automatic evaluation of summaries. In Text summarization branches out: Proceedings of the ACL-04 workshop, volume 8. Barcelona, Spain. Luong, M.-T., Sutskever, I., Le, Q. V., Vinyals, O., and Zaremba, W. (2015). Addressing the rare word problem in neural machine translation. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 11\u201319, Beijing, China. Association for Computational Linguistics. 17",
  "MacCartney, B., Grenager, T., de Marne\ufb00e, M.-C., Cer, D., and Manning, C. D. (2006). Learning to recognize features of valid textual entailments. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 41\u201348. Association for Computational Linguistics. Mairesse, F., Ga\u02c7si\u00b4c, M., Jur\u02c7c\u00b4\u0131\u02c7cek, F., Keizer, S., Thomson, B., Yu, K., and Young, S. (2010). Phrase-based statistical language generation using graphical models and active learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1552\u20131561. Association for Computational Linguistics. Mikolov, T., Kara\ufb01\u00b4at, M., Burget, L., Cernock`y, J., and Khudanpur, S. (2010). Recurrent neural network based language model. In Interspeech, volume 2, page 3.",
  "(2010). Recurrent neural network based language model. In Interspeech, volume 2, page 3. Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 311\u2013318. Association for Computational Linguistics. Parikh, A. P., T\u00a8ackstr\u00a8om, O., Das, D., and Uszkoreit, J. (2016). A decomposable attention model for natural language inference. arXiv preprint arXiv:1606.01933. Pennington, J., Socher, R., and Manning, C. D. (2014). Glove: Global vectors for word representation. In EMNLP, volume 14, pages 1532\u201343. Reiter, E. and Belz, A. (2009). An investigation into the validity of some metrics for automatically evaluating natural language generation systems.",
  "Glove: Global vectors for word representation. In EMNLP, volume 14, pages 1532\u201343. Reiter, E. and Belz, A. (2009). An investigation into the validity of some metrics for automatically evaluating natural language generation systems. Computational Linguistics, 35(4):529\u2013558. Reiter, E., Robertson, R., and Osman, L. M. (2003). Lessons from a failure: Generating tailored smoking cessation letters. Arti\ufb01cial Intelligence, 144(1):41\u201358. Rockt\u00a8aschel, T., Grefenstette, E., Hermann, K. M., Ko\u02c7cisk`y, T., and Blunsom, P. (2016). Reasoning about entailment with neural attention. In International Conference on Learning Representations. Rush, A. M., Chopra, S., and Weston, J. (2015). A neural attention model for abstractive sentence summarization.",
  "(2016). Reasoning about entailment with neural attention. In International Conference on Learning Representations. Rush, A. M., Chopra, S., and Weston, J. (2015). A neural attention model for abstractive sentence summarization. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 379\u2013389, Lisbon, Portugal. Association for Computational Linguistics. Serban, I. V., Sordoni, A., Bengio, Y., Courville, A., and Pineau, J. (2016a). Building end-to-end dialogue systems using generative hierarchical neural network models. In Proceedings of the 30th AAAI Conference on Arti\ufb01cial Intelligence (AAAI-16). Serban, I. V., Sordoni, A., Lowe, R., Charlin, L., Pineau, J., Courville, A., and Bengio, Y. (2016b). A hierarchical latent variable encoder-decoder model for generating dialogues. arXiv preprint arXiv:1605.06069.",
  "(2016b). A hierarchical latent variable encoder-decoder model for generating dialogues. arXiv preprint arXiv:1605.06069. Socher, R., Karpathy, A., Le, Q. V., Manning, C. D., and Ng, A. Y. (2014). Grounded compositional semantics for \ufb01nding and describing images with sentences. Transactions of the Association for Computational Linguistics, 2:207\u2013218. Sutskever, I., Vinyals, O., and Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104\u20133112. Tatu, M. and Moldovan, D. (2006). A logic-based semantic approach to recognizing textual entailment. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 819\u2013826. Association for Computational Linguistics. Theano Development Team (2016). Theano: A Python framework for fast computation of mathematical expressions. arXiv e-prints, abs/1605.02688.",
  "Association for Computational Linguistics. Theano Development Team (2016). Theano: A Python framework for fast computation of mathematical expressions. arXiv e-prints, abs/1605.02688. Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. (2015). Show and tell: A neural image caption generator. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3156\u20133164. Wang, S. and Jiang, J. (2016). Learning natural language inference with lstm. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1442\u2013 1451, San Diego, California. Association for Computational Linguistics. Wen, T.-H., Gasic, M., Mrk\u02c7si\u00b4c, N., Su, P.-H., Vandyke, D., and Young, S. (2015). Semantically conditioned lstm-based natural language generation for spoken dialogue systems.",
  "Wen, T.-H., Gasic, M., Mrk\u02c7si\u00b4c, N., Su, P.-H., Vandyke, D., and Young, S. (2015). Semantically conditioned lstm-based natural language generation for spoken dialogue systems. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1711\u20131721, Lisbon, Portugal. Association for Computational Linguistics. Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., and Bengio, Y. (2015). Show, attend and tell: Neural image caption generation with visual attention. In Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 2048\u20132057. Yan, X., Yang, J., Sohn, K., and Lee, H. (2015). Attribute2image: Conditional image generation from visual attributes. arXiv preprint arXiv:1512.00570. Appendix A. More Examples In this section more generated hypotheses are presented.",
  "(2015). Attribute2image: Conditional image generation from visual attributes. arXiv preprint arXiv:1512.00570. Appendix A. More Examples In this section more generated hypotheses are presented. Each example starts with the original example data. Then, several hypotheses generated with from the original example with our best model are displayed. 18",
  "Premise: a little boy in a blue shirt holding a toy. Hypothesis: boy dressed in blue carrying toy to a toybox. Label: neutral Generated Hypotheses: the little boy is caucasian. a boy in blue holds a toy for the \ufb01rst time. a child in a blue shirt holds a toy outside. a little boy watches the toy to his friend. a little boy is playing with a toy in the kitchen. the boy likes to his toy. the boy is in the store. Premise: a little boy in a blue shirt holding a toy. Hypothesis: boy dressed in red lighting things on \ufb01re. Label: contradiction Generated Hypotheses: the little boy is dancing. a boy is jumping into the pool. a boy is watching television. the boy is sleeping on the \ufb02oor. a boy is watching television indoors. a boy is holding a kitten. the little boy is standing in the pool. Premise: a little boy in a blue shirt holding a toy. Hypothesis: boy dressed in blue holds a toy.",
  "a boy is watching television indoors. a boy is holding a kitten. the little boy is standing in the pool. Premise: a little boy in a blue shirt holding a toy. Hypothesis: boy dressed in blue holds a toy. Label: entailment Generated Hypotheses: the boy is holding a toy. a kid is holding a toy. a boy with a toy is riding a toy. little little boy holding a toy. a boy is riding on a toy. a boy is with an object. the little boy is wearing a shirt. Premise: one woman with a dark coat on walking by herself in a city. Hypothesis: the woman is walking on a sidewalk. Label: neutral Generated Hypotheses: a woman at a city street has a sunny day. the woman is shopping. a woman is walking to the store. the woman is asian. the lady with the coat walking by her way to a store in the city. the woman is afraid of the woman. a woman was watching to go to a party 19",
  "Premise: one woman with a dark coat on walking by herself in a city. Hypothesis: the woman is standing in a building. Label: contradiction Generated Hypotheses: the woman is sitting on a couch. a woman is sitting on the ground. a woman in a coat and a coat is sitting next to her way a woman is watching the movie at the theater. a man is walking on the street the men are asleep the dog is wearing a pink coat. Premise: one woman with a dark coat on walking by herself in a city. Hypothesis: the woman is outdoors. Label: entailment Generated Hypotheses: a female is walking there are people present. woman walk. a woman in a coat walking through a city. there is a woman and a man in a crosswalk. woman are walking by a city. the woman is talking to each other. Premise: two young boys of opposing teams play football, while wearing full protection uniforms and helmets. Hypothesis: boys scoring a touchdown Label: neutral Generated Hypotheses: the boys in uniform are trying to win the game. the brothers are wearing a uniforms for the football game.",
  "Premise: two young boys of opposing teams play football, while wearing full protection uniforms and helmets. Hypothesis: boys scoring a touchdown Label: neutral Generated Hypotheses: the boys in uniform are trying to win the game. the brothers are wearing a uniforms for the football game. the boys were waiting to play the game. two boys are \ufb01ghting with their team. two teams wearing uniforms being \ufb01nished for the game two young boys are having fun. the boys are wearing helmets and are standing nearby. Premise: two young boys of opposing teams play football, while wearing full protection uniforms and helmets. Hypothesis: dog eats out of bowl Label: contradiction Generated Hypotheses: the two boys are watching tv. the boys are playing baseball. the man is on a trampoline. two young girls are dressed in tuxedos. two kids playing with the ball at the beach. two kids are in the ocean. the boys are chasing an elephant 20",
  "Premise: two young boys of opposing teams play football, while wearing full protection uniforms and helmets. Hypothesis: boys play football Label: entailment Generated Hypotheses: a trio of young boys wearing uniforms. two kids are being photographed for a football player. the boys have uniforms. two boys are wearing uniforms. the boys are dressed two boys are performing. the boys all in uniforms for their team. 21"
]