{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "arXiv:1910.07481v1  [cs.CL]  16 Oct 2019 Using Whole Document Context in Neural Machine Translation Valentin Mac\u00b4e, Christophe Servan QWANT RESEARCH - 7 Rue Spontini, 75116 Paris, France initial.lastname@qwant.com Abstract In Machine Translation, considering the document as a whole can help to resolve ambiguities and inconsistencies. In this paper, we propose a simple yet promising approach to add contextual information in Neural Machine Transla- tion. We present a method to add source context that cap- ture the whole document with accurate boundaries, taking every word into account. We provide this additional infor- mation to a Transformer model and study the impact of our method on three language pairs. The proposed approach obtains promising results in the English-German, English- French and French-English document-level translation tasks. We observe interesting cross-sentential behaviors where the model learns to use document-level information to improve translation coherence. 1. Introduction Neural machine translation (NMT) has grown rapidly in the past years [1, 2].",
            "We observe interesting cross-sentential behaviors where the model learns to use document-level information to improve translation coherence. 1. Introduction Neural machine translation (NMT) has grown rapidly in the past years [1, 2]. It usually takes the form of an encoder- decoder neural network architecture in which source sen- tences are summarized into a vector representation by the encoder and are then decoded into target sentences by the decoder. NMT has outperformed conventional statistical ma- chine translation (SMT) by a signi\ufb01cant margin over the past years, bene\ufb01ting from gating and attention techniques. Vari- ous models have been proposed based on different architec- tures such as RNN [1], CNN [3] and Transformer [2], the lat- ter having achieved state-of-the-art performances while sig- ni\ufb01cantly reducing training time. However, by considering sentence pairs separately and ignoring broader context, these models suffer from the lack of valuable contextual information, sometimes leading to in- consistency in a translated document. Adding document- level context helps to improve translation of context-dependent parts.",
            "However, by considering sentence pairs separately and ignoring broader context, these models suffer from the lack of valuable contextual information, sometimes leading to in- consistency in a translated document. Adding document- level context helps to improve translation of context-dependent parts. Previous study [4] showed that such context gives sub- stantial improvement in the handling of discourse phenom- ena like lexical disambiguation or co-reference resolution. Most document-level NMT approaches focus on adding contextual information by taking into account a set of sen- tences surrounding the current pair [5, 6, 7, 8, 9, 10]. While giving signi\ufb01cant improvementover the context-agnosticver- sions, none of these studies consider the whole document with well delimited boundaries. The majority of these ap- proaches also rely on structural modi\ufb01cation of the NMT model [7, 8, 9, 10]. To the best of our knowledge, there is no existing work considering whole documents without struc- tural modi\ufb01cations.",
            "The majority of these ap- proaches also rely on structural modi\ufb01cation of the NMT model [7, 8, 9, 10]. To the best of our knowledge, there is no existing work considering whole documents without struc- tural modi\ufb01cations. Contribution: We propose a preliminary study of a generic approach allowing any model to bene\ufb01t from document-level information while translating sentence pairs. The core idea is to augment source data by adding document information to each sentence of a source corpus. This document infor- mation corresponds to the belonging document of a sentence and is computed prior to training, it takes every document word into account. Our approach focuses on pre-processing and consider whole documents as long as they have de\ufb01ned boundaries. We conduct experiments using the Transformer base model [2]. For the English-German language pair we use the full WMT 2019 parallel dataset. For the English- French language pair we use a restricted dataset containing the full TED corpus from MUST-C [11] and sampled sen- tences from WMT 2019 dataset.",
            "For the English-German language pair we use the full WMT 2019 parallel dataset. For the English- French language pair we use a restricted dataset containing the full TED corpus from MUST-C [11] and sampled sen- tences from WMT 2019 dataset. We obtain important im- provements over the baseline and present evidences that this approach helps to resolve cross-sentence ambiguities. 2. Related Work Interest in considering the whole document instead of a set of sentences preceding the current pair lies in the necessity for a human translator to account for broader context in or- der to keep a coherent translation. The idea of represent- ing and using documents for a model is interesting, since the model could bene\ufb01t from information located before or after the current processed sentence. Previous work on document-levelSMT started with cache based approaches, [12] suggest a conjunction of dynamic, static and topic-centered cache. More recent work tend to focus on strategies to capture context at the encoder level. Authors of [6] propose an auxiliary context source with a RNN dedicated to encode contextual information in addition to a warm-start of encoder and decoder states. They obtain signi\ufb01cant gains over the baseline.",
            "More recent work tend to focus on strategies to capture context at the encoder level. Authors of [6] propose an auxiliary context source with a RNN dedicated to encode contextual information in addition to a warm-start of encoder and decoder states. They obtain signi\ufb01cant gains over the baseline. A \ufb01rst extension to attention-based neural architectures is proposed by [7], they add an encoder devoted to capture the preceding source sentence. Authors of [8] introduce a hi- erarchical attention network to model contextual information from previous sentences. Here the attention allows dynamic access to the context by focusing on different sentences and words. They show signi\ufb01cant improvements over a strong",
            "SOURCE TARGET <doc1> Pauli is a theoretical physicist Pauli est un physicien th\u00b4eoricien <doc1> He received the Nobel Prize Il a rec\u00b8u le Prix Nobel <doc2> Bees are found on every continent On trouve des abeilles sur tous les continents <doc2> They feed on nectar using their tongue Elles se nourrissent de nectar avec leur langue <doc2> The smallest bee is the dwarf bee La plus petite abeille est l\u2019abeille naine Table 1: Example of augmented parallel data used to train the Document model. The source corpus contains document tags while the target corpus remains unchanged. NMT baseline. More recently, [10] extend Transformer ar- chitecture with an additional encoder to capture context and selectively merge sentence and context representations. They focus on co-reference resolution and obtain improvements in overall performances. The closest approach to ours is presented by [5], they simply concatenate the previous source sentence to the one being translated. While they do not make any structural mod- i\ufb01cation to the model, their method still does not take the whole document into account. 3.",
            "The closest approach to ours is presented by [5], they simply concatenate the previous source sentence to the one being translated. While they do not make any structural mod- i\ufb01cation to the model, their method still does not take the whole document into account. 3. Approach We propose to use the simplest method to estimate document embeddings. The approach is called SWEM-aver (Simple Word Embedding Model \u2013 average) [13]. The embedding of a document k is computed by taking the average of all its N word vectors (see Eq. 1) and therefore has the same dimension. Out of vocabulary words are ignored. Dock = 1 N N X i=1 wi,k (1) Despite being straightforward, our approach raises the need of already computed word vectors to keep consistency between word and document embeddings. Otherwise, \ufb01ne- tuning embeddings as the model is training would shift them in a way that totally wipes off the connection between docu- ment and word vectors. To address this problem, we adopt the following approach: First, we train a baseline Transformer model (noted Base- line model) from which we extract word embeddings.",
            "To address this problem, we adopt the following approach: First, we train a baseline Transformer model (noted Base- line model) from which we extract word embeddings. Then, we estimate document embeddings using the SWEM-aver method and train an enhanced model (noted Document model) bene\ufb01ting from these document embeddings and the extracted word embeddings. During training, the Document model does not \ufb01ne-tune its embeddings to preserve the relation be- tween words and document vectors. It should be noted that we could directly use word embeddings extracted from an- other model such as Word2Vec [14], in practice we obtain better results when we get these vectors from a Transformer model. In our case, we simply extract them from the Baseline after it has been trained. Using domain adaptation ideas [15, 16, 17], we associate a tag to each sentence of the source corpus, which represents the document information. This tag takes the form of an additional token placed at the \ufb01rst position in the sentence and corresponds to the belonging document of the sentence (see Table 1). The model considers the tag as an additional word and replace it with the corresponding document embed- ding.",
            "This tag takes the form of an additional token placed at the \ufb01rst position in the sentence and corresponds to the belonging document of the sentence (see Table 1). The model considers the tag as an additional word and replace it with the corresponding document embed- ding. The Baseline model is trained on a standard corpus that does not contain document tags, while the Document model is trained on corpus that contains document tags. The proposed approach requires strong hypotheses about train and test data. The \ufb01rst downfall is the need for well de- \ufb01ned document boundaries that allow to mark each sentence with its document tag. The second major downfall is the need to compute an embedding vector for each new document fed in the model, adding a preprocessing step before inference time. 4. Experiments We consider two different models for each language pair: the Baseline and the Document model. We evaluate them on 3 test sets and report BLEU and TER scores. All experiments are run 8 times with different seeds, we report averaged re- sults and p-values for each experiment.",
            "We evaluate them on 3 test sets and report BLEU and TER scores. All experiments are run 8 times with different seeds, we report averaged re- sults and p-values for each experiment. Translation tasks are English to German, proposed in the \ufb01rst document-level translation task at WMT 2019 [18], En- glish to French and French to English, following the IWSLT translation task [19]. 4.1. Training and test sets Table 2 describes the data used for the English-German lan- guage pair. These corpora correspond to the WMT 2019 document-level translation task. Table 3 describes corpora for the English-French language pair, the same data is used for both translation directions. For the English-German pair, only 10.4% (3.638M lines) of training data contains document boundaries. For English- French pair, we restricted the total amount of training data in order to keep 16.1% (602K lines) of document delim- ited corpora. To achieve this we randomly sampled 10% of the ParaCrawl V3.",
            "For English- French pair, we restricted the total amount of training data in order to keep 16.1% (602K lines) of document delim- ited corpora. To achieve this we randomly sampled 10% of the ParaCrawl V3. It means that only a fraction of the source training data contains document context. The en- hanced model learns to use document information only when it is available. All test sets contain well delimited documents, Baseline models are evaluated on standard corpora while Document models are evaluated on the same standard corpora that have",
            "Corpora #lines # EN # DE Common Crawl 2.2M 54M 50M Europarl V9\u2020 1.8M 50M 48M News Comm. V14\u2020 338K 8.2M 8.3M ParaCrawl V3 27.5M 569M 527M Rapid 19\u2020 1.5M 30M 29M WikiTitles 1.3M 3.2M 2.8M Total Training 34.7M 716M 667M newstest2017\u2020 3004 64K 60K newstest2018\u2020 2998 67K 64K newstest2019\u2020 1997 48K 49K Table 2: Detail of training and evaluation sets for the English-German pair, showing the number of lines, words in English (EN) and words in German (DE). Corpora with document boundaries are denoted by \u2020. Corpora #lines # EN # FR News Comm.",
            "Corpora with document boundaries are denoted by \u2020. Corpora #lines # EN # FR News Comm. V14\u2020 325K 9.2M 11.2M ParaCrawl V3 (sampled) 3.1M 103M 91M TED\u2020 277K 7M 7.8M Total Training 3.7M 119.2M 110M tst2013\u2020 1379 34K 40K tst2014\u2020 1306 30K 35K tst2015\u2020 1210 28K 31K Table 3: Detail of training and evaluation sets for the English-French pair in both directions, showing the number of lines, words in English (EN) and words in French (FR). Corpora with document boundaries are denoted by \u2020. been augmented with document context. We evaluate the English-German systems on newstest2017, newstest2018 and newstest2019 where documents consist of newspaper articles to keep consistency with the training data.",
            "Corpora with document boundaries are denoted by \u2020. been augmented with document context. We evaluate the English-German systems on newstest2017, newstest2018 and newstest2019 where documents consist of newspaper articles to keep consistency with the training data. English to French and French to English systems are evaluated over IWSLT TED tst2013, tst2014 and tst2015 where documents are tran- scriptions of TED conferences (see Table 3). Prior to experiments, corpora are tokenized using Moses tokenizer [20]. To limit vocabulary size, we adopt the BPE subword unit approach [21], through the SentencePiece toolkit [22], with 32K rules. 4.2. Training details We use the OpenNMT framework [23] in its TensorFlow ver- sion to create and train our models. All experiments are run on a single NVIDIA V100 GPU. Since the proposed ap- proach relies on a preprocessing step and not on structural enhancement of the model, we keep the same Transformer architecture in all experiments.",
            "All experiments are run on a single NVIDIA V100 GPU. Since the proposed ap- proach relies on a preprocessing step and not on structural enhancement of the model, we keep the same Transformer architecture in all experiments. Our Transformer con\ufb01gura- tion is similar to the baseline of [2] except for the size of word and document vectors that we set to dmodel = 1024, these vectors are \ufb01xed during training. We use N = 6 as the number of encoder layers, dff = 2048 as the inner-layer di- mensionality, h = 8 attention heads, dk = 64 as queries and keys dimension and Pdrop = 0.1 as dropout probability. All experiments, including baselines, are run over 600k training steps with a batch size of approximately 3000 tokens. For all language pairs we trained a Baseline and a Doc- ument model. The Baseline is trained on a standard parallel corpus and is not aware of document embeddings, it is blind to the context and cannot link the sentences of a document.",
            "For all language pairs we trained a Baseline and a Doc- ument model. The Baseline is trained on a standard parallel corpus and is not aware of document embeddings, it is blind to the context and cannot link the sentences of a document. The Document model uses extracted word embeddings from the Baseline as initialization for its word vectors and also bene\ufb01ts from document embeddings that are computed from the extracted word embeddings. It is trained on the same cor- pus as the Baseline one, but the training corpus is augmented with (see Table 1) and learns to make use of the document context. The Document model does not consider its embeddings as tunable parameters, we hypothesize that \ufb01ne-tuning word and document vectors breaks the relation between them, lead- ing to poorer results. We provide evidence of this phenomena with an additional system for the French-English language pair, noted Document+tuning (see Table 5) that is identical to the Document model except that it adjusts its embeddings during training. The evaluated models are obtained by taking the aver- age of their last 6 checkpoints, which were written at 5000 steps intervals.",
            "The evaluated models are obtained by taking the aver- age of their last 6 checkpoints, which were written at 5000 steps intervals. All experiments are run 8 times with differ- ent seeds to ensure the statistical robustness of our results. We provide p-values that indicate the probability of observ- ing similar or more extreme results if the Document model is actually not superior to the Baseline. 4.3. Results Table 4 presents results associated to the experiments for the English to German translation task, models are evalu- ated on the newstest2017, neswtest2018 and newstest2019 test sets. Table 5 contains results for both English to French and French to English translation tasks, models are evaluated on the tst2013, tst2014 and tst2015 test sets. En\u2192De: The Baseline model obtained State-of-The-Art BLEU and TER results according to [24, 25]. The Document system shows best results, up to 0.85 BLEU points over the Baseline on the newstest2019 corpus.",
            "En\u2192De: The Baseline model obtained State-of-The-Art BLEU and TER results according to [24, 25]. The Document system shows best results, up to 0.85 BLEU points over the Baseline on the newstest2019 corpus. It also surpassed the Baselinee by 0.18 points on the newstest2017 with strong statistical signi\ufb01cance, and by 0.15 BLEU points on the new- stest2018 but this time with no statistical evidence. These en- couraging results prompted us to extend experiments to an- other language pair: English-French. En\u2192Fr: The Document system obtained the best results considering all metrics on all test sets with strong statistical evidence. It surpassed the Baseline by 1.09 BLEU points and 0.85 TER points on tst2015, 0.75 BLEU points and 0.76 TER points on tst2014, and 0.48 BLEU points and 0.68 TER points on tst2013. Fr\u2192En: Of all experiments, this language pair shows the most important improvements over the Baseline. The",
            "Model newstest2017 newstest2018 newstest2019 En\u2192De BLEU TER BLEU TER BLEU TER Baseline 26.78 54.82 40.61 41.02 35.67 46.80 Document 26.96\u2217\u2217 54.76 40.77 40.97 36.52\u2217 46.36\u2217 Table 4: Results obtained for the English-German translation task, scored on three test sets using BLEU and TER metrics. p-values are denoted by * and correspond to the following values: \u2217< .05, \u2217\u2217< .01, \u2217\u2217\u2217< .001.",
            "p-values are denoted by * and correspond to the following values: \u2217< .05, \u2217\u2217< .01, \u2217\u2217\u2217< .001. Translation Model tst2013 tst2014 tst2015 direction BLEU TER BLEU TER BLEU TER En\u2192Fr Baseline 46.05 37.83 43.38 39.71 41.41 42.18 Document 46.53\u2217 37.15\u2217\u2217 44.14\u2217\u2217 38.95\u2217\u2217 42.50\u2217\u2217\u2217 41.33\u2217\u2217\u2217 Fr\u2192En Baseline 45.99 34.64 42.96 37.30 39.91 39.06 Document+tuning 45.94 34.42 43.16 36.93 40.14 38.70 Document 47.28\u2217\u2217\u2217 33.80\u2217\u2217\u2217 44.46\u2217\u2217\u2217 36.34\u2217\u2217\u2217 41.72\u2217\u2217\u2217 38.04\u2217\u2217\u2217 Table 5: Results obtained for the English-French and French-English translation tasks, scored on three test sets using BLEU and TER metrics.",
            "p-values are denoted by * and correspond to the following values: \u2217< .05, \u2217\u2217< .01, \u2217\u2217\u2217< .001. Document model obtained substantial gains with very strong statistical evidence on all test sets. It surpassed the Baseline model by 1.81 BLEU points and 1.02 TER points on tst2015, 1.50 BLEU points and 0.96 TER points on tst2014, and 1.29 BLEU points and 0.83 TER points on tst2013. The Document+tuning system, which only differs from the fact that it tunes its embeddings, shows little or no im- provement over the Baseline, leading us to the conclusion that the relation between word and document embeddings described by Eq. 1 must be preserved for the model to fully bene\ufb01t from document context. 4.4. Manual Analysis In this analysis we present some of the many cases that sug- gest the Document model can handle ambiguous situations.",
            "1 must be preserved for the model to fully bene\ufb01t from document context. 4.4. Manual Analysis In this analysis we present some of the many cases that sug- gest the Document model can handle ambiguous situations. These examples are often isolated sentences where even a human translator could not predict the good translation with- out looking at the document, making it almost impossible for the Baseline model which is blind to the context. Table 6 contains an extract of these interesting cases for the French- English language pair. Translation from French to English is challenging and of- ten requires to take the context into account. The personal pronoun \u201dlui\u201d can refer to a person of feminine gender, mas- culine gender or even an object and can therefore be trans- lated into \u201dher\u201d, \u201dhim\u201d or \u201dit\u201d. The \ufb01rst example in Table 6 perfectly illustrate this ambiguity: the context clearly indi- cates that \u201dlui\u201d in the source sentence refers to \u201dma \ufb01lle\u201d, which is located three sentences above, and should be trans- lated into \u201dher\u201d.",
            "The \ufb01rst example in Table 6 perfectly illustrate this ambiguity: the context clearly indi- cates that \u201dlui\u201d in the source sentence refers to \u201dma \ufb01lle\u201d, which is located three sentences above, and should be trans- lated into \u201dher\u201d. In this case, the Baseline model predict the personal pronoun \u201dhim\u201d while the Document model cor- rectly predicts \u201dher\u201d. It seems that the Baseline model does not bene\ufb01t from any valuable information in the source sen- tence. Some might argue that the source sentence actually contains clues about the correct translation, considering that \u201drobe `a paillettes\u201d (\u201dsparkly dress\u201d) and \u201dbaguette mag- ique\u201d (\u201dmagic wand\u201d) probably refer to a little girl, but we will see that the model makes similar choices in more re- stricted contexts. This example is relevant mainly because the actual reference to the subject \u201dma \ufb01lle\u201d is made long before the source sentence. The second example in Table 6 is interesting because none of our models correctly translate the source sentence.",
            "This example is relevant mainly because the actual reference to the subject \u201dma \ufb01lle\u201d is made long before the source sentence. The second example in Table 6 is interesting because none of our models correctly translate the source sentence. However, we observe that the Baseline model opts for a lit- eral translation of \u201dje peux faire le poirier\u201d (\u201dI can stand on my head\u201d) into \u201dI can do the pear\u201d while the Document model predicts \u201dI can wring\u201d. Even though these transla- tions are both incorrect, we observe that the Document model makes a prediction that somehow relates to the context: a woman talking about her past disability, who has become more \ufb02exible thanks to yoga and can now twist her body. The third case in table 6 is a perfect example of isolated sentence that cannot be translated correctly with no contex- tual information. This example is tricky because the word \u201dElle\u201d would be translated into \u201dShe\u201d in most cases if no ad- ditional information were provided, but here it refers to \u201dla conscience\u201d (\u201dconsciousness\u201d) from the previous sentence and must be translated into \u201dIt\u201d.",
            "This example is tricky because the word \u201dElle\u201d would be translated into \u201dShe\u201d in most cases if no ad- ditional information were provided, but here it refers to \u201dla conscience\u201d (\u201dconsciousness\u201d) from the previous sentence and must be translated into \u201dIt\u201d. As expected the Baseline model does not make the correct guess and predicts the per- sonal pronoun \u201dShe\u201d while the Document model correctly predicts \u201dIt\u201d. This example present a second dif\ufb01cult part, the word \u201dson\u201d from the source sentence is ambiguous and does not, in itself, inform the translator if it must be translated into \u201dher\u201d, \u201dhis\u201d or \u201dits\u201d. With contextual information we know that it refers to \u201d[le] monde physique\u201d (\u201d[the] physical world\u201d) and that the correct choice is the word \u201dits\u201d. Here the Baseline incorrectly predicts \u201dher\u201d, possibly because of its earlier choice for \u201dShe\u201d as the subject. The Document model makes again the correct translation. According to our results (see Table 5), the English-French language pair also bene\ufb01ts from document-level information but to a lesser extent. For this language pair, ambiguities",
            "Fr-En Context [...] et quand ma \ufb01lle avait quatre ans, nous avons regard\u00b4e \u201dLe Magicien d\u2019Oz\u201d ensemble. Ce \ufb01lm a compl`etement captiv\u00b4e son imagination pendant des mois. Son personnage pr\u00b4ef\u00b4er\u00b4e \u00b4etait Glinda, bien entendu. Source C\u00b8 a lui donnait une bonne excuse pour porter une robe `a paillettes et avoir une baguette magique. Ref. It gave her a great excuse to wear a sparkly dress and carry a wand. Baseline It gave him a good excuse to wear a glitter dress and have a magic wand. Document It gave her a good excuse to wear a glitter dress and have a magic wand. Context Mon p`ere passait souvent les grandes vacances `a essayer de me gu\u00b4erir ... Mais nous avons trouv\u00b4e un rem`ede miracle : le yoga. [...] j\u2019\u00b4etais une comique de stand-up qui ne tenait pas debout. Source Maintenant, je peux faire le poirier. Ref. And now I can stand on my head.",
            "[...] j\u2019\u00b4etais une comique de stand-up qui ne tenait pas debout. Source Maintenant, je peux faire le poirier. Ref. And now I can stand on my head. Baseline Now I can do the pear. Document Now, I can wring. Context C\u2019est le but ultime de la physique : d\u00b4ecrire le \ufb02ux de conscience. Selon cette id\u00b4ee, c\u2019est donc la conscience qui met le feu aux \u00b4equations. Selon cette id\u00b4ee, la conscience ne pendouille pas en dehors du monde physique ... Source Elle si`ege bien en son c\u0153ur. Ref. It\u2019s there right at its heart. Baseline She sits well in her heart. Document It sits well in its heart . Table 6: Translation examples for the French-English pair.",
            "Ref. It\u2019s there right at its heart. Baseline She sits well in her heart. Document It sits well in its heart . Table 6: Translation examples for the French-English pair. We took the best models of all runs for both the Baseline and the Document enhanced model En-Fr Context [The speaker in this example is an old police of\ufb01cer saving a man from suicide] But I asked him, \u201dWhat was it that made you come back and give hope and life another chance ?\u201d And you know what he told me ? Source He said \u201dYou listened.\u201d Ref. Il a dit : \u201dVous avez \u00b4ecout\u00b4e.\u201d Baseline Il a dit : \u201dTu as \u00b4ecout\u00b4e.\u201d Document Il a dit : \u201dVous avez \u00b4ecout\u00b4e.\u201d Table 7: Translation example for the English-French pair. about personal pronouns are less frequent. Other ambigu- ous phenomena like the formal mode (use of \u201dvous\u201d instead of \u201dtu\u201d) appear. Table7 presents an example of this kind of situation where the word \u201dYou\u201d from the source sentence does not indicate if the correct translation is \u201dVous\u201d or \u201dTu\u201d.",
            "Other ambigu- ous phenomena like the formal mode (use of \u201dvous\u201d instead of \u201dtu\u201d) appear. Table7 presents an example of this kind of situation where the word \u201dYou\u201d from the source sentence does not indicate if the correct translation is \u201dVous\u201d or \u201dTu\u201d. However it refers to the narrator of the story who is an old police of\ufb01cer. In this case, it is very likely that the use of formal mode is the correct translation. The Baseline model incorrectly predicts \u201dTu\u201d and the Document model predicts \u201dVous\u201d. 5. Conclusion In this work, we presented a preliminary study of a simple approach for document-level translation. The method allows to bene\ufb01t from the whole document context at the sentence level, leading to encouraging results. In our experimental setup, we observed improvement of translation outcomes up to 0.85 BLEU points in the English to German translation task and exceeding 1 BLEU point in the English to French and French to English translation tasks.",
            "In our experimental setup, we observed improvement of translation outcomes up to 0.85 BLEU points in the English to German translation task and exceeding 1 BLEU point in the English to French and French to English translation tasks. Looking at the trans- lation outputs, we provided evidence that the approach al- lows NMT models to disambiguate complex situations where the context is absolutely necessary, even for a human trans- lator. The next step is to go further by investigating more elabo- rate document embedding approaches and to bring these ex- periments to other languages (e.g.: Asian, Arabic, Italian, Spanish, etc.). To consider a training corpus with a majority of document delimited data is also very promising. 6. References [1] I. Sutskever, O. Vinyals, and Q. V. Le, \u201cSequence to sequence learning with neural networks,\u201d in Advances in neural information processing systems, 2014, pp. 3104\u20133112.",
            "[2] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, \u0141. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d in Advances in neural in- formation processing systems, 2017, pp. 5998\u20136008. [3] J. Gehring, M. Auli, D. Grangier, D. Yarats, and Y. N. Dauphin, \u201cConvolutional sequence to sequence learn- ing,\u201d in Proceedings of the 34th International Confer- ence on Machine Learning-Volume 70. JMLR. org, 2017, pp. 1243\u20131252. [4] R. Bawden, R. Sennrich, A. Birch, and B. Haddow, \u201cEvaluating discourse phenomena in neural machine translation,\u201d in Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech- nologies, Volume 1 (Long Papers).",
            "New Orleans, Louisiana: Association for Computational Linguistics, June 2018. [5] J. Tiedemann and Y. Scherrer, \u201cNeural machine trans- lation with extended context,\u201d in Proceedings of the Third Workshop on Discourse in Machine Translation. Copenhagen, Denmark: Association for Computational Linguistics, Sept. 2017, pp. 82\u201392. [6] L. Wang, Z. Tu, A. Way, and Q. Liu, \u201cExploiting cross-sentence context for neural machine translation,\u201d in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Copen- hagen, Denmark: Association for Computational Lin- guistics, Sept. 2017, pp. 2826\u20132831. [7] S. Jean, S. Lauly, O. Firat, and K. Cho, \u201cDoes neural machine translation bene\ufb01t from larger context?\u201d arXiv preprint arXiv:1704.05135, 2017.",
            "2826\u20132831. [7] S. Jean, S. Lauly, O. Firat, and K. Cho, \u201cDoes neural machine translation bene\ufb01t from larger context?\u201d arXiv preprint arXiv:1704.05135, 2017. [8] L. Miculicich, D. Ram, N. Pappas, and J. Henderson, \u201cDocument-level neural machine translation with hier- archical attention networks,\u201d in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. Brussels, Belgium: Association for Com- putational Linguistics, Oct.-Nov. 2018, pp. 2947\u20132954. [9] J. Zhang, H. Luan, M. Sun, F. Zhai, J. Xu, M. Zhang, and Y. Liu, \u201cImproving the transformer translation model with document-level context,\u201d in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. Brussels, Belgium: Associa- tion for Computational Linguistics, Oct.-Nov. 2018, pp. 533\u2013542.",
            "Brussels, Belgium: Associa- tion for Computational Linguistics, Oct.-Nov. 2018, pp. 533\u2013542. [10] E. Voita, P. Serdyukov, R. Sennrich, and I. Titov, \u201cContext-aware neural machine translation learns anaphora resolution,\u201d in Proceedings of the 56th An- nual Meeting of the Association for Computational Lin- guistics (Volume 1: Long Papers). Melbourne, Aus- tralia: Association for Computational Linguistics, July 2018, pp. 1264\u20131274. [11] M. A. Di Gangi, R. Cattoni, L. Bentivogli, M. Negri, and M. Turchi, \u201cMuST-C: a Multilin- gual Speech Translation Corpus,\u201d in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Lin- guistics: Human Language Technologies, Volume 1 (Long and Short Papers). Minneapolis, Min- nesota: Association for Computational Linguistics, June 2019, pp. 2012\u20132017. [Online].",
            "Minneapolis, Min- nesota: Association for Computational Linguistics, June 2019, pp. 2012\u20132017. [Online]. Available: https:\/\/www.aclweb.org\/anthology\/N19-1202 [12] Z. Gong, M. Zhang, and G. Zhou, \u201cCache-based document-level statistical machine translation,\u201d in Pro- ceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Com- putational Linguistics, 2011, pp. 909\u2013919. [13] D. Shen, G. Wang, W. Wang, M. R. Min, Q. Su, Y. Zhang, C. Li, R. Henao, and L. Carin, \u201cBaseline needs more love: On simple word-embedding-based models and associated pooling mechanisms,\u201d in Pro- ceedings of the 56th Annual Meeting of the Associa- tion for Computational Linguistics (Volume 1: Long Papers). Melbourne, Australia: Association for Com- putational Linguistics, July 2018.",
            "Melbourne, Australia: Association for Com- putational Linguistics, July 2018. [14] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, \u201cDistributed representations of words and phrases and their compositionality,\u201d in Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2013, pp. 3111\u20133119. [15] R. Sennrich, B. Haddow, and A. Birch, \u201cControlling politeness in neural machine translation via side con- straints,\u201d in Proceedings of the 2016 Conference of the North American Chapter of the Association for Compu- tational Linguistics: Human Language Technologies, 2016, pp. 35\u201340.",
            "35\u201340. [16] C. Chu, R. Dabre, and S. Kurohashi, \u201cAn empirical comparison of domain adaptation methods for neural machine translation,\u201d in Proceedings of the 55th Annual Meeting of the Association for Computational Linguis- tics (Volume 2: Short Papers), 2017, pp. 385\u2013391. [17] C. Chu and R. Wang, \u201cA survey of domain adaptation for neural machine translation,\u201d in Proceedings of the 27th International Conference on Computational Lin- guistics, 2018, pp. 1304\u20131319. [18] L. Barrault, O. Bojar, M. R. Costa-juss`a, C. Feder- mann, M. Fishel, Y. Graham, B. Haddow, M. Huck, P. Koehn, S. Malmasi, C. Monz, M. M\u00a8uller, S. Pal, M. Post, and M. Zampieri, \u201cFindings of the 2019 con- ference on machine translation (wmt19),\u201d in Proceed- ings of the Fourth Conference on Machine Translation",
            "(Volume 2: Shared Task Papers, Day 1). Florence, Italy: Association for Computational Linguistics, Au- gust 2019, pp. 1\u201361. [19] M. Cettolo, J. Niehues, S. St\u00a8uker, L. Bentivogli, R. Cat- toni, and F. Marcello, \u201cThe iwslt 2015 evaluation cam- paign,\u201d in Proceedings of the twelfth International Workshop on Spoken Language Translation, Da Nang, Vietnam, December 2015, pp. 2\u201310. [20] P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, et al., \u201cMoses: Open source toolkit for statistical machine translation,\u201d in Proceedings of the 45th annual meeting of the association for compu- tational linguistics companion volume proceedings of the demo and poster sessions, 2007, pp. 177\u2013180.",
            "177\u2013180. [21] R. Sennrich, B. Haddow, and A. Birch, \u201cNeural Ma- chine Translation of Rare Words with Subword Units,\u201d in Proceedings of the 54th Annual Meeting of the Asso- ciation for Computational Linguistics (Volume 1: Long Papers), vol. 1, 2016, pp. 1715\u20131725. [22] T. Kudo and J. Richardson, \u201cSentencepiece: A simple and language independent subword tokenizer and deto- kenizer for neural text processing,\u201d in Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, 2018, pp. 66\u201371. [23] G. Klein, Y. Kim, Y. Deng, J. Senellart, and A. Rush, \u201cOpenNMT: Open-source toolkit for neural machine translation,\u201d in Proceedings of ACL 2017, System Demonstrations, Vancouver, Canada, July 2017, pp. 67\u201372.",
            "67\u201372. [24] O. Bojar, R. Chatterjee, C. Federmann, Y. Graham, B. Haddow, S. Huang, M. Huck, P. Koehn, Q. Liu, V. Logacheva, C. Monz, M. Negri, M. Post, R. Rubino, L. Specia, and M. Turchi, \u201cFindings of the 2017 confer- ence on machine translation (wmt17),\u201d in Proceedings of the Second Conference on Machine Translation, Vol- ume 2: Shared Task Papers. Copenhagen, Denmark: Association for Computational Linguistics, September 2017, pp. 169\u2013214. [25] O. Bojar, C. Federmann, M. Fishel, Y. Graham, B. Had- dow, M. Huck, P. Koehn, and C. Monz, \u201cFindings of the 2018 conference on machine translation (wmt18),\u201d in Proceedings of the Third Conference on Machine Translation, Volume 2: Shared Task Papers. Belgium, Brussels: Association for Computational Linguistics, October 2018, pp.",
            "Belgium, Brussels: Association for Computational Linguistics, October 2018, pp. 272\u2013307."
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-1910.07481.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 7649.000061035156,
    "avg_doclen_est": 182.11904907226562
}
