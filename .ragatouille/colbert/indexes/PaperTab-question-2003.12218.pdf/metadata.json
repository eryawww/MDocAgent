{
  "config":{
    "query_token_id":"[unused0]",
    "doc_token_id":"[unused1]",
    "query_token":"[Q]",
    "doc_token":"[D]",
    "ncells":null,
    "centroid_score_threshold":null,
    "ndocs":null,
    "load_index_with_mmap":false,
    "index_path":null,
    "index_bsize":32,
    "nbits":4,
    "kmeans_niters":20,
    "resume":false,
    "pool_factor":1,
    "clustering_mode":"hierarchical",
    "protected_tokens":0,
    "similarity":"cosine",
    "bsize":64,
    "accumsteps":1,
    "lr":0.00001,
    "maxsteps":400000,
    "save_every":null,
    "warmup":20000,
    "warmup_bert":null,
    "relu":false,
    "nway":64,
    "use_ib_negatives":true,
    "reranker":false,
    "distillation_alpha":1.0,
    "ignore_scores":false,
    "model_name":null,
    "query_maxlen":32,
    "attend_to_mask_tokens":false,
    "interaction":"colbert",
    "dim":128,
    "doc_maxlen":256,
    "mask_punctuation":true,
    "checkpoint":"colbert-ir/colbertv2.0",
    "triples":"/future/u/okhattab/root/unit/experiments/2021.10/downstream.distillation.round2.2_score/round2.nway6.cosine.ib/examples.64.json",
    "collection":[
      "Comprehensive Named Entity Recognition on CORD-19 with Distant or Weak Supervision Xuan Wang1, Xiangchen Song1, Bangzheng Li1, Yingjun Guan2, Jiawei Han1 1Department of Computer Science, University of Illinois at Urbana-Champaign 2School of Information Sciences, University of Illinois at Urbana-Champaign 1,2{xwang174,xs22,yingjun2,bl17@,hanj}@illinois.edu Abstract We created this CORD-NER dataset with comprehensive named entity recognition (NER) on the COVID-19 Open Research Dataset Challenge (CORD-19) corpus (2020- 03-13). This CORD-NER dataset covers 75 \ufb01ne-grained entity types: In addition to the common biomedical entity types (e.g., genes, chemicals and diseases), it covers many new entity types related explicitly to the COVID-19 studies (e.g., coronaviruses, viral proteins, evolution, materials, substrates and immune responses), which may ben- e\ufb01t research on COVID-19 related virus, spreading mechanisms, and potential vaccines. CORD-NER annotation is a combination of four sources with different NER methods.",
      "CORD-NER annotation is a combination of four sources with different NER methods. The quality of CORD-NER annotation surpasses SciSpacy (over 10% higher on the F1 score based on a sample set of documents), a fully supervised BioNER tool. Moreover, CORD-NER supports incrementally adding new documents as well as adding new entity types when needed by adding dozens of seeds as the input examples. We will constantly update CORD-NER based on the incremen- tal updates of the CORD-19 corpus and the improvement of our system. 1 Introduction Coronavirus disease 2019 (COVID-19) is an in- fectious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The dis- ease was \ufb01rst identi\ufb01ed in 2019 in Wuhan, Central China, and has since spread globally, resulting in the 20192020 coronavirus pandemic.",
      "The dis- ease was \ufb01rst identi\ufb01ed in 2019 in Wuhan, Central China, and has since spread globally, resulting in the 20192020 coronavirus pandemic. On March 16th, 2020, researchers and leaders from the Allen Institute for AI, Chan Zuckerberg Initiative (CZI), Georgetown University\u2019s Center for Security and Emerging Technology (CSET), Microsoft, and the National Library of Medicine (NLM) at the Na- tional Institutes of Health released the COVID-19 Open Research Dataset (CORD-19)1 of scholarly literature about COVID-19, SARS-CoV-2, and the coronavirus group. Named entity recognition (NER) is a fundamen- tal step in text mining system development to fa- cilitate COVID-19 studies. There is a critical need for NER methods that can quickly adapt to all the COVID-19 related new types without much hu- man effort for training data annotation. We created this CORD-NER dataset2 with comprehensive named entity annotation on the CORD-19 corpus (2020-03-13). This dataset covers 75 \ufb01ne-grained named entity types.",
      "We created this CORD-NER dataset2 with comprehensive named entity annotation on the CORD-19 corpus (2020-03-13). This dataset covers 75 \ufb01ne-grained named entity types. CORD-NER is automatically generated by combining the annotation results from four sources. In the following sections, we intro- duce the details of CORD-NER dataset construc- tion. We also show some NER annotation results in this dataset. 2 CORD-NER Dataset 2.1 Corpus The input corpus is generated from the 29,500 documents in the CORD-19 corpus (2020- 03-13). We \ufb01rst merge all the meta-data (all sources metadata 2020-03-13.csv) with their corresponding full-text papers. Then we create a tokenized corpus (CORD-NER-corpus.json) for further NER annotations. The input corpus is a combination of the \u201dtitle\u201d, \u201dabstract\u201d and \u201dfull-text\u201d from the CORD-19 cor- pus. We \ufb01rst conduct automatic phrase mining and tokenization on the input corpus using AutoPhrase (Shang et al., 2018a).",
      "The input corpus is a combination of the \u201dtitle\u201d, \u201dabstract\u201d and \u201dfull-text\u201d from the CORD-19 cor- pus. We \ufb01rst conduct automatic phrase mining and tokenization on the input corpus using AutoPhrase (Shang et al., 2018a). Then we do a second round of tokenization with Spacy3 on the phrase-replaced 1https://www.kaggle.com/ allen-institute-for-ai/ CORD-19-research-challenge 2https://xuanwang91.github.io/ 2020-03-20-cord19-ner/ 3https://spacy.io/api/annotation# arXiv:2003.12218v5  [cs.CL]  15 Apr 2020",
      "Gene Chemical Disease Total Prec Rec F1 Prec Rec F1 Prec Rec F1 Prec Rec F1 SciSpacy (BIONLP13CG) 91.48 82.06 86.51 64.66 39.81 49.28 8.11 2.75 4.11 76.36 53.59 62.98 SciSpacy (BC5CDR) - - - 86.97 51.86 64.69 80.31 59.65 68.46 82.40 54.57 65.66 Ours 82.14 74.68 78.23 82.93 75.22 78.89 75.73 68.42 71.89 81.29 73.65 77.28 Table 1: Performance comparison on three major biomedical entity types in COVID-19 corpus. corpus. We found that keeping the AutoPhrase re- sults will signi\ufb01cantly improve the distantly- and weakly-supervised NER performance.",
      "corpus. We found that keeping the AutoPhrase re- sults will signi\ufb01cantly improve the distantly- and weakly-supervised NER performance. 2.2 NER Methods CORD-NER annotation is a combination of four sources with different NER methods: 1. Pre-trained NER on 18 general en- tity types from Spacy using the model \u201den core web sm\u201d. 2. Pre-trained NER on 18 biomedical en- tity types from SciSpacy4 using the models \u201cen ner bionlp13cg md\u201d and \u201cen ner bc5cdr md\u201d. 3. Knowledgebase (KB)-guided NER on 127 biomedical entity types with our distantly- supervised NER methods (Wang et al., 2019; Shang et al., 2018b). We do not require any human-annotated training data for the NER model training. Instead, We rely on UMLS 5 as the input KB for distant supervision. 4.",
      "We do not require any human-annotated training data for the NER model training. Instead, We rely on UMLS 5 as the input KB for distant supervision. 4. Seed-guided NER on nine new entity types (speci\ufb01cally related to the COVID-19 studies) with our weakly-supervised NER method. We only require several (10-20) human-input seed entities for each new type. Then we expand the seed entity sets with CatE (Meng et al., 2020) and apply our distant NER method for the new entity type recognition. We reorganized all the entity types from the four sources into one entity type hierarchy (CORD- NER-types.xlsx). Speci\ufb01cally, we align all the types from SciSpacy to UMLS. We also merge some \ufb01ne-grained UMLS entity types to their more coarse-grained types based on the corpus count.",
      "Speci\ufb01cally, we align all the types from SciSpacy to UMLS. We also merge some \ufb01ne-grained UMLS entity types to their more coarse-grained types based on the corpus count. Our entity type hierarchy covers 75 \ufb01ne-grained named-entities 4https://allenai.github.io/scispacy/ 5ttps://www.nlm.nih.gov/research/umls/ META3_current_semantic_types.html entity types: In addition to the common biomedical entity types (e.g., genes, chemicals and diseases), it covers many new entity types related explicitly to the COVID-19 studies (e.g., coronaviruses, viral proteins, evolution, materials, substrates and im- mune responses), which may bene\ufb01t research on COVID-19 related virus, spreading mechanisms, and potential vaccines. Then we conduct named entity annotation on the 75 \ufb01ne-grained entity types with the four sources of NER methods. After we get the NER annotation result with each method, we merge the results into one NER annotation \ufb01le (CORD-NER.json).",
      "Then we conduct named entity annotation on the 75 \ufb01ne-grained entity types with the four sources of NER methods. After we get the NER annotation result with each method, we merge the results into one NER annotation \ufb01le (CORD-NER.json). The con\ufb02icts are resolved by giving priority to different entity types annotated by different methods accord- ing to their annotation quality. Finally, we merge all the related information (meta-data, full-text cor- pus and NER results) into one \ufb01le (CORD-NER- full.json) for users\u2019 convenience. The size of the dataset is about 1.2GB. 3 Results 3.1 NER Annotation Results In Table 1, we show the performance comparison between our annotation and the SciSpacy models. BIONLP13CG is the model in SciSpacy that covers the most entity types (18 entity types). BC5CDR is another model in SciSpacy that has the best perfor- mance on two entity types (chemicals and diseases). We manually annotated more than 1000 sentences for evaluation.",
      "BC5CDR is another model in SciSpacy that has the best perfor- mance on two entity types (chemicals and diseases). We manually annotated more than 1000 sentences for evaluation. Then we calculate the precision, re- call and F1 scores on three major biomedical entity types: gene, chemical and disease. We can see that our annotation has worse performance on the gene type but much better performance on the chemi- cal and disease types. In summary, the quality of our annotation surpasses SciSpacy by a large mar- gin (over 10% higher on the F1 score). Moreover, SciSpacy requires human effort for training data annotation and covers only 18 types. Our NER sys- tem supports incrementally adding new documents as well as adding new entity types when needed by adding dozens of seeds as the input examples.",
      "(a) CORD-19 corpus (b) New York Times corpus Figure 1: Examples of the annotation results with CORD-NER system. In Figure 1a, we show some examples of the annotation results in CORD-NER. We can see that our distantly- or weakly supervised methods achieve high quality recognizing the new entity types, requiring only several seed examples as the input. For instance, we recognized \u201dSARS-CoV-2\u201d as the \u201dCORONAVIRUS\u201d type, \u201dbat\u201d and \u201dpan- golins\u201d as the \u201dWILDLIFE\u201d type and \u201dVan der Waals forces\u201d as the \u201dPHYSICAL SCIENCE\u201d type. This NER annotation can help downstream text mining tasks in discovering the origin and the phys- ical nature of the virus. Also, our NER methods are domain-independent that can be applied to the corpus in different domains. We show another ex- ample of NER annotation on the New York Times corpus with our system in Figure 1b. In Figure 2, we show the comparison of our anno- tation with existing fully-supervised NER/BioNER systems.",
      "We show another ex- ample of NER annotation on the New York Times corpus with our system in Figure 1b. In Figure 2, we show the comparison of our anno- tation with existing fully-supervised NER/BioNER systems. In Figure 2a, we can see that our method can identify \u201dSARS-CoV-2\u201d as a coronavirus. In Figure 2b, we can see that our method can iden- tify many more entities such as \u201dphylogenetic\u201d as an evolution term and \u201dbat\u201d as a wildlife term. In Figure 2c, we can also see that our method can identify many more entities such as \u201dracism\u201d as social behavior. In summary, our distantly- and weakly-supervised NER methods are reliable for high-quality entity recognition without requiring human effort for training data annotation. 3.2 Top-Frequent Entity Summarization In Table 2, we show some examples of the most frequent entities in our annotated corpus. Specif- ically, we show the entity types, including both our new types and some UMLS types that have not been manually annotated before.",
      "3.2 Top-Frequent Entity Summarization In Table 2, we show some examples of the most frequent entities in our annotated corpus. Specif- ically, we show the entity types, including both our new types and some UMLS types that have not been manually annotated before. We \ufb01nd our annotated entities very informative for the COVID- 19 studies. For example, the most frequent enti-",
      "(a) (b) (c) Figure 2: Annotation result comparison with other NER methods. ties for the type \u201dSIGN OR SYMPTOM behav- ior\u201d includes \u201dcough\u201d and \u201drespiratory symptoms\u201d that are the most common symptoms for COVID- 19. The most frequent entities for the type \u201dINDI- VIDUAL BEHAVIOR\u201d include \u201dhand hygiene\u201d, \u201cdisclosures\u201d and \u201dabsenteeism\u201d, which indicates that people focus more on hand cleaning for the COVID-19 issue. Also, the most frequent enti- ties for the type \u201dMACHINE ACTIVITY\u201d include \u201cmachine learning\u201d, \u201cdata processing\u201d and \u201dautoma- tion\u201d, which indicates that people focus more on automated methods that can process massive data for the COVID-19 studies. This type also includes \u201dtelecommunication\u201d as the top results, which is quite reasonable under the current COVID-19 situ- ation. More examples can be found in our dataset. 4 Conclusion CORD-NER will be constantly updated based on the incremental updates of the CORD-19 corpus and the improvement of our system.",
      "More examples can be found in our dataset. 4 Conclusion CORD-NER will be constantly updated based on the incremental updates of the CORD-19 corpus and the improvement of our system. We will also build text mining systems based on the CORD- NER dataset with richer functionalities. We hope this dataset can help the text mining community build downstream applications for the COVID-19 related tasks. We also hope this dataset can bring insights for the COVID-19 studies on making sci- enti\ufb01c discoveries. Acknowledgment Research was sponsored in part by US DARPA KAIROS Program No. FA8750-19-2-1004 and",
      "CORONAVIRUS EVOLUTION WILDLIFE PHYSICAL SCIENCE sars mutation bat positively charged cov phylogenetic wild birds negatively charged mers evolution wild animals force \ufb01eld covid-19 recombination fruit bats highly hydrophobic sars-cov-2 substitutions pteropus van der waals interactions LIVESTOCK MATERIAL SUBSTRATE IMMUNE RESPONSE pigs air blood immunization poultry plastic urine immunity calves \ufb02uids sputum immune cells chicken copper saliva innate immune pig silica fecal in\ufb02ammatory response SIGN OR SYMPTOM SOCIAL BEHAVIOR INDIVIDUAL BEHAVIOR THERAPEUTIC OR PREVENTIVE PROCEDURE cough collaboration hand hygiene detection respiratory symptoms sharing disclosures vaccination diarrhoea herd absenteeism isolation vomiting mediating compliance stimulation wheezing adoption empathy inoculation DIAGNOSTIC PROCEDURE RESEARCH ACTIVITY EDUCATIONAL ACTIVITY MACHINE ACTIVITY imaging rt-pcr health education machine learning immunohistochemistry sequencing workshops data processing necropsy screening nursery automation scanning diagnosis medical education deconvolution biopsy prevention residency telecommunication Table 2: Examples of the most frequent entities annotated in CORD-NER. SocialSim Program No.",
      "SocialSim Program No. W911NF-17-C-0099, National Science Foundation IIS 16-18481, IIS 17-04532, and IIS-17-41317, and DTRA HD- TRA11810026. Any opinions, \ufb01ndings, and con- clusions or recommendations expressed herein are those of the authors and should not be interpreted as necessarily representing the views, either ex- pressed or implied, of DARPA or the U.S. Gov- ernment. The U.S. Government is authorized to reproduce and distribute reprints for government purposes notwithstanding any copyright annotation hereon. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies. References Yu Meng, Jiaxin Huang, Guangyuan Wang, Zihan Wang, Chao Zhang, Yu Zhang, and Jiawei Han. 2020. Discriminative topic mining via category- name guided text embedding. In Proceedings of The Web Conference 2020 (WWW20). Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare R Voss, and Jiawei Han.",
      "2020. Discriminative topic mining via category- name guided text embedding. In Proceedings of The Web Conference 2020 (WWW20). Jingbo Shang, Jialu Liu, Meng Jiang, Xiang Ren, Clare R Voss, and Jiawei Han. 2018a. Automated phrase mining from massive text corpora. IEEE Transactions on Knowledge and Data Engineering, 30(10):1825\u20131837. Jingbo Shang, Liyuan Liu, Xiang Ren, Xiaotao Gu, Teng Ren, and Jiawei Han. 2018b. Learning named entity tagger using domain-speci\ufb01c dictionary. In EMNLP. ACL. Xuan Wang, Yu Zhang, Qi Li, Xiang Ren, Jingbo Shang, and Jiawei Han. 2019. Distantly supervised biomedical named entity recognition with dictionary expansion. In BIBM."
    ],
    "queries":"/future/u/okhattab/data/MSMARCO/queries.train.tsv",
    "index_name":"PaperTab-question-2003.12218.pdf",
    "overwrite":false,
    "root":".ragatouille/",
    "experiment":"colbert",
    "index_root":null,
    "name":"2025-05/17/10.22.50",
    "rank":0,
    "nranks":1,
    "amp":true,
    "gpus":1,
    "avoid_fork_if_possible":false
  },
  "num_chunks":1,
  "num_partitions":512,
  "num_embeddings":3389,
  "avg_doclen":178.3684210526,
  "RAGatouille":{
    "index_config":{
      "index_type":"PLAID",
      "index_name":"PaperTab-question-2003.12218.pdf"
    }
  }
}