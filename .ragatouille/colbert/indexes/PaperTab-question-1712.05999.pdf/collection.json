[
  "Characterizing Political Fake News in Twitter by its Meta-Data Julio Amador D\u00b4\u0131az L\u00b4opez Axel Oehmichen Miguel Molina-Solana ( j.amador, axelfrancois.oehmichen11, mmolinas@imperial.ac.uk ) Imperial College London Abstract This article presents a preliminary approach towards characterizing political fake news on Twitter through the analysis of their meta-data. In particular, we focus on more than 1.5M tweets collected on the day of the election of Donald Trump as 45th president of the United States of America. We use the meta-data embedded within those tweets in order to look for di\ufb00erences between tweets containing fake news and tweets not containing them. Speci\ufb01cally, we perform our analysis only on tweets that went viral, by studying proxies for users\u2019 exposure to the tweets, by characterizing accounts spreading fake news, and by looking at their polarization. We found signi\ufb01cant di\ufb00erences on the distribution of followers, the number of URLs on tweets, and the veri\ufb01cation of the users.",
  "We found signi\ufb01cant di\ufb00erences on the distribution of followers, the number of URLs on tweets, and the veri\ufb01cation of the users. Introduction While fake news, understood as deliberately mislead- ing pieces of information, have existed since long ago (e.g. it is not unusual to receive news falsely claiming the death of a celebrity), the term reached the mainstream, particularly so in politics, during the 2016 presidential election in the United States.1 Since then, governments and corporations alike (e.g. Google2 and Facebook3) have begun e\ufb00orts to tackle fake news as they can a\ufb00ect political decisions.4 Yet, the ability to de\ufb01ne, identify and stop fake news from spreading is limited. Since the Obama campaign in 2008, social media has been pervasive in the political arena in the United States.",
  "Since the Obama campaign in 2008, social media has been pervasive in the political arena in the United States. Studies report that up to 62% of American adults receive their news from social media.5 The wide use of platforms such as Twitter and Facebook has facilitated the di\ufb00usion of fake news by simpli- fying the process of receiving content with no sig- ni\ufb01cant third party \ufb01ltering, fact-checking or edito- rial judgement. Such characteristics make these plat- forms suitable means for sharing news that, disguised as legit ones, try to confuse readers. Such use and their prominent rise has been con- \ufb01rmed by Craig Silverman, a Canadian journalist who is a prominent \ufb01gure on fake news:6 \u201cIn the \ufb01nal three months of the US presidential campaign, the top-performing fake election news stories on Face- book generated more engagement than the top stories from major news outlet\u201d. Our current research hence departs from the as- sumption that social media is a conduit for fake news and asks the question of whether fake news (as spam was some years ago) can be identi\ufb01ed, modelled and eventually blocked.",
  "Our current research hence departs from the as- sumption that social media is a conduit for fake news and asks the question of whether fake news (as spam was some years ago) can be identi\ufb01ed, modelled and eventually blocked. In order to do so, we use a sam- ple of more that 1.5M tweets collected on November 8th 2016 \u2014election day in the United States\u2014 with the goal of identifying features that tweets contain- ing fake news are likely to have. As such, our paper aims to provide a preliminary characterization of fake news in Twitter by looking into meta-data embedded in tweets. Considering meta-data as a relevant factor of analysis is in line with \ufb01ndings reported by Morris et al.7 We argue that understanding di\ufb00erences be- tween tweets containing fake news and regular tweets will allow researchers to design mechanisms to block fake news in Twitter.",
  "Considering meta-data as a relevant factor of analysis is in line with \ufb01ndings reported by Morris et al.7 We argue that understanding di\ufb00erences be- tween tweets containing fake news and regular tweets will allow researchers to design mechanisms to block fake news in Twitter. Speci\ufb01cally, our goals are: 1) compare the char- acteristics of tweets labelled as containing fake news to tweets labelled as not containing them, 2) char- acterize, through their meta-data, viral tweets con- taining fake news and the accounts from which they originated, and 3) determine the extent to which tweets containing fake news expressed polarized po- litical views. For our study, we used the number of retweets to single-out those that went viral within our sample. Tweets within that subset (viral tweets hereafter) are varied and relate to di\ufb00erent topics.",
  "For our study, we used the number of retweets to single-out those that went viral within our sample. Tweets within that subset (viral tweets hereafter) are varied and relate to di\ufb00erent topics. We consider that a tweet contains fake news if its text falls within any of the following categories described by Rubin et al.8 (see next section for the details of such categories): serious fabrication, large-scale hoaxes, jokes taken at face value, slanted reporting of real facts and stories where the truth is contentious. The dataset,9 manu- ally labelled by an expert, has been publicly released and is available to researchers and interested parties. From our results, the following main observations can be made: \u2022 Distribution in the number of retweets, favourites and hashtags in tweets containing fake news are not signi\ufb01cantly di\ufb00erent from their counterparts in tweets not containing fake news. \u2022 Accounts generating fake news are compara- tively more unveri\ufb01ed that accounts not produc- 1 arXiv:1712.05999v1  [cs.CL]  16 Dec 2017",
  "ing fake news. \u2022 There are signi\ufb01cant di\ufb00erences in both the number of friends and followers of the accounts creating tweets with fake news when compared with accounts not generating them. \u2022 There are no signi\ufb01cant di\ufb00erences in the num- ber of media elements, but there are indications that the number of URLs it is indeed di\ufb00erent. Our \ufb01ndings resonate with similar work done on fake news such as the one from Allcot and Gentzkow.10 Therefore, even if our study is a prelim- inary attempt at characterizing fake news on Twitter using only their meta-data, our results provide exter- nal validity to previous research. Moreover, our work not only stresses the importance of using meta-data, but also underscores which parameters may be useful to identify fake news on Twitter. The rest of the paper is organized as follows. The next section brie\ufb02y discusses where this work is lo- cated within the literature on fake news and con- textualizes the type of fake news we are studying. Then, we present our hypotheses, the data, and the methodology we follow.",
  "The next section brie\ufb02y discusses where this work is lo- cated within the literature on fake news and con- textualizes the type of fake news we are studying. Then, we present our hypotheses, the data, and the methodology we follow. Finally, we present our \ufb01nd- ings, conclusions of this study, and future lines of work. De\ufb01ning Fake news Our research is connected to di\ufb00erent strands of aca- demic knowledge related to the phenomenon of fake news. In relation to Computer Science, a recent sur- vey by Conroy and colleagues11 identi\ufb01es two popular approaches to single-out fake news. On the one hand, the authors pointed to linguistic approaches consist- ing in using text, its linguistic characteristics and ma- chine learning techniques to automatically \ufb02ag fake news. On the other, these researchers underscored the use of network approaches, which make use of network characteristics and meta-data, to identify fake news.",
  "On the other, these researchers underscored the use of network approaches, which make use of network characteristics and meta-data, to identify fake news. With respect to social sciences, e\ufb00orts from psy- chology, political science and sociology, have been dedicated to understand why people consume and/or believe misinformation.12\u201315 Most of these studies consistently reported that psychological biases such as priming e\ufb00ects and con\ufb01rmation bias play an im- portant role in people ability to discern misinforma- tion. In relation to the production and distribution of fake news, a recent paper in the \ufb01eld of Economics10 found that most fake news sites use names that re- semble those of legitimate organizations, and that sites supplying fake news tend to be short-lived. These authors also noticed that fake news items are more likely shared than legitimate articles coming from trusted sources, and they tend to exhibit a larger level of polarization. The conceptual issue of how to de\ufb01ne fake news is a serious and unresolved issue. As the focus of our work is not attempting to o\ufb00er light on this, we will rely on work by other authors to describe what we consider as fake news.",
  "The conceptual issue of how to de\ufb01ne fake news is a serious and unresolved issue. As the focus of our work is not attempting to o\ufb00er light on this, we will rely on work by other authors to describe what we consider as fake news. In particular, we use the categorization provided by Rubin et al.8 The \ufb01ve categories they described, together with illustrative examples from our dataset, are as follows: 1. Serious fabrication. These are news stories created entirely to deceive readers. During the 2016 US presidential election there were plenty of examples of this (e.g. claiming a celebrity has endorsed Donald Trump when that was not the case). For instance: [@JebBush - Maybe Donald negotiated a deal with his buddy @HillaryClin- ton. Continuing this path will put her in the White House. https: // t. co/ AlvByiSrMn ] 2. Large-scale hoaxes. Deceptions that are then reported in good faith by reputable sources. A recent example would be the story that the founder of Corona beer made everyone in his home village a millionaire in his will.",
  "https: // t. co/ AlvByiSrMn ] 2. Large-scale hoaxes. Deceptions that are then reported in good faith by reputable sources. A recent example would be the story that the founder of Corona beer made everyone in his home village a millionaire in his will. For instance: [@FullFrontalSamB - Unfortunately Melania copied HER ballot from Michelle so... Donald just voted for Hillary. #ElectionDay https: // t. co/ x2ZimtFxyl ] 3. Jokes taken at face value. Humour sites such as the Onion or Daily Mash present fake news stories in order to satirise the media. Is- sues can arise when readers see the story out of context and share it with others. For in- stance: [@BBCTaster - BREAKING NEWS: If you face-swap @realDonaldTrump with @Mayo- rofLondon you get Owen Wilson. https: // t. co/ YY8a20wQVP ] 4. Slanted reporting of real facts. Selectively- chosen but truthful elements of a story put to- gether to serve an agenda.",
  "https: // t. co/ YY8a20wQVP ] 4. Slanted reporting of real facts. Selectively- chosen but truthful elements of a story put to- gether to serve an agenda. One of the most prevalent examples of this is the well-known problems of voting machine faults. For instance: [@NeilTurner - @realDonaldTrump Trump pre- dicted it. #BrusselsAttack https: // t. co/ BM3UxA7heR ] 5. Stories where the \u2018truth\u2019 is contentious. On issues where ideologies or opinions clash \u2014 for example, territorial con\ufb02icts\u2014 there is some- times no established baseline for truth. Re- porters may be unconsciously partisan, or per- ceived as such. For instance: [@FoxNews - Re- port: @HillaryClinton\u2019s plan would raise taxes $1.3T/10 years. https: // t. co/ Dh1tWM4FAP ] Research Hypotheses Previous works on the area (presented in the section above) suggest that there may be important deter- minants for the adoption and di\ufb00usion of fake news. 2",
  "Our hypotheses builds on them and identi\ufb01es three important dimensions that may help distinguishing fake news from legit information: 1. Exposure. Given that psychological e\ufb00ects such as priming and con\ufb01rmation biases are likely to increase the probability an individual believes in a certain piece of information, we be- lieve exposure to misinformation is an important determinant of a fake news distribution strategy. 2. Characterization. Given that distributors of fake news may want to simulate legitimate in- formation outlets, we believe it is important to analyse speci\ufb01c features that may help a fake news outlet \u2018disguise\u2019 as a legit one. 3. Polarization. Given that fake news outlets are more likely to attract attention with polarizing content (See15), we believe the level of polariza- tion is an important determinant of a fake news distribution strategy. Taking those three dimensions into account, we propose the following hypotheses about the features that we believe can help to identify tweets containing fake news from those not containing them. They will be later tested over our collected dataset. Exposure.",
  "Taking those three dimensions into account, we propose the following hypotheses about the features that we believe can help to identify tweets containing fake news from those not containing them. They will be later tested over our collected dataset. Exposure. H1A: The average number of retweets of a viral tweet containing fake news is larger than that of viral tweets not containing them. H1B: The average number of hashtags and user mentions in viral tweets with fake news is larger than that of viral tweets with no fake news in them. Characterization. H2A: Viral tweets containing fake news have a larger number of URLs. H2B: Creation date of an account generating tweets with fake news is more recent that those ac- counts tweeting non-fake news content. H2C: The rate of friends/followers of accounts tweeting fake news is larger than the rate of those creating tweets without them. Polarization. H3: Viral tweets containing fake news are slanted towards one candidate. Data and Methodology For this study, we collected publicly available tweets using Twitter\u2019s public API.",
  "Polarization. H3: Viral tweets containing fake news are slanted towards one candidate. Data and Methodology For this study, we collected publicly available tweets using Twitter\u2019s public API. Given the nature of the data, it is important to emphasize that such tweets are subject to Twitter\u2019s terms and conditions which indicate that users consent to the collection, transfer, manipulation, storage, and disclosure of data. Therefore, we do not expect ethical, legal, or social implications from the us- age of the tweets. Our data was collected using search terms related to the presidential election held in the United States on November 8th 2016. Particularly, we queried Twitter\u2019s streaming API, more precisely the \ufb01lter endpoint of the streaming API, using the following hashtags and user handles: #MyVote2016, #ElectionDay, #electionnight, @realDonaldTrump and @HillaryClinton. The data collection ran for just one day (Nov 8th 2016). One straightforward way of sharing information on Twitter is by using the retweet functionality, which enables a user to share a exact copy of a tweet with his followers.",
  "The data collection ran for just one day (Nov 8th 2016). One straightforward way of sharing information on Twitter is by using the retweet functionality, which enables a user to share a exact copy of a tweet with his followers. Among the reasons for retweeting, Body et al.16 reported the will to: 1) spread tweets to a new audience, 2) to show one\u2019s role as a listener, and 3) to agree with someone or validate the thoughts of others. As indicated, our initial interest is to char- acterize tweets containing fake news that went viral (as they are the most harmful ones, as they reach a wider audience), and understand how it di\ufb00ers from other viral tweets (that do not contain fake news). For our study, we consider that a tweet went viral if it was retweeted more than 1000 times. Once we have the dataset of viral tweets, we elim- inated duplicates (some of the tweets were collected several times because they had several handles) and an expert manually inspected the text \ufb01eld within the tweets to label them as containing fake news, or not containing them (according to the characteriza- tion presented before).",
  "This annotated dataset9 is publicly available and can be freely reused. Finally, we use the following \ufb01elds within tweets (from the ones returned by Twitter\u2019s API) to com- pare their distributions and look for di\ufb00erences be- tween viral tweets containing fake news and viral tweets not containing fake news: \u2022 Exposure: created at, retweet count, favourites count and hashtags. \u2022 Characterization. screen name, verified, urls, followers count, friends count and media. \u2022 Polarization. text and hashtags. In the following section, we provide graphical de- scriptions of the distribution of each of the identi\ufb01ed attributes for the two sets of tweets (those labelled as containing fake news and those labelled as not con- taining them). Where appropriate, we normalized and/or took logarithms of the data for better repre- sentation. To gain a better understanding of the sig- ni\ufb01cance of those di\ufb00erences, we use the Kolmogorov- Smirnov test with the null hypothesis that both dis- tributions are equal. 3",
  "Results The sample collected consisted on 1 785 855 tweets published by 848 196 di\ufb00erent users. Within our sample, we identi\ufb01ed 1327 tweets that went viral (retweeted more than 1000 times by the 8th of November 2016) produced by 643 users. Such small subset of viral tweets were retweeted on 290 841 oc- casions in the observed time-window. The 1327 \u2018viral\u2019 tweets were manually annotated as containing fake news or not. The annotation was carried out by a single person in order to obtain a consistent annotation throughout the dataset. Out of those 1327 tweets, we identi\ufb01ed 136 as potentially containing fake news (according to the categories pre- viously described), and the rest were classi\ufb01ed as \u2018non containing fake news\u2019. Note that the categorization is far from being perfect given the ambiguity of fake news themselves and human judgement involved in the process of categorization. Because of this, we do not claim that this dataset can be considered a ground truth. The following results detail characteristics of these tweets along the previously mentioned dimensions.",
  "Note that the categorization is far from being perfect given the ambiguity of fake news themselves and human judgement involved in the process of categorization. Because of this, we do not claim that this dataset can be considered a ground truth. The following results detail characteristics of these tweets along the previously mentioned dimensions. Table 1 reports the actual di\ufb00erences (together with their associated p-values) of the distributions of vi- ral tweets containing fake news and viral tweets not containing them for every variable considered.",
  "The following results detail characteristics of these tweets along the previously mentioned dimensions. Table 1 reports the actual di\ufb00erences (together with their associated p-values) of the distributions of vi- ral tweets containing fake news and viral tweets not containing them for every variable considered. Kolmogorov-Smirnov test feature di\ufb00erence p-value Followers 0.2357 2.6E-6 Friends 0.1747 0.0012 URLs 0.1285 0.0358 Favourites 0.1218 0.0535 Mentions 0.1135 0.0862 Media 0.0948 0.2231 Retweets 0.0609 0.7560 Hashtags 0.0350 0.9983 Table 1: For each one of the selected features, the table shows the di\ufb00erence between the set of tweets containing fake news and those non containing them, and the associated p-value (applying a Kolmogorov- Smirnov test). The null hypothesis is that both dis- tributions are equal (two sided). Results are ordered by decreasing p-value.",
  "The null hypothesis is that both dis- tributions are equal (two sided). Results are ordered by decreasing p-value. Exposure Figure 1 shows that, in contrast to other kinds of viral tweets, those containing fake news were created more recently. As such, Twitter users were exposed to fake news related to the election for a shorter period of time. However, in terms of retweets, Figure 2 shows no apparent di\ufb00erence between containing fake news or not containing them. That is con\ufb01rmed by the Kolmogorov-Smirno\ufb00test, which does not discard the hypothesis that the associated distributions are equal. Figure 1: Distribution of the date of creation of the tweets that were viral on November 8th. For clarity, the image only shows the year 2016, and no more than 150 tweets per day. Figure 2: Density distributions of achieved retweets for tweets in our dataset 1)containing fake news and 2)not containing them. No di\ufb00erences are apparent. Figure 3: Density distributions of the number of favourites that the user generating the tweet has.",
  "Figure 2: Density distributions of achieved retweets for tweets in our dataset 1)containing fake news and 2)not containing them. No di\ufb00erences are apparent. Figure 3: Density distributions of the number of favourites that the user generating the tweet has. The di\ufb00erences are not statistically signi\ufb01cant. 4",
  "Figure 4: Distribution of the number of hashtags used in tweets labelled as containing fake news and those labelled as not containing them. In relation to the number of favourites, users that generated at least a viral tweet containing fake news appear to have, on average, less favourites than users that do not generate them. Figure 3 shows the dis- tribution of favourites. Despite the apparent visual di\ufb00erences, the di\ufb00erence are not statistically signif- icant. Finally, the number of hashtags used in viral fake news appears to be larger than those in other viral tweets. Figure 4 shows the density distribution of the number of hashtags used. However, once again, we were not able to \ufb01nd any statistical di\ufb00erence between the average number of hashtags in a viral tweet and the average number of hashtags in viral fake news. Characterization We found that 82 users within our sample were spreading fake news (i.e. they produced at least one tweet which was labelled as fake news). Out of those, 34 had veri\ufb01ed accounts, and the rest were unveri\ufb01ed.",
  "Characterization We found that 82 users within our sample were spreading fake news (i.e. they produced at least one tweet which was labelled as fake news). Out of those, 34 had veri\ufb01ed accounts, and the rest were unveri\ufb01ed. From the 48 unveri\ufb01ed accounts, 6 have been sus- pended by Twitter at the date of writing, 3 tried to imitate legitimate accounts of others, and 4 accounts have been already deleted. Figure 5 shows the pro- portion of veri\ufb01ed accounts to unveri\ufb01ed accounts for viral tweets (containing fake news vs. not containing fake news). From the chart, it is clear that there is a higher chance of fake news coming from unveri\ufb01ed accounts. Turning to friends, accounts distributing fake news appear to have, on average, the same number of friends than those distributing tweets with no fake Figure 5: Tweets labelled as containing fake news mostly come from non-veri\ufb01ed users. This contrasts with the opposite pattern for tweets non containing them (which mostly originate from veri\ufb01ed accounts). news.",
  "This contrasts with the opposite pattern for tweets non containing them (which mostly originate from veri\ufb01ed accounts). news. However, the density distribution of friends from the accounts (Figure 6) shows that there is in- deed a statistically signi\ufb01cant di\ufb00erence in their dis- tributions. If we take into consideration the number of follow- ers, accounts generating viral tweets with fake news do have a very di\ufb00erent distribution on this dimen- sion, compared to those accounts generating viral tweets with no fake news (see Figure 7). In fact, such di\ufb00erences are statistically signi\ufb01cant. A useful representation for friends and followers is the ratio between friends/followers. Figures 8 and 9 show this representation. Notice that accounts spreading viral tweets with fake news have, on av- erage, a larger ratio of friends/followers. The distri- bution of those accounts not generating fake news is 5",
  "Figure 6: Density distributions (for tweets labelled as containing fake news, and tweets labelled as not con- taining them) of the number of friends that the user generating the tweet has. Di\ufb00erence is statistically signi\ufb01cant. Figure 7: Density distributions of the number of followers that the accounts generating viral tweets (within our sample) have. Accounts producing fake news have a narrower window of followers. Figure 8: Density distribution of friends/followers ra- tio, showing quartiles. Accounts that generate fake news tend to have a higher ratio value. more evenly distributed. With respect to the number of mentions, Figure 10 shows that viral tweets labelled as containing fake news appear to use mentions to other users less fre- quently than viral tweets not containing fake news. In other words, tweets containing fake news mostly contain 1 mention, whereas other tweets tend to have two). Such di\ufb00erences are statistically signi\ufb01cant. Figure 9: Density distribution of friends/followers ratio. Note that they do not follow a normal dis- tribution.",
  "Such di\ufb00erences are statistically signi\ufb01cant. Figure 9: Density distribution of friends/followers ratio. Note that they do not follow a normal dis- tribution. A higher friends/followers ratio exists for accounts that has at least produced a tweet labelled as containing fake news. Figure 10: Number of mentions within tweets la- belled as containing fake news and tweets not con- taining them. There is almost a similar distribution of 1 and 2 mentions for tweets containing fake news. This contrasts with tweets not containing fake news, in which 2 mentions is much more common. The analysis (Figure 11) of the presence of media in the tweets in our dataset shows that tweets labelled as not containing fake news appear to present more media elements than those labelled as fake news. However, the di\ufb00erence is not statistically signi\ufb01cant. On the other hand, Figure 12 shows that viral tweets containing fake news appear to include more URLs to other sites than viral tweets that do not contain fake news.",
  "However, the di\ufb00erence is not statistically signi\ufb01cant. On the other hand, Figure 12 shows that viral tweets containing fake news appear to include more URLs to other sites than viral tweets that do not contain fake news. In fact, the di\ufb00erence between the two distributions is statistically signi\ufb01cant (as- suming \u03b1 = 0.05). Polarization Finally, manual inspection of the text \ufb01eld of those viral tweets labelled as containing fake news shows that 117 of such tweets expressed support for Don- ald Trump, while only 8 supported Hillary Clinton. The remaining tweets contained fake news related to other topics, not expressing support for any of the candidates. 6",
  "Figure 11: Number of media elements embedded within viral tweets (labelled as containing fake news vs. labelled as not containing them) Figure 12: Number of URLs embedded within viral tweets (with fake news vs. without them). Di\ufb00er- ences are statistically signi\ufb01cant with \u03b1 = 0.05 Discussion As a summary, and constrained by our existing dataset, we made the following observations regard- ing di\ufb00erences between viral tweets labelled as con- taining fake news and viral tweets labelled as not containing them: \u2022 Less than 0.1% of the tweets went viral. Out of those, only 10% were labelled as containing fake news. \u2022 Tweets containing fake news that became viral during the day of the election were mostly cre- ated very shortly before that day or in the day. That contrasts with tweets not containing fake news (which were initially created much before election day). \u2022 Considering retweets, favourites and hashtags as proxies for exposures, we did not \ufb01nd any di\ufb00er- ence between viral tweets labelled as containing fake news and viral tweets labelled as not con- taining them.",
  "\u2022 Considering retweets, favourites and hashtags as proxies for exposures, we did not \ufb01nd any di\ufb00er- ence between viral tweets labelled as containing fake news and viral tweets labelled as not con- taining them. \u2022 The characterization of accounts spreading fake news has shown that the proportion of unveri- \ufb01ed accounts that generates at least a tweet con- taining fake news is larger than that of accounts spreading tweets not labelled as fake news. \u2022 Even if the accounts producing fake news are, on average, following the same number of other users than those producing tweet with no fake news in them, the distribution of followers are statistically di\ufb00erent. \u2022 There is no signi\ufb01cant di\ufb00erence between the number of media elements in viral tweets la- belled as containing fake news and viral tweets labelled as not containing them. \u2022 Viral tweets labelled as containing fake news tend to have more URLs than viral tweets with labelled as not containing fake news. \u2022 Regarding polarization, fake news were heavily supportive of the Trump campaign.",
  "\u2022 Viral tweets labelled as containing fake news tend to have more URLs than viral tweets with labelled as not containing fake news. \u2022 Regarding polarization, fake news were heavily supportive of the Trump campaign. These \ufb01ndings (related to our initial hypothesis in Table 2) clearly suggest that there are speci\ufb01c pieces of meta-data about tweets that may allow the iden- ti\ufb01cation of fake news. One such parameter is the time of exposure. Viral tweets containing fake news are shorter-lived than those containing other type of content. This notion seems to resonate with our \ufb01nd- ings showing that a number of accounts spreading fake news have already been deleted or suspended by Twitter by the time of writing. If one considers that researchers using di\ufb00erent data have found simi- lar results,10 it appears that the lifetime of accounts, together with the age of the questioned viral content could be useful to identify fake news. In the light of this \ufb01nding, accounts newly created should prob- ably put under higher scrutiny than older ones. This in fact, would be a nice a-priori bias for a Bayesian classi\ufb01er.",
  "In the light of this \ufb01nding, accounts newly created should prob- ably put under higher scrutiny than older ones. This in fact, would be a nice a-priori bias for a Bayesian classi\ufb01er. Accounts spreading fake news appear to have a larger proportion of friends/followers (i.e. they have, on average, the same number of friends but a smaller number of followers) than those spreading viral con- tent only. Together with the fact that, on average, tweets containing fake news have more URLs than those spreading viral content, it is possible to hy- pothesize that, both, the ratio of friends/followers of the account producing a viral tweet and number of URLs contained in such a tweet could be useful to single-out fake news in Twitter. Not only that, but our \ufb01nding related to the number of URLs is in line with intuitions behind the incentives to create fake news commonly found in the literature10 (in partic- ular that of obtaining revenue through click-through advertising). Finally, it is interesting to notice that the content of viral fake news was highly polarized.",
  "Finally, it is interesting to notice that the content of viral fake news was highly polarized. This \ufb01nding is also in line with those of Alcott et al.10 This fea- ture suggests that textual sentiment analysis of the 7",
  "Hypothesis H1A: The average number of retweets of a viral tweet containing fake news is larger than that of viral tweets not containing them NOT CONFIRMED H1B: The average number of hashtags and user mentions in viral tweets with fake news is larger than that of viral tweets with no fake news in them. NOT CONFIRMED H2A: Viral tweets containing fake news have a larger number of URLs. CONFIRMED H2B: Creation date of an account generating tweets with fake news is more recent that those accounts tweeting non-fake news content. CONFIRMED H2C: The rate of friends/followers of accounts tweeting fake news is larger than the rate of those creating tweets without them. CONFIRMED H3: Viral tweets containing fake news are slanted towards one candidate. CONFIRMED Table 2: Summary of our conclusions, and tested hypothesis content of tweets (as most researchers do), together with the above mentioned parameters from meta- data, may prove useful for identifying fake news. Conclusions With the election of Donald Trump as President of the United States, the concept of fake news has be- come a broadly-known phenomenon that is getting tremendous attention from governments and media companies.",
  "Conclusions With the election of Donald Trump as President of the United States, the concept of fake news has be- come a broadly-known phenomenon that is getting tremendous attention from governments and media companies. We have presented a preliminary study on the meta-data of a publicly available dataset of tweets that became viral during the day of the 2016 US presidential election. Our aim is to advance the understanding of which features might be character- istic of viral tweets containing fake news in compari- son with viral tweets without fake news. We believe that the only way to automatically identify those deceitful tweets (i.e. containing fake news) is by actually understanding and modelling them. Only then, the automation of the processes of tagging and blocking these tweets can be success- fully performed. In the same way that spam was fought, we anticipate fake news will su\ufb00er a similar evolution, with social platforms implementing tools to deal with them. With most works so far focusing on the actual content of the tweets, ours is a novel attempt from a di\ufb00erent, but also complementary, angle.",
  "With most works so far focusing on the actual content of the tweets, ours is a novel attempt from a di\ufb00erent, but also complementary, angle. Within the used dataset, we found there are dif- ferences around exposure, characteristics of accounts spreading fake news and the tone of the content. Those \ufb01ndings suggest that it is indeed possible to model and automatically detect fake news. We plan to replicate and validate our experiments in an ex- tended sample of tweets (until 4 months after the US election), and tests the predictive power of the features we found relevant within our sample. Author Disclosure Statement No competing \ufb01nancial interest exist. References 1 Connolly K, Chrisa\ufb01s A, McPherson P, Kirchgaessner S, Haas B, Phillips D, Hunt E, Sa\ufb01 M. Fake news: an insidious trend that\u2019s fast becoming a global prob- lem. The Guardian 02 Dec 2016; https: //www.theguardian.com/media/2016/dec/02/ fake-news-facebook-us-election-around-the-world Accessed: 2017-05-03.",
  "The Guardian 02 Dec 2016; https: //www.theguardian.com/media/2016/dec/02/ fake-news-facebook-us-election-around-the-world Accessed: 2017-05-03. 2 Fact check now available in Google Search and News around the world. https://blog.google/products/search/ fact-check-now-available-google-search-and-news-around Accessed: 2017-05-20. 3 News feed FYI: New test with related arti- cles. https://newsroom.fb.com/news/2017/04/ news-feed-fyi-new-test-with-related-articles/. Accessed: 2017-05-15. 4 Hillary Clinton blames the Russians, Facebook, and Fake News for her loss. http://fortune.com/ 2017/05/31/clinton-fake-news/. Accessed: 2017-05-31. 5 Gottfried J, Shearer E. News use across so- cial media platforms 2016. Technical Report 202.419.4372, Pew Research Center 2016.",
  "Accessed: 2017-05-31. 5 Gottfried J, Shearer E. News use across so- cial media platforms 2016. Technical Report 202.419.4372, Pew Research Center 2016. URL http://www.journalism.org/2016/05/26/ news-use-across-social-media-platforms-2016. 6 Silverman C. Lies, damn lies and viral content. Technical report, Tow Center for Digital Journal- ism 2015. doi:10.7916/D8Q81RHH. 7 Morris M, Counts S, Roseway A, Ho\ufb00A, Schwarz J. Tweeting is believing?: understanding mi- croblog credibility perceptions. In Procs. ACM 2012 Conf. Computer Supported Cooperative Work. 2012, 441\u2013450. 8 Rubin VL, Chen Y, Conroy NJ. Deception detec- tion for news: three types of fakes. In Proceedings of the 78th ASIS&T Annual Meeting: Information 8",
  "Science with Impact: Research in and for the Com- munity. 2015, 83:1\u201383:4. 9 Amador J, Oehmichen A, Molina-Solana M. Vi- ral tweets with fakenews on 2016 US election day. http://dx.doi.org/10.5281/zenodo.1048820 2017. doi:10.5281/zenodo.1048820. 10 Allcott H, Gentzkow M. Social media and fake news in the 2016 election. Technical Report 23089, National Bureau of Economic Research 2017. doi: 10.3386/w23089. 11 Conroy NJ, Chen Y, Rubin VL. Automatic decep- tion detection: Methods for \ufb01nding fake news. In Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community. 2015, 82:1\u201382:4. 12 Pennycook G, Rand DG. Who Falls for Fake News?",
  "In Proceedings of the 78th ASIS&T Annual Meeting: Information Science with Impact: Research in and for the Community. 2015, 82:1\u201382:4. 12 Pennycook G, Rand DG. Who Falls for Fake News? The Roles of Analytic Thinking, Moti- vated Reasoning, Political Ideology, and Bullshit Receptivity 2017. URL https://papers.ssrn. com/sol3/papers.cfm?abstract_id=3023545. 13 Flynn D, Nyhan B, Rei\ufb02er J. The nature and ori- gins of misperceptions: Understanding false and unsupported beliefs about politics. Advances in Political Psychology 2017; 38(S1):127\u2013150. doi: 10.1111/pops.12394. 14 Polage DC, Polage DC. Making up History: False Memories of Fake News Stories. Europe\u2019s Jour- nal of Psychology 2012; 8(2):245\u2013250. ISSN 1841- 0413. doi:10.5964/ejop.v8i2.456.",
  "Making up History: False Memories of Fake News Stories. Europe\u2019s Jour- nal of Psychology 2012; 8(2):245\u2013250. ISSN 1841- 0413. doi:10.5964/ejop.v8i2.456. URL http:// ejop.psychopen.eu/article/view/456. 15 Swire B, Berinsky AJ, Lewandowsky S, Ecker UKH. Processing political misinformation: com- prehending the Trump phenomenon. Royal Society Open Science 2017; 4(3):160802. ISSN 2054-5703. doi:10.1098/rsos.160802. 16 Boyd D, Golder S, Lotan G. Tweet, tweet, retweet: Conversational aspects of retweeting on twitter. In Proc. 43rd Hawaii Int. Conf. on System Sciences. 2010. ISSN 1530-1605, 1\u201310. doi:10.1109/HICSS. 2010.412. 9"
]