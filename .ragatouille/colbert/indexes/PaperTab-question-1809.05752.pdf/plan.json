{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "Analysis of Risk Factor Domains in Psychosis Patient Health Records Eben Holderness1,2, Nicholas Miller1,2, Philip Cawkwell1, Kirsten Bolton1, James Pustejovsky2, Marie Meteer2 and Mei-Hua Hall1 1Psychosis Neurobiology Laboratory, McLean Hospital, Harvard Medical School 2Department of Computer Science, Brandeis University {eholderness, mhall}@mclean.harvard.edu nicholas.anthony.miller@gmail.com {pcawkwell, kbolton}@partners.org {jamesp, mmeteer}@cs.brandeis.edu Abstract Readmission after discharge from a hospital is disruptive and costly, regardless of the rea- son. However, it can be particularly prob- lematic for psychiatric patients, so predicting which patients may be readmitted is critically important but also very dif\ufb01cult. Clinical nar- ratives in psychiatric electronic health records (EHRs) span a wide range of topics and vo- cabulary; therefore, a psychiatric readmission prediction model must begin with a robust and interpretable topic extraction component.",
            "Clinical nar- ratives in psychiatric electronic health records (EHRs) span a wide range of topics and vo- cabulary; therefore, a psychiatric readmission prediction model must begin with a robust and interpretable topic extraction component. We created a data pipeline for using document vector similarity metrics to perform topic ex- traction on psychiatric EHR data in service of our long-term goal of creating a readmission risk classi\ufb01er. We show initial results for our topic extraction model and identify additional features we will be incorporating in the future. 1 Introduction Psychotic disorders typically emerge in late ado- lescence or early adulthood (Kessler et al., 2007; Thomsen, 1996) and affect approximately 2.5-4% of the population (Per\u00a8al\u00a8a et al., 2007; Bogren et al., 2009), making them one of the leading causes of disability worldwide (Vos et al., 2015). A sub- stantial proportion of psychiatric inpatients are readmitted after discharge (Wiersma et al., 1998).",
            "A sub- stantial proportion of psychiatric inpatients are readmitted after discharge (Wiersma et al., 1998). Readmissions are disruptive for patients and fami- lies, and are a key driver of rising healthcare costs (Mangalore and Knapp, 2007; Wu et al., 2005). Reducing readmission risk is therefore a major un- met need of psychiatric care. Developing clini- cally implementable machine learning tools to en- able accurate assessment of risk factors associated with readmission offers opportunities to inform the selection of treatment interventions and imple- ment appropriate preventive measures. In psychiatry, traditional strategies to study readmission risk factors rely on clinical observa- tion and manual retrospective chart review (Olf- son et al., 1999; Lorine et al., 2015). This ap- proach, although bene\ufb01tting from clinical exper- tise, does not scale well for large data sets, is effort-intensive, and lacks automation.",
            "This ap- proach, although bene\ufb01tting from clinical exper- tise, does not scale well for large data sets, is effort-intensive, and lacks automation. An ef\ufb01- cient, more robust, and cheaper NLP-based alter- native approach has been developed and met with some success in other medical \ufb01elds (Murff et al., 2011). However, this approach has seldom been applied in psychiatry because of the unique char- acteristics of psychiatric medical record content. There are several challenges for topic extraction when dealing with clinical narratives in psychi- atric EHRs. First, the vocabulary used is highly varied and context-sensitive. A patient may report \u201cfeeling \u2018really great and excited\u2019\u201d \u2013 symptoms of mania \u2013 without any explicit mention of keywords that differ from everyday vocabulary. Also, many technical terms in clinical narratives are multiword expressions (MWEs) such as \u2018obsessive body im- age\u2019, \u2018linear thinking\u2019, \u2018short attention span\u2019, or \u2018panic attack\u2019.",
            "Also, many technical terms in clinical narratives are multiword expressions (MWEs) such as \u2018obsessive body im- age\u2019, \u2018linear thinking\u2019, \u2018short attention span\u2019, or \u2018panic attack\u2019. These phrasemes are comprised of words that in isolation do not impart much infor- mation in determining relatedness to a given topic but do in the context of the expression. Second, the narrative structure in psychiatric clinical narratives varies considerably in how the same phenomenon can be described. Hallucina- tions, for example, could be described as \u201cthe pa- tient reports auditory hallucinations,\u201d or \u201cthe pa- tient has been hearing voices for several months,\u201d amongst many other possibilities. Third, phenomena can be directly mentioned without necessarily being relevant to the patient speci\ufb01cally. Psychosis patient discharge sum- maries, for instance, can include future treatment plans (e.g. \u201cPrevent relapse of a manic or major depressive episode.\u201d, \u201cPrevent recurrence of psy- chosis.\u201d) containing vocabulary that at the word- level seem strongly correlated with readmission arXiv:1809.05752v1  [cs.CL]  15 Sep 2018",
            "risk. Yet at the paragraph-level these do not in- dicate the presence of a readmission risk factor in the patient and in fact indicate the absence of a risk factor that was formerly present. Lastly, given the complexity of phenotypic as- sessment in psychiatric illnesses, patients with psychosis exhibit considerable differences in terms of illness and symptom presentation. The constellation of symptoms leads to various diag- noses and comorbidities that can change over time, including schizophrenia, schizoaffective disorder, bipolar disorder with psychosis, and substance use induced psychosis. Thus, the lexicon of words and phrases used in EHRs differs not only across diag- noses but also across patients and time. Taken together, these factors make topic extrac- tion a dif\ufb01cult task that cannot be accomplished by keyword search or other simple text-mining tech- niques.",
            "Taken together, these factors make topic extrac- tion a dif\ufb01cult task that cannot be accomplished by keyword search or other simple text-mining tech- niques. To identify speci\ufb01c risk factors to focus on, we not only reviewed clinical literature of risk factors associated with readmission (Alvarez- Jimenez et al., 2012; Addington et al., 2010), but also considered research related to functional remission (Harvey and Bellack, 2009), forensic risk factors (Singh and Fazel, 2010), and con- sulted clinicians involved with this project. Seven risk factor domains \u2013 Appearance, Mood, Inter- personal, Occupation, Thought Content, Thought Process, and Substance \u2013 were chosen because they are clinically relevant, consistent with liter- ature, replicable across data sets, explainable, and implementable in NLP algorithms.",
            "Seven risk factor domains \u2013 Appearance, Mood, Inter- personal, Occupation, Thought Content, Thought Process, and Substance \u2013 were chosen because they are clinically relevant, consistent with liter- ature, replicable across data sets, explainable, and implementable in NLP algorithms. In our present study, we evaluate multiple ap- proaches to automatically identify which risk fac- tor domains are associated with which paragraphs in psychotic patient EHRs.1 We perform this study in support of our long-term goal of creating a read- mission risk classi\ufb01er that can aid clinicians in tar- geting individual treatment interventions and as- sessing patient risk of harm (e.g. suicide risk, homicidal risk). Unlike other contemporary ap- proaches in machine learning, we intend to create a model that is clinically explainable and \ufb02exible across training data while maintaining consistent performance. To incorporate clinical expertise in the identi- \ufb01cation of risk factor domains, we undertake an annotation project, detailed in section 3.1. We identify a test set of over 1,600 EHR paragraphs 1This study has received IRB approval.",
            "To incorporate clinical expertise in the identi- \ufb01cation of risk factor domains, we undertake an annotation project, detailed in section 3.1. We identify a test set of over 1,600 EHR paragraphs 1This study has received IRB approval. which a team of three domain-expert clinicians annotate paragraph-by-paragraph for relevant risk factor domains. Section 3.2 describes the results of this annotation task. We then use the gold stan- dard from the annotation project to assess the per- formance of multiple neural classi\ufb01cation mod- els trained exclusively on Term Frequency \u2013 In- verse Document Frequency (TF-IDF) vectorized EHR data, described in section 4. To further im- prove the performance of our model, we incor- porate domain-relevant MWEs identi\ufb01ed using all in-house data. 2 Related Work McCoy et al. (2015) constructed a corpus of web data based on the Research Domain Criteria (RDoC)(Insel et al., 2010), and used this corpus to create a vector space document similarity model for topic extraction.",
            "2 Related Work McCoy et al. (2015) constructed a corpus of web data based on the Research Domain Criteria (RDoC)(Insel et al., 2010), and used this corpus to create a vector space document similarity model for topic extraction. They found that the \u2018neg- ative valence\u2019 and \u2018social\u2019 RDoC domains were associated with readmission. Using web data (in this case data retrieved from the Bing API) to train a similarity model for EHR texts is problematic since it differs from the target data in both struc- ture and content. Based on reconstruction of the procedure, we conclude that many of the informa- tive MWEs critical to understanding the topics of paragraphs in EHRs are not captured in the web data. Additionally, RDoC is by design a general- ized research construct to describe the entire spec- trum of mental disorders and does not include do- mains that are based on observation or causes of symptoms. Important indicators within EHRs of patient health, like appearance or occupation, are not included in the RDoC constructs. Rumshisky et al.",
            "Important indicators within EHRs of patient health, like appearance or occupation, are not included in the RDoC constructs. Rumshisky et al. (2016) used a corpus of EHRs from patients with a primary diagnosis of ma- jor depressive disorder to create a 75-topic LDA topic model that they then used in a readmission prediction classi\ufb01er pipeline. Like with McCoy et al. (2015), the data used to train the LDA model was not ideal as the generalizability of the data was narrow, focusing on only one disorder. Their model achieved readmission prediction per- formance with an area under the curve of .784 compared to a baseline of .618. To perform clini- cal validation of the topics derived from the LDA model, they manually evaluated and annotated the topics, identifying the most informative vocabu- lary for the top ten topics. With their training data, they found the strongest coherence occurred",
            "in topics involving substance use, suicidality, and anxiety disorders. But given the unsupervised na- ture of the LDA clustering algorithm, the topic coherence they observed is not guaranteed across data sets. 3 Data Our target data set consists of a corpus of dis- charge summaries, admission notes, individual en- counter notes, and other clinical notes from 220 patients in the OnTrackTM program at McLean Hospital. OnTrackTM is an outpatient program, focusing on treating adults ages 18 to 30 who are experiencing their \ufb01rst episodes of psychosis. The length of time in the program varies depending on patient improvement and insurance coverage, with an average of two to three years. The program focuses primarily on early intervention via indi- vidual therapy, group therapy, medication evalu- ation, and medication management. See Table 1 for a demographic breakdown of the 220 pa- tients, for which we have so far extracted approx- imately 240,000 total EHR paragraphs spanning from 2011 to 2014 using Meditech, the software employed by McLean for storing and organizing EHR data.",
            "See Table 1 for a demographic breakdown of the 220 pa- tients, for which we have so far extracted approx- imately 240,000 total EHR paragraphs spanning from 2011 to 2014 using Meditech, the software employed by McLean for storing and organizing EHR data. These patients are part of a larger research co- hort of approximately 1,800 psychosis patients, which will allow us to connect the results of this EHR study with other ongoing research studies incorporating genetic, cognitive, neurobiological, and functional outcome data from this cohort. We also use an additional data set for training our vector space model, comprised of EHR texts queried from the Research Patient Data Registry (RPDR), a centralized regional data repository of clinical data from all institutions in the Partners HealthCare network. These records are highly comparable in style and vocabulary to our target data set. The corpus consists of discharge sum- maries, encounter notes, and visit notes from ap- proximately 30,000 patients admitted to the sys- tem\u2019s hospitals with psychiatric diagnoses and symptoms. This breadth of data captures a wide range of clinical narratives, creating a comprehen- sive foundation for topic extraction.",
            "This breadth of data captures a wide range of clinical narratives, creating a comprehen- sive foundation for topic extraction. After using the RPDR query tool to extract EHR paragraphs from the RPDR database, we created a training corpus by categorizing the extracted para- 2The vast majority of patients in our target cohort are dependents on a parental private health insurance plan. Mean Age (2014) 20.7 Gender (Male) 79% Race Asian 6% Black 7% Caucasian 77% Latino 5% Multiracial 5% Insurance (Public)2 5.5% 30-day Inpatient Readmission Rate 14% Table 1: Demographic breakdown of the target cohort. graphs according to their risk factor domain using a lexicon of 120 keywords that were identi\ufb01ed by the clinicians involved in this project. Certain do- mains \u2013 particularly those involving thoughts and other abstract concepts \u2013 are often identi\ufb01able by MWEs rather than single words.",
            "graphs according to their risk factor domain using a lexicon of 120 keywords that were identi\ufb01ed by the clinicians involved in this project. Certain do- mains \u2013 particularly those involving thoughts and other abstract concepts \u2013 are often identi\ufb01able by MWEs rather than single words. The same clin- icians who identi\ufb01ed the keywords manually ex- amined the bigrams and trigrams with the highest TF-IDF scores for each domain in the categorized paragraphs, identifying those which are conceptu- ally related to the given domain. We then used this lexicon of 775 keyphrases to identify more relevant training paragraphs in RPDR and treat them as (non-stemmed) unigrams when generating the matrix. By converting MWEs such as \u2018short- ened attention span\u2019, \u2018unusual motor activity\u2019, \u2018wide-ranging affect\u2019, or \u2018linear thinking\u2019 to non- stemmed unigrams, the TF-IDF score (and there- fore the predictive value) of these terms is magni- \ufb01ed. In total, we constructed a corpus of roughly 100,000 paragraphs consisting of 7,000,000 to- kens for training our model.",
            "In total, we constructed a corpus of roughly 100,000 paragraphs consisting of 7,000,000 to- kens for training our model. 3.1 Annotation Task In order to evaluate our models, we annotated 1,654 paragraphs selected from the 240,000 para- graphs extracted from Meditech with the clinically relevant domains described in Table 2. The anno- tation task was completed by three licensed clini- cians. All paragraphs were removed from the sur- rounding EHR context to ensure annotators were not in\ufb02uenced by the additional contextual infor- mation. Our domain classi\ufb01cation models con- sider each paragraph independently and thus we designed the annotation task to mirror the infor- mation available to the models. The annotators were instructed to label each",
            "Domain Description Example Paragraph Example Keywords Appearance Physical appearance, gestures, and mannerisms \u201cA well-appearing, clean young woman appearing her stated age, pleasant and cooperative. Eye contact was good.\u201d disheveled, clothing, groomed, wearing, clean Thought Content Suicidal\/homicidal ideation, obsessions, phobias, delusions, hallucinations \u201cNo SI3, No HI4, No hallucinations, Ideas of reference, Paranoid delusions\u201d obsession, delusion, grandiose, ideation, suicidal, paranoid Interpersonal Family situation, friendships, and other social relationships \u201cPt. overall appears to be functioning very well despite this con\ufb02ict with a romantic interest of hers.\u201d boyfriend, relationship, peers, family, parents, social Mood Feelings and overall disposition \u201cPt. indicates that his mood is becoming more \u2018depressed.\u2019\u201d anxious, calm, depressed, labile, confused, cooperative Occupation School and\/or employment \u201cPt. followed through with decision to leave college at this point in time.\u201d boss, employed, job, school, class, homework, work Thought Process Pace and coherence of thoughts.",
            "followed through with decision to leave college at this point in time.\u201d boss, employed, job, school, class, homework, work Thought Process Pace and coherence of thoughts. Includes linear, goal-directed, perseverative, tangential, and \ufb02ight of ideas \u201cDisorganized (Dif\ufb01cult to communicate with patient.), Paucity of thought, Thought-blocking.\u201d linear, tangential, prosody, blocking, goal-directed, perseverant Substance Drug and\/or alcohol use \u201cPatient used marijuana once which he believes triggered the current episode.\u201d cocaine, marijuana, ETOH5, addiction, narcotic Other Any paragraph that does not fall into any of the other seven domains \u201cMaintain mood stabilization, prevent future episodes of mania, improve self-monitoring skills.\u201d \u2013 Table 2: Annotation scheme for the domain classi\ufb01cation task. paragraph with one or more of the seven risk fac- tor domains. In instances where more than one do- main was applicable, annotators assigned the do- mains in order of prevalence within the paragraph.",
            "paragraph with one or more of the seven risk fac- tor domains. In instances where more than one do- main was applicable, annotators assigned the do- mains in order of prevalence within the paragraph. An eighth label, \u2018Other\u2019, was included if a para- graph was ambiguous, uninterpretable, or about a domain not included in the seven risk factor do- mains (e.g. non-psychiatric medical concerns and lab results). The annotations were then reviewed by a team of two clinicians who adjudicated col- laboratively to create a gold standard. The gold standard and the clinician-identi\ufb01ed keywords and MWEs have received IRB approval for release to the community. They are available as supplemen- tary data to this paper. 3.2 Inter-Annotator Agreement Inter-annotator agreement (IAA) was assessed us- ing a combination of Fleiss\u2019s Kappa (a variant of Scott\u2019s Pi that measures pairwise agreement for annotation tasks involving more than two anno- tators) (Fleiss, 1971) and Cohen\u2019s Multi-Kappa as proposed by Davies and Fleiss (1982).",
            "Table 3 shows IAA calculations for both overall agree- ment and agreement on the \ufb01rst (most important) domain only. Following adjudication, accuracy scores were calculated for each annotator by eval- uating their annotations against the gold standard. Overall agreement was generally good and aligned almost exactly with the IAA on the \ufb01rst domain only. Out of the 1,654 annotated para- graphs, 671 (41%) had total agreement across all three annotators. We de\ufb01ned total agreement for the task as a set-theoretic complete intersection of domains for a paragraph identi\ufb01ed by all anno- tators. 98% of paragraphs in total agreement in- volved one domain. Only 35 paragraphs had total disagreement, which we de\ufb01ned as a set-theoretic null intersection between the three annotators. An analysis of the 35 paragraphs with total disagree- ment showed that nearly 30% included the term \u201cblunted\/restricted\u201d. In clinical terminology, these terms can be used to refer to appearance, affect, mood, or emotion.",
            "An analysis of the 35 paragraphs with total disagree- ment showed that nearly 30% included the term \u201cblunted\/restricted\u201d. In clinical terminology, these terms can be used to refer to appearance, affect, mood, or emotion. Because the paragraphs be- ing annotated were extracted from larger clinical narratives and examined independently of any sur- rounding context, it was dif\ufb01cult for the annotators to determine the most appropriate domain. This lack of contextual information resulted in each annotator using a different \u2018default\u2019 label: Ap- pearance, Mood, and Other. During adjudication, Other was decided as the most appropriate label unless the paragraph contained additional content that encompassed other domains, as it avoids mak- ing unnecessary assumptions. 3Suicidal ideation 4Homicidal ideation 5Ethyl alcohol and ethanol",
            "Labels Fleiss\u2019s Kappa Cohen\u2019s Multi-Kappa Mean Accuracy Overall 0.575 0.571 0.746 First Domain Only 0.536 0.528 0.805 Table 3: Inter-annotator agreement Network MLP RBF Input Layer Nodes 100 100 Dropout 0.2 0.2 Activation ReLU6 ReLU Hidden Layer Nodes 100 350 Dropout 0.5 0.0 Activation ReLU RBF Output Layer Nodes 7 7 Activation Sigmoid Linear Optimizer Adam7 Adam Loss Function Categorical Cross Entropy Mean Squared Error Training Epochs 30 50 Batch Size 128 128 Table 4: Architectures of our highest-performing MLP and RBF networks. A Fleiss\u2019s Kappa of 0.575 lies on the boundary between \u2018Moderate\u2019 and \u2018Substantial\u2019 agreement as proposed by Landis and Koch (1977). This is a promising indication that our risk factor do- mains are adequately de\ufb01ned by our present guide- lines and can be employed by clinicians involved in similar work at other institutions.",
            "This is a promising indication that our risk factor do- mains are adequately de\ufb01ned by our present guide- lines and can be employed by clinicians involved in similar work at other institutions. The fourth column in Table 3, Mean Accuracy, was calculated by averaging the three annotator accuracies as evaluated against the gold standard. This provides us with an informative baseline of human parity on the domain classi\ufb01cation task. 4 Topic Extraction Figure 1 illustrates the data pipeline for generat- ing our training and testing corpora, and applying them to our classi\ufb01cation models. 6Recti\ufb01ed Linear Units, f(x) = max(0, x) (Nair and Hinton, 2010) 7Adaptive Moment Estimation (Kingma and Ba, 2014) We use the T\ufb01dfVectorizer tool included in the scikit-learn machine learning toolkit (Pedregosa et al., 2011) to generate our TF-IDF vector space models, stemming tokens with the Porter Stemmer tool provided by the NLTK library (Bird et al., 2009), and calculating TF-IDF scores for uni- grams, bigrams, and trigrams.",
            "Applying Singular Value Decomposition (SVD) to the TF-IDF ma- trix, we reduce the vector space to 100 dimen- sions, which Zhang et al. (2011) found to improve classi\ufb01er performance. Starting with the approach taken by McCoy et al. (2015), who used aggregate cosine similarity scores to compute domain similarity directly from their TF-IDF vector space model, we extend this method by training a suite of three-layer multi- layer perceptron (MLP) and radial basis function (RBF) neural networks using a variety of param- eters to compare performance. We employ the Keras deep learning library (Chollet et al., 2015) using a TensorFlow backend (Abadi et al.) for this task. The architectures of our highest performing MLP and RBF models are summarized in Table 4. Prototype vectors for the nodes in the hidden layer of our RBF model are selected via k-means clus- tering (MacQueen et al., 1967) on each domain paragraph megadocument individually.",
            "The architectures of our highest performing MLP and RBF models are summarized in Table 4. Prototype vectors for the nodes in the hidden layer of our RBF model are selected via k-means clus- tering (MacQueen et al., 1967) on each domain paragraph megadocument individually. The RBF transfer function for each hidden layer node is as- signed the same width, which is based off the max- imum Euclidean distance between the centroids that were computed using k-means. To prevent over\ufb01tting to the training data, we utilize a dropout rate (Srivastava et al., 2014) of 0.2 on the input layer of all models and 0.5 on the MLP hidden layer. Since our classi\ufb01cation problem is multiclass, multilabel, and open-world, we employ seven nodes with sigmoid activations in the output layer, one for each risk factor domain. This allows us to identify paragraphs that fall into more than one of the seven domains, as well as determine para- graphs that should be classi\ufb01ed as Other.",
            "This allows us to identify paragraphs that fall into more than one of the seven domains, as well as determine para- graphs that should be classi\ufb01ed as Other. Unlike the traditionally used softmax activation function, which is ideal for single-label, closed-world clas- si\ufb01cation tasks, sigmoid nodes output class like-",
            "Figure 1: Data pipeline for training and evaluating our risk factor domain classi\ufb01ers. lihoods for each node independently without the normalization across all classes that occurs in soft- max. We \ufb01nd that the risk factor domains vary in the degree of homogeneity of language used, and as such certain domains produce higher simi- larity scores, on average, than others. To ac- count for this, we calculate threshold similar- ity scores for each domain using the formula min=avg(sim)+\u03b1*\u03c3(sim), where \u03c3 is standard de- viation and \u03b1 is a constant, which we set to 0.78 for our MLP model and 1.2 for our RBF model through trial-and-error. Employing a gen- eralized formula as opposed to manually identify- ing threshold similarity scores for each domain has the advantage of \ufb02exibility in regards to the target data, which may vary in average similarity scores depending on its similarity to the training data. If a paragraph does not meet threshold on any domain, it is classi\ufb01ed as Other.",
            "If a paragraph does not meet threshold on any domain, it is classi\ufb01ed as Other. 5 Results and Discussion Table 5 shows the performance of our models on classifying the paragraphs in our gold standard. To assess relative performance of feature representa- tions, we also include performance metrics of our models without MWEs. Because this is a multil- abel classi\ufb01cation task we use macro-averaging to compute precision, recall, and F1 scores for each paragraph in the testing set. In identifying do- mains individually, our models achieved the high- est per-domain scores on Substance (F1 \u22480.8) and the lowest scores on Interpersonal and Mood (F1 \u22480.5). We observe a consistency in per-domain performance rankings between our MLP and RBF models. The wide variance in per-domain performance is due to a number of factors. Most notably, the training examples we extracted from RPDR \u2013 while very comparable to our target OnTrackTM Precision Recall F1 Aggregate Cosine Similarity Scores 0.602 0.563 0.574 MLP Baseline (No MWEs) 0.611 0.567 0.",
            "Most notably, the training examples we extracted from RPDR \u2013 while very comparable to our target OnTrackTM Precision Recall F1 Aggregate Cosine Similarity Scores 0.602 0.563 0.574 MLP Baseline (No MWEs) 0.611 0.567 0.579 RBF Baseline (No MWEs) 0.603 0.618 0.606 MLP (w\/ MWEs) 0.717 0.666 0.681 Appearance 0.886 0.414 0.564 Interpersonal 0.548 0.453 0.496 Mood 0.691 0.430 0.530 Occupation 0.826 0.461 0.592 Substance 0.920 0.703 0.797 Thought Content 0.926 0.590 0.721 Thought Process 0.654 0.617 0.635 Other 0.632 0.798 0.710 RBF (w\/ MWEs) 0.684 0.630 0.645 Appearance 0.670 0.490 0.566 Interpersonal 0.410 0.",
            "617 0.635 Other 0.632 0.798 0.710 RBF (w\/ MWEs) 0.684 0.630 0.645 Appearance 0.670 0.490 0.566 Interpersonal 0.410 0.493 0.448 Mood 0.655 0.399 0.496 Occupation 0.720 0.501 0.598 Substance 0.866 0.730 0.792 Thought Content 0.892 0.547 0.678 Thought Process 0.569 0.691 0.624 Other 0.651 0.650 0.651 Table 5: Overall and domain-speci\ufb01c Precision, Recall, and F1 scores for our models. The \ufb01rst row computes similarity directly from the TF-IDF matrix, as in (Mc- Coy et al., 2015). All other rows are classi\ufb01er outputs. data \u2013 may not have an adequate variety of con- tent and range of vocabulary.",
            "The \ufb01rst row computes similarity directly from the TF-IDF matrix, as in (Mc- Coy et al., 2015). All other rows are classi\ufb01er outputs. data \u2013 may not have an adequate variety of con- tent and range of vocabulary. Although using key- word and MWE matching to create our training corpus has the advantage of being signi\ufb01cantly less labor intensive than manually labeling every paragraph in the corpus, it is likely that the ho- mogeneity of language used in the training para-",
            "Figure 2: 2-component linear discriminant analysis of the RPDR training data. graphs is higher than it would be otherwise. Addi- tionally, all of the paragraphs in the training data are assigned exactly one risk factor domain even if they actually involve multiple risk factor domains, making the clustering behavior of the paragraphs more dif\ufb01cult to de\ufb01ne. Figure 2 illustrates the distribution of paragraphs in vector space using 2- component Linear Discriminant Analysis (LDA) (Johnson and Wichern, 2004). Despite prior research indicating that similar classi\ufb01cation tasks to ours are more effectively performed by RBF networks (Scheirer et al., 2014; Jain et al., 2014; Bendale and Boult, 2015), we \ufb01nd that a MLP network performs marginally bet- ter with signi\ufb01cantly less preprocessing (i.e. k- means and width calculations) involved.",
            "k- means and width calculations) involved. We can see in Figure 2 that Thought Process, Appearance, Substance, and \u2013 to a certain extent \u2013 Occupation clearly occupy speci\ufb01c regions, whereas Interper- sonal, Mood, and Thought Content occupy the same noisy region where multiple domains over- lap. Given that similarity is computed using Eu- clidean distance in an RBF network, it is dif\ufb01- cult to accurately classify paragraphs that fall in regions occupied by multiple risk factor domain clusters since prototype centroids from the risk factor domains will overlap and be less differen- tiable.",
            "Given that similarity is computed using Eu- clidean distance in an RBF network, it is dif\ufb01- cult to accurately classify paragraphs that fall in regions occupied by multiple risk factor domain clusters since prototype centroids from the risk factor domains will overlap and be less differen- tiable. This is con\ufb01rmed by the results in Table 5, where the differences in performance between the RBF and MLP models are more pronounced in the three overlapping domains (0.496 vs 0.448 for Interpersonal, 0.530 vs 0.496 for Mood, and 0.721 vs 0.678 for Thought Content) compared to the non-overlapping domains (0.564 vs 0.566 for Appearance, 0.592 vs 0.598 for Occupation, 0.797 vs 0.792 for Substance, and 0.635 vs 0.624 for Thought Process). We also observe a similarity in the words and phrases with the highest TF-IDF scores across the overlapping domains: many of the Thought Content words and phrases with the highest TF-IDF scores involve interpersonal rela- tions (e.g.",
            "We also observe a similarity in the words and phrases with the highest TF-IDF scores across the overlapping domains: many of the Thought Content words and phrases with the highest TF-IDF scores involve interpersonal rela- tions (e.g. \u2018fear surrounding daughter\u2019, \u2018father\u2019, \u2018family history\u2019, \u2018familial con\ufb02ict\u2019) and there is a high degree of similarity between high-scoring words for Mood (e.g. \u2018meets anxiety criteria\u2019, \u2018cope with mania\u2019, \u2018ocd\u20198) and Thought Content (e.g. \u2018mania\u2019, \u2018feels anxious\u2019, \u2018feels exhausted\u2019). 8Obsessive-compulsive disorder",
            "MWEs play a large role in correctly identifying risk factor domains. Factoring them into our mod- els increased classi\ufb01cation performance by 15%, a marked improvement over our baseline model. This aligns with our expectations that MWEs com- prised of a quotidian vocabulary hold much more clinical signi\ufb01cance than when the words in the expressions are treated independently. Threshold similarity scores also play a large role in determining the precision and recall of our models: higher thresholds lead to a smaller num- ber of false positives and a greater number of false negatives for each risk factor domain. Conversely, more paragraphs are incorrectly classi\ufb01ed as Other when thresholds are set higher. Since our classi- \ufb01er will be used in future work as an early step in a data analysis pipeline for determining read- mission risk, misclassifying a paragraph with an incorrect risk factor domain at this stage can lead to greater inaccuracies at later stages. Paragraphs misclassi\ufb01ed as Other, however, will be discarded from the data pipeline.",
            "Paragraphs misclassi\ufb01ed as Other, however, will be discarded from the data pipeline. Therefore, we intention- ally set a conservative threshold where only the most con\ufb01dently labeled paragraphs are assigned membership in a particular domain. 6 Future Work and Conclusion To achieve our goal of creating a framework for a readmission risk classi\ufb01er, the present study per- formed necessary evaluation steps by updating and adding to our model iteratively. In the \ufb01rst stage of the project, we focused on collecting the data necessary for training and testing, and on the do- main classi\ufb01cation annotation task. At the same time, we began creating the tools necessary for automatically extracting domain relevance scores at the paragraph and document level from patient EHRs using several forms of vectorization and topic modeling. In future versions of our risk fac- tor domain classi\ufb01cation model we will explore increasing robustness through sequence modeling that considers more contextual information.",
            "In future versions of our risk fac- tor domain classi\ufb01cation model we will explore increasing robustness through sequence modeling that considers more contextual information. Our current feature set for training a machine learning classi\ufb01er is relatively small, consisting of paragraph domain scores, bag-of-words, length of stay, and number of previous admissions, but we intend to factor in many additional features that extend beyond the scope of the present study. These include a deeper analysis of clinical nar- ratives in EHRs: our next task will be to extend our EHR data pipeline by distinguishing between clinically positive and negative phenomena within each risk factor domain. This will involve a series of annotation tasks that will allow us to generate lexicon-based and corpus-based sentiment analy- sis tools. We can then use these clinical sentiment scores to generate a gradient of patient improve- ment or deterioration over time.",
            "This will involve a series of annotation tasks that will allow us to generate lexicon-based and corpus-based sentiment analy- sis tools. We can then use these clinical sentiment scores to generate a gradient of patient improve- ment or deterioration over time. We will also take into account structured data that have been collected on the target cohort throughout the course of this study such as brain based electrophysiological (EEG) biomark- ers, structural brain anatomy from MRI scans (gray matter volume, cortical thickness, cortical surface-area), social and role functioning assess- ments, personality assessment (NEO-FFI9), and various symptom scales (PANSS10, MADRS11, YMRS12). For each feature we consider adding, we will evaluate the performance of the classi\ufb01er with and without the feature to determine its con- tribution as a predictor of readmission. 7 Acknowledgments This work was supported by a grant from the National Institute of Mental Health (grant no. 5R01MH109687 to Mei-Hua Hall). We would also like to thank the LOUHI 2018 Workshop re- viewers for their constructive and helpful com- ments.",
            "7 Acknowledgments This work was supported by a grant from the National Institute of Mental Health (grant no. 5R01MH109687 to Mei-Hua Hall). We would also like to thank the LOUHI 2018 Workshop re- viewers for their constructive and helpful com- ments. References Mart\u00b4\u0131n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. Tensor\ufb02ow: a system for large-scale machine learning. Donald Emile Addington, Cindy Beck, JianLi Wang, Beverly Adams, Cathy Pryce, Haifeng Zhu, Jian Kang, and Emily McKenzie. 2010. Predictors of ad- mission in \ufb01rst-episode psychosis: developing a risk adjustment model for service comparisons. Psychi- atric Services, 61(5):483\u2013488. Mario Alvarez-Jimenez, A Priede, SE Hetrick, Sarah Bendall, Eoin Killackey, AG Parker, PD McGorry, and JF Gleeson. 2012.",
            "Psychi- atric Services, 61(5):483\u2013488. Mario Alvarez-Jimenez, A Priede, SE Hetrick, Sarah Bendall, Eoin Killackey, AG Parker, PD McGorry, and JF Gleeson. 2012. Risk factors for relapse following treatment for \ufb01rst episode psychosis: a systematic review and meta-analysis of longitudi- nal studies. Schizophrenia Research, 139(1-3):116\u2013 128. 9NEO Five-Factor Inventory (Costa and McCrae, 2010) 10Positive and Negative Syndrome Scale (Kay et al., 1987) 11Montgomery-Asperg Depression Rating Scale (Mont- gomery and \u02daAsberg, 1979) 12Young Mania Rating Scale (Young et al., 1978)",
            "Abhijit Bendale and Terrance Boult. 2015. Towards open world recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recog- nition, pages 1893\u20131902. Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural language processing with Python: analyz- ing text with the natural language toolkit. \u201d O\u2019Reilly Media, Inc.\u201d. Mats Bogren, Cecilia Mattisson, Per-Erik Isberg, and Per Nettelbladt. 2009. How common are psychotic and bipolar disorders? a 50-year follow-up of the lundby population. Nordic journal of psychiatry, 63(4):336\u2013346. Franc\u00b8ois Chollet et al. 2015. Keras. https:\/\/ keras.io. PT Costa and Robert R McCrae. 2010. The neo per- sonality inventory: 3. Odessa, FL: Psychological assessment resources. Mark Davies and Joseph L Fleiss. 1982. Measuring agreement for multinomial data.",
            "https:\/\/ keras.io. PT Costa and Robert R McCrae. 2010. The neo per- sonality inventory: 3. Odessa, FL: Psychological assessment resources. Mark Davies and Joseph L Fleiss. 1982. Measuring agreement for multinomial data. Biometrics, pages 1047\u20131051. Joseph L Fleiss. 1971. Measuring nominal scale agree- ment among many raters. Psychological bulletin, 76(5):378. Philip D Harvey and Alan S Bellack. 2009. Toward a terminology for functional recovery in schizophre- nia: is functional remission a viable concept? Schizophrenia Bulletin, 35(2):300\u2013306. Thomas Insel, Bruce Cuthbert, Marjorie Garvey, Robert Heinssen, Daniel S Pine, Kevin Quinn, Charles Sanislow, and Philip Wang. 2010. Research domain criteria (rdoc): toward a new classi\ufb01cation framework for research on mental disorders. Lalit P Jain, Walter J Scheirer, and Terrance E Boult. 2014.",
            "2010. Research domain criteria (rdoc): toward a new classi\ufb01cation framework for research on mental disorders. Lalit P Jain, Walter J Scheirer, and Terrance E Boult. 2014. Multi-class open set recognition using prob- ability of inclusion. In European Conference on Computer Vision, pages 393\u2013409. Springer. Richard A Johnson and Dean W Wichern. 2004. Mul- tivariate analysis. Encyclopedia of Statistical Sci- ences, 8. Stanley R Kay, Abraham Fiszbein, and Lewis A Opler. 1987. The positive and negative syndrome scale (panss) for schizophrenia. Schizophrenia bulletin, 13(2):261\u2013276. Ronald C Kessler, G Paul Amminger, Sergio Aguilar- Gaxiola, Jordi Alonso, Sing Lee, and T Bedirhan Ustun. 2007. Age of onset of mental disorders: a review of recent literature. Current opinion in psy- chiatry, 20(4):359. Diederik P Kingma and Jimmy Ba. 2014.",
            "2007. Age of onset of mental disorders: a review of recent literature. Current opinion in psy- chiatry, 20(4):359. Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980. J Richard Landis and Gary G Koch. 1977. The mea- surement of observer agreement for categorical data. biometrics, pages 159\u2013174. Kim Lorine, Haig Goenjian, Soeun Kim, Alan M Stein- berg, Kendall Schmidt, and Armen K Goenjian. 2015. Risk factors associated with psychiatric read- mission. The Journal of nervous and mental dis- ease, 203(6):425\u2013430. James MacQueen et al. 1967. Some methods for clas- si\ufb01cation and analysis of multivariate observations. Roshni Mangalore and Martin Knapp. 2007. Cost of schizophrenia in england. The journal of mental health policy and economics, 10(1):23\u201341.",
            "1967. Some methods for clas- si\ufb01cation and analysis of multivariate observations. Roshni Mangalore and Martin Knapp. 2007. Cost of schizophrenia in england. The journal of mental health policy and economics, 10(1):23\u201341. Thomas H McCoy, Victor M Castro, Hannah R Rosen- \ufb01eld, Andrew Cagan, Isaac S Kohane, and Roy H Perlis. 2015. A clinical perspective on the rel- evance of research domain criteria in electronic health records. American Journal of Psychiatry, 172(4):316\u2013320. Stuart A Montgomery and MARIE \u02daAsberg. 1979. A new depression scale designed to be sensitive to change. The British journal of psychiatry, 134(4):382\u2013389. Harvey J Murff, Fern FitzHenry, Michael E Matheny, Nancy Gentry, Kristen L Kotter, Kimberly Crimin, Robert S Dittus, Amy K Rosen, Peter L Elkin, Steven H Brown, et al. 2011.",
            "Harvey J Murff, Fern FitzHenry, Michael E Matheny, Nancy Gentry, Kristen L Kotter, Kimberly Crimin, Robert S Dittus, Amy K Rosen, Peter L Elkin, Steven H Brown, et al. 2011. Automated identi\ufb01ca- tion of postoperative complications within an elec- tronic medical record using natural language pro- cessing. Jama, 306(8):848\u2013855. Vinod Nair and Geoffrey E Hinton. 2010. Recti\ufb01ed linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10), pages 807\u2013814. Mark Olfson, David Mechanic, Carol A Boyer, Stephen Hansell, James Walkup, and Peter J Wei- den. 1999. Assessing clinical predictions of early rehospitalization in schizophrenia. The Journal of nervous and mental disease, 187(12):721\u2013729.",
            "1999. Assessing clinical predictions of early rehospitalization in schizophrenia. The Journal of nervous and mental disease, 187(12):721\u2013729. Fabian Pedregosa, Ga\u00a8el Varoquaux, Alexandre Gram- fort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. 2011. Scikit-learn: Machine learning in python. Journal of machine learning research, 12(Oct):2825\u20132830. Jonna Per\u00a8al\u00a8a, Jaana Suvisaari, Samuli I Saarni, Kimmo Kuoppasalmi, Erkki Isomets\u00a8a, Sami Pirkola, Timo Partonen, Annamari Tuulio-Henriksson, Jukka Hin- tikka, Tuula Kiesepp\u00a8a, et al. 2007. Lifetime preva- lence of psychotic and bipolar i disorders in a gen- eral population. Archives of general psychiatry, 64(1):19\u201328.",
            "2007. Lifetime preva- lence of psychotic and bipolar i disorders in a gen- eral population. Archives of general psychiatry, 64(1):19\u201328. A Rumshisky, M Ghassemi, T Naumann, P Szolovits, VM Castro, TH McCoy, and RH Perlis. 2016. Pre- dicting early psychiatric readmission with natural",
            "language processing of narrative discharge sum- maries. Translational psychiatry, 6(10):e921. Walter J Scheirer, Lalit P Jain, and Terrance E Boult. 2014. Probability models for open set recognition. IEEE transactions on pattern analysis and machine intelligence, 36(11):2317\u20132324. Jay P Singh and Seena Fazel. 2010. Forensic risk as- sessment: A metareview. Criminal Justice and Be- havior, 37(9):965\u2013988. Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from over\ufb01tting. The Journal of Machine Learning Research, 15(1):1929\u20131958. PH Thomsen. 1996. Schizophrenia with childhood and adolescent onseta nationwide register-based study. Acta Psychiatrica Scandinavica, 94(3):187\u2013193.",
            "The Journal of Machine Learning Research, 15(1):1929\u20131958. PH Thomsen. 1996. Schizophrenia with childhood and adolescent onseta nationwide register-based study. Acta Psychiatrica Scandinavica, 94(3):187\u2013193. Theo Vos, Ryan M Barber, Brad Bell, Amelia Bertozzi- Villa, Stan Biryukov, Ian Bolliger, Fiona Charlson, Adrian Davis, Louisa Degenhardt, Daniel Dicker, et al. 2015. Global, regional, and national inci- dence, prevalence, and years lived with disability for 301 acute and chronic diseases and injuries in 188 countries, 1990\u20132013: a systematic analysis for the global burden of disease study 2013. The Lancet, 386(9995):743\u2013800. Durk Wiersma, Fokko J Nienhuis, Cees J Slooff, and Robert Giel. 1998. Natural course of schizophrenic disorders: a 15-year followup of a dutch incidence cohort. Schizophrenia bulletin, 24(1):75\u201385.",
            "1998. Natural course of schizophrenic disorders: a 15-year followup of a dutch incidence cohort. Schizophrenia bulletin, 24(1):75\u201385. Eric Q Wu, Howard G Birnbaum, Lizheng Shi, Daniel E Ball, Ronald C Kessler, Matthew Moulis, and Jyoti Aggarwal. 2005. The economic burden of schizophrenia in the united states in 2002. Journal of Clinical Psychiatry, 66(9):1122\u20131129. RC Young, JT Biggs, VE Ziegler, and DA Meyer. 1978. A rating scale for mania: reliability, validity and sensitivity. The British Journal of Psychiatry, 133(5):429\u2013435. Wen Zhang, Taketoshi Yoshida, and Xijin Tang. 2011. A comparative study of tf* idf, lsi and multi-words for text classi\ufb01cation. Expert Systems with Applica- tions, 38(3):2758\u20132765."
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-1809.05752.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 9298.000061035156,
    "avg_doclen_est": 178.8076934814453
}
