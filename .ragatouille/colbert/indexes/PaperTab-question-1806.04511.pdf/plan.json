{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "Multilingual Sentiment Analysis: An RNN-Based Framework for Limited Data Ethem F. Can SAS Inst. ethfcan@gmail.com Aysu Ezen-Can SAS Inst. aysu.e.can@gmail.com Fazli Can Bilkent IR Group Bilkent University canf@cs.bilkent.edu.tr ABSTRACT Sentiment analysis is a widely studied NLP task where the goal is to determine opinions, emotions, and evaluations of users to- wards a product, an entity or a service that they are reviewing. One of the biggest challenges for sentiment analysis is that it is highly language dependent. Word embeddings, sentiment lexicons, and even annotated data are language speci\ufb01c. Further, optimiz- ing models for each language is very time consuming and labor intensive especially for recurrent neural network models. From a resource perspective, it is very challenging to collect data for di\ufb00erent languages. In this paper, we look for an answer to the following research question: can a sentiment analysis model trained on a language be reused for sentiment analysis in other languages, Russian, Spanish, Turkish, and Dutch, where the data is more limited?",
            "In this paper, we look for an answer to the following research question: can a sentiment analysis model trained on a language be reused for sentiment analysis in other languages, Russian, Spanish, Turkish, and Dutch, where the data is more limited? Our goal is to build a single model in the language with the largest dataset available for the task, and reuse it for languages that have lim- ited resources. For this purpose, we train a sentiment analysis model using recurrent neural networks with reviews in English. We then translate reviews in other languages and reuse this model to evaluate the sentiments. Experimental results show that our robust approach of single model trained on English reviews statis- tically signi\ufb01cantly outperforms the baselines in several di\ufb00erent languages. CCS CONCEPTS \u2022Computing methodologies \u2192Natural language processing; \u2022Information systems \u2192Content analysis and feature selection; KEYWORDS sentiment analysis, multilingual NLP, deep learning ACM Reference format: Ethem F. Can, Aysu Ezen-Can, and Fazli Can. 2018. Multilingual Sentiment Analysis: An RNN-Based Framework for Limited Data.",
            "2018. Multilingual Sentiment Analysis: An RNN-Based Framework for Limited Data. In Proceedings of ACM SIGIR 2018 Workshop on Learning from Limited or Noisy Data, Ann Arbor, Michigan, USA, July 12, 2018 (LND4IR \u201918), 5 pages. DOI: Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro\ufb01t or commercial advantage and that copies bear this notice and the full citation on the \ufb01rst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permited. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci\ufb01c permission and\/or a fee. Request permissions from permissions@acm.org. LND4IR \u201918, Ann Arbor, Michigan, USA \u00a9 2018 Copyright held by the owner\/author(s). Publication rights licensed to ACM. .",
            "Request permissions from permissions@acm.org. LND4IR \u201918, Ann Arbor, Michigan, USA \u00a9 2018 Copyright held by the owner\/author(s). Publication rights licensed to ACM. . DOI: 1 INTRODUCTION With the steady growth in the commercial websites and social media venues, the access to users\u2019 reviews have become easier. As the amount of data that can be mined for opinion increased, commercial companies\u2019 interests for sentiment analysis increased as well. Sentiment analysis is an important part of understanding user behavior and opinions on products, places, or services. Sentiment analysis has long been studied by the research com- munity, leading to several sentiment-related resources such as senti- ment dictionaries that can be used as features for machine learning models [6, 14, 26, 27]. Tese resources help increase sentiment anal- ysis accuracies; however, they are highly dependent on language and require researchers to build such resources for every language to process. Feature engineering is a large part of the model building phase for most sentiment analysis and emotion detection models [19]. De- termining the correct set of features is a task that requires thorough investigation.",
            "Feature engineering is a large part of the model building phase for most sentiment analysis and emotion detection models [19]. De- termining the correct set of features is a task that requires thorough investigation. Furthermore, these features are mostly language and dataset dependent making it even further challenging to build models for di\ufb00erent languages. For example, the sentiment and emotion lexicons, as well as pre-trained word embeddings are not completely transferable to other languages which replicates the e\ufb00orts for every language that users would like to build sentiment classi\ufb01cation models on. For languages and tasks where the data is limited, extracting these features, building language models, train- ing word embeddings, and creating lexicons are big challenges. In addition to the feature engineering e\ufb00ort, the machine learn- ing models\u2019 parameters also need to be tuned separately for each language to get the optimal results. In this paper, we take a di\ufb00erent approach. We build a reusable sentiment analysis model that does not utilize any lexicons.",
            "In this paper, we take a di\ufb00erent approach. We build a reusable sentiment analysis model that does not utilize any lexicons. Our goal is to evaluate how well a generic model can be used to mine opinion in di\ufb00erent languages where data is more limited than the language where the generic model is trained on. To that end, we build a training set that contains reviews from di\ufb00erent domains in English (e.g., movie reviews, product reviews) and train a recurrent neural network (RNN) model to predict polarity of those reviews. Ten focusing on a domain, we make the model specialized in that domain by using the trained weights from the larger data and further training with data on a speci\ufb01c domain. To evaluate the reusability of the sentiment analysis model, we test with non- English datasets. We \ufb01rst translate the test set to English and use the pre-trained model to score polarity in the translated text. In this way, our proposed approach eliminates the need to train language- dependent models, use of sentiment lexicons and word embeddings for each language.",
            "We \ufb01rst translate the test set to English and use the pre-trained model to score polarity in the translated text. In this way, our proposed approach eliminates the need to train language- dependent models, use of sentiment lexicons and word embeddings for each language. Our experiments show that a generalizable sentiment analysis model can be utilized successfully to perform arXiv:1806.04511v1  [cs.CL]  8 Jun 2018",
            "LND4IR \u201918, July 12, 2018, Ann Arbor, Michigan, USA Ethem F. Can, Aysu Ezen-Can, and Fazli Can opinion mining for languages that do not have enough resources to train speci\ufb01c models. Te contributions of this study are; 1) a robust approach that uti- lizes machine translation to reuse a model trained on one language in other languages, 2) an RNN-based approach to eliminate feature extraction as well as resource requirements for sentiment analysis, and 3) a technique that statistically signi\ufb01cantly outperforms base- lines for multilingual sentiment analysis task when data is limited. To the best of our knowledge, this study is the \ufb01rst to apply a deep learning model to the multilingual sentiment analysis task. 2 RELATED WORK Tere is a rich body of work in sentiment analysis including so- cial media platforms such as Twiter [20] and Facebook [19]. One common factor in most of the sentiment analysis work is that features that are speci\ufb01c to sentiment analysis are extracted (e.g., sentiment lexicons) and used in di\ufb00erent machine learning models.",
            "One common factor in most of the sentiment analysis work is that features that are speci\ufb01c to sentiment analysis are extracted (e.g., sentiment lexicons) and used in di\ufb00erent machine learning models. Lexical resources [6, 19, 27] for sentiment analysis such as Senti- WordNet [2, 11], linguistic features and expressions [7], polarity dictionaries [14, 26], other features such as topic-oriented features and syntax [21], emotion tokens [10], word vectors [15], and emo- graphics [29] are some of the information that are found useful for improving sentiment analysis accuracies. Although these features are bene\ufb01cial, extracting them requires language-dependent data (e.g., a sentiment dictionary for Spanish is trained on Spanish data instead of using all data from di\ufb00erent languages). Our goal in this work is to streamline the feature engineering phase by not relying on any dictionary other than English word embeddings that are trained on any data (i.e. not necessarily senti- ment analysis corpus).",
            "Our goal in this work is to streamline the feature engineering phase by not relying on any dictionary other than English word embeddings that are trained on any data (i.e. not necessarily senti- ment analysis corpus). To that end, we utilize o\ufb00-the-shelf machine translation tools to \ufb01rst translate corpora to the language where more training data is available and use the translated corpora to do inference on. Machine translation for multilingual sentiment analysis has also seen atention from researchers. Hiroshi et al. [13] translated only sentiment units with a patern-based approach. Balahur and Turchi [5] used uni-grams, bi-grams and tf-idf features for build- ing support vector machines on translated text. Boyd-Graber and Resnik [8] built Latent Dirichlet Allocation models to investigate how multilingual concepts are clustered into topics. Mohammed et al. [17] translate Twiter posts to English as well as the English sentiment lexicons. Tellez et al. [28] propose a framework where language-dependent and independent features are used with an SVM classi\ufb01er.",
            "Mohammed et al. [17] translate Twiter posts to English as well as the English sentiment lexicons. Tellez et al. [28] propose a framework where language-dependent and independent features are used with an SVM classi\ufb01er. Tese machine learning approaches also require a feature extraction phase where we eliminate by incorporating a deep learning approach that does the feature learning intrinsically. Further, Wan [30] uses an ensemble approach where the resources (e.g., lexicons) in both the original language and the translated language are used \u2013 requiring resources to be present in both lan- guages. Brooke et al. [9] also use multiple dictionaries. In this paper, we address the resource botleneck of these translation- based approaches and propose a deep learning approach that does not require any dictionaries. Figure 1: Multilingual sentiment analysis approach. 3 METHODOLOGY In order to eliminate the need to \ufb01nd data and build separate models for each language, we propose a multilingual approach where a single model is built in the language where the largest resources are available. In this paper we focus on English as there are several sen- timent analysis datasets in English.",
            "In this paper we focus on English as there are several sen- timent analysis datasets in English. To make the English sentiment analysis model as generalizable as possible, we \ufb01rst start by training with a large dataset that has product reviews for di\ufb00erent categories. Ten, using the trained weights from the larger generic dataset, we make the model more specialized for a speci\ufb01c domain. We further train the model with domain-speci\ufb01c English reviews and use this trained model to score reviews that share the same domain from di\ufb00erent languages. To be able to employ the trained model, test sets are \ufb01rst translated to English via machine translation and then inference takes place. Figure 1 shows our multilingual sentiment analysis approach. It is important to note that this approach does not utilize any resource in any of the languages of the test sets (e.g., word embeddings, lexicons, training set). Deep learning approaches have been successful in many applica- tions ranging from computer vision to natural language processing [3].",
            "It is important to note that this approach does not utilize any resource in any of the languages of the test sets (e.g., word embeddings, lexicons, training set). Deep learning approaches have been successful in many applica- tions ranging from computer vision to natural language processing [3]. Recurrent neural network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU) are subsets of deep learning algorithms where the dependencies between tokens can be used by the model. Tese models can also be used with variable length input vectors which makes them suitable for text input. LSTM and GRU models allow operations of sequences of vectors over time and have the capability to \u2018remember\u2019 previous information [3]. RNN have been found useful for several natural language processing tasks including language modeling, text clas- si\ufb01cation, machine translation. RNN can also utilize pre-trained word embeddings (numeric vector representations of words trained on unlabeled data) without requiring hand-crafed features. Tere- fore in this paper, we employ an RNN architecture that takes text and pre-trained word embeddings as inputs and generates a clas- si\ufb01cation result.",
            "Tere- fore in this paper, we employ an RNN architecture that takes text and pre-trained word embeddings as inputs and generates a clas- si\ufb01cation result. Word embeddings represent words as numeric vectors and capture semantic information. Tey are trained in an unsupervised fashion making it useful for our task. Te sentiment analysis model that is trained on English re- views has two bidirectional layers, each with 40 neurons and a dropout [25] of 0.2 is used. Te training phase takes pre-trained word embeddings and reviews in textual format, then predicts the polarity of the reviews. For this study, an embedding length of 100 is used (i.e., each word is represented by a vector of length 100).",
            "Multilingual Sentiment Analysis: An RNN-Based Framework for Limited Data LND4IR \u201918, July 12, 2018, Ann Arbor, Michigan, USA Figure 2: Training sentiment analysis model with RNN. Dataset name # of observations Amazon reviews 9, 478, 095 Yelp restaurant reviews 8, 539 Competition restaurant reviews 68, 170 Table 1: Datasets used for training. We utilized pre-trained global vectors [22]. Te training phase is depicted in Figure 2. 4 EXPERIMENTS To evaluate the proposed approach for multilingual sentiment anal- ysis task, we conducted experiments. Tis section \ufb01rst presents the corpora used in this study followed by experimental results. Troughout our experiments, we use SAS Deep Learning Toolkit. For machine translation, Google translation API is used. 4.1 Corpora Two sets of corpora are used in this study, both are publicly avail- able. Te \ufb01rst set consists of English reviews and the second set contains restaurant reviews from four di\ufb00erent languages (Spanish, Turkish, Dutch, Russian).",
            "4.1 Corpora Two sets of corpora are used in this study, both are publicly avail- able. Te \ufb01rst set consists of English reviews and the second set contains restaurant reviews from four di\ufb00erent languages (Spanish, Turkish, Dutch, Russian). We focus on polarity detection in reviews, therefore all datasets in this study have two class values (positive, negative). 4.1.1 Training Sets. With the goal of building a generalizable sentiment analysis model, we used three di\ufb00erent training sets as provided in Table 1. One of these three datasets (Amazon re- views [12, 16]) is larger and has product reviews from several di\ufb00er- ent categories including book reviews, electronics products reviews, and application reviews. Te other two datasets are to make the model more specialized in the domain. In this paper we focus on restaurant reviews as our domain and use Yelp restaurant reviews dataset extracted from Yelp Dataset Challenge [1] and restaurant reviews dataset as part of a Kaggle competition [18]. 4.1.2 Test Sets. For evaluation of the multilingual approach, we use four languages.",
            "In this paper we focus on restaurant reviews as our domain and use Yelp restaurant reviews dataset extracted from Yelp Dataset Challenge [1] and restaurant reviews dataset as part of a Kaggle competition [18]. 4.1.2 Test Sets. For evaluation of the multilingual approach, we use four languages. Tese datasets are part of SemEval-2016 Challenge Task 5 [23, 24]. Table 2 shows the number of observations in each test corpus. Dataset name Description # of observations s r Spanish restaurant reviews 2, 045 t r Turkish restaurant reviews 932 d r Dutch restaurant reviews 1, 635 r r Russian restaurant reviews 2, 529 Table 2: Datasets used for testing. Dataset Majority Baseline Lexicon-based Baseline RNN s r 72.71 70.98 84.21 t r 56.97 61.59 74.36 d r 59.63 70.52 81.77 r r 79.60 67.81 85.61 Table 3: Accuracy results (%) for RNN-based approach com- pared with majority baseline and lexicon-based baseline.",
            "Dataset False positives False negatives s r 30.03 69.97 t r 18.83 81.17 d r 13.42 86.58 r r 35.16 64.84 Table 4: Percentage of false positives and false negatives of wrong classi\ufb01cations. 4.2 Experimental Results For experimental results, we report majority baseline for each lan- guage where the majority baseline corresponds to a model\u2019s ac- curacy if it always predicts the majority class in the dataset. For example, if the dataset has 60% of all reviews positive and 40% neg- ative, majority baseline would be 60% because a model that always predicts \u201cpositive\u201d will be 60% accurate and will make mistakes 40% of the time. In addition to the majority baseline, we also compare our results with a lexicon-based approach. We use SentiWordNet [4] to obtain a positive and a negative sentiment score for each token in a review. Ten sum of positive sentiment scores and negative sentiment scores for each review is obtained by summing up the scores for each token.",
            "We use SentiWordNet [4] to obtain a positive and a negative sentiment score for each token in a review. Ten sum of positive sentiment scores and negative sentiment scores for each review is obtained by summing up the scores for each token. If the positive sum score for a given review is greater than the negative sum score, we accept that review as a positive review. If negative sum is larger than or equal to the positive sum, the review is labeled as a negative review. RNN outperforms both baselines in all four datasets (see Table 3). Also for Spanish restaurant review, the lexicon-based baseline is below the majority baseline which shows that solely translating data and using lexicons is not su\ufb03cient to achieve good results in multilingual sentiment analysis. Among the wrong classi\ufb01cations for each test set, we calculated the percentage of false positives and false negatives. Table 4 shows the distribution of false positives and false negatives for each class. In all four classes, the number of false negatives are more than the number of false positives.",
            "Among the wrong classi\ufb01cations for each test set, we calculated the percentage of false positives and false negatives. Table 4 shows the distribution of false positives and false negatives for each class. In all four classes, the number of false negatives are more than the number of false positives. Tis can be explained by the unbalanced training dataset where the number of positive reviews are more than the number of negative reviews (59,577 vs 17,132).",
            "LND4IR \u201918, July 12, 2018, Ann Arbor, Michigan, USA Ethem F. Can, Aysu Ezen-Can, and Fazli Can Figure 3: Multiple comparisons between majority baseline, lexicon-based baseline and RNN. group1 group2 meandi\ufb00 lower upper reject lexicon majority -0.5 -14.3168 13.3168 False lexicon RNN 14.0 0.1832 27.8168 True majority RNN 14.5 0.6832 28.3168 True Table 5: Multiple comparison of means. To be able to see the di\ufb00erence between baseline and RNN, we took each method\u2019s results as a group (4 values: one for each lan- guage) and compared the means. Post hoc comparisons using the Tukey HSD test indicated that the mean accuracies for baselines (majority and lexicon-based) are signi\ufb01cantly di\ufb00erent than RNN accuracies as can be seen in Table 5 (family-wise error rate=0.06).",
            "Post hoc comparisons using the Tukey HSD test indicated that the mean accuracies for baselines (majority and lexicon-based) are signi\ufb01cantly di\ufb00erent than RNN accuracies as can be seen in Table 5 (family-wise error rate=0.06). When RNN is compared with lexicon-based baseline and majority baseline, the null hypothesis can be rejected meaning that each test is signi\ufb01cant. In addition to these comparisons, we also calculated the e\ufb00ect sizes (using Cohen\u2019s d) between the baselines and our method. Te results are aligning with Tukey HSD results such that while our method versus baselines have very large e\ufb00ect sizes, lexicon-based baseline and majority baseline have negligible e\ufb00ect size. Figure 3 shows the di\ufb00erences in minimum and maximum values of all three approaches. As the \ufb01gure shows, RNN signi\ufb01cantly outperforms both baselines for the sentiment classi\ufb01cation task. 5 DISCUSSION One of the crucial elements while using machine translation is to have highly accurate translations.",
            "As the \ufb01gure shows, RNN signi\ufb01cantly outperforms both baselines for the sentiment classi\ufb01cation task. 5 DISCUSSION One of the crucial elements while using machine translation is to have highly accurate translations. It is likely that non-English words would not have word embeddings, which will dramatically a\ufb00ect the e\ufb00ectiveness of the system. We analyzed the e\ufb00ect of incorrect translations into our approach. To that end, we extracted all wrong predictions from the test set and computed the ratio of misclassi\ufb01cations that have non-English words in them. We \ufb01rst extracted all misclassi\ufb01cations for a given language and for each observation in the misclassi\ufb01cation set, we iterated through each token to check if the token is in English. In this way, we counted the number of observations that contained at least one non-English word and divided that with the size of the misclassi\ufb01cations set. We used this ratio to investigate the e\ufb00ect of machine translation errors.",
            "In this way, we counted the number of observations that contained at least one non-English word and divided that with the size of the misclassi\ufb01cations set. We used this ratio to investigate the e\ufb00ect of machine translation errors. We found that 25.84% of Dutch, 21.76% of Turkish, 24.46% Span- ish, and 10.71% of Russian reviews that were misclassi\ufb01ed had non-English words in them. Tese non-English words might be causing the misclassi\ufb01cations. However, a large portion of the miss- classi\ufb01cations is not caused due to not-translated words. At the end, the machine translation errors has some but not noticeable e\ufb00ects on our model. Terefore, we can claim that machine translation preserves most of the information necessary for sentiment analysis. We also evaluated our model with an English corpus [23] to see its performance without any interference from machine translation errors.",
            "Terefore, we can claim that machine translation preserves most of the information necessary for sentiment analysis. We also evaluated our model with an English corpus [23] to see its performance without any interference from machine translation errors. Using the English data for testing, the model achieved 87.06% accuracy where a majority baseline was 68.37% and the lexicon-based baseline was 60.10%. Considering the improvements over the majority baseline achieved by the RNN model for both non-English (on the average 22.76% rela- tive improvement; 15.82% relative improvement on Spanish, 72.71% vs. 84.21%, 30.53% relative improvement on Turkish, 56.97% vs. 74.36%, 37.13% relative improvement on Dutch, 59.63% vs. 81.77%, and 7.55% relative improvement on Russian, 79.60% vs. 85.62%) and English test sets (27.34% relative improvement), we can draw the conclusion that our model is robust to handle multiple languages. Building separate models for each language requires both labeled and unlabeled data.",
            "85.62%) and English test sets (27.34% relative improvement), we can draw the conclusion that our model is robust to handle multiple languages. Building separate models for each language requires both labeled and unlabeled data. Even though having lots of labeled data in every language is the perfect case, it is unrealistic. Terefore, elimi- nating the resource requirement in this resource-constrained task is crucial. Te fact that machine translation can be used in reusing models from di\ufb00erent languages is promising for reducing the data requirements. 6 CONCLUSION Building e\ufb00ective machine learning models for text requires data and di\ufb00erent resources such as pre-trained word embeddings and reusable lexicons. Unfortunately, most of these resources are not entirely transferable to di\ufb00erent domains, tasks or languages. Sen- timent analysis is one such task that requires additional e\ufb00ort to transfer knowledge between languages. In this paper, we studied the research question: Can we build reusable sentiment analysis models that can be utilized for making inferences in di\ufb00erent languages without requiring separate models and resources for each language?",
            "In this paper, we studied the research question: Can we build reusable sentiment analysis models that can be utilized for making inferences in di\ufb00erent languages without requiring separate models and resources for each language? To that end, we built a recurrent neural network model in the language that had largest data avail- able. We took a general-to-speci\ufb01c model building strategy where the larger corpus that had reviews from di\ufb00erent domains was \ufb01rst used to train the RNN model and a smaller single-domain corpus of sentiment reviews was used to specialize the model on the given domain. During scoring time, we used corpora for the given domain in di\ufb00erent languages and translated them to English to be able to classify sentiments with the trained model. Experimental results showed that the proposed multilingual approach outperforms both the majority baseline and the lexicon-based baseline. In this paper we made the sentiment analysis model speci\ufb01c to a single domain. For future work, we would like to investigate the e\ufb00ectiveness of our model on di\ufb00erent review domains including hotel reviews and on di\ufb00erent problems such as detecting stance.",
            "Multilingual Sentiment Analysis: An RNN-Based Framework for Limited Data LND4IR \u201918, July 12, 2018, Ann Arbor, Michigan, USA REFERENCES [1] 2018. htps:\/\/www.yelp.com\/dataset\/challenge. (2018). htps:\/\/www.yelp.com\/ dataset\/challenge [2] Khurshid Ahmad, David Cheng, and Yousif Almas. 2006. Multi-lingual sentiment analysis of \ufb01nancial news streams. PoS (2006), 001. [3] Md Zahangir Alom, Tarek M Taha, Christopher Yakopcic, Stefan Westberg, Mahmudul Hasan, Brian C Van Esesn, Abdul A S Awwal, and Vijayan K Asari. 2018. Te History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches. arXiv preprint arXiv:1803.01164 (2018). [4] Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010.",
            "Te History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches. arXiv preprint arXiv:1803.01164 (2018). [4] Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. Sentiwordnet 3.0: an enhanced lexical resource for sentiment analysis and opinion mining.. In LREC, Vol. 10. 2200\u20132204. [5] Alexandra Balahur and Marco Turchi. 2014. Comparative experiments using supervised learning and machine translation for multilingual sentiment analysis. Computer Speech & Language 28, 1 (2014), 56\u201375. [6] Carmen Banea, Rada Mihalcea, and Janyce Wiebe. 2008. A Bootstrapping Method for Building Subjectivity Lexicons for Languages with Scarce Resources. In LREC, Vol. 8. 2\u2013764. [7] Erik Boiy and Marie-Francine Moens. 2009. A machine learning approach to sentiment analysis in multilingual Web texts.",
            "In LREC, Vol. 8. 2\u2013764. [7] Erik Boiy and Marie-Francine Moens. 2009. A machine learning approach to sentiment analysis in multilingual Web texts. Information Retrieval 12, 5 (2009), 526\u2013558. [8] Jordan Boyd-Graber and Philip Resnik. 2010. Holistic Sentiment Analysis Across Languages: Multilingual Supervised Latent Dirichlet Allocation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP \u201910). Stroudsburg, PA, USA, 45\u201355. [9] Julian Brooke, Milan To\ufb01loski, and Maite Taboada. 2009. Cross-linguistic sen- timent analysis: From English to Spanish. In Proceedings of the International Conference RANLP-2009. 50\u201354. [10] Anqi Cui, Min Zhang, Yiqun Liu, and Shaoping Ma. 2011. Emotion tokens: Bridg- ing the gap among multilingual twiter sentiment analysis.",
            "In Proceedings of the International Conference RANLP-2009. 50\u201354. [10] Anqi Cui, Min Zhang, Yiqun Liu, and Shaoping Ma. 2011. Emotion tokens: Bridg- ing the gap among multilingual twiter sentiment analysis. In Asia Information Retrieval Symposium. Springer, 238\u2013249. [11] Kerstin Denecke. 2008. Using sentiwordnet for multilingual sentiment analysis. In IEEE 24th International Conference on Data Engineering Workshop ICDEW. IEEE, 507\u2013512. [12] Ruining He and Julian McAuley. 2016. Ups and Downs: Modeling the Visual Evo- lution of Fashion Trends with One-Class Collaborative Filtering. In Proceedings of the 25th International Conference on World Wide Web (WWW \u201916). International World Wide Web Conferences Steering Commitee, Republic and Canton of Geneva, Switzerland, 507\u2013517. htps:\/\/doi.org\/10.1145\/2872427.2883037 [13] Kanayama Hiroshi, Nasukawa Tetsuya, and Watanabe Hideo.",
            "htps:\/\/doi.org\/10.1145\/2872427.2883037 [13] Kanayama Hiroshi, Nasukawa Tetsuya, and Watanabe Hideo. 2004. Deeper sentiment analysis using machine translation technology. In Proceedings of the 20th International Conference on Computational Linguistics. 494. [14] Takashi Inui and Mikio Yamamoto. 2011. Applying sentiment-oriented sentence \ufb01ltering to multilingual review classi\ufb01cation. In Proceedings of the Workshop on Sentiment Analysis where AI meets Psychology (SAAIP 2011). 51\u201358. [15] Andrew L Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, and Christopher Pots. 2011. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Lin- guistics: Human language technologies-volume 1. Association for Computational Linguistics, 142\u2013150. [16] Julian McAuley. 2018. (2018).",
            "In Proceedings of the 49th Annual Meeting of the Association for Computational Lin- guistics: Human language technologies-volume 1. Association for Computational Linguistics, 142\u2013150. [16] Julian McAuley. 2018. (2018). htp:\/\/jmcauley.ucsd.edu\/data\/amazon\/ [17] Saif M. Mohammad, Mohammad Salameh, and Svetlana Kiritchenko. 2016. How Translation Alters Sentiment. J. Artif. Int. Res. 55, 1 (Jan. 2016), 95\u2013130. htp: \/\/dl.acm.org\/citation.cfm?id=3013558.3013562 [18] Yandex School of Data Analysis at Imperial College London. 2018. (2018). htps: \/\/www.kaggle.com\/c\/restaurant-reviews\/data [19] Alvaro Ortigosa, Jos\u00b4e M Mart\u00b4\u0131n, and Rosa M Carro. 2014. Sentiment analysis in Facebook and its application to e-learning. Computers in Human Behavior 31 (2014), 527\u2013541.",
            "2014. Sentiment analysis in Facebook and its application to e-learning. Computers in Human Behavior 31 (2014), 527\u2013541. [20] Alexander Pak and Patrick Paroubek. 2010. Twiter as a corpus for sentiment analysis and opinion mining. In LREC, Vol. 10. [21] Bo Pang, Lillian Lee, et al. 2008. Opinion mining and sentiment analysis. Foun- dations and Trends in Information Retrieval 2, 1\u20132 (2008), 1\u2013135. [22] Je\ufb00rey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. In Empirical Methods in Natural Lan- guage Processing (EMNLP). 1532\u20131543.",
            "[22] Je\ufb00rey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. In Empirical Methods in Natural Lan- guage Processing (EMNLP). 1532\u20131543. htp:\/\/www.aclweb.org\/anthology\/ D14-1162 [23] Maria Pontiki, Dimitris Galanis, Haris Papageorgiou, Ion Androutsopoulos, Suresh Manandhar, AL-Smadi Mohammad, Mahmoud Al-Ayyoub, Yanyan Zhao, Bing Qin, Orph\u00b4ee De Clercq, et al. 2016. SemEval-2016 task 5: Aspect based sentiment analysis. In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval). 19\u201330. [24] SemEval. 2018. Task 5: Aspect-Based Sentiment Analysis. (2018). htp:\/\/alt.qcri.",
            "In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval). 19\u201330. [24] SemEval. 2018. Task 5: Aspect-Based Sentiment Analysis. (2018). htp:\/\/alt.qcri. org\/semeval2016\/task5\/ [25] Nitish Srivastava, Geo\ufb00rey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from over\ufb01ting. Te Journal of Machine Learning Research 15, 1 (2014), 1929\u20131958. [26] Josef Steinberger, Mohamed Ebrahim, Maud Ehrmann, Ali Hurriyetoglu, Mijail Kabadjov, Polina Lenkova, Ralf Steinberger, Hristo Tanev, Silvia V\u00b4azquez, and Vanni Zavarella. 2012. Creating sentiment dictionaries via triangulation. Decision Support Systems 53, 4 (2012), 689\u2013694.",
            "2012. Creating sentiment dictionaries via triangulation. Decision Support Systems 53, 4 (2012), 689\u2013694. [27] Maite Taboada, Julian Brooke, Milan To\ufb01loski, Kimberly Voll, and Manfred Stede. 2011. Lexicon-based methods for sentiment analysis. Computational Linguistics 37, 2 (2011), 267\u2013307. [28] Eric S Tellez, Sabino Miranda-Jim\u00b4enez, Mario Gra\ufb00, Daniela Moctezuma, Ran- yart R Su\u00b4arez, and Oscar S Siordia. 2017. A simple approach to multilingual polarity classi\ufb01cation in Twiter. Patern Recognition Leters 94 (2017), 68\u201374. [29] Svitlana Volkova, Teresa Wilson, and David Yarowsky. 2013. Exploring demo- graphic language variations to improve multilingual sentiment analysis in social media. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. 1815\u20131827. [30] Xiaojun Wan.",
            "2013. Exploring demo- graphic language variations to improve multilingual sentiment analysis in social media. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. 1815\u20131827. [30] Xiaojun Wan. 2008. Using bilingual knowledge and ensemble techniques for unsupervised Chinese sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 553\u2013561."
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-1806.04511.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 6835.000091552734,
    "avg_doclen_est": 179.86842346191406
}
