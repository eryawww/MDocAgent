{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "A Multi-cascaded Deep Model for Bilingual SMS Classi\ufb01cation Muhammad Haroon Shakeel[0000\u22120001\u22126237\u22123388], Asim Karim[0000\u22120002\u22129872\u22125020], and Imdadullah Khan[0000\u22120002\u22126955\u22126168] Department of Computer Science, Syed Babar Ali School of Science and Engineering, Lahore University of Management Sciences (LUMS), Lahore, Pakistan {15030040,akarim,imdad.khan}@lums.edu.pk Abstract. Most studies on text classi\ufb01cation are focused on the English language. However, short texts such as SMS are in\ufb02uenced by regional languages. This makes the automatic text classi\ufb01cation task challenging due to the multilingual, informal, and noisy nature of language in the text. In this work, we propose a novel multi-cascaded deep learning model called McM for bilingual SMS classi\ufb01cation. McM exploits n-gram level information as well as long-term dependencies of text for learning.",
            "In this work, we propose a novel multi-cascaded deep learning model called McM for bilingual SMS classi\ufb01cation. McM exploits n-gram level information as well as long-term dependencies of text for learning. Our approach aims to learn a model without any code-switching indication, lexical normalization, language translation, or language transliteration. The model relies entirely upon the text as no external knowledge base is utilized for learning. For this purpose, a 12 class bilingual text dataset is developed from SMS feedbacks of citizens on public services contain- ing mixed Roman Urdu and English languages. Our model achieves high accuracy for classi\ufb01cation on this dataset and outperforms the previous model for multilingual text classi\ufb01cation, highlighting language indepen- dence of McM. Keywords: Deep Learning \u00b7 Roman Urdu \u00b7 SMS Classi\ufb01cation \u00b7 Code- switching. 1 Introduction Social media such as Facebook, Twitter, and Short Text Messaging Service (SMS) are popular channels for getting feedback from consumers on products and services.",
            "Keywords: Deep Learning \u00b7 Roman Urdu \u00b7 SMS Classi\ufb01cation \u00b7 Code- switching. 1 Introduction Social media such as Facebook, Twitter, and Short Text Messaging Service (SMS) are popular channels for getting feedback from consumers on products and services. In Pakistan, with the emergence of e-government practices, SMS is being used for getting feedback from the citizens on di\ufb00erent public services with the aim to reduce petty corruption and de\ufb01cient delivery in services. Automatic classi\ufb01cation of these SMS into prede\ufb01ned categories can greatly decrease the response time on complaints and consequently improve the public services ren- dered to the citizens. While Urdu is the national language of Pakistan, English is treated as the o\ufb03cial language of the country. This leads to the development of a distinct dialect of communication known as Roman Urdu, which utilizes En- glish alphabets to write Urdu. Hence, the SMS texts contain multilingual text written in the non-native script and informal diction. The utilization of two or arXiv:1911.13066v1  [cs.CL]  29 Nov 2019",
            "2 M. H. Shakeel et al. more languages simultaneously is known as multilingualism [2]. Consequently, alternation of two languages in a single conversation, a phenomenon known as code-switching, is inevitable for a multilingual speaker [15]. Factors like informal verbiage, improper grammar, variation in spellings, code-switching, and short text length make the problem of automatic bilingual SMS classi\ufb01cation highly challenging. In Natural Language Processing (NLP), deep learning has revolutionized the modeling and understanding of human languages. The richness, expressiveness, ambiguities, and complexity of the natural language can be addressed by deep neural networks without the need to produce complex engineered features [1]. Deep learning models have been successfully used in many NLP tasks involv- ing multilingual text. A Convolutional Neural Network (CNN) based model for sentiment classi\ufb01cation of a multilingual dataset was proposed in [4]. However, a particular record in the dataset belonged to one language only. In our case, a record can have either one or two languages. There is very little published work on this speci\ufb01c setting.",
            "However, a particular record in the dataset belonged to one language only. In our case, a record can have either one or two languages. There is very little published work on this speci\ufb01c setting. One way to classify bilingual text is to normal- ize the di\ufb00erent variations of a word to a standard spelling before training the model [8]. However, such normalization requires external resources such as lexical database, and Roman Urdu is under-resourced in this context. Another approach for an under-resourced language is to adapt the resources from resource-rich lan- guage [16]. However, such an approach is not generalizable in the case of Roman Urdu text as it is an informal language with no proper grammatical rules and dictionary. More recent approach utilizes code-switching annotations to improve the predictive performance of the model, where each word is annotated with its respective language label. Such an approach is not scalable for large data as annotation task becomes tedious. In this paper, we propose a multi-cascaded deep learning network, called as McM for multi-class classi\ufb01cation of bilingual short text.",
            "Such an approach is not scalable for large data as annotation task becomes tedious. In this paper, we propose a multi-cascaded deep learning network, called as McM for multi-class classi\ufb01cation of bilingual short text. Our goal is to achieve this without any prior knowledge of the language, code-switching indication, lan- guage translation, normalizing lexical variations, or language transliteration. In multilingual text classi\ufb01cation, previous approaches employ a single deep learn- ing architecture, such as CNN or Long Short Term Memory (LSTM) for feature learning and classi\ufb01cation. McM, on the other hand, employs three cascades (aka feature learners) to learn rich textual representations from three perspectives. These representations are then forwarded to a small discriminator network for \ufb01nal prediction. We compare the performance of the proposed model with exist- ing CNN-based model for multilingual text classi\ufb01cation [4]. We report a series of experiments using 3 kinds of embedding initialization approaches as well as the e\ufb00ect of attention mechanism [14].",
            "We compare the performance of the proposed model with exist- ing CNN-based model for multilingual text classi\ufb01cation [4]. We report a series of experiments using 3 kinds of embedding initialization approaches as well as the e\ufb00ect of attention mechanism [14]. The English language is well studied under the umbrella of NLP, hence many resources and datasets for the di\ufb00erent problems are available. However, research on English-Roman Urdu bilingual text lags behind because of non-availability of gold standard datasets. Our second contribution is that we present a large scale annotated dataset in Roman Urdu and English language with code-switching, for",
            "A Multi-cascaded Deep Model for Bilingual SMS Classi\ufb01cation 3 Table 1. Description of class label along with distribution of each class (in %) in the acquired dataset Class label Description Class% Appreciation Citizen provided appreciative feedback. 43.1% Satis\ufb01ed Citizen satis\ufb01ed with the service. 31.1% Peripheral complaint Complains about peripheral service like non-availability of parking or complex- ity of the procedure. 8.2% Demanded inquiry More inquiry is required on the com- plaint. 5.7% Corruption Citizen reported bribery. 3.5% Lagged response Department responded with delay. 2.1% Unresponsive No response received by the citizen from the department. 2.0% Medicine payment Complainant was asked to buy basic medicine on his expense. 1.8% Adverse behavior Aggressive\/intolerant behavior of the sta\ufb00towards the citizen. 1.5% Resource nonexistence Department lacks necessary resources. 0.6% Grievance ascribed Malfeasance\/Abuse of powers\/o\ufb03cial misconduct\/sexual harassment to the complainant.",
            "1.5% Resource nonexistence Department lacks necessary resources. 0.6% Grievance ascribed Malfeasance\/Abuse of powers\/o\ufb03cial misconduct\/sexual harassment to the complainant. 0.3% Obnoxious\/irrelevant The SMS was irrelevant to public ser- vices. 0.2% multi-class classi\ufb01cation. The dataset consists of more than 0.3 million records and has been made available for future research. The rest of the paper is organized as follows. Section 2 de\ufb01nes the dataset acquiring process and provides an explanation of the class labels. In section 3, the architecture of the proposed model, its hyperparameters, and the experimental setup is discussed. We discuss the results in section 4 and \ufb01nally, concluding remarks are presented in section 5. . 2 Dataset Acquisition and Description The dataset consists of SMS feedbacks of the citizens of Pakistan on di\ufb00erent public services availed by them. The objective of collecting these responses is to measure the performance of government departments rendering di\ufb00erent pub- lic services. Preprocessing of the data is kept minimal.",
            "The objective of collecting these responses is to measure the performance of government departments rendering di\ufb00erent pub- lic services. Preprocessing of the data is kept minimal. All records having only single word in SMS were removed as cleaning step. To construct the \u201cgold stan- dard\u201d, 313, 813 samples are manually annotated into 12 prede\ufb01ned categories by",
            "4 M. H. Shakeel et al. Global  average  pooling Global  max  pooling Global  average  pooling Global  max  pooling Sentence Embedding Matrix Feature Learners Discriminator \ud835\udc59\u00d7 \ud835\udc51 \ud835\udc59\u00d7 300 \ud835\udc59\u00d7 300 1 \u00d7 300 1 \u00d7 600 1 \u00d7 300 1 \u00d7 12 1 \u00d7 300 1 \u00d7 150 1 \u00d7 600 1 \u00d7 12 1 \u00d7 300 1 \u00d7 150 1 \u00d7 12 1 \u00d7 300 1 \u00d7 150 1 \u00d7 12 1 \u00d7 300 1 \u00d7 150 1 \u00d7 450 Convolution LSTM Batch Normalization Dropout Fully Connected Softmax Concatenate Fig. 1. Multi-cascaded model (McM) for bilingual short text classi\ufb01cation (\ufb01gure best seen in color) two annotators in supervision of a domain-expert. Involvement of the domain- expert was to ensure the practicality and quality of the \u201cgold standard\u201d.",
            "Multi-cascaded model (McM) for bilingual short text classi\ufb01cation (\ufb01gure best seen in color) two annotators in supervision of a domain-expert. Involvement of the domain- expert was to ensure the practicality and quality of the \u201cgold standard\u201d. Finally, strati\ufb01ed sampling method was opted for splitting the data into train and test partitions with 80 \u221220 ratio (i.e., 80% records for training and 20% records for testing). This way, training split has 251, 050 records while testing split has 62, 763 records. The rationale behind strati\ufb01ed sampling was to maintain the ra- tio of every class in both splits. The preprocessed and annotated data along with train and test split is made available 1. Note that the department names and service availed by the citizens is mapped to an integer identi\ufb01er for anonymity. Class label ratios, corresponding labels, and it\u2019s description are presented in Table 1.",
            "The preprocessed and annotated data along with train and test split is made available 1. Note that the department names and service availed by the citizens is mapped to an integer identi\ufb01er for anonymity. Class label ratios, corresponding labels, and it\u2019s description are presented in Table 1. 3 Proposed Model and Experimentation The proposed model, named McM, is mainly inspired by the \ufb01ndings by Reimers, N., & Gurevych (2017) , who concluded that deeper model have minimal e\ufb00ect on the predictive performance of the model [9]. McM manifests a wider model, which employ three feature learners (cascades) that are trained for classi\ufb01cation independently (in parallel). 1 https:\/\/github.com\/haroonshakeel\/bilingual sms classi\ufb01cation",
            "A Multi-cascaded Deep Model for Bilingual SMS Classi\ufb01cation 5 The input text is \ufb01rst mapped to embedding matrix of size l \u00d7 d where l denotes the number of words in the text while d is dimensions of the embed- ding vector for each of these words. More formally, let T \u2208{w1, w2, ..., wl} be the input text with l words, embedding matrix is de\ufb01ned by X \u2208Rl\u00d7d. This representation is then fed to three feature learners, which are trained with local supervision. The learned features are then forwarded to discriminator network for \ufb01nal prediction as shown in Fig. 1. Each of these components are discussed in subsequent subsections. 3.1 Stacked-CNN Learner CNN learner is employed to learn n-gram features for identi\ufb01cation of relation- ships between words. A 1-d convolution \ufb01lter is used with a sliding window (kernel) of size k (number of n-grams) in order to extract the features. A \ufb01lter W is de\ufb01ned as W \u2208Rk\u00d7d for the convolution function.",
            "A 1-d convolution \ufb01lter is used with a sliding window (kernel) of size k (number of n-grams) in order to extract the features. A \ufb01lter W is de\ufb01ned as W \u2208Rk\u00d7d for the convolution function. The word vectors start- ing from the position j to the position j + k \u22121 are processed by the \ufb01lter W at a time. The window hj is expressed as: hj = [Xj \u2295Xj+1\u2295, ..., \u2295Xj+k\u22121] (1) Where, the \u2295represents the concatenation of word vectors. The number of \ufb01lters are usually decided empirically. Each \ufb01lter convolves with one window at a time to generate a feature map fj for that speci\ufb01c window as: fj = \u03c3(hj \u2299W + b) (2) Where, the \u2299represents convolution operation, b is a bias term, and \u03c3 is a nonlinear transformation function ReLU, which is de\ufb01ned as \u03c3(x) = max(x, 0).",
            "The feature maps of each window are concatenated across all \ufb01lters to get a high level vector representation and fed as input to next CNN layer. Output of second CNN layer is followed by (i) global max-pooling to remove low activation information from feature maps of all \ufb01lters, and (ii) global average-pooling to get average activation across all the n-grams. These two outputs are then concatenated and forwarded to a small feed- forward network having two fully-connected layers, followed by a softmax layer for prediction of this particular learner. Dropout and batch-normalization lay- ers are repeatedly used between both fully-connected layers to avoid features co-adaptation [11,3]. 3.2 Stacked-LSTM Learner The traditional methods in deep learning do not account for previous informa- tion while processing current input. LSTM, however, is able to memorize past information and correlate it with current information [13]. LSTM structure has memory cells (aka LSTM cells) that store the information selectively. Each word is treated as one time step and is fed to LSTM in a sequential manner. While processing the input at current time step Xt, LSTM also takes into account the",
            "6 M. H. Shakeel et al. previous hidden state ht\u22121. The LSTM represents each time step with an input, a memory, and an output gate, denoted as it, ft and ot respectively. The hidden state ht of input Xt for each time step t is given by: it = \u03c3(WiXt + Uiht\u22121 + bi), (3) ft = \u03c3(WfXt + Ufht\u22121 + bf), (4) ot = \u03c3(WoXt + Uoht\u22121 + bo), (5) ut = tanh(Wu + Uuht\u22121 + bu), (6) ct = it \u2217ut + ft \u2217ct\u22121, (7) ht = ot \u2217tanh(ct). (8) Where, the \u2217is element-wise multiplication and \u03c3 is sigmoid activation function. Stacked-LSTM learner is comprised of two LSTM layers. Let H1 be a matrix consisting of output vectors {h1, h2, ..., hl} that the \ufb01rst LSTM layer produced, denoting output at each time steps. This matrix is fed to second LSTM layer.",
            "Stacked-LSTM learner is comprised of two LSTM layers. Let H1 be a matrix consisting of output vectors {h1, h2, ..., hl} that the \ufb01rst LSTM layer produced, denoting output at each time steps. This matrix is fed to second LSTM layer. Similarly, second layer produces another output matrix H2 which is used to ap- ply global max-pooling and global-average pooling. These two outputs are con- catenated and forwarded to a two layered feedforward network for intermediate supervision (prediction), identical to previously described stacked-CNN learner. 3.3 LSTM Learner LSTM learner is employed to learn long-term dependencies of the text as de- scribed in [13]. This learner encodes complete input text recursively. It takes one word vector at a time as input and outputs a single vector. The dimensions of the output vector are equal to the number of LSTM units deployed. This encoded text representation is then forwarded to a small feedforward network, identical to aforementioned two learners, for intermediate supervision in order to learn features.",
            "It takes one word vector at a time as input and outputs a single vector. The dimensions of the output vector are equal to the number of LSTM units deployed. This encoded text representation is then forwarded to a small feedforward network, identical to aforementioned two learners, for intermediate supervision in order to learn features. This learner di\ufb00ers from stacked-LSTM learner as it learns sentence features, and not average and max features of all time steps (input words). 3.4 Discriminator Network The objective of discriminator network is to aggregate features learned by each of above described three learners and squash them into a small network for \ufb01nal prediction. The discriminator employs two fully-connected layers with batch- normalization and dropout layer along with ReLU activation function for non- linearity. The softmax activation function with categorical cross-entropy loss is used on the \ufb01nal prediction layer to get probabilities of each class. The class label is assigned based on maximum probability. This is treated as \ufb01nal prediction of the proposed model. The complete architecture, along with dimensions of each output is shown in Fig. 1.",
            "A Multi-cascaded Deep Model for Bilingual SMS Classi\ufb01cation 7 3.5 Experimental Setup Pre-trained word embeddings on massive data, such as GloVe [6], give boost to predictive performance for multi-class classi\ufb01cation [12]. However, such embed- dings are limited to English language only with no equivalence for Roman Urdu. Therefore, in this study, we avoid using any word-based pre-trained embeddings to give equal treatment to words of each language. We perform three kinds of experiments. (1) Embedding matrix is constructed using ELMo embeddings [7], which utilizes characters to form word vectors and produces a word vector with d = 1024. We call this variation of the model McME. (2) Embedding matrix is initialized randomly for each word with word vector of size d = 300. We refer this particular model as McMR. (3) We train domain speci\ufb01c embeddings2 using word2vec with word vector of size d = 300 as suggested in original study [5]. We refer to this particular model as McMD.",
            "We refer this particular model as McMR. (3) We train domain speci\ufb01c embeddings2 using word2vec with word vector of size d = 300 as suggested in original study [5]. We refer to this particular model as McMD. Furthermore, we also introduce soft-attention [14] between two layers of CNN and LSTM (in respective feature learner) to evaluate e\ufb00ect of attention on bilin- gual text classi\ufb01cation. Attention mechanism \u201chighlights\u201d (assigns more weight) a particular word that contributes more towards correct classi\ufb01cation. We re- fer to attention based experiments with subscript A for all three embedding initializations. This way, a total of 6 experiments are performed with di\ufb00erent variations of the proposed model. To mitigate e\ufb00ect of random initialization of network weights, we \ufb01x the random seed across all experiments. We train each model for 20 epochs and create a checkpoint at epoch with best predictive performance on test split. We re-implement the model proposed in [4], and use it as a baseline for our problem.",
            "We train each model for 20 epochs and create a checkpoint at epoch with best predictive performance on test split. We re-implement the model proposed in [4], and use it as a baseline for our problem. The rationale behind choosing this particular model as a baseline is it\u2019s proven good predictive performance on multilingual text classi\ufb01cation. For McM, the choices of number of convolutional \ufb01lters, number of hidden units in \ufb01rst dense layer, number of hidden units in second dense layer, and recurrent units for LSTM are made empirically. Rest of the hyperparameters were selected by performing grid search using 20% strati\ufb01ed validation set from training set on McMR. Available choices and \ufb01nal selected parameters are mentioned in Table 2. These choices remained same for all experiments and the validation set was merged back into training set. Table 2.",
            "Available choices and \ufb01nal selected parameters are mentioned in Table 2. These choices remained same for all experiments and the validation set was merged back into training set. Table 2. Hyperparameter tuning, the selection range, and \ufb01nal choice Hyperparameter Possible Values Chosen Value First CNN layer kernel size (k) 1, 2, 3, 4, 5 1 Second CNN layer kernel size (k) 1, 2, 3, 4, 5 2 Dropout rate 0.1, 0.2, 0.3, 0.4, 0.5 0.2 Optimizer Adam, Adadelta, SGD Adam Learning rate 0.001, 0.002, 0.003, 0.004, 0.005 0.002 2 These embeddings are also made available along with dataset.",
            "8 M. H. Shakeel et al. 3.6 Evaluation Metrics We employed the standard metrics that are widely adapted in the literature for measuring multi-class classi\ufb01cation performance. These metrics are accuracy, precision, recall, and F1-score, where latter three can be computed using micro- average or macro-average strategies [10]. In micro-average strategy, each instance holds equal weight and outcomes are aggregated across all classes to compute a particular metric. This essentially means that the outcome would be in\ufb02uenced by the frequent class, if class distribution is skewed. In macro-average however, metrics for each class are calculated separately and then averaged, irrespective of their class label occurrence ratio. This gives each class equal weight instead of each instance, consequently favoring the under-represented classes. In our particular dataset, it is more plausible to favor smaller classes (i.e., other than \u201cAppreciation\u201d and \u201cSatis\ufb01ed\u201d) to detect potential complaints. There- fore, we choose to report macro-average values for precision, recall, and F1-score which are de\ufb01ned by (9), (10), and (11) respectively.",
            "There- fore, we choose to report macro-average values for precision, recall, and F1-score which are de\ufb01ned by (9), (10), and (11) respectively. Precision = PC i=1 T Pi T Pi+F Pi C , (9) Recall = PC i=1 T Pi T Pi+F Ni C , (10) F1 \u2212score = PC i=1 2\u00d7P recisioni\u00d7Recalli P recisioni+Recalli C . (11) 4 Results and Discussion Before evaluating the McM, we \ufb01rst tested the baseline model on our dataset. Table 3 presents results of baseline and all variations of our experiments. We focus our discussion on F1-score as accuracy is often misleading for dataset with unbalanced class distribution. However, for completeness sake, all measures are reported. It is observed from the results that baseline model performs worst among all the experiments. The reason behind this degradation in performance can be traced back to the nature of the texts in the datasets (i.e., datasets used in orig- inal paper of baseline model [4] and in our study).",
            "It is observed from the results that baseline model performs worst among all the experiments. The reason behind this degradation in performance can be traced back to the nature of the texts in the datasets (i.e., datasets used in orig- inal paper of baseline model [4] and in our study). The approach in base model measure the performance of the model on multilingual dataset in which there is no code-switching involved. The complete text belongs to either one language or the other. However, in our case, the SMS text can have code-switching between two language, variation of spelling, or non-standard grammar. Baseline model is simple 1 layered CNN model that is unable to tackle such challenges. On the other hand, McM learns the features from multiple perspectives, hence fea- ture representations are richer, which consequently leads to a superior predictive performance. As every learner in McM is also supervised, all 4 components of the proposed model (i.e., stacked-CNN learner, stacked-LSTM learner, LSTM- learner, and discriminator) can also be compared with each other.",
            "A Multi-cascaded Deep Model for Bilingual SMS Classi\ufb01cation 9 Table 3. Performance evaluation of variations of the proposed model and baseline. Showing highest scores in boldface. Model Component Accuracy Precision Recall F1-score Baseline [4] - 0.68 0.52 0.37 0.39 McME Stacked-CNN Learner 0.83 0.66 0.62 0.63 Stacked-LSTM Learner 0.84 0.70 0.60 0.64 LSTM Learner 0.80 0.69 0.48 0.51 Discriminator 0.84 0.68 0.63 0.66 McMEA Stacked-CNN Learner 0.82 0.65 0.57 0.60 Stacked-LSTM Learner 0.82 0.65 0.57 0.60 LSTM Learner 0.80 0.62 0.49 0.51 Discriminator 0.83 0.66 0.60 0.62 McMR Stacked-CNN Learner 0.82 0.",
            "65 0.57 0.60 LSTM Learner 0.80 0.62 0.49 0.51 Discriminator 0.83 0.66 0.60 0.62 McMR Stacked-CNN Learner 0.82 0.66 0.59 0.62 Stacked-LSTM Learner 0.82 0.66 0.58 0.61 LSTM Learner 0.81 0.62 0.59 0.59 Discriminator 0.83 0.64 0.61 0.62 McMRA Stacked-CNN Learner 0.80 0.65 0.52 0.53 Stacked-LSTM Learner 0.81 0.65 0.55 0.58 LSTM Learner 0.81 0.64 0.55 0.58 Discriminator 0.81 0.64 0.58 0.59 McMD Stacked-CNN Learner 0.84 0.71 0.63 0.66 Stacked-LSTM Learner 0.85 0.71 0.",
            "55 0.58 Discriminator 0.81 0.64 0.58 0.59 McMD Stacked-CNN Learner 0.84 0.71 0.63 0.66 Stacked-LSTM Learner 0.85 0.71 0.67 0.69 LSTM Learner 0.83 0.68 0.60 0.63 Discriminator 0.86 0.72 0.68 0.69 McMDA Stacked-CNN Learner 0.82 0.66 0.59 0.62 Stacked-LSTM Learner 0.84 0.69 0.64 0.66 LSTM Learner 0.83 0.67 0.61 0.63 Discriminator 0.85 0.70 0.66 0.67 In our experiments, the best performing variation of the proposed model is McMD. On this particular setting, discriminator is able to achieve an F1-score of 0.69 with precision and recall values of 0.72 and 0.68 respectively.",
            "70 0.66 0.67 In our experiments, the best performing variation of the proposed model is McMD. On this particular setting, discriminator is able to achieve an F1-score of 0.69 with precision and recall values of 0.72 and 0.68 respectively. Other com- ponents of McM also show the highest stats for all performance measures. How- ever, for McMDA, a signi\ufb01cant reduction in performance is observed, although, attention-based models have been proven to show improvement in performance [14]. Investigating the reason behind this drop in performance is beyond the scope of this study. The model variations trained on ELMo embedding have sec- ond highest performance. Discriminator of McME achieves an F1-score of 0.66, beating other learners in this experiment. However, reduction in performance is persistent when attention is used for McMEA. Regarding the experiments with random embedding initialization, McMR shows similar performance to McMEA, while McMRA performs the worst. It is worth noting that in each experiment, discriminator network stays on top or",
            "10 M. H. Shakeel et al. 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Epoch 0.5 0.6 0.7 0.8 0.9 1.0 Error Discriminator Stacked-CNN Stacked-LSTM LSTM 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Epoch 0.5 0.6 0.7 0.8 0.9 1.0 Error Discriminator Stacked-CNN Stacked-LSTM LSTM (a) McME (b) McMEA 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Epoch 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.",
            "5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 Error Discriminator Stacked-CNN Stacked-LSTM LSTM 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Epoch 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 Error Discriminator Stacked-CNN Stacked-LSTM LSTM (c) McMR (d) McMRA 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Epoch 0.45 0.55 0.65 0.",
            "45 0.55 0.65 0.75 Error Discriminator Stacked-CNN Stacked-LSTM LSTM 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Epoch 0.45 0.55 0.65 0.75 Error Discriminator Stacked-CNN Stacked-LSTM LSTM (e) McMD (f) McMDA Fig. 2. Test error for all three feature learners and discriminator network over the epochs for all 4 variations of the model, showing lowest error for domain speci\ufb01c em- beddings while highest for random embedding initialization. performs equally as compared to other components in terms of F1-score. This is indication that discriminator network is able to learn richer representations of text as compared to methods where only single feature learner is deployed. Furthermore, the results for testing error for each component (i.e., 3 learners and a discriminator network) for all 4 variations of the proposed model are pre- sented in Fig. 2. It is evident that the least error across all components is achieved",
            "A Multi-cascaded Deep Model for Bilingual SMS Classi\ufb01cation 11 by McMD model. Turning now to individual component performance, in ELMo embeddings based two models, lowest error is achieved by discriminator net- work, closely followed by stacked LSTM learner and stacked-CNN learner, while LSTM learner has the highest error. As far as model variations with random embeddings initializations are concerned, most interesting results are observed. As shown in subplot (c) and (d) in Fig. 2, McMR and McMRA tend to over\ufb01t. After second epoch, the error rate for all components of these two variations tend to increase drastically. However, it shows minimum error for discriminator in both variations, again proving that the features learned through multiple cas- cades are more robust and hold greater discriminative power. Note that in all 6 variations of experiments, the error of discriminator network is the lowest as compared to other components of McM. Hence it can be deduced that learning features through multiple perspectives and aggregating them for \ufb01nal prediction is more fruitful as compared to single method of learning.",
            "Note that in all 6 variations of experiments, the error of discriminator network is the lowest as compared to other components of McM. Hence it can be deduced that learning features through multiple perspectives and aggregating them for \ufb01nal prediction is more fruitful as compared to single method of learning. 5 Concluding Remarks In this work, a new large-scale dataset and a novel deep learning architecture for multi-class classi\ufb01cation of bilingual (English-Roman Urdu) text with code- switching is presented. The dataset is intended for enhancement of petty cor- ruption detection in public o\ufb03ces and provides grounds for future research in this direction. While deep learning architecture is proposed for multi-class clas- si\ufb01cation of bilingual SMS without utilizing any external resource. Three word embedding initialization techniques and soft-attention mechanism is also investi- gated.",
            "While deep learning architecture is proposed for multi-class clas- si\ufb01cation of bilingual SMS without utilizing any external resource. Three word embedding initialization techniques and soft-attention mechanism is also investi- gated. The observations from extensive experimentation led us to conclude that: (1) word embeddings vectors generated through characters tend to favor bilin- gual text classi\ufb01cation as compared to random embedding initialization, (2) the attention mechanism tend to decrease the predictive performance of the model, irrespective of embedding types used, (3) using features learned through single perspective yield poor performance for bilingual text with code-switching, (4) training domain speci\ufb01c embeddings on a large corpus and using them to train the model achieves the highest performance. With regards to future work, we intend to investigate the reason behind degradation of model performance with soft-attention. References 1. Denecke, K.: Using sentiwordnet for multilingual sentiment analysis. In: Interna- tional Conference on Data Engineering Workshop. pp. 507\u2013512 (2008) 2.",
            "References 1. Denecke, K.: Using sentiwordnet for multilingual sentiment analysis. In: Interna- tional Conference on Data Engineering Workshop. pp. 507\u2013512 (2008) 2. Fatima, M., Anwar, S., Naveed, A., Arshad, W., Nawab, R.M.A., Iqbal, M., Ma- sood, A.: Multilingual sms-based author pro\ufb01ling: Data and methods. Natural Language Engineering, (NLE) 24(5), 695\u2013724 (2018) 3. Io\ufb00e, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift. In: International Conference on Machine Learning (ICML). pp. 448\u2013456 (2015)",
            "12 M. H. Shakeel et al. 4. Medrouk, L., Pappa, A.: Deep learning model for sentiment analysis in multi- lingual corpus. In: International Conference on Neural Information Processing (ICONIP). pp. 205\u2013212 (2017) 5. Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J.: Distributed repre- sentations of words and phrases and their compositionality. In: Advances in Neural Information Processing Systems (NIPS). pp. 3111\u20133119 (2013) 6. Pennington, J., Socher, R., Manning, C.: Glove: Global vectors for word repre- sentation. In: Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 1532\u20131543 (2014) 7. Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., Zettlemoyer, L.: Deep contextualized word representations.",
            "pp. 1532\u20131543 (2014) 7. Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., Zettlemoyer, L.: Deep contextualized word representations. In: Conference of the North Ameri- can Chapter of the Association for Computational Linguistics (ACACL): Human Language Technologies, Volume 1 (Long Papers). pp. 2227\u20132237 (2018) 8. Rafae, A., Qayyum, A., Moeenuddin, M., Karim, A., Sajjad, H., Kamiran, F.: An unsupervised method for discovering lexical variations in roman urdu informal text. In: Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 823\u2013828 (2015) 9. Reimers, N., Gurevych, I.: Reporting score distributions makes a di\ufb00erence: Per- formance study of lstm-networks for sequence tagging. In: Conference on Empirical Methods in Natural Language Processing (EMNLP). pp.",
            "Reimers, N., Gurevych, I.: Reporting score distributions makes a di\ufb00erence: Per- formance study of lstm-networks for sequence tagging. In: Conference on Empirical Methods in Natural Language Processing (EMNLP). pp. 338\u2013348 (2017) 10. Sokolova, M., Lapalme, G.: A systematic analysis of performance measures for classi\ufb01cation tasks. Information Processing & Management, (IPM) 45(4), 427\u2013437 (2009) 11. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.: Dropout: a simple way to prevent neural networks from over\ufb01tting. The Journal of Machine Learning Research, (JMLR) 15(1), 1929\u20131958 (2014) 12. Subramani, S., Michalska, S., Wang, H., Du, J., Zhang, Y., Shakeel, H.: Deep learning for multi-class identi\ufb01cation from domestic violence online posts.",
            "Subramani, S., Michalska, S., Wang, H., Du, J., Zhang, Y., Shakeel, H.: Deep learning for multi-class identi\ufb01cation from domestic violence online posts. IEEE Access 7, 46210\u201346224 (2019) 13. Wang, X., Jiang, W., Luo, Z.: Combination of convolutional and recurrent neu- ral network for sentiment analysis of short texts. In: International Conference on Computational Linguistics (COLING): Technical Papers. pp. 2428\u20132437 (2016) 14. Wang, Z., Zhang, Y., Lee, S., Li, S., Zhou, G.: A bilingual attention network for code-switched emotion prediction. In: International Conference on Computational Linguistics (COLING): Technical Papers. pp. 1624\u20131634 (2016) 15. Williams, A., Srinivasan, M., Liu, C., Lee, P., Zhou, Q.: Why do bilinguals code- switch when emotional? insights from immigrant parent-child interactions. Emo- tion (Washington, DC) (2019) 16.",
            "Williams, A., Srinivasan, M., Liu, C., Lee, P., Zhou, Q.: Why do bilinguals code- switch when emotional? insights from immigrant parent-child interactions. Emo- tion (Washington, DC) (2019) 16. Zhou, X., Wan, X., Xiao, J.: Attention-based lstm network for cross-lingual sen- timent classi\ufb01cation. In: Conference on Empirical Methods in Natural Language Processing, (EMNLP). pp. 247\u2013256 (2016)"
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-1911.13066.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 7499.000152587891,
    "avg_doclen_est": 178.54762268066406
}
