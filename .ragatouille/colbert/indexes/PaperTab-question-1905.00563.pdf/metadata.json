{
  "config":{
    "query_token_id":"[unused0]",
    "doc_token_id":"[unused1]",
    "query_token":"[Q]",
    "doc_token":"[D]",
    "ncells":null,
    "centroid_score_threshold":null,
    "ndocs":null,
    "load_index_with_mmap":false,
    "index_path":null,
    "index_bsize":32,
    "nbits":4,
    "kmeans_niters":20,
    "resume":false,
    "pool_factor":1,
    "clustering_mode":"hierarchical",
    "protected_tokens":0,
    "similarity":"cosine",
    "bsize":64,
    "accumsteps":1,
    "lr":0.00001,
    "maxsteps":400000,
    "save_every":null,
    "warmup":20000,
    "warmup_bert":null,
    "relu":false,
    "nway":64,
    "use_ib_negatives":true,
    "reranker":false,
    "distillation_alpha":1.0,
    "ignore_scores":false,
    "model_name":null,
    "query_maxlen":32,
    "attend_to_mask_tokens":false,
    "interaction":"colbert",
    "dim":128,
    "doc_maxlen":256,
    "mask_punctuation":true,
    "checkpoint":"colbert-ir/colbertv2.0",
    "triples":"/future/u/okhattab/root/unit/experiments/2021.10/downstream.distillation.round2.2_score/round2.nway6.cosine.ib/examples.64.json",
    "collection":[
      "Investigating Robustness and Interpretability of Link Prediction via Adversarial Modi\ufb01cations Pouya Pezeshkpour University of California Irvine, CA pezeshkp@uci.edu Yifan Tian University of California Irvine, CA yifant@uci.edu Sameer Singh University of California Irvine, CA sameer@uci.edu Abstract Representing entities and relations in an em- bedding space is a well-studied approach for machine learning on relational data. Existing approaches, however, primarily focus on im- proving accuracy and overlook other aspects such as robustness and interpretability. In this paper, we propose adversarial modi\ufb01ca- tions for link prediction models: identifying the fact to add into or remove from the knowl- edge graph that changes the prediction for a target fact after the model is retrained. Us- ing these single modi\ufb01cations of the graph, we identify the most in\ufb02uential fact for a pre- dicted link and evaluate the sensitivity of the model to the addition of fake facts.",
      "Us- ing these single modi\ufb01cations of the graph, we identify the most in\ufb02uential fact for a pre- dicted link and evaluate the sensitivity of the model to the addition of fake facts. We in- troduce an ef\ufb01cient approach to estimate the effect of such modi\ufb01cations by approximating the change in the embeddings when the knowl- edge graph changes. To avoid the combinato- rial search over all possible facts, we train a network to decode embeddings to their corre- sponding graph components, allowing the use of gradient-based optimization to identify the adversarial modi\ufb01cation. We use these tech- niques to evaluate the robustness of link predic- tion models (by measuring sensitivity to addi- tional facts), study interpretability through the facts most responsible for predictions (by iden- tifying the most in\ufb02uential neighbors), and de- tect incorrect facts in the knowledge base. 1 Introduction Knowledge graphs (KG) play a critical role in many real-world applications such as search, structured data management, recommendations, and question answering.",
      "1 Introduction Knowledge graphs (KG) play a critical role in many real-world applications such as search, structured data management, recommendations, and question answering. Since KGs often suffer from incom- pleteness and noise in their facts (links), a number of recent techniques have proposed models that em- bed each entity and relation into a vector space, and use these embeddings to predict facts. These dense representation models for link prediction include tensor factorization [Nickel et al., 2011, Socher et al., 2013, Yang et al., 2015], algebraic opera- tions [Bordes et al., 2011, 2013b, Dasgupta et al., 2018], multiple embeddings [Wang et al., 2014, Lin et al., 2015, Ji et al., 2015, Zhang et al., 2018], and complex neural models [Dettmers et al., 2018, Nguyen et al., 2018]. However, there are only a few studies [Kadlec et al., 2017, Sharma et al., 2018] that investigate the quality of the different KG mod- els.",
      "However, there are only a few studies [Kadlec et al., 2017, Sharma et al., 2018] that investigate the quality of the different KG mod- els. There is a need to go beyond just the accuracy on link prediction, and instead focus on whether these representations are robust and stable, and what facts they make use of for their predictions. In this paper, our goal is to design approaches that minimally change the graph structure such that the prediction of a target fact changes the most after the embeddings are relearned, which we collectively call Completion Robustness and Inter- pretability via Adversarial Graph Edits (CRIAGE). First, we consider perturbations that remove a neighboring link for the target fact, thus identi- fying the most in\ufb02uential related fact, providing an explanation for the model\u2019s prediction. As an exam- ple, consider the excerpt from a KG in Figure 1a with two observed facts, and a target predicted fact that Princes Henriette is the parent of Violante Bavaria.",
      "As an exam- ple, consider the excerpt from a KG in Figure 1a with two observed facts, and a target predicted fact that Princes Henriette is the parent of Violante Bavaria. Our proposed graph perturbation, shown in Figure 1b, identi\ufb01es the existing fact that Fer- dinal Maria is the father of Violante Bavaria as the one when removed and model retrained, will change the prediction of Princes Henriette\u2019s child. We also study attacks that add a new, fake fact into the KG to evaluate the robustness and sensitivity of link prediction models to small additions to the graph. An example attack for the original graph in Figure 1a, is depicted in Figure 1c. Such pertur- bations to the the training data are from a family of adversarial modi\ufb01cations that have been applied to other machine learning tasks, known as poison- ing [Biggio et al., 2012, Corona et al., 2013, Biggio arXiv:1905.00563v1  [cs.LG]  2 May 2019",
      "Ferdinand Maria Princess Henriette Violante Bavaria isMarried hasChild hasChild target prediction \u27e8s, r, o\u27e9 (a) KG, with the target prediction Ferdinand Maria Princess Henriette Violante Bavaria A.S.D. Astrea isMarried hasChild \u27e8s\u2032, r\u2032, o\u27e9 removed hasChild (b) After removing a fact Ferdinand Maria Princess Henriette Violante Bavaria New York Al Jazira Club isMarried hasChild playsFor \u27e8s\u2032, r\u2032, o\u27e9 added hasChild (c) After adding a fact Figure 1: Completion Robustness and Interpretability via Adversarial Graph Edits (CRIAGE): Change in the graph structure that changes the prediction of the retrained model, where (a) is the original sub-graph of the KG, (b) removes a neighboring link of the target, resulting in a change in the prediction, and (c) shows the effect of adding an attack triple on the target. These modi\ufb01cations were identi\ufb01ed by our proposed approach. et al., 2014, Z\u00fcgner et al., 2018].",
      "These modi\ufb01cations were identi\ufb01ed by our proposed approach. et al., 2014, Z\u00fcgner et al., 2018]. Since the setting is quite different from tradi- tional adversarial attacks, search for link prediction adversaries brings up unique challenges. To \ufb01nd these minimal changes for a target link, we need to identify the fact that, when added into or removed from the graph, will have the biggest impact on the predicted score of the target fact. Unfortunately, computing this change in the score is expensive since it involves retraining the model to recompute the embeddings. We propose an ef\ufb01cient estimate of this score change by approximating the change in the embeddings using Taylor expansion. The other challenge in identifying adversarial modi\ufb01- cations for link prediction, especially when con- sidering addition of fake facts, is the combinato- rial search space over possible facts, which is in- tractable to enumerate. We introduce an inverter of the original embedding model, to decode the em- beddings to their corresponding graph components, making the search of facts tractable by performing ef\ufb01cient gradient-based continuous optimization.",
      "We introduce an inverter of the original embedding model, to decode the em- beddings to their corresponding graph components, making the search of facts tractable by performing ef\ufb01cient gradient-based continuous optimization. We evaluate our proposed methods through fol- lowing experiments. First, on relatively small KGs, we show that our approximations are accurate com- pared to the true change in the score. Second, we show that our additive attacks can effectively reduce the performance of state of the art mod- els [Yang et al., 2015, Dettmers et al., 2018] up to 27.3% and 50.7% in Hits@1 for two large KGs: WN18 and YAGO3-10. We also explore the util- ity of adversarial modi\ufb01cations in explaining the model predictions by presenting rule-like descrip- tions of the most in\ufb02uential neighbors. Finally, we use adversaries to detect errors in the KG, obtaining up to 55% accuracy in detecting errors.",
      "Finally, we use adversaries to detect errors in the KG, obtaining up to 55% accuracy in detecting errors. 2 Background and Notation In this section, we brie\ufb02y introduce some notations, and existing relational embedding approaches that model knowledge graph completion using dense vectors. In KGs, facts are represented using triples of subject, relation, and object, \u27e8s, r, o\u27e9, where s, o \u2208\u03be, the set of entities, and r \u2208R, the set of relations. To model the KG, a scoring function \u03c8 : \u03be \u00d7 R \u00d7 \u03be \u2192R is learned to evaluate whether any given fact is true. In this work, we focus on multiplicative models of link prediction1, speci\ufb01- cally DistMult [Yang et al., 2015] because of its simplicity and popularity, and ConvE [Dettmers et al., 2018] because of its high accuracy. We can represent the scoring function of such methods as \u03c8(s, r, o) = f(es, er) \u00b7 eo, where es, er, eo \u2208Rd are embeddings of the subject, relation, and object respectively.",
      "We can represent the scoring function of such methods as \u03c8(s, r, o) = f(es, er) \u00b7 eo, where es, er, eo \u2208Rd are embeddings of the subject, relation, and object respectively. In DistMult, f(es, er) = es \u2299er, where \u2299is element-wise multiplication operator. Similarly, in ConvE, f(es, er) is computed by a convolution on the concatenation of es and er. We use the same setup as Dettmers et al. [2018] for training, i.e., incorporate binary cross-entropy loss over the triple scores. In particular, for subject- relation pairs (s, r) in the training data G, we use binary ys,r o to represent negative and positive facts. Using the model\u2019s probability of truth as \u03c3(\u03c8(s, r, o)) for \u27e8s, r, o\u27e9, the loss is de\ufb01ned as: L(G) = X (s,r) X o ys,r o log(\u03c3(\u03c8(s, r, o))) + (1 \u2212ys,r o ) log(1 \u2212\u03c3(\u03c8(s, r, o))).",
      "(1) Gradient descent is used to learn the embeddings es, er, eo, and the parameters of f, if any. 1As opposed to additive models, such as TransE [Bordes et al., 2013a], as categorized in Sharma et al. [2018].",
      "3 Completion Robustness and Interpretability via Adversarial Graph Edits (CRIAGE) For adversarial modi\ufb01cations on KGs, we \ufb01rst de- \ufb01ne the space of possible modi\ufb01cations. For a tar- get triple \u27e8s, r, o\u27e9, we constrain the possible triples that we can remove (or inject) to be in the form of \u27e8s\u2032, r\u2032, o\u27e9i.e s\u2032 and r\u2032 may be different from the target, but the object is not. We analyze other forms of modi\ufb01cations such as \u27e8s, r\u2032, o\u2032\u27e9and \u27e8s, r\u2032, o\u27e9in appendices A.1 and A.2, and leave empirical evalu- ation of these modi\ufb01cations for future work. 3.1 Removing a fact (CRIAGE-Remove) For explaining a target prediction, we are inter- ested in identifying the observed fact that has the most in\ufb02uence (according to the model) on the pre- diction.",
      "3.1 Removing a fact (CRIAGE-Remove) For explaining a target prediction, we are inter- ested in identifying the observed fact that has the most in\ufb02uence (according to the model) on the pre- diction. We de\ufb01ne in\ufb02uence of an observed fact on the prediction as the change in the prediction score if the observed fact was not present when the embeddings were learned. Previous work have used this concept of in\ufb02uence similarly for sev- eral different tasks [Kononenko et al., 2010, Koh and Liang, 2017]. Formally, for the target triple \u27e8s, r, o\u27e9and observed graph G, we want to identify a neighboring triple \u27e8s\u2032, r\u2032, o\u27e9\u2208G such that the score \u03c8(s, r, o) when trained on G and the score \u03c8(s, r, o) when trained on G\u2212{\u27e8s\u2032, r\u2032, o\u27e9} are max- imally different, i.e.",
      "argmax (s\u2032,r\u2032)\u2208Nei(o) \u2206(s\u2032,r\u2032)(s, r, o) (2) where \u2206(s\u2032,r\u2032)(s, r, o) = \u03c8(s, r, o)\u2212\u03c8(s, r, o), and Nei(o) = {(s\u2032, r\u2032)|\u27e8s\u2032, r\u2032, o\u27e9\u2208G}. 3.2 Adding a new fact (CRIAGE-Add) We are also interested in investigating the robust- ness of models, i.e., how sensitive are the predic- tions to small additions to the knowledge graph. Speci\ufb01cally, for a target prediction \u27e8s, r, o\u27e9, we are interested in identifying a single fake fact \u27e8s\u2032, r\u2032, o\u27e9that, when added to the knowledge graph G, changes the prediction score \u03c8(s, r, o) the most.",
      "Speci\ufb01cally, for a target prediction \u27e8s, r, o\u27e9, we are interested in identifying a single fake fact \u27e8s\u2032, r\u2032, o\u27e9that, when added to the knowledge graph G, changes the prediction score \u03c8(s, r, o) the most. Using \u03c8(s, r, o) as the score after training on G \u222a{\u27e8s\u2032, r\u2032, o\u27e9}, we de\ufb01ne the adversary as: argmax (s\u2032,r\u2032) \u2206(s\u2032,r\u2032)(s, r, o) (3) where \u2206(s\u2032,r\u2032)(s, r, o) = \u03c8(s, r, o) \u2212\u03c8(s, r, o). The search here is over any possible s\u2032 \u2208\u03be, which is often in the millions for most real-world KGs, and r\u2032 \u2208R.",
      "The search here is over any possible s\u2032 \u2208\u03be, which is often in the millions for most real-world KGs, and r\u2032 \u2208R. We also identify adversaries that increase the prediction score for speci\ufb01c false triple, i.e., for a target fake fact \u27e8s, r, o\u27e9, the ad- versary is argmax(s\u2032,r\u2032) \u2212\u2206(s\u2032,r\u2032)(s, r, o), where \u2206(s\u2032,r\u2032)(s, r, o) is de\ufb01ned as before. 3.3 Challenges There are a number of crucial challenges when con- ducting such adversarial attack on KGs. First, eval- uating the effect of changing the KG on the score of the target fact (\u03c8(s, r, o)) is expensive since we need to update the embeddings by retraining the model on the new graph; a very time-consuming process that is at least linear in the size of G. Sec- ond, since there are many candidate facts that can be added to the knowledge graph, identifying the most promising adversary through search-based methods is also expensive.",
      "Speci\ufb01cally, the search size for unobserved facts is |\u03be|\u00d7|R|, which, for ex- ample in YAGO3-10 KG, can be as many as 4.5M possible facts for a single target prediction. 4 Ef\ufb01ciently Identifying the Modi\ufb01cation In this section, we propose algorithms to address mentioned challenges by (1) approximating the ef- fect of changing the graph on a target prediction, and (2) using continuous optimization for the dis- crete search over potential modi\ufb01cations. 4.1 First-order Approximation of In\ufb02uence We \ufb01rst study the addition of a fact to the graph, and then extend it to cover removal as well. To capture the effect of an adversarial modi\ufb01- cation on the score of a target triple, we need to study the effect of the change on the vector representations of the target triple.",
      "To capture the effect of an adversarial modi\ufb01- cation on the score of a target triple, we need to study the effect of the change on the vector representations of the target triple. We use es, er, and eo to denote the embeddings of s, r, o at the solution of argmin L(G), and when con- sidering the adversarial triple \u27e8s\u2032, r\u2032, o\u27e9, we use es, er, and eo for the new embeddings of s, r, o, respectively. Thus es, er, eo is a solution to argmin L(G \u222a{\u27e8s\u2032, r\u2032, o\u27e9}), which can also be written as argmin L(G) + L(\u27e8s\u2032, r\u2032, o\u27e9). Similarly, f(es, er) changes to f(es, er) after retraining. Since we only consider adversaries in the form of \u27e8s\u2032, r\u2032, o\u27e9, we only consider the effect of the at- tack on eo and neglect its effect on es and er.",
      "Similarly, f(es, er) changes to f(es, er) after retraining. Since we only consider adversaries in the form of \u27e8s\u2032, r\u2032, o\u27e9, we only consider the effect of the at- tack on eo and neglect its effect on es and er. This assumption is reasonable since the adversary is con- nected with o and directly affects its embedding when added, but it will only have a secondary, neg- ligible effect on es and er, in comparison to its",
      "effect on eo. Further, calculating the effect of the attack on es and er requires a third order derivative of the loss, which is not practical (O(n3) in the number of parameters). In other words, we assume that es \u2243es and er \u2243er. As a result, to calculate the effect of the attack, \u03c8(s, r, o) \u2212\u03c8(s, r, o), we need to compute eo \u2212eo, followed by: \u03c8(s, r, o) \u2212\u03c8(s, r, o) = zs,r(eo \u2212eo) (4) where zs,r = f(es, er). We now derive an ef\ufb01cient computation for eo \u2212eo. First, the derivative of the loss L(G) = L(G) + L(\u27e8s\u2032, r\u2032, o\u27e9) over eo is: \u2207eoL(G) = \u2207eoL(G) \u2212(1 \u2212\u03d5)zs\u2032,r\u2032 (5) where zs\u2032,r\u2032 = f(e\u2032 s, e\u2032 r), and \u03d5 = \u03c3(\u03c8(s\u2032, r\u2032, o)).",
      "At convergence, after retraining, we expect \u2207eoL(G) = 0. We perform \ufb01rst order Taylor ap- proximation of \u2207eoL(G) to get: 0 \u2243\u2212(1 \u2212\u03d5)z\u22ba s\u2032,r\u2032+ (Ho + \u03d5(1 \u2212\u03d5)z\u22ba s\u2032,r\u2032zs\u2032,r\u2032)(eo \u2212eo) (6) where Ho is the d\u00d7d Hessian matrix for o, i.e., sec- ond order derivative of the loss w.r.t. eo, computed sparsely. Solving for eo \u2212eo gives us, eo \u2212eo =: (1 \u2212\u03d5)(Ho + \u03d5(1 \u2212\u03d5)z\u22ba s\u2032,r\u2032zs\u2032,r\u2032)\u22121z\u22ba s\u2032,r\u2032. In practice, Ho is positive de\ufb01nite, making Ho + \u03d5(1 \u2212\u03d5)z\u22ba s\u2032,r\u2032zs\u2032,r\u2032 positive de\ufb01nite as well, and invertible.",
      "In practice, Ho is positive de\ufb01nite, making Ho + \u03d5(1 \u2212\u03d5)z\u22ba s\u2032,r\u2032zs\u2032,r\u2032 positive de\ufb01nite as well, and invertible. Then, we compute the score change as: \u03c8(s, r, o) \u2212\u03c8(s, r, o) = zs,r(eo \u2212eo) (7) = zs,r((1 \u2212\u03d5)(Ho + \u03d5(1 \u2212\u03d5)z\u22ba s\u2032,r\u2032zs\u2032,r\u2032)\u22121z\u22ba s\u2032,r\u2032). Calculating this expression is ef\ufb01cient since Ho is a d\u00d7d matrix (d is the embedding dimension), and zs,r, zs\u2032,r\u2032 \u2208Rd. Similarly, we estimate the score change of \u27e8s, r, o\u27e9after removing \u27e8s\u2032, r\u2032, o\u27e9as: \u2212zs,r((1\u2212\u03d5)(Ho +\u03d5(1\u2212\u03d5)z\u22ba s\u2032,r\u2032zs\u2032,r\u2032)\u22121z\u22ba s\u2032,r\u2032).",
      "4.2 Continuous Optimization for Search Using the approximations provided in the previous section, Eq. (7) and (4.1), we can use brute force enumeration to \ufb01nd the adversary \u27e8s\u2032, r\u2032, o\u27e9. This approach is feasible when removing an observed triple since the search space of such modi\ufb01cations is usually small; it is the number of observed facts that share the object with the target. On the other hand, \ufb01nding the most in\ufb02uential unobserved fact s es r er f(es, er) (Fixed) zs,r Inverter Network \u02dcs \u02dces \u02dcr \u02dcer Figure 2: Inverter Network The architecture of our in- verter function that translate zs,r to its respective (\u02dcs, \u02dcr). The encoder component is \ufb01xed to be the encoder net- work of DistMult and ConvE respectively. to add requires search over a much larger space of all possible unobserved facts (that share the object).",
      "The encoder component is \ufb01xed to be the encoder net- work of DistMult and ConvE respectively. to add requires search over a much larger space of all possible unobserved facts (that share the object). Instead, we identify the most in\ufb02uential unobserved fact \u27e8s\u2032, r\u2032, o\u27e9by using a gradient-based algorithm on vector zs\u2032,r\u2032 in the embedding space (reminder, zs\u2032,r\u2032 = f(e\u2032 s, e\u2032 r)), solving the following continu- ous optimization problem in Rd: argmax zs\u2032,r\u2032 \u2206(s\u2032,r\u2032)(s, r, o). (8) After identifying the optimal zs\u2032,r\u2032, we still need to generate the pair (s\u2032, r\u2032). We design a network, shown in Figure 2, that maps the vector zs\u2032,r\u2032 to the entity-relation space, i.e., translating it into (s\u2032, r\u2032).",
      "We design a network, shown in Figure 2, that maps the vector zs\u2032,r\u2032 to the entity-relation space, i.e., translating it into (s\u2032, r\u2032). In particular, we train an auto-encoder where the encoder is \ufb01xed to receive the s and r as one-hot inputs, and calculates zs,r in the same way as the DistMult and ConvE encoders respectively (using trained embeddings). The decoder is trained to take zs,r as input and produce s and r, essentially invert- ing f and the embedding layers. As our decoder, for DistMult, we pass zs,r through a linear layer and then use two other linear layers for the subject and the relation separately, providing one-hot vectors as \u02dcs and \u02dcr. For ConvE, we pass zs,r through a decon- volutional layer, and then use the same architecture as the DistMult decoder. Although we could use maximum inner-product search [Shrivastava and Li, 2014] for DistMult instead of our de\ufb01ned inverter function, we are looking for a general approach that works across multiple models.",
      "Although we could use maximum inner-product search [Shrivastava and Li, 2014] for DistMult instead of our de\ufb01ned inverter function, we are looking for a general approach that works across multiple models. We evaluate the performance of our inverter net- works (one for each model/dataset) on correctly recovering the pairs of subject and relation from the test set of our benchmarks, given the zs,r. The accuracy of recovered pairs (and of each argument)",
      "WordNet YAGO DistMult ConvE DistMult ConvE Recover s 93.4 96.1 97.2 98.1 Recover r 91.3 95.3 99.0 99.6 Recover {s, r} 89.5 94.2 96.4 98.0 Table 1: Inverter Functions Accuracy, we calculate the accuracy of our inverter networks in correctly re- covering the pairs of subject and relation from the test set of our benchmarks. # Rels #Entities # Train #Test Nations 56 14 1592 200 Kinship 26 104 4,006 155 WN18 18 40,943 141,442 5000 YAGO3-10 37 123,170 1,079,040 5000 Table 2: Data Statistics of the benchmarks. is given in Table 1. As shown, our networks achieve a very high accuracy, demonstrating their ability to invert vectors zs,r to {s, r} pairs. 5 Experiment Setup Datasets To evaluate our method, we conduct several experiments on four widely used KGs.",
      "is given in Table 1. As shown, our networks achieve a very high accuracy, demonstrating their ability to invert vectors zs,r to {s, r} pairs. 5 Experiment Setup Datasets To evaluate our method, we conduct several experiments on four widely used KGs. To validate the accuracy of the approximations, we use smaller sized Kinship and Nations KGs for which we can make comparisons against more expensive but less approximate approaches. For the remain- ing experiments, we use YAGO3-10 and WN18 KGs, which are closer to real-world KGs in their size and characteristics (see Table 2). Models We implement all methods using the same loss and optimization for training, i.e., Ada- Grad and the binary cross-entropy loss. We use validation data to tune the hyperparameters and use a grid search to \ufb01nd the best hyperparameters, such as regularization parameter, and learning rate of the gradient-based method.",
      "We use validation data to tune the hyperparameters and use a grid search to \ufb01nd the best hyperparameters, such as regularization parameter, and learning rate of the gradient-based method. To capture the effect of our method on link prediction task, we study the change in commonly-used metrics for evalua- tion in this task: mean reciprocal rank (MRR) and Hits@K. Further, we use the same hyperparame- ters as in Dettmers et al. [2018] for training link prediction models for these knowledge graphs. In\ufb02uence Function We also compare our method with in\ufb02uence function (IF) [Koh and Liang, 2017]. The in\ufb02uence function approximates the effect of upweighting a training sample on the loss for a speci\ufb01c test point.",
      "The in\ufb02uence function approximates the effect of upweighting a training sample on the loss for a speci\ufb01c test point. We use IF to approximate the 20 40 60 80 100 Number of entities 0 200 400 600 800 1000 1200 1400 1600 Time (s) IF (d=5) IF (d=10) CRIAGE (d=5) CRIAGE (d=10) Figure 3: In\ufb02uence function vs CRIAGE. We plot the average time (over 10 facts) of in\ufb02uence function (IF) and CRIAGE to identify an adversary as the number of entities in the Kinship KG is varied (by randomly sam- pling subgraphs of the KG). Even with small graphs and dimensionality, IF quickly becomes impractical.",
      "Even with small graphs and dimensionality, IF quickly becomes impractical. change in the loss after removing a triple as: Iup,loss(\u27e8s\u2032, r\u2032, o\u27e9, \u27e8s, r, o\u27e9) = \u2212\u2207\u03b8L(\u27e8s, r, o\u27e9, \u02c6\u03b8)\u22baH\u22121 \u02c6\u03b8 \u2207\u03b8L(\u27e8s\u2032, r\u2032, o\u27e9, \u02c6\u03b8) (9) where \u27e8s\u2032, r\u2032, o\u27e9and \u27e8s, r, o\u27e9are training and test samples respectively, \u02c6\u03b8 represents the optimum pa- rameters and L(\u27e8s, r, o\u27e9, \u02c6\u03b8) represents the loss func- tion for the test sample \u27e8s, r, o\u27e9. In\ufb02uence func- tion does not scale well, so we only compare our method with IF on the smaller size KGs.",
      "In\ufb02uence func- tion does not scale well, so we only compare our method with IF on the smaller size KGs. 6 Experiments We evaluate CRIAGE by (6.1) comparing CRIAGE estimate with the actual effect of the attacks, (6.2) studying the effect of adversarial attacks on evaluation metrics, (6.3) exploring its application to the interpretability of KG representations, and (6.4) detecting incorrect triples. 6.1 In\ufb02uence Function vs CRIAGE To evaluate the quality of our approximations and compare with in\ufb02uence function (IF), we conduct leave one out experiments. In this setup, we take all the neighbors of a random target triple as can- didate modi\ufb01cations, remove them one at a time, retrain the model each time, and compute the exact change in the score of the target triple.",
      "In this setup, we take all the neighbors of a random target triple as can- didate modi\ufb01cations, remove them one at a time, retrain the model each time, and compute the exact change in the score of the target triple. We can use the magnitude of this change in score to rank the candidate triples, and compare this exact ranking with ranking as predicted by: CRIAGE-Remove, in\ufb02uence function with and without Hessian matrix, and the original model score (with the intuition that facts that the model is most con\ufb01dent of will have",
      "Methods Nations Kinship Adding Removing Adding Removing \u03c1 \u03c4 \u03c1 \u03c4 \u03c1 \u03c4 \u03c1 \u03c4 Ranking Based on Score 0.03 0.02 -0.01 -0.01 -0.09 -0.06 0.01 0.01 In\ufb02uence Function without Hessian 0.15 0.12 0.12 0.1 0.77 0.71 0.77 0.71 CRIAGE (Brute Force) 0.95 0.84 0.94 0.85 0.99 0.97 0.99 0.95 In\ufb02uence Function 0.99 0.95 0.99 0.96 0.99 0.98 0.99 0.98 Table 3: Ranking modi\ufb01cations by their impact on the target. We compare the true ranking of candidate triples with a number of approximations using ranking correlation coef\ufb01cients.",
      "We compare the true ranking of candidate triples with a number of approximations using ranking correlation coef\ufb01cients. We compare our method with in\ufb02uence function (IF) with and without Hessian, and ranking the candidates based on their score, on two KGs (d = 10, averaged over 10 random targets). For the sake of brevity, we represent the Spearman\u2019s \u03c1 and Kendall\u2019s \u03c4 rank correlation coef\ufb01cients simply as \u03c1 and \u03c4. the largest impact when removed). Similarly, we evaluate CRIAGE-Add by considering 200 random triples that share the object entity with the target sample as candidates, and rank them as above. The average results of Spearman\u2019s \u03c1 and Kendall\u2019s \u03c4 rank correlation coef\ufb01cients over 10 random target samples is provided in Table 3. CRIAGE performs comparably to the in\ufb02uence function, con\ufb01rming that our approximation is ac- curate. In\ufb02uence function is slightly more accurate because they use the complete Hessian matrix over all the parameters, while we only approximate the change by calculating the Hessian over eo.",
      "In\ufb02uence function is slightly more accurate because they use the complete Hessian matrix over all the parameters, while we only approximate the change by calculating the Hessian over eo. The effect of this difference on scalability is dramatic, constraining IF to very small graphs and small em- bedding dimensionality (d \u226410) before we run out of memory. In Figure 3, we show the time to compute a single adversary by IF compared to CRIAGE, as we steadily grow the number of enti- ties (randomly chosen subgraphs), averaged over 10 random triples. As it shows, CRIAGE is mostly unaffected by the number of entities while IF in- creases quadratically. Considering that real-world KGs have tens of thousands of times more entities, making IF unfeasible for them. 6.2 Robustness of Link Prediction Models Now we evaluate the effectiveness of CRIAGE to successfully attack link prediction by adding false facts. The goal here is to identify the attacks for triples in the test data, and measuring their effect on MRR and Hits@ metrics (ranking evaluations) after conducting the attack and retraining the model.",
      "The goal here is to identify the attacks for triples in the test data, and measuring their effect on MRR and Hits@ metrics (ranking evaluations) after conducting the attack and retraining the model. Since this is the \ufb01rst work on adversarial attacks for link prediction, we introduce several baselines to compare against our method. For \ufb01nding the adversarial fact to add for the target triple \u27e8s, r, o\u27e9, we consider two baselines: 1) choosing a random fake fact \u27e8s\u2032, r\u2032, o\u27e9(Random Attack); 2) \ufb01nding (s\u2032, r\u2032) by \ufb01rst calculating f(es, er) and then feed- ing \u2212f(es, er) to the decoder of the inverter func- tion (Opposite Attack).",
      "In addition to CRIAGE- Add, we introduce two other alternatives of our method: (1) CRIAGE-FT, that uses CRIAGE to increase the score of fake fact over a test triple, i.e., we \ufb01nd the fake fact the model ranks second after the test triple, and identify the adversary for them, and (2) CRIAGE-Best that selects between CRIAGE-Add and CRIAGE-FT attacks based on which has a higher estimated change in score. All-Test The result of the attack on all test facts as targets is provided in the Table 4. CRIAGE- Add outperforms the baselines, demonstrating its ability to effectively attack the KG representations. It seems DistMult is more robust against random attacks, while ConvE is more robust against de- signed attacks. CRIAGE-FT is more effective than CRIAGE-Add since changing the score of a fake fact is easier than of actual facts; there is no ex- isting evidence to support fake facts. We also see that YAGO3-10 models are more robust than those for WN18.",
      "CRIAGE-FT is more effective than CRIAGE-Add since changing the score of a fake fact is easier than of actual facts; there is no ex- isting evidence to support fake facts. We also see that YAGO3-10 models are more robust than those for WN18. Looking at sample attacks (provided in Appendix A.4), CRIAGE mostly tries to change the type of the target object by associating it with a subject and a relation for a different entity type. Uncertain-Test To better understand the effect of attacks, we consider a subset of test triples that 1) the model predicts correctly, 2) difference be- tween their scores and the negative sample with the highest score is minimum. This \u201cUncertain-Test\u201d subset contains 100 triples from each of the original",
      "Models YAGO3-10 WN18 All-Test Uncertain-Test All-Test Uncertain-Test MRR Hits@1 MRR Hits@1 MRR Hits@1 MRR Hits@1 DistMult DistMult 0.458 37 (0) 1.0 100 (0) 0.938 93.1 (0) 1.0 100 (0) + Adding Random Attack 0.442 34.9 (-2.1) 0.91 87.6 (-12.4) 0.926 91.1 (-2) 0.929 90.4 (-9.6) + Adding Opposite Attack 0.427 33.2 (-3.8) 0.884 84.1 (-15.9) 0.906 87.3 (-5.8) 0.921 91 (-9) + CRIAGE-Add 0.379 29.1 (-7.9) 0.71 58 (-42) 0.89 86.4 (-6.7) 0.844 81.2 (-18.8) + CRIAGE-FT 0.",
      "379 29.1 (-7.9) 0.71 58 (-42) 0.89 86.4 (-6.7) 0.844 81.2 (-18.8) + CRIAGE-FT 0.387 27.7 (-9.3) 0.673 50.5 (-49.5) 0.86 79.2 (-13.9) 0.83 74.5 (-25.5) + CRIAGE-Best 0.372 26.9 (-10.1) 0.658 49.3 (-50.7) 0.838 77.9 (-15.2) 0.814 72.7 (-27.3) ConvE ConvE 0.497 41.2 (0) 1.0 100 (0) 0.94 93.3 (0) 1.0 100 (0) + Adding Random Attack 0.474 38.4 (-2.8) 0.889 83 (-17) 0.921 90.1 (-3.2) 0.923 89.7 (-10.",
      "3 (0) 1.0 100 (0) + Adding Random Attack 0.474 38.4 (-2.8) 0.889 83 (-17) 0.921 90.1 (-3.2) 0.923 89.7 (-10.3) + Adding Opposite Attack 0.469 38 (-3.2) 0.874 81.9 (-18.1) 0.915 88.9 (-4.4) 0.908 88.1 (-11.9) + CRIAGE-Add 0.454 36.9 (-4.3) 0.738 61.5 (-38.5) 0.897 87.8 (-5.5) 0.895 87.6 (-12.4) + CRIAGE-FT 0.441 33.2 (-8) 0.703 57.4 (-42.6) 0.865 80 (-13.3) 0.874 79.5 (-20.5) + CRIAGE-Best 0.423 31.9 (-9.3) 0.",
      "2 (-8) 0.703 57.4 (-42.6) 0.865 80 (-13.3) 0.874 79.5 (-20.5) + CRIAGE-Best 0.423 31.9 (-9.3) 0.677 54.8 (-45.2) 0.849 79.1 (-14.2) 0.858 78.4 (-21.6) Table 4: Robustness of Representation Models, the effect of adversarial attack on link prediction task. We consider two scenario for the target triples, 1) choosing the whole test dataset as the targets (All-Test) and 2) choosing a subset of test data that models are uncertain about them (Uncertain-Test).",
      "the effect of adversarial attack on link prediction task. We consider two scenario for the target triples, 1) choosing the whole test dataset as the targets (All-Test) and 2) choosing a subset of test data that models are uncertain about them (Uncertain-Test). 0 1 2 3 4 5 6 7 8 Change in Hits@1 isAffiliatedTo playsFor isConnectedTo isMarriedTo 4.50 3.30 7.20 5.80 0.70 4.60 6.90 6.40 Hits@1 Change in Per-Relation Breakdown DistMult ConvE Figure 4: Per-Relation Breakdown showing the effect of CRIAGE-Add on different relations in YAGO3-10. test sets, and we provide results of attacks on this data in Table 4. The attacks are much more effec- tive in this scenario, causing a considerable drop in the metrics. Further, in addition to CRIAGE signi\ufb01- cantly outperforming other baselines, they indicate that ConvE\u2019s con\ufb01dence is much more robust.",
      "The attacks are much more effec- tive in this scenario, causing a considerable drop in the metrics. Further, in addition to CRIAGE signi\ufb01- cantly outperforming other baselines, they indicate that ConvE\u2019s con\ufb01dence is much more robust. Relation Breakdown We perform additional anal- ysis on the YAGO3-10 dataset to gain a deeper understanding of the performance of our model. As shown in Figure 4, both DistMult and ConvE provide a more robust representation for isA\ufb03li- atedTo and isConnectedTo relations, demonstrat- ing the con\ufb01dence of models in identifying them. Moreover, the CRIAGE affects DistMult more in playsFor and isMarriedTo relations while affecting ConvE more in isConnectedTo relations. Rule Body, R1(a, c) \u2227R2(c, b) \u21d2 Target, R(a, b) Common to both isConnectedTo(a, c)\u2227isConnectedTo(c, b) isConnectedTo isLocatedIn(a, c)\u2227isLocatedIn(c, b) isLocatedIn isAf\ufb01liatedTo(a, c)\u2227isLocatedIn(c,",
      "R(a, b) Common to both isConnectedTo(a, c)\u2227isConnectedTo(c, b) isConnectedTo isLocatedIn(a, c)\u2227isLocatedIn(c, b) isLocatedIn isAf\ufb01liatedTo(a, c)\u2227isLocatedIn(c, b) wasBornIn isMarriedTo(a, c)\u2227hasChild(c, b) hasChild only in DistMult playsFor(a, c)\u2227isLocatedIn(c, b) wasBornIn dealsWith(a, c)\u2227participatedIn(c, b) participatedIn isAf\ufb01liatedTo(a, c)\u2227isLocatedIn(c, b) diedIn isLocatedIn(a, c)\u2227hasCapital(c, b) isLocatedIn only in ConvE in\ufb02uences(a, c)\u2227in\ufb02uences(c, b) in\ufb02uences isLocatedIn(a, c)\u2227hasNeighbor(c, b) isLocatedIn hasCapital(a, c)\u2227isLocatedIn(c, b) exports hasAdvisor(a, c)\u2227graduatedFrom(c,",
      "b) in\ufb02uences isLocatedIn(a, c)\u2227hasNeighbor(c, b) isLocatedIn hasCapital(a, c)\u2227isLocatedIn(c, b) exports hasAdvisor(a, c)\u2227graduatedFrom(c, b) graduatedFrom Extractions from DistMult [Yang et al., 2015] isLocatedIn(a, c) \u2227isLocatedIn(c, b) isLocatedIn isAf\ufb01liatedTo(a, c) \u2227isLocatedIn(c, b) wasBornIn playsFor(a, c) \u2227isLocatedIn(c, b) wasBornIn isAf\ufb01liatedTo(a, c) \u2227isLocatedIn(c, b) diedIn Table 5: Extracted Rules for identifying the most in- \ufb02uential link. We extract the patterns that appear more than 90% times in the neighborhood of the target triple. The output of CRIAGE-Remove is presented in red.",
      "b) diedIn Table 5: Extracted Rules for identifying the most in- \ufb02uential link. We extract the patterns that appear more than 90% times in the neighborhood of the target triple. The output of CRIAGE-Remove is presented in red. 6.3 Interpretability of Models To be able to understand and interpret why a link is predicted using the opaque, dense embeddings, we need to \ufb01nd out which part of the graph was most in\ufb02uential on the prediction. To provide such expla- nations for each predictions, we identify the most in\ufb02uential fact using CRIAGE-Remove. Instead of focusing on individual predictions, we aggregate the explanations over the whole dataset for each re- lation using a simple rule extraction technique: we",
      "Methods \u27e8s\u2032, r\u2032, o\u27e9Noise \u27e8s\u2032, r, o\u27e9Noise Hits@1 Hits@2 Hits@1 Hits@2 Random 19.7 39.4 19.7 39.4 Lowest 16 37 26 47 CRIAGE 42 62 55 76 Table 6: Error Detection Accuracy in the neighbor- hood of 100 chosen samples. We choose the neighbor with the least value of \u2206(s\u2032,r\u2032)(s, r, o) as the incorrect fact. This experiment assumes we know each target fact has exactly one error. \ufb01nd simple patterns on subgraphs that surround the target triple and the removed fact from CRIAGE- Remove, and appear more than 90% of the time. We only focus on extracting length-2 horn rules, i.e., R1(a, c) \u2227R2(c, b) \u21d2R(a, b), where R(a, b) is the target and R2(c, b) is the removed fact. Table 5 shows extracted YAGO3-10 rules that are common to both models, and ones that are not.",
      "Table 5 shows extracted YAGO3-10 rules that are common to both models, and ones that are not. The rules show several interesting inferences, such that hasChild is often inferred via married parents, and isLocatedIn via transitivity. There are several differences in how the models reason as well; Dist- Mult often uses the hasCapital as an intermedi- ate step for isLocatedIn, while ConvE incorrectly uses isNeighbor. We also compare against rules extracted by Yang et al. [2015] for YAGO3-10 that utilizes the structure of DistMult: they require do- main knowledge on types and cannot be applied to ConvE. Interestingly, the extracted rules contain all the rules provided by CRIAGE, demonstrating that CRIAGE can be used to accurately interpret mod- els, including ones that are not interpretable, such as ConvE. These are preliminary steps toward inter- pretability of link prediction models, and we leave more analysis of interpretability to future work. 6.4 Finding Errors in Knowledge Graphs Here, we demonstrate another potential use of ad- versarial modi\ufb01cations: \ufb01nding erroneous triples in the knowledge graph.",
      "6.4 Finding Errors in Knowledge Graphs Here, we demonstrate another potential use of ad- versarial modi\ufb01cations: \ufb01nding erroneous triples in the knowledge graph. Intuitively, if there is an error in the graph, the triple is likely to be inconsistent with its neighborhood, and thus the model should put least trust on this triple. In other words, the error triple should have the least in\ufb02uence on the model\u2019s prediction of the training data. Formally, to \ufb01nd the incorrect triple \u27e8s\u2032, r\u2032, o\u27e9in the neigh- borhood of the train triple \u27e8s, r, o\u27e9, we need to \ufb01nd the triple \u27e8s\u2032, r\u2032, o\u27e9that results in the least change \u2206(s\u2032,r\u2032)(s, r, o) when removed from the graph. To evaluate this application, we inject random triples into the graph, and measure the ability of CRIAGE to detect the errors using our optimiza- tion.",
      "To evaluate this application, we inject random triples into the graph, and measure the ability of CRIAGE to detect the errors using our optimiza- tion. We consider two types of incorrect triples: 1) incorrect triples in the form of \u27e8s\u2032, r, o\u27e9where s\u2032 is chosen randomly from all of the entities, and 2) in- correct triples in the form of \u27e8s\u2032, r\u2032, o\u27e9where s\u2032 and r\u2032 are chosen randomly. We choose 100 random triples from the observed graph, and for each of them, add an incorrect triple (in each of the two sce- narios) to its neighborhood. Then, after retraining DistMult on this noisy training data, we identify error triples through a search over the neighbors of the 100 facts. The result of choosing the neighbor with the least in\ufb02uence on the target is provided in the Table 6. When compared with baselines that randomly choose one of the neighbors, or assume that the fact with the lowest score is incorrect, we see that CRIAGE outperforms both of these with a considerable gap, obtaining an accuracy of 42% and 55% in detecting errors.",
      "When compared with baselines that randomly choose one of the neighbors, or assume that the fact with the lowest score is incorrect, we see that CRIAGE outperforms both of these with a considerable gap, obtaining an accuracy of 42% and 55% in detecting errors. 7 Related Work Learning relational knowledge representations has been a focus of active research in the past few years, but to the best of our knowledge, this is the \ufb01rst work on conducting adversarial modi\ufb01cations on the link prediction task. Knowledge graph embedding There is a rich lit- erature on representing knowledge graphs in vector spaces that differ in their scoring functions [Wang et al., 2017, Goyal and Ferrara, 2018, Fooshee et al., 2018].",
      "Knowledge graph embedding There is a rich lit- erature on representing knowledge graphs in vector spaces that differ in their scoring functions [Wang et al., 2017, Goyal and Ferrara, 2018, Fooshee et al., 2018]. Although CRIAGE is primarily applicable to multiplicative scoring functions [Nickel et al., 2011, Socher et al., 2013, Yang et al., 2015, Trouil- lon et al., 2016], these ideas apply to additive scor- ing functions [Bordes et al., 2013a, Wang et al., 2014, Lin et al., 2015, Nguyen et al., 2016] as well, as we show in Appendix A.3.",
      "Furthermore, there is a growing body of litera- ture that incorporates an extra types of evidence for more informed embeddings such as numeri- cal values [Garcia-Duran and Niepert, 2017], im- ages [O\u00f1oro-Rubio et al., 2017], text [Toutanova et al., 2015, 2016, Tu et al., 2017], and their combi- nations [Pezeshkpour et al., 2018]. Using CRIAGE, we can gain a deeper understanding of these meth- ods, especially those that build their embeddings wit hmultiplicative scoring functions. Interpretability and Adversarial Modi\ufb01cation There has been a signi\ufb01cant recent interest in con- ducting an adversarial attacks on different machine",
      "learning models [Biggio et al., 2014, Papernot et al., 2016, Dong et al., 2017, Zhao et al., 2018a,b, Brunet et al., 2018] to attain the interpretability, and further, evaluate the robustness of those mod- els. Koh and Liang [2017] uses in\ufb02uence function to provide an approach to understanding black-box models by studying the changes in the loss occur- ring as a result of changes in the training data. In addition to incorporating their established method on KGs, we derive a novel approach that differs from their procedure in two ways: (1) instead of changes in the loss, we consider the changes in the scoring function, which is more appropriate for KG representations, and (2) in addition to searching for an attack, we introduce a gradient-based method that is much faster, especially for \u201cadding an attack triple\u201d (the size of search space make the in\ufb02uence function method infeasible).",
      "Previous work has also considered adversaries for KGs, but as part of training to improve their representation of the graph [Minervini et al., 2017, Cai and Wang, 2018]. Adversarial Attack on KG Although this is the \ufb01rst work on adversarial attacks for link prediction, there are two approaches [Dai et al., 2018, Z\u00fcgner et al., 2018] that consider the task of adversarial attack on graphs. There are a few fundamental dif- ferences from our work: (1) they build their method on top of a path-based representations while we fo- cus on embeddings, (2) they consider node classi\ufb01- cation as the target of their attacks while we attack link prediction, and (3) they conduct the attack on small graphs due to restricted scalability, while the complexity of our method does not depend on the size of the graph, but only the neighborhood, allowing us to attack real-world graphs. 8 Conclusions Motivated by the need to analyze the robustness and interpretability of link prediction models, we present a novel approach for conducting adversarial modi\ufb01cations to knowledge graphs.",
      "8 Conclusions Motivated by the need to analyze the robustness and interpretability of link prediction models, we present a novel approach for conducting adversarial modi\ufb01cations to knowledge graphs. We introduce CRIAGE, completion robustness and interpretabil- ity via adversarial graph edits: identifying the fact to add into or remove from the KG that changes the prediction for a target fact. CRIAGE uses (1) an es- timate of the score change for any target triple after adding or removing another fact, and (2) a gradient- based algorithm for identifying the most in\ufb02uential modi\ufb01cation. We show that CRIAGE can effec- tively reduce ranking metrics on link prediction models upon applying the attack triples. Further, we incorporate the CRIAGE to study the inter- pretability of KG representations by summarizing the most in\ufb02uential facts for each relation. Finally, using CRIAGE, we introduce a novel automated error detection method for knowledge graphs. We have release the open-source implementation of our models at: https://pouyapez.github.io/criage.",
      "Finally, using CRIAGE, we introduce a novel automated error detection method for knowledge graphs. We have release the open-source implementation of our models at: https://pouyapez.github.io/criage. Acknowledgements We would like to thank Matt Gardner, Marco Tulio Ribeiro, Zhengli Zhao, Robert L. Logan IV, Dheeru Dua and the anonymous reviewers for their detailed feedback and suggestions. This work is supported in part by Allen Institute for Arti\ufb01cial Intelligence (AI2) and in part by NSF awards #IIS-1817183 and #IIS-1756023. The views expressed are those of the authors and do not re\ufb02ect the of\ufb01cial policy or position of the funding agencies. References Battista Biggio, Blaine Nelson, and Pavel Laskov. Poisoning attacks against support vector machines. In International Conference on Machine Learning (ICML), 2012. Battista Biggio, Giorgio Fumera, and Fabio Roli. Se- curity evaluation of pattern classi\ufb01ers under attack.",
      "Poisoning attacks against support vector machines. In International Conference on Machine Learning (ICML), 2012. Battista Biggio, Giorgio Fumera, and Fabio Roli. Se- curity evaluation of pattern classi\ufb01ers under attack. IEEE transactions on knowledge and data engineer- ing, 2014. Antoine Bordes, Jason Weston, Ronan Collobert, Yoshua Bengio, et al. Learning structured embed- dings of knowledge bases. In AAAI Conference on Arti\ufb01cial Intelligence, 2011. Antoine Bordes, Nicolas Usunier, Alberto Garcia- Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi- relational data. In Neural Information Processing Systems (NeurIPS), 2013a. Antoine Bordes, Nicolas Usunier, Alberto Garcia- Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi- relational data. In Neural Information Processing Systems (NeurIPS), 2013b.",
      "Antoine Bordes, Nicolas Usunier, Alberto Garcia- Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi- relational data. In Neural Information Processing Systems (NeurIPS), 2013b. Marc-Etienne Brunet, Colleen Alkalay-Houlihan, Ash- ton Anderson, and Richard Zemel. Understand- ing the origins of bias in word embeddings. arXiv preprint arXiv:1810.03611, 2018. Liwei Cai and William Yang Wang. Kbgan: Adversar- ial learning for knowledge graph embeddings. In Annual Conference of the North American Chap- ter of the Association for Computational Linguistics (NAACL-HLT), 2018.",
      "Igino Corona, Giorgio Giacinto, and Fabio Roli. Ad- versarial attacks against intrusion detection systems: Taxonomy, solutions and open issues. Information Sciences, 2013. Hanjun Dai, Hui Li, Tian Tian, Xin Huang, Lin Wang, Jun Zhu, and Le Song. Adversarial attack on graph structured data. In International Conference on Ma- chine Learning (ICML), 2018. Shib Sankar Dasgupta, Swayambhu Nath Ray, and Partha Talukdar. Hyte: Hyperplane-based tempo- rally aware knowledge graph embedding. In Em- pirical Methods in Natural Language Processing (EMNLP), 2018. Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. Convolutional 2d knowledge graph embeddings. AAAI Conference on Arti\ufb01cial Intelligence, 2018. Yinpeng Dong, Hang Su, Jun Zhu, and Fan Bao. Towards interpretable deep neural networks by leveraging adversarial examples.",
      "Convolutional 2d knowledge graph embeddings. AAAI Conference on Arti\ufb01cial Intelligence, 2018. Yinpeng Dong, Hang Su, Jun Zhu, and Fan Bao. Towards interpretable deep neural networks by leveraging adversarial examples. arXiv preprint arXiv:1708.05493, 2017. David Fooshee, Aaron Mood, Eugene Gutman, Mo- hammadamin Tavakoli, Gregor Urban, Frances Liu, Nancy Huynh, David Van Vranken, and Pierre Baldi. Deep learning for chemical reaction predic- tion. Molecular Systems Design & Engineering, 2018. Alberto Garcia-Duran and Mathias Niepert. Kblrn: End-to-end learning of knowledge base representa- tions with latent, relational, and numerical features. arXiv preprint arXiv:1709.04676, 2017. Palash Goyal and Emilio Ferrara. Graph embedding techniques, applications, and performance: A sur- vey. Knowledge-Based Systems, 2018.",
      "arXiv preprint arXiv:1709.04676, 2017. Palash Goyal and Emilio Ferrara. Graph embedding techniques, applications, and performance: A sur- vey. Knowledge-Based Systems, 2018. Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and Jun Zhao. Knowledge graph embedding via dynamic mapping matrix. In Annual Meeting of the Associ- ation for Computational Linguistics and the 7th In- ternational Joint Conference on Natural Language Processing, 2015. Rudolf Kadlec, Ondrej Bajgar, and Jan Kleindienst. Knowledge base completion: Baselines strike back. Annual Meeting of the Association for Computa- tional Linguistics (ACL), 2017. Pang Wei Koh and Percy Liang. Understanding black- box predictions via in\ufb02uence functions. In Inter- national Conference on Machine Learning (ICML), 2017. Igor Kononenko et al. An ef\ufb01cient explanation of indi- vidual classi\ufb01cations using game theory.",
      "Understanding black- box predictions via in\ufb02uence functions. In Inter- national Conference on Machine Learning (ICML), 2017. Igor Kononenko et al. An ef\ufb01cient explanation of indi- vidual classi\ufb01cations using game theory. Journal of Machine Learning Research, 2010. Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. Learning entity and relation embeddings for knowledge graph completion. In AAAI Confer- ence on Arti\ufb01cial Intelligence, 2015. P Minervini, T Demeester, T Rockt\u00e4schel, and S Riedel. Adversarial sets for regularising neural link predic- tors. In Uncertainty in Arti\ufb01cial Intelligence (UAI), 2017. Dai Quoc Nguyen, Tu Dinh Nguyen, Dat Quoc Nguyen, and Dinh Phung. A novel embedding model for knowledge base completion based on con- volutional neural network.",
      "In Uncertainty in Arti\ufb01cial Intelligence (UAI), 2017. Dai Quoc Nguyen, Tu Dinh Nguyen, Dat Quoc Nguyen, and Dinh Phung. A novel embedding model for knowledge base completion based on con- volutional neural network. In Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT), 2018. Dat Quoc Nguyen, Kairit Sirts, Lizhen Qu, and Mark Johnson. Stranse: a novel embedding model of enti- ties and relationships in knowledge bases. In Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL- HLT), 2016. Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. A three-way model for collective learning on multi-relational data. In International conference on machine learning (ICML), 2011. Daniel O\u00f1oro-Rubio, Mathias Niepert, Alberto Garc\u00eda- Dur\u00e1n, Roberto Gonz\u00e1lez-S\u00e1nchez, and Roberto J L\u00f3pez-Sastre. Representation learning for visual- relational knowledge graphs.",
      "In International conference on machine learning (ICML), 2011. Daniel O\u00f1oro-Rubio, Mathias Niepert, Alberto Garc\u00eda- Dur\u00e1n, Roberto Gonz\u00e1lez-S\u00e1nchez, and Roberto J L\u00f3pez-Sastre. Representation learning for visual- relational knowledge graphs. arXiv preprint arXiv:1709.02314, 2017. Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, and Ananthram Swami. The limitations of deep learning in adversarial set- tings. In IEEE European Symposium on Security and Privacy (EuroS&P), 2016. Pouya Pezeshkpour, Liyan Chen, and Sameer Singh. Embedding multimodal relational data for knowl- edge base completion. In Empirical Methods in Nat- ural Language Processing (EMNLP), 2018. Aditya Sharma, Partha Talukdar, et al. Towards un- derstanding the geometry of knowledge graph em- beddings. In Annual Meeting of the Association for Computational Linguistics (ACL), 2018.",
      "Aditya Sharma, Partha Talukdar, et al. Towards un- derstanding the geometry of knowledge graph em- beddings. In Annual Meeting of the Association for Computational Linguistics (ACL), 2018. Anshumali Shrivastava and Ping Li. Asymmetric lsh (alsh) for sublinear time maximum inner product search (mips). In Neural Information Processing Systems (NeurIPS), 2014. Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. Reasoning with neural tensor net- works for knowledge base completion. In Neural Information Processing Systems (NeurIPS), 2013. Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoi- fung Poon, Pallavi Choudhury, and Michael Gamon. Representing text for joint embedding of text and knowledge bases. In Empirical Methods in Natural Language Processing (EMNLP), 2015. Kristina Toutanova, Victoria Lin, Wen-tau Yih, Hoi- fung Poon, and Chris Quirk. Compositional learn- ing of embeddings for relation paths in knowledge base and text.",
      "In Empirical Methods in Natural Language Processing (EMNLP), 2015. Kristina Toutanova, Victoria Lin, Wen-tau Yih, Hoi- fung Poon, and Chris Quirk. Compositional learn- ing of embeddings for relation paths in knowledge base and text. In Annual Meeting of the Association for Computational Linguistics (ACL), 2016.",
      "Th\u00e9o Trouillon, Johannes Welbl, Sebastian Riedel, \u00c9ric Gaussier, and Guillaume Bouchard. Complex em- beddings for simple link prediction. In International Conference on Machine Learning (ICML), 2016. Cunchao Tu, Han Liu, Zhiyuan Liu, and Maosong Sun. Cane: Context-aware network embedding for rela- tion modeling. In Annual Meeting of the Association for Computational Linguistics (ACL), 2017. Quan Wang, Zhendong Mao, Bin Wang, and Li Guo. Knowledge graph embedding: A survey of ap- proaches and applications. IEEE Transactions on Knowledge and Data Engineering, 2017. Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph embedding by translating on hyperplanes. In AAAI Conference on Arti\ufb01cial Intelligence, 2014. Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and rela- tions for learning and inference in knowledge bases.",
      "In AAAI Conference on Arti\ufb01cial Intelligence, 2014. Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and rela- tions for learning and inference in knowledge bases. International Conference on Learning Representa- tions (ICLR), 2015. Zhao Zhang, Fuzhen Zhuang, Meng Qu, Fen Lin, and Qing He. Knowledge graph embedding with hierar- chical relation structure. In Empirical Methods in Natural Language Processing (EMNLP), 2018. Mengchen Zhao, Bo An, Yaodong Yu, Sulin Liu, and Sinno Jialin Pan. Data poisoning attacks on multi- task relationship learning. In AAAI Conference on Arti\ufb01cial Intelligence, 2018a. Zhengli Zhao, Dheeru Dua, and Sameer Singh. Gener- ating natural adversarial examples. In International Conference on Learning Representations (ICLR), 2018b. Daniel Z\u00fcgner, Amir Akbarnejad, and Stephan G\u00fcnne- mann.",
      "Gener- ating natural adversarial examples. In International Conference on Learning Representations (ICLR), 2018b. Daniel Z\u00fcgner, Amir Akbarnejad, and Stephan G\u00fcnne- mann. Adversarial attacks on neural networks for graph data. In ACM SIGKDD International Con- ference on Knowledge Discovery & Data Mining, 2018. A Appendix We approximate the change on the score of the target triple upon applying attacks other than the \u27e8s\u2032, r\u2032, o\u27e9ones. Since each relation appears many times in the training triples, we can assume that applying a single attack will not considerably af- fect the relations embeddings. As a result, we just need to study the attacks in the form of \u27e8s, r\u2032, o\u27e9 and \u27e8s, r\u2032, o\u2032\u27e9. De\ufb01ning the scoring function as \u03c8(s, r, o) = f(es, er) \u00b7 eo = zs,r \u00b7 eo, we further assume that \u03c8(s, r, o) = es \u00b7 g(er, eo) = es \u00b7 xr,o.",
      "De\ufb01ning the scoring function as \u03c8(s, r, o) = f(es, er) \u00b7 eo = zs,r \u00b7 eo, we further assume that \u03c8(s, r, o) = es \u00b7 g(er, eo) = es \u00b7 xr,o. A.1 Modi\ufb01cations of the Form \u27e8s, r\u2032, o\u2032\u27e9 Using similar argument as the attacks in the form of \u27e8s\u2032, r\u2032, o\u27e9, we can calculate the effect of the attack, \u03c8(s, r, o) \u2212\u03c8(s, r, o) as: \u03c8(s, r, o) \u2212\u03c8(s, r, o) = (es \u2212es)xs,r (10) where xs,r = g(er, eo). We now derive an ef\ufb01cient computation for (es\u2212 es).",
      "We now derive an ef\ufb01cient computation for (es\u2212 es). First, the derivative of the loss L(G) = L(G)+ L(\u27e8s, r\u2032, o\u2032\u27e9) over es is: \u2207esL(G) = \u2207esL(G) \u2212(1 \u2212\u03d5)xr\u2032,o\u2032 (11) where xr\u2032,o\u2032 = g(e\u2032 r, e\u2032 o), and \u03d5 = \u03c3(\u03c8(s, r\u2032, o\u2032)). At convergence, after retraining, we expect \u2207esL(G) = 0. We perform \ufb01rst order Taylor ap- proximation of \u2207esL(G) to get: 0 \u2243\u2212(1 \u2212\u03d5)x\u22ba r\u2032,o\u2032+ (Hs + \u03d5(1 \u2212\u03d5)x\u22ba r\u2032,o\u2032xr\u2032,o\u2032)(es \u2212es) (12) where Hs is the d\u00d7d Hessian matrix for s, i.e. sec- ond order derivative of the loss w.r.t. es, computed sparsely.",
      "sec- ond order derivative of the loss w.r.t. es, computed sparsely. Solving for es \u2212es gives us: es \u2212es = (1 \u2212\u03d5)(Hs + \u03d5(1 \u2212\u03d5)x\u22ba r\u2032,o\u2032xr\u2032,o\u2032)\u22121x\u22ba r\u2032,o\u2032 In practice, Hs is positive de\ufb01nite, making Hs + \u03d5(1 \u2212\u03d5)x\u22ba r\u2032,o\u2032xr\u2032,o\u2032 positive de\ufb01nite as well, and invertible. Then, we compute the score change as: \u03c8(s, r, o) \u2212\u03c8(s, r, o) = xr,o(es \u2212es) = ((1 \u2212\u03d5)(Hs + \u03d5(1 \u2212\u03d5)x\u22ba r\u2032,o\u2032xr\u2032,o\u2032)\u22121x\u22ba r\u2032,o\u2032)xr,o. (13) A.2 Modi\ufb01cations of the Form \u27e8s, r\u2032, o\u27e9 In this section we approximate the effect of attack in the form of \u27e8s, r\u2032, o\u27e9.",
      "(13) A.2 Modi\ufb01cations of the Form \u27e8s, r\u2032, o\u27e9 In this section we approximate the effect of attack in the form of \u27e8s, r\u2032, o\u27e9. In contrast to \u27e8s\u2032, r\u2032, o\u27e9 attacks, for this scenario we need to consider the change in the es, upon applying the attack, in ap- proximation of the change in the score as well. Using previous results, we can approximate the eo \u2212eo as: eo \u2212eo = (1 \u2212\u03d5)(Ho + \u03d5(1 \u2212\u03d5)z\u22ba s,r\u2032zs,r\u2032)\u22121z\u22ba s,r\u2032 (14)",
      "Target Triple CRIAGE-Add DistMult Brisbane Airport, isConnectedTo, Boulia Airport Osman Ozk\u00f6yl\u00fc, isPoliticianOf, Boulia Airport Jalna District, isLocatedIn, India United States, hasWonPrize, India Quincy Promes, wasBornIn, Amsterdam Gmina Krzeszyce, hasGender, Amsterdam Princess Henriette, hasChild, Violante Bavaria Al Jazira Club, playsFor, Violante Bavaria ConvE Brisbane Airport, isConnectedTo, Boulia Airport Victoria Wood, wasBornIn, Boulia Airport National Union(Israel), isLocatedIn, Jerusalem Sejad Halilovi\u00b4c, isAf\ufb01liatedTo, Jerusalem Robert Louis, in\ufb02uences, David Leavitt David Louhoungou, hasGender, David Leavitt Princess Henriette, hasChild, Violante Bavaria Jonava, isAf\ufb01liatedTo, Violante Bavaria Table 7: Top adversarial triples for target samples.",
      "and similarly, we can approximate es \u2212es as: es \u2212es = (1 \u2212\u03d5)(Hs + \u03d5(1 \u2212\u03d5)x\u22ba r\u2032,oxr\u2032,o)\u22121x\u22ba r\u2032,o (15) where Hs is the Hessian matrix over es. Then using these approximations: zs,r(eo \u2212eo) = zs,r((1 \u2212\u03d5)(Ho + \u03d5(1 \u2212\u03d5)z\u22ba s,r\u2032zs,r\u2032)\u22121z\u22ba s,r\u2032) and: (es \u2212es)xr,\u00afo = ((1 \u2212\u03d5)(Hs + \u03d5(1 \u2212\u03d5)x\u22ba r\u2032,oxr\u2032,o)\u22121x\u22ba r\u2032,o)xr,\u00afo and then calculate the change in the score as: \u03c8(s, r, o) \u2212\u03c8(s, r, o) = zs,r.",
      "(eo \u2212eo) + (es \u2212es).xr,\u00afo = zs,r((1 \u2212\u03d5)(Ho + \u03d5(1 \u2212\u03d5)z\u22ba s,r\u2032zs,r\u2032)\u22121z\u22ba s,r\u2032)+ ((1 \u2212\u03d5)(Hs + \u03d5(1 \u2212\u03d5)x\u22ba r\u2032,oxr\u2032,o)\u22121x\u22ba r\u2032,o)xr,\u00afo (16) A.3 First-order Approximation of the Change For TransE In here we derive the approximation of the change in the score upon applying an adversarial modi\ufb01- cation for TransE [Bordes et al., 2013a]. Using similar assumptions and parameters as before, to calculate the effect of the attack, \u03c8(s, r, o) (where \u03c8(s, r, o) = |es + er \u2212eo|), we need to compute eo. To do so, we need to derive an ef\ufb01cient com- putation for eo.",
      "To do so, we need to derive an ef\ufb01cient com- putation for eo. First, the derivative of the loss L(G) = L(G) + L(\u27e8s\u2032, r\u2032, o\u27e9) over eo is: \u2207eoL(G) = \u2207eoL(G) + (1 \u2212\u03d5) zs\u2032,r\u2032 \u2212eo \u03c8(s\u2032, r\u2032, o) (17) where zs\u2032,r\u2032 = e\u2032 s + e\u2032 r, and \u03d5 = \u03c3(\u03c8(s\u2032, r\u2032, o)). At convergence, after retraining, we expect \u2207eoL(G) = 0.",
      "At convergence, after retraining, we expect \u2207eoL(G) = 0. We perform \ufb01rst order Taylor ap- proximation of \u2207eoL(G) to get: 0 \u2243 (1 \u2212\u03d5)(zs\u2032,r\u2032 \u2212eo)\u22ba \u03c8(s\u2032, r\u2032, o) + (Ho \u2212Hs\u2032,r\u2032,o)(eo \u2212eo) (18) Hs\u2032,r\u2032,o = (1 \u2212\u03d5)\u03d5(zs\u2032,r\u2032 \u2212eo)\u22ba(zs\u2032,r\u2032 \u2212eo) \u03c8(s\u2032, r\u2032, o)2 + 1 \u2212\u03d5 \u03c8(s\u2032, r\u2032, o) \u2212(1 \u2212\u03d5)(zs\u2032,r\u2032 \u2212eo)\u22ba(zs\u2032,r\u2032 \u2212eo) \u03c8(s\u2032, r\u2032, o)3 (19) where Ho is the d\u00d7d Hessian matrix for o, i.e., sec- ond order derivative of the loss w.r.t. eo, computed sparsely.",
      "eo, computed sparsely. Solving for eo gives us: eo = \u2212(1 \u2212\u03d5)(Ho \u2212Hs\u2032,r\u2032,o)\u22121 (zs\u2032,r\u2032 \u2212eo)\u22ba \u03c8(s\u2032, r\u2032, o) + eo (20) Then, we compute the score change as: \u03c8(s, r, o) = |es + er \u2212eo| = |es + er + (1 \u2212\u03d5)(Ho \u2212Hs\u2032,r\u2032,o)\u22121 (zs\u2032,r\u2032 \u2212eo)\u22ba \u03c8(s\u2032, r\u2032, o) \u2212eo| (21) Calculating this expression is ef\ufb01cient since Ho is a d \u00d7 d matrix. A.4 Sample Adversarial Attacks In this section, we provide the output of the CRIAGE-Add for some target triples. Sample ad- versarial attacks are provided in Table 7. As it shows, CRIAGE-Add attacks mostly try to change the type of the target triple\u2019s object by associating it with a subject and a relation that require a different entity types."
    ],
    "queries":"/future/u/okhattab/data/MSMARCO/queries.train.tsv",
    "index_name":"PaperTab-question-1905.00563.pdf",
    "overwrite":false,
    "root":".ragatouille/",
    "experiment":"colbert",
    "index_root":null,
    "name":"2025-05/17/10.22.50",
    "rank":0,
    "nranks":1,
    "amp":true,
    "gpus":1,
    "avoid_fork_if_possible":false
  },
  "num_chunks":1,
  "num_partitions":1024,
  "num_embeddings":13837,
  "avg_doclen":168.743902439,
  "RAGatouille":{
    "index_config":{
      "index_type":"PLAID",
      "index_name":"PaperTab-question-1905.00563.pdf"
    }
  }
}