{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "Neural Architectures for Fine-Grained Propaganda Detection in News Pankaj Gupta1,2, Khushbu Saxena1, Usama Yaseen1,2, Thomas Runkler1, Hinrich Sch\u00a8utze2 1Corporate Technology, Machine-Intelligence (MIC-DE), Siemens AG Munich, Germany 2CIS, University of Munich (LMU) Munich, Germany pankaj.gupta@siemens.com | pankaj.gupta@campus.lmu.de Abstract This paper describes our system (MIC-CIS) details and results of participation in the \ufb01ne-grained propaganda detection shared task 2019. To address the tasks of sentence (SLC) and fragment level (FLC) propaganda detec- tion, we explore different neural architectures (e.g., CNN, LSTM-CRF and BERT) and ex- tract linguistic (e.g., part-of-speech, named en- tity, readability, sentiment, emotion, etc.), lay- out and topical features. Speci\ufb01cally, we have designed multi-granularity and multi-tasking neural architectures to jointly perform both the sentence and fragment level propaganda de- tection.",
            "), lay- out and topical features. Speci\ufb01cally, we have designed multi-granularity and multi-tasking neural architectures to jointly perform both the sentence and fragment level propaganda de- tection. Additionally, we investigate different ensemble schemes such as majority-voting, relax-voting, etc. to boost overall system per- formance. Compared to the other participating systems, our submissions are ranked 3rd and 4th in FLC and SLC tasks, respectively. 1 Introduction In the age of information dissemination without quality control, it has enabled malicious users to spread misinformation via social media and aim individual users with propaganda campaigns to achieve political and \ufb01nancial gains as well as ad- vance a speci\ufb01c agenda. Often disinformation is complied in the two major forms: fake news and propaganda, where they differ in the sense that the propaganda is possibly built upon true information (e.g., biased, loaded language, repetition, etc.).",
            "Often disinformation is complied in the two major forms: fake news and propaganda, where they differ in the sense that the propaganda is possibly built upon true information (e.g., biased, loaded language, repetition, etc.). Prior works (Rashkin et al., 2017; Habernal et al., 2017; Barr\u00b4on-Cede\u02dcno et al., 2019) in de- tecting propaganda have focused primarily at doc- ument level, typically labeling all articles from a propagandistic news outlet as propaganda and thus, often non-propagandistic articles from the outlet are mislabeled. To this end, Da San Mar- tino et al. (2019) focuses on analyzing the use of propaganda and detecting speci\ufb01c propagandistic techniques in news articles at sentence and frag- ment level, respectively and thus, promotes ex- plainable AI. For instance, the following text is a propaganda of type \u2018slogan\u2019.",
            "(2019) focuses on analyzing the use of propaganda and detecting speci\ufb01c propagandistic techniques in news articles at sentence and frag- ment level, respectively and thus, promotes ex- plainable AI. For instance, the following text is a propaganda of type \u2018slogan\u2019. Trump tweeted: \u2018\u2018BUILD THE WALL!\u201d | {z } slogan Shared Task: This work addresses the two tasks in propaganda detection (Da San Mar- tino et al., 2019) of different granularities: (1) Sentence-level Classi\ufb01cation (SLC), a binary clas- si\ufb01cation that predicts whether a sentence con- tains at least one propaganda technique, and (2) Fragment-level Classi\ufb01cation (FLC), a token-level (multi-label) classi\ufb01cation that identi\ufb01es both the spans and the type of propaganda technique(s). Contributions: (1) To address SLC, we de- sign an ensemble of different classi\ufb01ers based on Logistic Regression, CNN and BERT, and lever- age transfer learning bene\ufb01ts using the pre-trained embeddings\/models from FastText and BERT.",
            "Contributions: (1) To address SLC, we de- sign an ensemble of different classi\ufb01ers based on Logistic Regression, CNN and BERT, and lever- age transfer learning bene\ufb01ts using the pre-trained embeddings\/models from FastText and BERT. We also employed different features such as linguistic (sentiment, readability, emotion, part-of-speech and named entity tags, etc.), layout, topics, etc. (2) To address FLC, we design a multi-task neural se- quence tagger based on LSTM-CRF and linguistic features to jointly detect propagandistic fragments and its type. Moreover, we investigate perform- ing FLC and SLC jointly in a multi-granularity network based on LSTM-CRF and BERT. (3) Our system (MIC-CIS) is ranked 3rd (out of 12 partic- ipants) and 4th (out of 25 participants) in FLC and SLC tasks, respectively.",
            "(3) Our system (MIC-CIS) is ranked 3rd (out of 12 partic- ipants) and 4th (out of 25 participants) in FLC and SLC tasks, respectively. 2 System Description 2.1 Linguistic, Layout and Topical Features Some of the propaganda techniques (Da San Mar- tino et al., 2019) involve word and phrases that express strong emotional implications, exaggera- tion, minimization, doubt, national feeling, label- arXiv:1909.06162v1  [cs.CL]  13 Sep 2019",
            "Category Feature Description Linguistic POS part-of-speech tags using NLTk toolkit NER named-entity tags using spacy toolkit, selected tags: {PERSON, NORP, FAC, ORG, GPE, LOC, EVENT, WORK OF ART, LAW, LANGUAGE} character analysis count of question and exclamation marks in sentence capital features for each word: \ufb01rst-char-capital, all-char-capital, etc. readability readability and complexity scores using measures from textstat API multi-meaning sum of meanings of a word (grouped by POS) or its synonym nest in the sentence using WordNet sentiment polarity (positive, negative, neural, compound) scores using spacy; subjectivity using TextBlob; max pos: maximum of positive, max neg: max of negative scores of each word in the sentence emotional Emotion features (sadness, joy, fear, disgust, and anger) using IBM Watson NLU API loaded words list of speci\ufb01c words and phrases with strong emotional implications (positive or negative) Layout sentence position categorized as [FIRST, TOP, MIDDLE, BOTTOM, LAST], where, FIRST: 1st, TOP: < 30%, Middle: between 30-70%, BOTTOM: > 70%,",
            "TOP, MIDDLE, BOTTOM, LAST], where, FIRST: 1st, TOP: < 30%, Middle: between 30-70%, BOTTOM: > 70%, LAST: last sentence of document sentence length (l) categorized as [= 2, 2 < l \u22644, 4 < l \u22648, 8 < l \u226420, 20 < l \u226440, 40 < l \u226460, l > 60] Topical topics document-topic proportion using LDA, features derived using dominant topic (DT): [DT of current sentence == DT of document, DT of current sentence == DT of the next and previous sentences] Representation word vector pre-trained word vectors from FastText (FastTextWordEmb) and BERT (BERTWordEmb) sentence vector summing word vectors of the sentence to obtain FastTextSentEmb and BERTSentEmb Decision relax-boundary (binary classi\ufb01cation) Relax decision boundary and tag propaganda if prediction probability \u2265\u03c4 Ensemble majority-voting Propaganda if majority says propaganda.",
            "In con\ufb02ict, take prediction of the model with highest F1 relax-voting Propaganda if M \u2208[20%, 30%, 40%] of models in the ensemble says propaganda. Table 1: Features used in SLC and FLC tasks ing , stereotyping, etc. This inspires1 us in extract- ing different features (Table 1) including the com- plexity of text, sentiment, emotion, lexical (POS, NER, etc.), layout, etc. To further investigate, we use topical features (e.g., document-topic propor- tion) (Blei et al., 2003; Gupta et al., 2019a, 2018) at sentence and document levels in order to deter- mine irrelevant themes, if introduced to the issue being discussed (e.g., Red Herring). For word and sentence representations, we use pre-trained vectors from FastText (Bojanowski et al., 2017) and BERT (Devlin et al., 2019).",
            "For word and sentence representations, we use pre-trained vectors from FastText (Bojanowski et al., 2017) and BERT (Devlin et al., 2019). 2.2 Sentence-level Propaganda Detection Figure 1 (left) describes the three components of our system for SLC task: features, classi\ufb01ers and ensemble. The arrows from features-to-classi\ufb01er indicate that we investigate linguistic, layout and topical features in the two binary classi\ufb01ers: Lo- gisticRegression and CNN. For CNN, we fol- low the architecture of Kim (2014) for sentence- level classi\ufb01cation, initializing the word vectors by FastText or BERT. We concatenate features in the last hidden layer before classi\ufb01cation. One of our strong classi\ufb01ers includes BERT that has achieved state-of-the-art performance on mul- 1some features from datasciencesociety.net\/ detecting-propaganda-on-sentence-level\/ tiple NLP benchmarks. Following Devlin et al.",
            "One of our strong classi\ufb01ers includes BERT that has achieved state-of-the-art performance on mul- 1some features from datasciencesociety.net\/ detecting-propaganda-on-sentence-level\/ tiple NLP benchmarks. Following Devlin et al. (2019), we \ufb01ne-tune BERT for binary classi\ufb01ca- tion, initializing with a pre-trained model (i.e., BERT-base, Cased). Additionally, we apply a de- cision function such that a sentence is tagged as propaganda if prediction probability of the classi- \ufb01er is greater than a threshold (\u03c4). We relax the binary decision boundary to boost recall, similar to Gupta et al. (2019b). Ensemble of Logistic Regression, CNN and BERT: In the \ufb01nal component, we collect pre- dictions (i.e., propaganda label) for each sentence from the three (M = 3) classi\ufb01ers and thus, ob- tain M number of predictions for each sentence. We explore two ensemble strategies (Table 1): majority-voting and relax-voting to boost preci- sion and recall, respectively.",
            "We explore two ensemble strategies (Table 1): majority-voting and relax-voting to boost preci- sion and recall, respectively. 2.3 Fragment-level Propaganda Detection Figure 1 (right) describes our system for FLC task, where we design sequence taggers (Vu et al., 2016; Gupta et al., 2016) in three modes: (1) LSTM- CRF (Lample et al., 2016) with word embed- dings (w e) and character embeddings c e, token- level features (t f) such as polarity, POS, NER, etc. (2) LSTM-CRF+Multi-grain that jointly per- forms FLC and SLC with FastTextWordEmb and BERTSentEmb, respectively. Here, we add binary",
            "w_e c_e t_f w_e c_e t_f w_e c_e t_f w_e c_e t_f Trump tweeted BUILD THE LSTM LSTM LSTM LSTM CRF CRF CRF CRF NP NP B-P I-P O O B-Slogan I-Slogan FLC  Layer PFD  Layer multi-tasking wordLSTM LSTM charLSTM LSTM LSTM LSTM Logistic Regression CNN BERT +Finetune Linguistic Layout Topical Decision FastText BERT Ensemble P\/NP SLC  Layer w_e c_e t_f LSTM CRF I-P I-Slogan LSTM WALL Trump tweeted: \u201cBUILD THE WALL!\u201d P\/NP BERT CLASSIFY sentence- embedding SLC Features Classifier Figure 1: (Left): System description for SLC, including features, transfer learning using pre-trained word embed- dings from FastText and BERT and classi\ufb01ers: LogisticRegression, CNN and BERT \ufb01ne-tuning. (Right): System description for FLC, including multi-tasking LSTM-CRF architecture consisting of Propaganda Fragment Detec- tion (PFD) and FLC layers.",
            "(Right): System description for FLC, including multi-tasking LSTM-CRF architecture consisting of Propaganda Fragment Detec- tion (PFD) and FLC layers. Observe, a binary classi\ufb01cation component at the last hidden layer in the recurrent architecture that jointly performs PFD, FLC and SLC tasks (i.e., multi-grained propaganda detection). Here, P: Propaganda, NP: Non-propaganda, B\/I\/O: Begin, Intermediate and Other tags of BIO tagging scheme. sentence classi\ufb01cation loss to sequence tagging weighted by a factor of \u03b1. (3) LSTM-CRF+Multi- task that performs propagandistic span\/fragment detection (PFD) and FLC (fragment detection + 19-way classi\ufb01cation). Ensemble of Multi-grain, Multi-task LSTM- CRF with BERT: Here, we build an ensemble by considering propagandistic fragments (and its type) from each of the sequence taggers. In doing so, we \ufb01rst perform majority voting at the frag- ment level for the fragment where their spans ex- actly overlap.",
            "In doing so, we \ufb01rst perform majority voting at the frag- ment level for the fragment where their spans ex- actly overlap. In case of non-overlapping frag- ments, we consider all. However, when the spans overlap (though with the same label), we consider the fragment with the largest span. 3 Experiments and Evaluation Data: While the SLC task is binary, the FLC con- sists of 18 propaganda techniques (Da San Mar- tino et al., 2019). We split (80-20%) the annotated corpus into 5-folds and 3-folds for SLC and FLC tasks, respectively. The development set of each the folds is represented by dev (internal); however, the un-annotated corpus used in leaderboard com- parisons by dev (external). We remove empty and single token sentences after tokenization. Experimental Setup: We use PyTorch frame- work for the pre-trained BERT model (Bert-base- cased2), \ufb01ne-tuned for SLC task.",
            "We remove empty and single token sentences after tokenization. Experimental Setup: We use PyTorch frame- work for the pre-trained BERT model (Bert-base- cased2), \ufb01ne-tuned for SLC task. In the multi- granularity loss, we set \u03b1 = 0.1 for sentence clas- si\ufb01cation based on dev (internal, fold1) scores.",
            "In the multi- granularity loss, we set \u03b1 = 0.1 for sentence clas- si\ufb01cation based on dev (internal, fold1) scores. We 2github.com\/ThilinaRajapakse\/ pytorch-transformers-classification Task: SLC (25 participants) Task: FLC (12 participants) Team F1 \/ P \/ R Team F1 \/ P \/ R ltuorp .6323 \/ .6028 \/ .6649 newspeak .2488 \/ .2863 \/ .2201 ProperGander .6256 \/ .5649 \/ .7009 Antiganda .2267 \/ .2882 \/ .1869 YMJA .6249 \/ .6253 \/ .6246 MIC-CIS .1999 \/ .2234 \/ .1808 MIC-CIS .6231 \/ .5736 \/ .6819 Stalin .1453 \/ .1921 \/ .1169 TeamOne .6183 \/ .5779 \/ .6649 TeamOne .1311 \/ .3235 \/ .0822 Table 2: Comparison of our system (MIC-CIS) with top-5 participants: Scores on Test set for SLC and FLC use BIO tagging scheme of NER in FLC task.",
            "For CNN, we follow Kim (2014) with \ufb01lter-sizes of [2, 3, 4, 5, 6], 128 \ufb01lters and 16 batch-size. We com- pute binary-F1and macro-F13 (Tsai et al., 2006) in SLC and FLC, respectively on dev (internal). 3.1 Results: Sentence-Level Propaganda Table 3 shows the scores on dev (internal and ex- ternal) for SLC task. Observe that the pre-trained embeddings (FastText or BERT) outperform TF- IDF vector representation. In row r2, we apply logistic regression classi\ufb01er with BERTSentEmb that leads to improved scores over FastTextSen- tEmb. Subsequently, we augment the sentence vector with additional features that improves F1 on dev (external), however not dev (internal). Next, we initialize CNN by FastTextWordEmb or BERT- WordEmb and augment the last hidden layer (be- fore classi\ufb01cation) with BERTSentEmb and fea- ture vectors, leading to gains in F1 for both the dev sets.",
            "Next, we initialize CNN by FastTextWordEmb or BERT- WordEmb and augment the last hidden layer (be- fore classi\ufb01cation) with BERTSentEmb and fea- ture vectors, leading to gains in F1 for both the dev sets. Further, we \ufb01ne-tune BERT and apply differ- ent thresholds in relaxing the decision boundary, where \u03c4 \u22650.35 is found optimal. 3evaluation measure with strict boundary detection",
            "Dev (internal), Fold1 Dev (external) Features F1 \/ P \/ R F1 \/ P \/ R r1 logisticReg + TF-IDF .569 \/ .542 \/ .598 .506 \/ .529 \/ .486 r2 logisticReg + FastTextSentEmb .606 \/ .544 \/ .685 .614 \/ .595 \/ .635 + Linguistic .605 \/ .553 \/ .667 .613 \/ .593 \/ .633 + Layout .600 \/ .550 \/ .661 .611 \/ .591 \/ .633 + Topical .603 \/ .552 \/ .664 .612 \/ .592 \/ .633 r3 logisticReg + BERTSentEmb .614 \/ .560 \/ .679 .636 \/ .638 \/ .635 r4 + Linguistic, Layout, Topical .611 \/ .564 \/ .666 .643 \/ .641 \/ .644 r5 CNN + FastTextWordEmb .616 \/ .685 \/ .559 .563 \/ .655 \/ .494 r6 + BERTSentEmb .612 \/ .693 \/ .548 .568 \/ .673 \/ .491 r7 + Linguistic, Layout, Topical .648 \/ .630 \/ .668 .632 \/ .644 \/ .",
            "616 \/ .685 \/ .559 .563 \/ .655 \/ .494 r6 + BERTSentEmb .612 \/ .693 \/ .548 .568 \/ .673 \/ .491 r7 + Linguistic, Layout, Topical .648 \/ .630 \/ .668 .632 \/ .644 \/ .621 r8 CNN + BERTWordEmb .610 \/ .688 \/ .549 .544 \/ .667 \/ .459 r9 + Linguistic, Layout, Topical .616 \/ .671 \/ .570 .555 \/ .662 \/ .478 r10 BERT + Fine-tune (\u03c4 \u2265.50) .662 \/ .635 \/ .692 .639 \/ .653 \/ .625 r11 BERT + Fine-tune (\u03c4 \u2265.40) .664 \/ .625 \/ .708 .649 \/ .651 \/ .647 r12 BERT + Fine-tune (\u03c4 \u2265.35) .662 \/ .615 \/ .715 .650 \/ .647 \/ .654 Ensemble of (r3, r6, r12) within Fold1 r15 majority-voting |M| > 50% .666 \/ .663 \/ .671 .638 \/ .674 \/ .605 r16 relax-voting,",
            "662 \/ .615 \/ .715 .650 \/ .647 \/ .654 Ensemble of (r3, r6, r12) within Fold1 r15 majority-voting |M| > 50% .666 \/ .663 \/ .671 .638 \/ .674 \/ .605 r16 relax-voting, |M| \u226530% .645 \/ .528 \/ .826 .676 \/ .592 \/ .788 Ensemble+ of (r3, r6, r12) from each Fold1-5, i.e., |M| = 15 r17 majority-voting |M| > 50% .666 \/ .683 \/ .649 r18 relax-voting, |M| \u226540% .670 \/ .646 \/ .696 r19 relax-voting, |M| \u226530% .673 \/ .619 \/ .737 r20 + postprocess (w=10, \u03bb \u2265.99) .669 \/ .612 \/ .737 r21 + postprocess (w=10, \u03bb \u2265.95) .671 \/ .612 \/ .741 Ensemble of (r4, r7, r12) within Fold1 r22 majority-voting |M| > 50% .669 \/ .",
            "99) .669 \/ .612 \/ .737 r21 + postprocess (w=10, \u03bb \u2265.95) .671 \/ .612 \/ .741 Ensemble of (r4, r7, r12) within Fold1 r22 majority-voting |M| > 50% .669 \/ .641 \/ .699 .660 \/ .663 \/ .656 r23 relax-voting, |M| \u226530% .650 \/ .525 \/ .852 .674 \/ .584 \/ .797 Ensemble+ of (r4, r7, r12) from each Fold1-5, i.e., |M| = 15 r24 majority-voting |M| > 50% .658 \/ .671 \/ .645 r25 relax-voting, |M| \u226540% .673 \/ .644 \/ .705 r26 relax-voting, |M| \u226530% .679 \/ .622 \/ .747 r27 + postprocess (w=10, \u03bb \u2265.99) .674 \/ .615 \/ .747 r28 + postprocess (w=10, \u03bb \u2265.95) .676 \/ .615 \/ .",
            "|M| \u226530% .679 \/ .622 \/ .747 r27 + postprocess (w=10, \u03bb \u2265.99) .674 \/ .615 \/ .747 r28 + postprocess (w=10, \u03bb \u2265.95) .676 \/ .615 \/ .751 Table 3: SLC: Scores on Dev (internal) of Fold1 and Dev (external) using different classi\ufb01ers and features. We choose the three different models in the en- semble: Logistic Regression, CNN and BERT on fold1 and subsequently an ensemble+ of r3, r6 and r12 from each fold1-5 (i.e., 15 models) to obtain predictions for dev (external). We investi- gate different ensemble schemes (r17-r19), where we observe that the relax-voting improves recall and therefore, the higher F1 (i.e., 0.673). In post- process step, we check for repetition propaganda technique by computing cosine similarity between the current sentence and its preceding w = 10 sentence vectors (i.e., BERTSentEmb) in the doc- ument.",
            "In post- process step, we check for repetition propaganda technique by computing cosine similarity between the current sentence and its preceding w = 10 sentence vectors (i.e., BERTSentEmb) in the doc- ument. If the cosine-similarity is greater than \u03bb \u2208{.99, .95}, then the current sentence is la- beled as propaganda due to repetition. Comparing r19 and r21, we observe a gain in recall, however an overall decrease in F1 applying postprocess. Dev (internal), Fold1 Dev (external) Features F1 \/ P \/ R F1 \/ P \/ R (I) LSTM-CRF + FastTextWordEmb .153 \/ .228 \/ .115 .122 \/ .248 \/ .081 (II) + Polarity, POS, NER .158 \/ .292 \/ .102 .101 \/ .286 \/ .061 (III) + Multi-grain (SLC+FLC) .148 \/ .215 \/ .112 .119 \/ .200 \/ .085 (IV) + BERTSentEmb .152 \/ .264 \/ .106 .099 \/ .248 \/ .062 (V) + Multi-task (PFD) .144 \/ .187 \/ .",
            "148 \/ .215 \/ .112 .119 \/ .200 \/ .085 (IV) + BERTSentEmb .152 \/ .264 \/ .106 .099 \/ .248 \/ .062 (V) + Multi-task (PFD) .144 \/ .187 \/ .117 .114 \/ .179 \/ .083 Ensemble of (II and IV) within Fold1 + postprocess .116 \/ .221 \/ .076 Ensemble of (II and IV) within Fold2 + postprocess .129 \/ .261 \/ .085 Ensemble of (II and IV) within Fold3 + postprocess .133 \/ .220 \/ .095 Ensemble+ of (II and IV) from each Fold1-3, i.e., |M| = 6 + postprocess .164 \/ .182 \/ .150 Table 4: FLC: Scores on Dev (internal) of Fold1 and Dev (external) with different models, features and en- sembles. PFD: Propaganda Fragment Detection. Finally, we use the con\ufb01guration of r19 on the test set. The ensemble+ of (r4, r7 r12) was ana- lyzed after test submission.",
            "features and en- sembles. PFD: Propaganda Fragment Detection. Finally, we use the con\ufb01guration of r19 on the test set. The ensemble+ of (r4, r7 r12) was ana- lyzed after test submission. Table 2 (SLC) shows that our submission is ranked at 4th position. 3.2 Results: Fragment-Level Propaganda Table 4 shows the scores on dev (internal and ex- ternal) for FLC task. Observe that the features (i.e., polarity, POS and NER in row II) when intro- duced in LSTM-CRF improves F1. We run multi- grained LSTM-CRF without BERTSentEmb (i.e., row III) and with it (i.e., row IV), where the lat- ter improves scores on dev (internal), however not on dev (external). Finally, we perform multi- tasking with another auxiliary task of PFD. Given the scores on dev (internal and external) using dif- ferent con\ufb01gurations (rows I-V), it is dif\ufb01cult to infer the optimal con\ufb01guration.",
            "Finally, we perform multi- tasking with another auxiliary task of PFD. Given the scores on dev (internal and external) using dif- ferent con\ufb01gurations (rows I-V), it is dif\ufb01cult to infer the optimal con\ufb01guration. Thus, we choose the two best con\ufb01gurations (II and IV) on dev (in- ternal) set and build an ensemble+ of predictions (discussed in section 2.3), leading to a boost in re- call and thus an improved F1 on dev (external). Finally, we use the ensemble+ of (II and IV) from each of the folds 1-3, i.e., |M| = 6 models to obtain predictions on test. Table 2 (FLC) shows that our submission is ranked at 3rd position. 4 Conclusion and Future Work Our system (Team: MIC-CIS) explores differ- ent neural architectures (CNN, BERT and LSTM- CRF) with linguistic, layout and topical features to address the tasks of \ufb01ne-grained propaganda detection. We have demonstrated gains in per-",
            "formance due to the features, ensemble schemes, multi-tasking and multi-granularity architectures. Compared to the other participating systems, our submissions are ranked 3rd and 4th in FLC and SLC tasks, respectively. In future, we would like to enrich BERT models with linguistic, layout and topical features during their \ufb01ne-tuning. Further, we would also be in- terested in understanding and analyzing the neural network learning, i.e., extracting salient fragments (or key-phrases) in the sentence that generate pro- paganda, similar to Gupta and Sch\u00a8utze (2018) in order to promote explainable AI. References Alberto Barr\u00b4on-Cede\u02dcno, Giovanni Da San Martino, Is- raa Jaradat, and Preslav Nakov. 2019. Proppy: A system to unmask propaganda in online news.",
            "References Alberto Barr\u00b4on-Cede\u02dcno, Giovanni Da San Martino, Is- raa Jaradat, and Preslav Nakov. 2019. Proppy: A system to unmask propaganda in online news. In The Thirty-Third AAAI Conference on Arti\ufb01cial In- telligence, AAAI 2019, The Thirty-First Innovative Applications of Arti\ufb01cial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Edu- cational Advances in Arti\ufb01cial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - Febru- ary 1, 2019., pages 9847\u20139848. David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993\u20131022. Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information. TACL, 5:135\u2013146.",
            "Learn. Res., 3:993\u20131022. Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017. Enriching word vectors with subword information. TACL, 5:135\u2013146. Giovanni Da San Martino, Seunghak Yu, Alberto Barr\u00b4on-Cede\u02dcno, Rostislav Petrov, and Preslav Nakov. 2019. Fine-grained analysis of propaganda in news articles. In Proceedings of the 2019 Con- ference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, EMNLP-IJCNLP 2019, Hong Kong, China. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: pre-training of deep bidirectional transformers for language under- standing.",
            "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: pre-training of deep bidirectional transformers for language under- standing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Pa- pers), pages 4171\u20134186. Pankaj Gupta, Yatin Chaudhary, Florian Buettner, and Hinrich Sch\u00a8utze. 2019a. Document informed neural autoregressive topic models with distributional prior.",
            "Pankaj Gupta, Yatin Chaudhary, Florian Buettner, and Hinrich Sch\u00a8utze. 2019a. Document informed neural autoregressive topic models with distributional prior. In The Thirty-Third AAAI Conference on Arti\ufb01cial Intelligence, AAAI 2019, The Thirty-First Innova- tive Applications of Arti\ufb01cial Intelligence Confer- ence, IAAI 2019, The Ninth AAAI Symposium on Ed- ucational Advances in Arti\ufb01cial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - Febru- ary 1, 2019., pages 6505\u20136512. Pankaj Gupta, Subburam Rajaram, Hinrich Sch\u00a8utze, and Bernt Andrassy. 2018. Deep temporal- recurrent-replicated-softmax for topical trends over time.",
            "Pankaj Gupta, Subburam Rajaram, Hinrich Sch\u00a8utze, and Bernt Andrassy. 2018. Deep temporal- recurrent-replicated-softmax for topical trends over time. In Proceedings of the 2018 Conference of the North American Chapter of the Associa- tion for Computational Linguistics: Human Lan- guage Technologies, NAACL-HLT 2018, New Or- leans, Louisiana, USA, June 1-6, 2018, Volume 1 (Long Papers), pages 1079\u20131089. Pankaj Gupta, Subburam Rajaram, Hinrich Sch\u00a8utze, and Thomas A. Runkler. 2019b. Neural relation extraction within and across sentence boundaries.",
            "Pankaj Gupta, Subburam Rajaram, Hinrich Sch\u00a8utze, and Thomas A. Runkler. 2019b. Neural relation extraction within and across sentence boundaries. In The Thirty-Third AAAI Conference on Arti\ufb01cial Intelligence, AAAI 2019, The Thirty-First Innova- tive Applications of Arti\ufb01cial Intelligence Confer- ence, IAAI 2019, The Ninth AAAI Symposium on Ed- ucational Advances in Arti\ufb01cial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - Febru- ary 1, 2019., pages 6513\u20136520. Pankaj Gupta and Hinrich Sch\u00a8utze. 2018. LISA: explaining recurrent neural network judgments via layer-wise semantic accumulation and example to pattern transformation. In Proceedings of the Work- shop: Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP@EMNLP 2018, Brussels, Belgium, November 1, 2018, pages 154\u2013164.",
            "In Proceedings of the Work- shop: Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP@EMNLP 2018, Brussels, Belgium, November 1, 2018, pages 154\u2013164. Pankaj Gupta, Hinrich Sch\u00a8utze, and Bernt Andrassy. 2016. Table \ufb01lling multi-task recurrent neural net- work for joint entity and relation extraction. In COLING 2016, 26th International Conference on Computational Linguistics, Proceedings of the Con- ference: Technical Papers, December 11-16, 2016, Osaka, Japan, pages 2537\u20132547. Ivan Habernal, Raffael Hannemann, Christian Pol- lak, Christopher Klamm, Patrick Pauli, and Iryna Gurevych. 2017. Argotario: Computational argu- mentation meets serious games. In Proceedings of the 2017 Conference on Empirical Methods in Nat- ural Language Processing, EMNLP 2017, Copen- hagen, Denmark, September 9-11, 2017 - System Demonstrations, pages 7\u201312.",
            "In Proceedings of the 2017 Conference on Empirical Methods in Nat- ural Language Processing, EMNLP 2017, Copen- hagen, Denmark, September 9-11, 2017 - System Demonstrations, pages 7\u201312. Yoon Kim. 2014. Convolutional neural networks for sentence classi\ufb01cation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Lan- guage Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 1746\u20131751. Guillaume Lample, Miguel Ballesteros, Sandeep Sub- ramanian, Kazuya Kawakami, and Chris Dyer. 2016. Neural architectures for named entity recognition. In NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for",
            "Computational Linguistics: Human Language Tech- nologies, San Diego California, USA, June 12-17, 2016, pages 260\u2013270. Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana Volkova, and Yejin Choi. 2017. Truth of varying shades: Analyzing language in fake news and polit- ical fact-checking. In Proceedings of the 2017 Con- ference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017, pages 2931\u20132937. Richard Tzong-Han Tsai, Shih-Hung Wu, Wen-Chi Chou, Yu-Chun Lin, Ding He, Jieh Hsiang, Ting- Yi Sung, and Wen-Lian Hsu. 2006. Various criteria in the evaluation of biomedical named entity recog- nition. BMC Bioinformatics, 7:92. Ngoc Thang Vu, Heike Adel, Pankaj Gupta, and Hin- rich Sch\u00a8utze. 2016.",
            "2006. Various criteria in the evaluation of biomedical named entity recog- nition. BMC Bioinformatics, 7:92. Ngoc Thang Vu, Heike Adel, Pankaj Gupta, and Hin- rich Sch\u00a8utze. 2016. Combining recurrent and convo- lutional neural networks for relation classi\ufb01cation. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, pages 534\u2013539. Association for Computational Lin- guistics."
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-1909.06162.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 6213.999801635742,
    "avg_doclen_est": 159.3333282470703
}
