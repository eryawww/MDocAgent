[
  "arXiv:1712.03547v1  [cs.CL]  10 Dec 2017 Inducing Interpretability in Knowledge Graph Embeddings Chandrahas and Tathagata Sengupta and Cibi Pragadeesh and Partha Pratim Talukdar chandrahas@iisc.ac.in Abstract We study the problem of inducing inter- pretability in KG embeddings. Speci\ufb01- cally, we explore the Universal Schema (Riedel et al., 2013) and propose a method to induce interpretability. There have been many vector space models proposed for the problem, however, most of these meth- ods don\u2019t address the interpretability (se- mantics) of individual dimensions. In this work, we study this problem and propose a method for inducing interpretability in KG embeddings using entity co-occurrence statistics. The proposed method signi\ufb01- cantly improves the interpretability, while maintaining comparable performance in other KG tasks. 1 Introduction Knowledge Graphs such as Freebase, WordNet etc. have become important resources for support- ing many AI applications like web search, Q&A etc.",
  "The proposed method signi\ufb01- cantly improves the interpretability, while maintaining comparable performance in other KG tasks. 1 Introduction Knowledge Graphs such as Freebase, WordNet etc. have become important resources for support- ing many AI applications like web search, Q&A etc. They store a collection of facts in the form of a graph. The nodes in the graph represent real world entities such as Roger Federer, Tennis, United States etc while the edges represent rela- tionships between them. These KGs have grown huge, but they are still not complete (Toutanova et al., 2015). Hence the task of inferring new facts becomes impor- tant. Many vector space models have been proposed which can perform reasoning over KGs ef\ufb01ciently (Bordes et al., 2011), (Wang et al., 2014), (Lin et al., 2015), (Socher et al., 2013), (Riedel et al., 2013), (Toutanova et al., 2015) etc.",
  "These methods learn representations for entities and relations as vectors in a vector space, cap- turing global information about the KG. The task of KG inference is then de\ufb01ned as operations over these vectors. Some of these methods like (Riedel et al., 2013), (Toutanova et al., 2015) are capable of exploiting additional text data apart from the KG, resulting in better representations. Although these methods have shown good per- formance in applications, they don\u2019t address the problem of understanding semantics of individual dimensions of the KG embedding. A recent work (Xiao et al., 2016) addressed the problem of learn- ing semantic features for KGs. However, they don\u2019t directly use vector space modeling. In this work, we focus on incorporating in- terpretability in KG embeddings. Speci\ufb01cally, we aim to learn interpretable embeddings for KG entities by incorporating additional entity co- occurrence statistics from text data. This work is motivated by (Lau et al., 2014) who presented au- tomated methods for evaluating topics learned via topic modelling methods.",
  "Speci\ufb01cally, we aim to learn interpretable embeddings for KG entities by incorporating additional entity co- occurrence statistics from text data. This work is motivated by (Lau et al., 2014) who presented au- tomated methods for evaluating topics learned via topic modelling methods. We adapt these mea- sures for the vector space model and propose a method to directly maximize them while learning KG embedding. To the best of our knowledge, this work presents the \ufb01rst regularization term which induces interpretability in KG embeddings. 2 Related Work Several methods have been proposed for learning KG embeddings. They differ on the modeling of entities and relations, usage of text data and inter- pretability of the learned embeddings. We summa- rize some of these methods in following sections. 2.1 Vector-space models for KG Embeddings A very effective and powerful set of models are based on translation vectors. These models rep- resent entities as vectors in d-dimensional space, Rd and relations as translation vectors from head entity to tail entity, in either same or a pro- jected space. TransE(Bordes et al., 2011) is one of the initial works, which was later improved",
  "by many works [(Wang et al., 2014), (Lin et al., 2015), (Xiao et al., 2015b), (Xiao et al., 2015a), (Ji et al., 2015), (Fan et al., 2014)]. Also, there are methods which are able to incorporate text data while learning KG embeddings. (Riedel et al., 2013) is one such method, which assumes a com- bined universal schema of relations from KG as well as text. (Toutanova et al., 2015) further im- proves the performance by sharing parameters among similar textual relations. 2.2 Interpretability of Embedding While the vector space models perform well in many tasks, the semantics of learned representa- tions are not directly clear. This problem for word embeddings was addressed by (Murphy et al., 2012) where they proposed a set of constraints in- ducing interpretability. However, its adaptation for KG embeddings hasn\u2019t been addressed.",
  "This problem for word embeddings was addressed by (Murphy et al., 2012) where they proposed a set of constraints in- ducing interpretability. However, its adaptation for KG embeddings hasn\u2019t been addressed. A recent work (Xiao et al., 2016) addressed a sim- ilar problem, where they learn coherent seman- tic features for entities and relations in KG. Our method differs from theirs in the following two as- pects. Firstly, we use vector space modeling lead- ing directly to KG embeddings while they need to infer KG embeddings from their probabilistic model. Second, we incorporate additional infor- mation about entities which helps in learning in- terpretable embeddings. 3 Proposed Method We are interested in inducing interpretability in KG embeddings and regularization is one good way to do it. So we want to look at novel regulariz- ers in KG embeddings. Hence, we explore a mea- sure of coherence proposed in (Lau et al., 2014). This measure allows automated evaluation of the quality of topics learned by topic modeling meth- ods by using additional Point-wise Mutual Infor- mation (PMI) for word pairs.",
  "Hence, we explore a mea- sure of coherence proposed in (Lau et al., 2014). This measure allows automated evaluation of the quality of topics learned by topic modeling meth- ods by using additional Point-wise Mutual Infor- mation (PMI) for word pairs. It was also shown to have high correlation with human evaluation of topics. Based on this measure of coherence, we pro- pose a regularization term. This term can be used with existing KG embedding methods (eg (Riedel et al., 2013)) for inducing interpretability. It is described in the following sections. 3.1 Coherence In topic models, coherence of a topic can be de- termined by semantic relatedness among top enti- ties within the topic. This idea can also be used in vector space models by treating dimensions of the vector space as topics. With this assumption, we can use a measure of coherence de\ufb01ned in fol- lowing section for evaluating interpretability of the embeddings.",
  "This idea can also be used in vector space models by treating dimensions of the vector space as topics. With this assumption, we can use a measure of coherence de\ufb01ned in fol- lowing section for evaluating interpretability of the embeddings. 3.1.1 Coherence@k Coherence@k has been shown to have high correlation with human interpretability of topics learned via various topic modeling methods(Lau et al., 2014). Hence, we can expect interpretable embeddings by maximizing it. Coherence for top k entities along dimension l is de\ufb01ned as follows: Coherence@k(l) = k X i=2 i\u22121 X j=1 pij (1) where pij is PMI score between entities ei and ej extracted from text data. Coherence@k for the entity embedding matrix \u03b8e is de\ufb01ned as the aver- age over all dimensions. Coherence@k = 1 d d X l=1 Coherence@k(l) (2) 3.1.2 Inducing coherence while learning embeddings We want to learn an embedding matrix \u03b8e which has high coherence (i.e. which maximizes Coherence@k).",
  "Coherence@k = 1 d d X l=1 Coherence@k(l) (2) 3.1.2 Inducing coherence while learning embeddings We want to learn an embedding matrix \u03b8e which has high coherence (i.e. which maximizes Coherence@k). Since \u03b8e changes during train- ing, the set of top k entities along each dimension varies over iterations. Hence, directly maximizing Coherence@k seems to be tricky. An alternate approach could be to promote higher values for entity pairs having high PMI score pij. This will result in an embedding ma- trix \u03b8e with a high value of Coherence@k since high PMI entity pairs are more likely to be among top k entities. This idea can be captured by following coher- ence term C(\u03b8e, P) = n X i=2 i\u22121 X j=1 \u2225v(ei)\u22bav(ej) \u2212pij\u22252 (3) where P is entity-pair PMI matrix and v(e) de- note vector for entity e. This term can be used in the objective function de\ufb01ned in Equation 6",
  "3.2 Entity Model (Model-E) We use the Entity Model proposed in (Riedel et al., 2013) for learning KG embed- dings. This model assumes a vector v(e) for each entity and two vectors vs(r) and vo(r) for each relation of the KG. The score for the triple (es, r, eo) is given by, f(es, r, eo) = v(es)\u22bavs(r) + v(eo)\u22bavo(r) (4) Training these vectors requires incorrect triples. So, we use the closed world assumption. For each triple t \u2208T , we create two negative triples t\u2212 o and t\u2212 s by corrupting the object and subject of the triples respectively such that the corrupted triples don\u2019t appear in training, test or validation data. The loss for a triple pair is de\ufb01ned as loss(t, t\u2212) = \u2212log(\u03c3(f(t) \u2212f(t\u2212))).",
  "The loss for a triple pair is de\ufb01ned as loss(t, t\u2212) = \u2212log(\u03c3(f(t) \u2212f(t\u2212))). Then, the aggregate loss function is de\ufb01ned as L(\u03b8e, \u03b8r, T ) = 1 |T | X t\u2208T \u0000loss(t, t\u2212 o ) + loss(t, t\u2212 s ) \u0001 (5) 3.3 Objective The overall loss function can be written as follows: L(\u03b8e, \u03b8r, T ) + \u03bbcC(\u03b8e, P) + \u03bbrR(\u03b8e, \u03b8r) (6) Where R(\u03b8e, \u03b8r) = 1 2 \u0010 \u2225\u03b8e\u22252 + \u2225\u03b8r\u22252\u0011 is the L2 regularization term and \u03bbc and \u03bbr are hyper- parameters controlling the trade-off among differ- ent terms in the objective function. 4 Experiments and Results 4.1 Datasets We use the FB15k-237(Toutanova and Chen, 2015) dataset for experiments. It contains 14541 entities and 237 relations.",
  "4 Experiments and Results 4.1 Datasets We use the FB15k-237(Toutanova and Chen, 2015) dataset for experiments. It contains 14541 entities and 237 relations. The triples are split into training, validation and test set having 272115, 17535 and 20466 triples respectively. For extracting entity co-occurrences, we use the textual relations used in (Toutanova et al., 2015). It contains around 3.7 millions textual triples, which we use for calculating PMI for entity pairs. 4.2 Experimental Setup We use the method proposed in (Riedel et al., 2013) as the baseline. Please refer to Section 3.2 for more details. For evaluating the learned em- beddings, we test them on different tasks. All the hyper-parameters are tuned using performance (MRR) on validation data. We use 100 dimen- sions after cross validating among 50, 100 and 200 dimensions.",
  "For evaluating the learned em- beddings, we test them on different tasks. All the hyper-parameters are tuned using performance (MRR) on validation data. We use 100 dimen- sions after cross validating among 50, 100 and 200 dimensions. For regularization, we use \u03bbr = 0.01 (from 10, 1, 0.1, 0.01) and \u03bbc = 0.01 (from 10, 1, 0.1, 0.01) for L2 and coherence regulariza- tion respectively. We use multiple random initial- izations sampled from a Gaussian distribution. For optimization, we use gradient descent and stop op- timization when gradient becomes 0 upto 3 deci- mal places. The \ufb01nal performance measures are reported for test data. 4.3 Results In following sections, we compare the perfor- mance of the proposed method with the baseline method in different tasks. Please refer to Table 1 for results.",
  "The \ufb01nal performance measures are reported for test data. 4.3 Results In following sections, we compare the perfor- mance of the proposed method with the baseline method in different tasks. Please refer to Table 1 for results. 4.3.1 Interpretability For evaluating the interpretability, we use Coherence@k (Equation 2) , automated and man- ual word intrusion tests. In word intrusion test (Chang et al., 2009), top k(= 5) entities along a dimension are mixed with the bottom most en- tity (the intruder) in that dimension and shuf\ufb02ed. Then multiple (3 in our case) human annotators are asked to \ufb01nd out the intruder. We use ma- jority voting to \ufb01nalize one intruder. Amazon Mechanical Turk was used for crowdsourcing the task and we used 25 randomly selected dimen- sions for evaluation.",
  "We use ma- jority voting to \ufb01nalize one intruder. Amazon Mechanical Turk was used for crowdsourcing the task and we used 25 randomly selected dimen- sions for evaluation. For automated word intrusion (Lau et al., 2014), we calculate following score for all k + 1 entities AutoWI(ei) = k+1 X j=1,j\u0338=i pij (7) where pij are the PMI scores. The entity having least score is identi\ufb01ed as the intruder. We report the fraction of dimensions for which we were able to identify the intruder correctly. As we can see in Table 1, the proposed method achieves better values for Coherence@5 as a direct consequence of the regularization term, thereby maximizing coherence between appropri- ate entities. Performance on the word intrusion task also improves drastically as the intruder along each dimension is a lot easier to identify owing",
  "to the fact that the top entities for each dimension group together more conspicuously. Method Link Prediction MRR MR Hits@10(%) Baseline 31.6 \u00b1 0.08 121.9 \u00b1 1.80 48.3 \u00b1 0.39 Proposed 30.4 \u00b1 0.08 111.9 \u00b1 1.12 46.8 \u00b1 0.08 Triple Classi\ufb01cation AUC(%) Accuracy(%) Baseline 72.9 \u00b1 0.16 63.2 \u00b1 0.50 Proposed 73.2 \u00b1 0.28 67.6 \u00b1 0.17 Interpretability AutoWI@5(%) Coherence@5 Manual WI(%) Baseline 6 \u00b1 4.14 \u221247.4 \u00b1 4.68 12 Proposed 66 \u00b1 5.89 \u221212.5 \u00b1 4.48 84 Table 1: Results on test data. The pro- posed method signi\ufb01cantly improves interpretabil- ity while maintaining comparable performance on KG tasks (Section 4.3).",
  "The pro- posed method signi\ufb01cantly improves interpretabil- ity while maintaining comparable performance on KG tasks (Section 4.3). Top 5 Baseline -Jurist, Pipe organ, USA, Lions Gate Entertainment, UK -Guitar, 71st Academy Awards, Jurist, Piano, Bass guitar -Actor, Of\ufb01cial Website, Screenwriter, Film Producer, USA -Jurist, USA, Marriage, Male, UK -Pipe organ, Of\ufb01cial Website, Actor, Film Producer, Screenwriter Proposed Method -Juris Doctor, Business Administration, Biology, Psychology, BS -Bachelor of Arts, PhD, Bachelor\u2019s degree, BS, MS -European Union, Europe, Netherlands, Portugal, Government -UK, Hollywood, DVD, London, Europe -Hollywood, Academy Awards, USA, DVD, Los Angeles Table 2: Top 5 and bottom most entities for ran- domly selected dimensions. As we see, the pro- posed method produces more coherent entities compared to the baseline. Incoherent entities are marked in bold face.",
  "As we see, the pro- posed method produces more coherent entities compared to the baseline. Incoherent entities are marked in bold face. 2 4.3.2 Link Prediction In this experiment, we test the model\u2019s ability to predict the best object entity for a given subject entity and relation. For each of the triples, we \ufb01x the subject and the relation and rank all entities (within same category as true object entity) based on their score according to Equation 4. We re- port Mean Rank (MR) and Mean Reciprocal rank (MRR) of the true object entity and Hits@10 (the number of times true object entity is ranked in top 10) as percentage. The objective of the coherence regularization term being tangential to that of the original loss function, is not expected to affect performance on the link prediction task. However, the results show a trivial drop of 1.2 in MRR as the coherence term gives credibility to triples that are otherwise deemed incorrect by the closed world assumption. 4.3.3 Triple Classi\ufb01cation In this experiment, we test the model on classify- ing correct and incorrect triples.",
  "4.3.3 Triple Classi\ufb01cation In this experiment, we test the model on classify- ing correct and incorrect triples. For \ufb01nding in- correct triples, we corrupt the object entity with a randomly selected entity within the same cate- gory. For classi\ufb01cation, we use validation data to \ufb01nd the best threshold for each relation by training an SVM classi\ufb01er and later use this threshold for classifying test triples. We report the mean accu- racy and mean AUC over all relations. We observe that the proposed method achieves slightly better performance for triple classi\ufb01cation improving the accuracy by 4.4. The PMI infor- mation adds more evidence to the correct triples which are related in text data, generating a better threshold that more accurately distinguishes cor- rect and incorrect triples. 4.4 Qualitative Analysis of Results Since our aim is to induce interpretability in rep- resentations, in this section, we evaluate the em- beddings learned by the baseline as well as the proposed method. For both methods, we select some dimensions randomly and present top 5 en- tities along those dimensions.",
  "For both methods, we select some dimensions randomly and present top 5 en- tities along those dimensions. The results are pre- sented in Table 2. As we can see from the results, the proposed method produces more coherent entities than the baseline method. 5 Conclusion and Future Works In this work, we proposed a method for induc- ing interpretability in KG embeddings using a co- herence regularization term. We evaluated the proposed and the baseline method on the inter- pretability of the learned embeddings. We also evaluated the methods on different KG tasks and compared their performance. We found that the proposed method achieves better interpretability while maintaining comparable performance on KG tasks. As next steps, we plan to evaluate the generalizability of the method with more recent KG embeddings. 2We have used abbreviations for BS (Bachelor of Sci- ence), MS (Master of Science), UK (United Kingdom) and USA (United States of America). They appear as full form in the data.",
  "References Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. 2011. Learning structured embed- dings of knowledge bases. In Conference on Arti\ufb01- cial Intelligence. EPFL-CONF-192344. Jonathan Chang, Jordan L Boyd-Graber, Sean Gerrish, Chong Wang, and David M Blei. 2009. Reading tea leaves: How humans interpret topic models. In Nips. volume 31, pages 1\u20139. Miao Fan, Qiang Zhou, Emily Chang, and Thomas Fang Zheng. 2014. Transition-based knowledge graph embedding with relational mapping properties. In PACLIC. pages 328\u2013337. Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and Jun Zhao. 2015. Knowledge graph embedding via dy- namic mapping matrix. In ACL (1). pages 687\u2013696. Jey Han Lau, David Newman, and Timothy Baldwin. 2014. Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality. In EACL. pages 530\u2013539.",
  "In ACL (1). pages 687\u2013696. Jey Han Lau, David Newman, and Timothy Baldwin. 2014. Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality. In EACL. pages 530\u2013539. Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning entity and relation em- beddings for knowledge graph completion. In AAAI. pages 2181\u20132187. Brian Murphy, Partha Pratim Talukdar, and Tom Mitchell. 2012. Learning effective and interpretable semantic models using non-negative sparse embed- ding. In International Conference on Computa- tional Linguistics (COLING 2012), Mumbai, India. http://aclweb.org/anthology/C/C12/C12-1118.pdf. Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. 2013. Relation extraction with matrix factorization and universal schemas. NAACL HLT 2013 pages 74\u201384.",
  "Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. 2013. Relation extraction with matrix factorization and universal schemas. NAACL HLT 2013 pages 74\u201384. Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. 2013. Reasoning with neural ten- sor networks for knowledge base completion. In Ad- vances in Neural Information Processing Systems. pages 926\u2013934. Kristina Toutanova and Danqi Chen. 2015. Observed versus latent features for knowledge base and text inference. In 3rd Workshop on Continuous Vec- tor Space Models and Their Compositionality. ACL Association for Computational Linguistics. Kristina Toutanova, Danqi Chen, Patrick Pantel, Hoi- fung Poon, Pallavi Choudhury, and Michael Gamon. 2015. Representing Text for Joint Embedding of Text and Knowledge Bases. In Empirical Methods in Natural Language Processing (EMNLP). ACL Association for Computational Linguistics. Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014.",
  "2015. Representing Text for Joint Embedding of Text and Knowledge Bases. In Empirical Methods in Natural Language Processing (EMNLP). ACL Association for Computational Linguistics. Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by trans- lating on hyperplanes. In AAAI. Citeseer, pages 1112\u20131119. Han Xiao, Minlie Huang, Yu Hao, and Xiaoyan Zhu. 2015a. Transa: An adaptive approach for knowledge graph embedding. arXiv preprint arXiv:1509.05490 . Han Xiao, Minlie Huang, Yu Hao, and Xiaoyan Zhu. 2015b. Transg: A generative mixture model for knowledge graph embedding. arXiv preprint arXiv:1509.05488 . Han Xiao, Minlie Huang, and Xiaoyan Zhu. 2016. Knowledge semantic representation: A generative model for interpretable knowledge graph embed- ding. arXiv preprint arXiv:1608.07685 ."
]