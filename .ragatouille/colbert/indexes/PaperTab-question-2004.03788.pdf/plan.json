{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "arXiv:2004.03788v1  [cs.CL]  8 Apr 2020 Satirical News Detection with Semantic Feature Extraction and Game-theoretic Rough Sets Yue Zhou1, Yan Zhang1, and JingTao Yao2 1 School of Computer Science and Engineering California State University, San Bernardino, CA USA 2 Department of Computer Science, University of Regina, SK Canada Yue.Zhou@csusb.edu, Yan.Zhang@csusb.edu, jtyao@cs.uregina.ca Abstract. Satirical news detection is an important yet challenging task to prevent spread of misinformation. Many feature based and end-to-end neural nets based satirical news detection systems have been proposed and delivered promising results. Existing approaches explore comprehen- sive word features from satirical news articles, but lack semantic metrics using word vectors for tweet form satirical news. Moreover, the vague- ness of satire and news parody determines that a news tweet can hardly be classi\ufb01ed with a binary decision, that is, satirical or legitimate. To address these issues, we collect satirical and legitimate news tweets, and propose a semantic feature based approach.",
            "Moreover, the vague- ness of satire and news parody determines that a news tweet can hardly be classi\ufb01ed with a binary decision, that is, satirical or legitimate. To address these issues, we collect satirical and legitimate news tweets, and propose a semantic feature based approach. Features are extracted by exploring inconsistencies in phrases, entities, and between main and rel- ative clauses. We apply game-theoretic rough set model to detect satirical news, in which probabilistic thresholds are derived by game equilibrium and repetition learning mechanism. Experimental results on the collected dataset show the robustness and improvement of the proposed approach compared with Pawlak rough set model and SVM. Keywords: Satirical news detection\u00b7 Social media\u00b7 Feature extraction\u00b7 Game-theoretic rough sets 1 Introduction Satirical news, which uses parody characterized in a conventional news style, has now become an entertainment on social media. While news satire is claimed to be pure comedic and of amusement, it makes statements on real events often with the aim of attaining social criticism and in\ufb02uencing change [15]. Satirical news can also be misleading to readers, even though it is not designed for falsi\ufb01cations.",
            "Satirical news can also be misleading to readers, even though it is not designed for falsi\ufb01cations. Given such sophistication, satirical news detection is a necessary yet challenging natural language processing (NLP) task. Many feature based fake or satirical news detection systems [3,11,14] extract features from word relations given by statistics or lexical database, and other linguistic features. In addition, with the great success of deep learning in NLP in recent years, many end-to-end neural nets based detection systems [6,12,16] have been proposed and delivered promising results on satirical news article detection.",
            "2 Y. Zhou & Y. Zhang & J. T. Yao However, with the evolution of fast-paced social media, satirical news has been condensed into a satirical-news-in-one-sentence form. For example, one sin- gle tweet of \u201cIf earth continues to warm at current rate moon will be mostly un- derwater by 2400\u201d by The Onion is largely consumed and spread by social media users than the corresponding full article posted on The Onion website. Exist- ing detection systems trained on full document data might not be applicable to such form of satirical news. Therefore, we collect news tweets from satirical news sources such as The Onion, The New Yorker (Borowitz Report) and legitimate news sources such as Wall Street Journal and CNN Breaking News. We explore the syntactic tree of the sentence and extract inconsistencies between attributes and head noun in noun phrases. We also detect the existence of named entities and relations between named entities and noun phrases as well as contradictions between the main clause and corresponding prepositional phrase. For a satiri- cal news, such inconsistencies often exist since satirical news usually combines irrelevant components so as to attain surprise and humor.",
            "We also detect the existence of named entities and relations between named entities and noun phrases as well as contradictions between the main clause and corresponding prepositional phrase. For a satiri- cal news, such inconsistencies often exist since satirical news usually combines irrelevant components so as to attain surprise and humor. The discrepancies are measured by cosine similarity between word components where words are represented by Glove [9]. Sentence structures are derived by Flair, a state-of- the-art NLP framework, which better captures part-of-speech and named entity structures [1]. Due to the obscurity of satire genre and lacks of information given tweet form satirical news, there exists ambiguity in satirical news, which causes great di\ufb03- culty to make a traditional binary decision. That is, it is di\ufb03cult to classify one news as satirical or legitimate with available information. Three-way decisions, proposed by YY Yao, added an option - deferral decision in the traditional yes- and-no binary decisions and can be used to classify satirical news [21,22]. That is, one news may be classi\ufb01ed as satirical, legitimate, and deferral.",
            "Three-way decisions, proposed by YY Yao, added an option - deferral decision in the traditional yes- and-no binary decisions and can be used to classify satirical news [21,22]. That is, one news may be classi\ufb01ed as satirical, legitimate, and deferral. We apply rough sets model, particularly the game-theoretic rough sets to classify news into three groups, i.e., satirical, legitimate, and deferral. Game-theoretic rough set (GTRS) model, proposed by JT Yao and Herbert, is a recent promising model for decision making in the rough set context [18]. GTRS determine three deci- sion regions from a tradeo\ufb00perspective when multiple criteria are involved to evaluate the classi\ufb01cation models [25]. Games are formulated to obtain a tradeo\ufb00 between involved criteria. The balanced thresholds of three decision regions can be induced from the game equilibria. GTRS have been applied in recommen- dation systems [2], medical decision making [19], uncertainty analysis [24], and spam \ufb01ltering [23].",
            "The balanced thresholds of three decision regions can be induced from the game equilibria. GTRS have been applied in recommen- dation systems [2], medical decision making [19], uncertainty analysis [24], and spam \ufb01ltering [23]. We apply GTRS model on our preprocessed dataset and divide all news into satirical, legitimate, or deferral regions. The probabilistic thresholds that de- termine three decision regions are obtained by formulating competitive games between accuracy and coverage and then \ufb01nding Nash equilibrium of games. We perform extensive experiments on the collected dataset, \ufb01ne-tuning the model by di\ufb00erent discretization methods and variation of equivalent classes. The ex- perimental result shows that the performance of the proposed model is superior compared with Pawlak rough sets model and SVM.",
            "Satirical News Detection with Semantic Feature Extraction and GTRS 3 2 Related Work Satirical news detection is an important yet challenging NLP task. Many feature based models have been proposed. Burfoot et al. extracted features of headline, profanity, and slang using word relations given by statistical metrics and lexical database [3]. Rubin et al. proposed a SVM based model with \ufb01ve features (absur- dity, humor, grammar, negative a\ufb00ect, and punctuation) for fake news document detection [11]. Yang et al. presented linguistic features such as psycholinguistic feature based on dictionary and writing stylistic feature from part-of-speech tags distribution frequency [17]. Shu et al. gave a survey in which a set of feature ex- traction methods is introduced for fake news on social media [14]. Conroy et al. also uses social network behavior to detect fake news [4]. For satirical sentence classi\ufb01cation, Davidov et al. extract patterns using word frequency and punc- tuation features for tweet sentences and amazon comments [5].",
            "Conroy et al. also uses social network behavior to detect fake news [4]. For satirical sentence classi\ufb01cation, Davidov et al. extract patterns using word frequency and punc- tuation features for tweet sentences and amazon comments [5]. The detection of a certain type of sarcasm which contracts positive sentiment with a negative situation by analyzing the sentence pattern with a bootstrapped learning was also discussed [10]. Although word level statistical features are widely used, with advanced word representations and state-of-the-art part-of-speech tagging and named entity recognition model, we observe that semantic features are more important than word level statistical features to model performance. Thus, we decompose the syntactic tree and use word vectors to more precisely capture the semantic inconsistencies in di\ufb00erent structural parts of a satirical news tweet. Recently, with the success of deep learning in NLP, many researchers at- tempted to detect fake news with end-to-end neural nets based approaches. Ruchansky et al. proposed a hybrid deep neural model which processes both text and user information [12], while Wang et al.",
            "Recently, with the success of deep learning in NLP, many researchers at- tempted to detect fake news with end-to-end neural nets based approaches. Ruchansky et al. proposed a hybrid deep neural model which processes both text and user information [12], while Wang et al. proposed a neural network model that takes both text and image data [16] for detection. Sarkar et al. presented a neural network with attention to both capture sentence level and document level satire [6]. Some research analyzed sarcasm from non-news text. Ghosh and Veale [7] used both the linguistic context and the psychological context informa- tion with a bi-directional LSTM to detect sarcasm in users\u2019 tweets. They also published a feedback-based dataset by collecting the responses from the tweets authors for future analysis. While all these works detect fake news given full text or image content, or target on non-news tweets, we attempt bridge the gap and detect satirical news by analyzing news tweets which concisely summarize the content of news. 3 Methodology In this section, we will describe the composition and preprocessing of our dataset and introduce our model in detail.",
            "3 Methodology In this section, we will describe the composition and preprocessing of our dataset and introduce our model in detail. We create our dataset by collecting legitimate and satirical news tweets from di\ufb00erent news source accounts. Our model aims to detect whether the content of a news tweet is satirical or legitimate. We \ufb01rst extract the semantic features based on inconsistencies in di\ufb00erent structural parts of the tweet sentences, and then use these features to train game-theoretic rough set decision model.",
            "4 Y. Zhou & Y. Zhang & J. T. Yao 3.1 Dataset We collected approximately 9,000 news tweets from satirical news sources such as The Onion and Borowitz Report and about 11,000 news tweets from legitimate new sources such as Wall Street Journal and CNN Breaking News over the past three years. Each tweet is a concise summary of a news article. The duplicated and extreme short tweets are removed.A news tweet is labeled as satirical if it is written by satirical news sources and legitimate if it is from legitimate news sources. Table 1 gives an example of tweet instances that comprise our dataset. Table 1. Examples of instances comprising the news tweet dataset Content Source Label The White House con\ufb01rms that President Donald Trump sent a letter to North Korean leader Kim Jong Un. CNN 0 Illinois Senate plans vote on bills that could become the state\u2019s \ufb01rst budget in more than two years. WSJ 0 Naked Andrew Yang emerges from time vortex to warn debate audience about looming threat Of automation. TheOnion 1 New study shows majority of late afternoon sleepiness at Work caused by undetected carbon monoxide leak.",
            "WSJ 0 Naked Andrew Yang emerges from time vortex to warn debate audience about looming threat Of automation. TheOnion 1 New study shows majority of late afternoon sleepiness at Work caused by undetected carbon monoxide leak. TheOnion 1 Devin Nunes accuses witnesses of misleading American people with facts. BorowitzReport 1 3.2 Semantic Feature Extraction Satirical news is not based on or does not aim to state the fact. Rather, it uses parody or humor to make statement, criticisms, or just amusements. In order to achieve such e\ufb00ect, contradictions are greatly utilized. Therefore, inconsistencies signi\ufb01cantly exist in di\ufb00erent parts of a satirical news tweet. In addition, there is a lack of entity or inconsistency between entities in news satire. We extracted these features at semantic level from di\ufb00erent sub-structures of the news tweet. Di\ufb00erent structural parts of the sentence are derived by part-of-speech tagging and named entity recognition by Flair.",
            "We extracted these features at semantic level from di\ufb00erent sub-structures of the news tweet. Di\ufb00erent structural parts of the sentence are derived by part-of-speech tagging and named entity recognition by Flair. The inconsistencies in di\ufb00erent structures are measured by cosine similarity of word phrases where words are represented by Glove word vectors. We explored three di\ufb00erent aspects of inconsistency and designed metrics for their measurements. A word level feature using tf-idf [13] is added for robustness. Inconsistency in Noun Phrase Structures One way for a news satire to obtain surprise or humor e\ufb00ect is to combine irrelevant or less jointly used attributes and the head noun which they modi\ufb01ed. For example, noun phrase such as \u201crampant accountability\u201d, \u201cposthumous apology\u201d, \u201cVatican basement\u201d,",
            "Satirical News Detection with Semantic Feature Extraction and GTRS 5 \u201cself-imposed mental construct\u201d and other rare combinations are widely used in satirical news, while individual words themselves are common. To measure such inconsistency, we \ufb01rst select all leaf noun phrases (NP) extracted from the semantic trees to avoid repeated calculation. Then for each noun phrase, each adjacent word pair is selected and represented by 100-dim Glove word vector denoted as (vt, wt). We de\ufb01ne the averaged cosine similarity of noun phrase word pairs as: SNP = 1 T T X t=1 cos(vt, wt) (1) where T is a total number of word pairs. We use SNP as a feature to capture the overall inconsistency in noun phrase uses. SNP ranges from -1 to 1, where a smaller value indicates more signi\ufb01cant inconsistency. Inconsistency Between Clauses Another commonly used rhetoric approach for news satire is to make contradiction between the main clause and its preposi- tional phrase or relative clause.",
            "SNP ranges from -1 to 1, where a smaller value indicates more signi\ufb01cant inconsistency. Inconsistency Between Clauses Another commonly used rhetoric approach for news satire is to make contradiction between the main clause and its preposi- tional phrase or relative clause. For instance, in the tweet \u201cTrump boys counter Chinese currency manipulation by adding extra zeros To $20 Bills.\u201d, contra- diction or surprise is gained by contrasting irrelevant statements provided by di\ufb00erent parts of the sentence. Let q and p denote two clauses separated by main\/relative relation or preposition, and (w1, w1, ...wq) and (v1, v1, ...vp) be the vectorized words in q and p. Then we de\ufb01ne inconsistency between q and p as: SQP = cos( Q X q=1 wq, P X p=1 vp)) (2) Similarly, the feature SQP is measured by cosine similarity of linear summations of word vectors, where smaller value indicates more signi\ufb01cant inconsistency.",
            "Inconsistency Between Named Entities and Noun Phrases Even though many satirical news tweets are made based on real persons or events, most of them lack speci\ufb01c entities. Rather, because the news is fabricated, news writers use the words such as \u201cman\u201d,\u201cwoman\u201d,\u201clocal man\u201d, \u201carea woman\u201d,\u201clocal fam- ily\u201d as subject. However, the inconsistency between named entities and noun phrases often exists in a news satire if a named entity is included. For exam- ple, the named entity \u201cAndrew Yang\u201d and the noun phrases \u201ctime vortex\u201d show great inconsistency than \u201cPresident Trump\u201d, \u201dSenate Republicans\u201d, and \u201cWhite House\u201d do in the legitimate news \u201cPresident Trump invites Senate Republicans to the White House to talk about the funding bill.\u201d We de\ufb01ne such inconsistency as a categorical feature that: CNERN = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 0 if SNERN < \u00afSNERN 1 if SNERN \u2265\u00afSNERN \u22121 if there\u2019s no named entity (3)",
            "6 Y. Zhou & Y. Zhang & J. T. Yao SNERN is the cosine similarity of named entities and noun phrases of a certain sentence and \u00afSNERN is the mean value of SNERN in corpus. Word Level Feature Using TF-IDF We calculated the di\ufb00erence of tf-idf scores between legitimate news corpus and satirical news corpus for each single word. Then, the set Svoc that includes most representative legitimate news words is created by selecting top 100 words given the tf-idf di\ufb00erence. For a news tweet and any word w in the tweet, we de\ufb01ne the binary feature Bvoc as: Bvoc = ( 1 if w \u2208Svoc 0 otherwise (4) 3.3 GTRS Decision Model We construct a Game-theoretic Rough Sets model for classi\ufb01cation given the extracted features. Suppose E \u2286U \u00d7 U is an equivalence relation on a \ufb01nite nonempty universe of objects U, where E is re\ufb02exive, symmetric, and transitive. The equivalence class containing an object x is given by [x] = {y \u2208U|xEy}.",
            "Suppose E \u2286U \u00d7 U is an equivalence relation on a \ufb01nite nonempty universe of objects U, where E is re\ufb02exive, symmetric, and transitive. The equivalence class containing an object x is given by [x] = {y \u2208U|xEy}. The objects in one equivalence class all have the same attribute values.",
            "The equivalence class containing an object x is given by [x] = {y \u2208U|xEy}. The objects in one equivalence class all have the same attribute values. In the satirical news context, given an unde\ufb01ned concept satire, probabilistic rough sets divide all news into three pairwise disjoint groups i.e., the satirical group POS(satire), legitimate group NEG(satire), and deferral group BND(satire), by using the conditional probability Pr(satire|[x]) = |satire\u2229[x]| |[x]| as the evaluation function, and (\u03b1, \u03b2) as the acceptance and rejection thresholds [20,21,22], that is, POS(\u03b1,\u03b2)(satire) = {x \u2208U | Pr(satire|[x]) \u2265\u03b1}, NEG(\u03b1,\u03b2)(satire) = {x \u2208U | Pr(satire|[x]) \u2264\u03b2}, BND(\u03b1,\u03b2)(satire) = {x \u2208U | \u03b2 < Pr(satire|[x]) < \u03b1}.",
            "(5) Given an equivalence class [x], if the conditional probability Pr(satire|[x]) is greater than or equal to the speci\ufb01ed acceptance threshold \u03b1, i.e., Pr(satire|[x]) \u2265 \u03b1, we accept the news in [x] as satirical. If Pr(satire|[x]) is less than or equal to the speci\ufb01ed rejection threshold \u03b2, i.e., Pr(satire|[x]) \u2264\u03b2 we reject the news in [x] as satirical, or we accept the news in [x] as legitimate. If Pr(satire|[x]) is between \u03b1 and \u03b2, i.e., \u03b2 < Pr(satire|[x]) < \u03b1, we defer to make decisions on the news in [x]. Pawlak rough sets can be viewed as a special case of probabilistic rough sets with (\u03b1, \u03b2) = (1, 0). Given a pair of probabilistic thresholds (\u03b1, \u03b2), we can obtain a news classi\ufb01er according to Equation (5).",
            "Pawlak rough sets can be viewed as a special case of probabilistic rough sets with (\u03b1, \u03b2) = (1, 0). Given a pair of probabilistic thresholds (\u03b1, \u03b2), we can obtain a news classi\ufb01er according to Equation (5). The three regions are a partition of the universe U, \u03c0(\u03b1,\u03b2)(Satire) = {POS(\u03b1,\u03b2)(Satire), BND(\u03b1,\u03b2)(Satire), NEG(\u03b1,\u03b2)(Satire)} (6) Then, the accuracy and coverage rate to evaluate the performance of the derived classi\ufb01er are de\ufb01ned as follows [25],",
            "Satirical News Detection with Semantic Feature Extraction and GTRS 7 Acc(\u03b1,\u03b2)(Satire) = |Satire \u2229POS(\u03b1,\u03b2)(Satire)| + |Satirec \u2229NEG(\u03b1,\u03b2)(Satire)| |POS(\u03b1,\u03b2)(Satire)| + |NEG(\u03b1,\u03b2)(Satire)| (7) Cov(\u03b1,\u03b2)(Satire) = |POS(\u03b1,\u03b2)(Satire)| + |NEG(\u03b1,\u03b2)(Satire)| |U| (8) The criterion coverage indicates the proportions of news that can be con\ufb01- dently classi\ufb01ed. Next, we will obtain (\u03b1, \u03b2) by game formulation and repetition learning. Game Formulation We construct a game G = {O, S, u} given the set of game players O, the set of strategy pro\ufb01le S, and the payo\ufb00functions u, where the accuracy and coverage are two players, respectively, i.e., O = {acc, cov}.",
            "The set of strategy pro\ufb01les S = Sacc \u00d7 Scov, where Sacc and Scov are sets of possible strategies or actions performed by players acc and cov. The initial thresholds are set as (1, 0). All these strategies are the changes made on the initial thresholds, Sacc = {\u03b2 no change, \u03b2 increases cacc, \u03b2 increases 2 \u00d7 cacc}, Scov = {\u03b1 no change, \u03b1 decreases ccov, \u03b1 decreases 2 \u00d7 ccov}. (9) cacc and ccov denote the change steps used by two players, and their values are determined by the concrete experiment date set. Payo\ufb00functions. The payo\ufb00s of players are u = (uacc, ucov), and uacc and ucov denote the payo\ufb00functions of players acc and cov, respectively. Given a strategy pro\ufb01le p = (s, t) with player acc performing s and player cov performing t, the payo\ufb00s of acc and cov are uacc(s, t) and ucov(s, t).",
            "Given a strategy pro\ufb01le p = (s, t) with player acc performing s and player cov performing t, the payo\ufb00s of acc and cov are uacc(s, t) and ucov(s, t). We use uacc(\u03b1, \u03b2) and ucov(\u03b1, \u03b2) to show this relationship. The payo\ufb00functions uacc(\u03b1, \u03b2) and ucov(\u03b1, \u03b2) are de\ufb01ned as, uacc(s, t) \u21d2uacc(\u03b1, \u03b2) = Acc(\u03b1,\u03b2)(Satire), ucov(s, t) \u21d2ucov(\u03b1, \u03b2) = Cov(\u03b1,\u03b2)(Satire), (10) where Acc(\u03b1,\u03b2)(Satire) and Cov(\u03b1,\u03b2)(Satire) are the accuracy and coverage de- \ufb01ned in Equations (7) and (8). Payo\ufb00table. We use payo\ufb00tables to represent the formulated game. Table 2 shows a payo\ufb00table example in which both players have 3 strategies de\ufb01ned in Equation refeq:stategies.",
            "Payo\ufb00table. We use payo\ufb00tables to represent the formulated game. Table 2 shows a payo\ufb00table example in which both players have 3 strategies de\ufb01ned in Equation refeq:stategies. The arrow \u2193denotes decreasing a value and \u2191denotes increasing a value. On each cell, the threshold values are determined by two players.",
            "8 Y. Zhou & Y. Zhang & J. T. Yao Table 2. An example of a payo\ufb00table cov \u03b1 \u03b1 \u2193ccov \u03b1 \u21932ccov \u03b2  uacc(\u03b1, \u03b2),  uacc(\u03b1 \u2212ccov, \u03b2),  uacc(\u03b1 \u22122ccov, \u03b2), ucov(\u03b1, \u03b2) \u000b ucov(\u03b1 \u2212ccov, \u03b2) \u000b ucov(\u03b1 \u22122ccov, \u03b2) \u000b acc \u03b2 \u2191cacc  uacc(\u03b1, \u03b2 + cacc),  uacc(\u03b1 \u2212ccov, \u03b2 + cacc),  uacc(\u03b1 \u22122ccov, \u03b2 + cacc), ucov(\u03b1, \u03b2 + cacc) \u000b ucov(\u03b1 \u2212ccov, \u03b2 + cacc) \u000b ucov(\u03b1 \u22122ccov, \u03b2 + cacc) \u000b \u03b2 \u21912cacc  uacc(\u03b1, \u03b2 +2cacc),  uacc(\u03b1\u2212ccov, \u03b2+2cacc),  uacc(\u03b1\u22122ccov, \u03b2+2cacc), ucov(\u03b1,",
            "\u03b2 + cacc) \u000b \u03b2 \u21912cacc  uacc(\u03b1, \u03b2 +2cacc),  uacc(\u03b1\u2212ccov, \u03b2+2cacc),  uacc(\u03b1\u22122ccov, \u03b2+2cacc), ucov(\u03b1, \u03b2 + 2cacc) \u000b ucov(\u03b1\u2212ccov, \u03b2 +2cacc) \u000b ucov(\u03b1\u22122ccov, \u03b2+2cacc) \u000b Repetition Learning Mechanism We repeat the game with the new thresh- olds until a balanced solution is reached. We \ufb01rst analyzes the pure strategy equilibrium of the game and then check if the stopping criteria are satis\ufb01ed. Game equilibrium. The game solution of pure strategy Nash equilibrium is used to determine possible game outcomes in GTRS.",
            "We \ufb01rst analyzes the pure strategy equilibrium of the game and then check if the stopping criteria are satis\ufb01ed. Game equilibrium. The game solution of pure strategy Nash equilibrium is used to determine possible game outcomes in GTRS. The strategy pro\ufb01le (si, tj) is a pure strategy Nash equilibrium, if \u2200s \u2032 i \u2208Sacc,uacc(si, tj) \u2a7euacc(s \u2032 i, tj), where si \u2208Sacc \u2227s \u2032 i \u0338= si, \u2200t \u2032 j \u2208Scov,ucov(si, tj) \u2a7eucov(si, t \u2032 j), where tj \u2208Scov \u2227t \u2032 j \u0338= tj. (11) This means that none of players would like to change his strategy or they would loss bene\ufb01t if deriving from this strategy pro\ufb01le, provided this player has the knowledge of other player\u2019s strategy. Repetition of games. Assuming that we formulate a game, in which the ini- tial thresholds are (\u03b1, \u03b2), and the equilibrium analysis shows that the thresholds corresponding to the equilibrium are (\u03b1\u2217, \u03b2\u2217).",
            "Repetition of games. Assuming that we formulate a game, in which the ini- tial thresholds are (\u03b1, \u03b2), and the equilibrium analysis shows that the thresholds corresponding to the equilibrium are (\u03b1\u2217, \u03b2\u2217). If the thresholds (\u03b1\u2217, \u03b2\u2217) do not satisfy the stopping criterion, we will update the initial thresholds in the subse- quent games. The initial thresholds of the new game will be set as (\u03b1\u2217, \u03b2\u2217). If the thresholds (\u03b1\u2217, \u03b2\u2217) satisfy the stopping criterion, we may stop the repetition of games. Stopping criterion. We de\ufb01ne the stopping criteria so that the iterations of games can stop at a proper time. In this research, we set the stopping criterion as within the range of thresholds, the increase of one player\u2019s payo\ufb00is less than the decrease of the other player\u2019s payo\ufb00. 4 Experiments There are 8757 news records in our preprocessed data set.",
            "In this research, we set the stopping criterion as within the range of thresholds, the increase of one player\u2019s payo\ufb00is less than the decrease of the other player\u2019s payo\ufb00. 4 Experiments There are 8757 news records in our preprocessed data set. We use Jenks nat- ural breaks [8] to discretize continuous variables SNP and SQP both into \ufb01ve categories denoted by nominal values from 0 to 4, where larger values still fall into bins with larger nominal value. Let DNP and DQP denote the discretized variables SNP and SQP , respectively. We derived the information table that only",
            "Satirical News Detection with Semantic Feature Extraction and GTRS 9 contains discrete features from our original dataset. A fraction of the information table is shown in Table 3. Table 3. The Information Table Id DNP DQP CNERN Bvoc target 1 0 2 0 0 1 2 1 2 0 0 1 3 2 2 0 1 0 4 2 4 1 1 0 5 2 3 0 0 1 6 4 3 -1 1 0 7 2 3 0 0 0 8 3 2 -1 0 1 The news whose condition attributes have the same values are classi\ufb01ed in an equivalence class Xi. We derived 149 equivalence classes and calculated the corresponding probability Pr(Xi) and condition probability Pr(Satire|Xi) for each Xi.",
            "We derived 149 equivalence classes and calculated the corresponding probability Pr(Xi) and condition probability Pr(Satire|Xi) for each Xi. The probability Pr(Xi) denotes the ratio of the number of news con- tained in the equivalence class Xi to the total number of news in the dataset, while the conditional probability Pr(Satire|Xi) is the proportion of news in Xi that are satirical. We combine the equivalence classes with the same conditional probability and reduce the number of equivalence classes to 108. Table 4 shows a part of the probabilistic data information about the concept satire. Table 4. Summary of the partial experimental data X1 X2 X3 X4 X5 X6 X7 X8 X9 ...... Pr(Xi) 0.0315 0.0054 0.0026 0.0071 0.0062 0.0018 0.0015 0.0098 0.0009 ...... Pr(Satire|Xi) 1 0.9787 0.9565 0.9516 0.9444 0.9375 0.",
            "0018 0.0015 0.0098 0.0009 ...... Pr(Satire|Xi) 1 0.9787 0.9565 0.9516 0.9444 0.9375 0.9231 0.9186 0.875 ...... ...... X100 X101 X102 X103 X104 X105 X106 X107 X108 Pr(Xi) ...... 0.0121 0.0138 0.0095 0.0065 0.0383 0.0078 0.0107 0.0163 0.048 Pr(Satire|Xi) ...... 0.0283 0.0248 0.0241 0.0175 0.0149 0.0147 0.0106 0.007 0 4.1 Finding Thresholds with GTRS We formulated a competitive game between the criteria accuracy and coverage to obtain the balanced probabilistic thresholds with the initial thresholds (\u03b1, \u03b2) = (1,",
            "0175 0.0149 0.0147 0.0106 0.007 0 4.1 Finding Thresholds with GTRS We formulated a competitive game between the criteria accuracy and coverage to obtain the balanced probabilistic thresholds with the initial thresholds (\u03b1, \u03b2) = (1, 0) and learning rate 0.03. As shown in the payo\ufb00table Table 5, the cell at the right bottom corner is the game equilibrium whose strategy pro\ufb01le is (\u03b2 increases 0.06, \u03b1 decreases 0.06). The payo\ufb00s of the players are (0.9784,0.3343). We set the stopping criterion as the increase of one player\u2019s payo\ufb00is less than the decrease of the other player\u2019s payo\ufb00when the thresholds are within the range. When the",
            "10 Y. Zhou & Y. Zhang & J. T. Yao Table 5. The payo\ufb00table cov \u03b1 \u03b1 \u21930.03 \u03b1 \u21930.06 \u03b2 < 1, 0.0795 > < 0.9986, 0.0849 > < 0.9909, 0.1008 > acc \u03b2 \u21910.03 < 0.9868, 0.2337 > < 0.9866, 0.2391 > < 0.9843, 0.255 > \u03b2 \u21910.06 < 0.9799, 0.3130 > < 0.9799, 0.3184 > < 0.9784,0.3343 > thresholds change from (1,0) to (0.94, 0.06), the accuracy is decreased from 1 to 0.9784 but the coverage is increased from 0.0795 to 0.3343. We repeat the game by setting (0.94, 0.06) as the next initial thresholds. The competitive games are repeated seven times. The result is shown in Table 6.",
            "We repeat the game by setting (0.94, 0.06) as the next initial thresholds. The competitive games are repeated seven times. The result is shown in Table 6. After the eighth iteration, the repetition of game is stopped because Table 6. The repetition of game Initial(\u03b1, \u03b2) Strategies Result(\u03b1, \u03b2) Payo\ufb00s \u2193>\u2191 1 (1, 0) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.94, 0.06) < 0.9784, 0.3343 > \u00d7 2 (0.94, 0.06) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.88, 0.12) < 0.9586, 0.4805 > \u00d7 3 (0.88, 0.12) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.82, 0.18) < 0.9433, 0.554 > \u00d7 4 (0.82, 0.18) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.",
            "03, \u03b1 \u21930.03) (0.82, 0.18) < 0.9433, 0.554 > \u00d7 4 (0.82, 0.18) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.76, 0.24) < 0.9218, 0.6409 > \u00d7 5 (0.76, 0.24) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.7, 0.3) < 0.8960, 0.7467 > \u00d7 6 (0.7, 0.3) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.64, 0.36) < 0.8791, 0.8059 > \u00d7 7 (0.64, 0.36) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.58, 0.42) < 0.8524, 0.8946 > \u00d7 8 (0.58, 0.42) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.",
            "03, \u03b1 \u21930.03) (0.58, 0.42) < 0.8524, 0.8946 > \u00d7 8 (0.58, 0.42) (\u03b2 \u21910.03, \u03b1 \u21930.03) (0.52, 0.48) < 0.8271, 0.9749 > \u00d7 the further changes on thresholds may cause the thresholds lay outside of the range 0 < \u03b2 < \u03b1 < 1, and the \ufb01nal result is the equilibrium of the seventh game (\u03b1, \u03b2) = (0.52, 0.48). 4.2 Results We compare Pawlak rough sets, SVM, and our GTRS approach on the proposed dataset. Table 7 shows the results on the experimental data. The SVM classi\ufb01er Table 7.",
            "\u03b2) = (0.52, 0.48). 4.2 Results We compare Pawlak rough sets, SVM, and our GTRS approach on the proposed dataset. Table 7 shows the results on the experimental data. The SVM classi\ufb01er Table 7. Experimental results (\u03b1, \u03b2) Accuracy Coverage Modi\ufb01ed accuracy SVM - 78% 100% 78% Pawlak (1, 0) 100% 7.95% 53.98% GTRS (0.58, 0.42) 82.71% 97.49% 81.89% achieved an accuracy of 78% with a 100% coverage. The Pawlak rough set model",
            "Satirical News Detection with Semantic Feature Extraction and GTRS 11 using (\u03b1, \u03b2) = (1, 0) achieves a 100% accuracy and a coverage ratio of 7.95%, which means it can only classify 7.95% of the data. The classi\ufb01er constructed by GTRS with (\u03b1, \u03b2) = (0.52, 0.48) reached an accuracy 82.71% and a cover- age 97.49%. which indicates that 97.49% of data are able to be classi\ufb01ed with accuracy of 82.71%. The remaining 2.51% of data can not be classi\ufb01ed without providing more information. To make our method comparable to other base- lines such as SVM, we assume random guessing is made on the deferral region and present the modi\ufb01ed accuracy. The modi\ufb01ed accuracy for our approach is then 0.8271 \u00d7 0.9749 + 0.5 \u00d7 0.0251 = 81.89%. Our methods shows signi\ufb01cant improvement as compared to Pawlak model and SVM.",
            "The modi\ufb01ed accuracy for our approach is then 0.8271 \u00d7 0.9749 + 0.5 \u00d7 0.0251 = 81.89%. Our methods shows signi\ufb01cant improvement as compared to Pawlak model and SVM. 5 Conclusion In this paper, we propose a satirical news detection approach based on extracted semantic features and game-theoretic rough sets. In our mode, the semantic features extraction captures the inconsistency in the di\ufb00erent structural parts of the sentences and the GTRS classi\ufb01er can process the incomplete information based on repetitive learning and the acceptance and rejection thresholds. The experimental results on our created satirical and legitimate news tweets dataset show that our model signi\ufb01cantly outperforms Pawlak rough set model and SVM. In particular, we demonstrate our model\u2019s ability to interpret satirical news detection from a semantic and information trade-o\ufb00perspective. Other interesting extensions of our paper may be to use rough set models to extract the linguistic features at document level. References 1.",
            "In particular, we demonstrate our model\u2019s ability to interpret satirical news detection from a semantic and information trade-o\ufb00perspective. Other interesting extensions of our paper may be to use rough set models to extract the linguistic features at document level. References 1. Akbik, A., Blythe, D., Vollgraf, R.: Contextual string embeddings for sequence labeling. In: Proceedings of the 27th International Conference on Computational Linguistics. pp. 1638\u20131649. Springer (2018) 2. Azam, N., Yao, J.T.: Game-theoretic rough sets for recommender systems. Knowledge-Based Systems 72, 96\u2013107 (2014) 3. Burfoot, C., Baldwin, T.: Automatic satire detection: Are you having a laugh? In: Proceedings of the 2009 International Conference on Natural Language Processing. pp. 161\u2013164. ACL (2009) 4. Conroy, N.J., Rubin, V.L., Chen, Y.: Automatic deception detection: Methods for \ufb01nding fake news. In: Proceedings of the Association for Information Science and Technology.",
            "pp. 161\u2013164. ACL (2009) 4. Conroy, N.J., Rubin, V.L., Chen, Y.: Automatic deception detection: Methods for \ufb01nding fake news. In: Proceedings of the Association for Information Science and Technology. pp. 1\u20134. Wiley Online Library (2015) 5. Davidov, D., Tsur, O., Rappoport, A.: Semi-supervised recognition of sarcastic sentences in twitter and amazon. In: Proceedings of the 14th Conference on Com- putational Natural Language Learning. pp. 107\u2013116. ACL (2010) 6. De Sarkar, S., Yang, F., Mukherjee, A.: Attending sentences to detect satirical fake news. In: Proceedings of the 27th International Conference on Computational Linguistics. pp. 3371\u20133380. Springer (2018) 7. Ghosh, A., Veale, T.: Magnets for sarcasm: Making sarcasm detection timely, con- textual and very personal.",
            "pp. 3371\u20133380. Springer (2018) 7. Ghosh, A., Veale, T.: Magnets for sarcasm: Making sarcasm detection timely, con- textual and very personal. In: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. pp. 482\u2013491 (2017)",
            "12 Y. Zhou & Y. Zhang & J. T. Yao 8. Jenks, G.F.: The data model concept in statistical mapping. International Year- book of Cartography 7, 186\u2013190 (1967) 9. Pennington, J., Socher, R., Manning, C.D.: Glove: Global vectors for word repre- sentation. In: Empirical Methods in Natural Language Processing. pp. 1532\u20131543. ACL (2014) 10. Rilo\ufb00, E., Qadir, A., Surve, P., De Silva, L., Gilbert, N., Huang, R.: Sarcasm as contrast between a positive sentiment and negative situation. In: Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. pp. 704\u2013714 (2013) 11. Rubin, V., Conroy, N., Chen, Y., Cornwell, S.: Fake news or truth? using satirical cues to detect potentially misleading news. In: Proceedings of the 2nd Workshop on Computational Approaches to Deception Detection. pp.",
            "Rubin, V., Conroy, N., Chen, Y., Cornwell, S.: Fake news or truth? using satirical cues to detect potentially misleading news. In: Proceedings of the 2nd Workshop on Computational Approaches to Deception Detection. pp. 7\u201317. ACM (2016) 12. Ruchansky, N., Seo, S., Liu, Y.: Csi: A hybrid deep model for fake news detection. In: Proceedings of the 2017 Conference on Information and Knowledge Manage- ment. pp. 797\u2013806. ACM (2017) 13. Salton, G., McGill, M.J.: Introduction to Modern Information Retrieval. McGraw- Hill (1986) 14. Shu, K., Sliva, A., Wang, S., Tang, J., Liu, H.: Fake news detection on social media: A data mining perspective. ACM SIGKDD Explorations Newsletter 19(1), 22\u201336 (2017) 15. Sterling, C.H.: Encyclopedia of Journalism. Sage Publications (2009) 16.",
            "ACM SIGKDD Explorations Newsletter 19(1), 22\u201336 (2017) 15. Sterling, C.H.: Encyclopedia of Journalism. Sage Publications (2009) 16. Wang, Y., Ma, F., Jin, Z., Yuan, Y., Xun, G., Jha, K., Su, L., Gao, J.: Eann: Event adversarial neural networks for multi-modal fake news detection. In: Proceedings of the 24th SIGKDD International Conference on Knowledge Discovery & Data Mining. pp. 849\u2013857. ACM (2018) 17. Yang, F., Mukherjee, A., Dragut, E.: Satirical news detection and analysis us- ing attention mechanism and linguistic features. arXiv preprint arXiv:1709.01189 (2017) 18. Yao, J.T., Herbert, J.P.: A game-theoretic perspective on rough set analysis. Jour- nal of Chongqing University of Posts and Telecommunications 20(3), 291\u2013298 (2008) 19.",
            "Yao, J.T., Herbert, J.P.: A game-theoretic perspective on rough set analysis. Jour- nal of Chongqing University of Posts and Telecommunications 20(3), 291\u2013298 (2008) 19. Yao, J.T., Azam, N.: Web-based medical decision support systems for three-way medical decision making with game-theoretic rough sets. IEEE Transactions on Fuzzy Systems 23(1), 3\u201315 (2015) 20. Yao, Y.Y.: The superiority of three-way decisions in probabilistic rough set models. Information Sciences 181(6), 1080\u20131096 (2011) 21. Yao, Y.Y.: An outline of a theory of three-way decisions. In: Proceedings of Inter- national Conference on Rough Sets and Current Trends in Computing. pp. 1\u201317. Springer (2012) 22. Yao, Y.Y.: Three-way decisions and cognitive computing. Cognitive Computation 8(4), 543\u2013554 (2016) 23.",
            "pp. 1\u201317. Springer (2012) 22. Yao, Y.Y.: Three-way decisions and cognitive computing. Cognitive Computation 8(4), 543\u2013554 (2016) 23. Zhang, Y., Liu, P.F., Yao, J.T.: Three-way email spam \ufb01ltering with game-theoretic rough sets. In: Proceedings of the 2019 International Conference on Computing, Networking and Communications. pp. 552\u2013556. IEEE (2019) 24. Zhang, Y., Yao, J.T.: Determining three-way decision regions by combining gini ob- jective functions and gtrs. In: Rough Sets, Fuzzy Sets, Data Mining, and Granular Computing. pp. 414\u2013425. Springer (2015) 25. Zhang, Y., Yao, J.T.: Multi-criteria based three-way classi\ufb01cations with game- theoretic rough sets. In: Proceedings of International Symposium on Methodologies for Intelligent Systems. pp. 550\u2013559. Springer (2017)"
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-2004.03788.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 8025.0,
    "avg_doclen_est": 160.5
}
