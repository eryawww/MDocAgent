[
  "arXiv:1912.00864v1  [cs.CL]  25 Nov 2019 Conclusion-Supplement Answer Generation for Non-Factoid Questions Makoto Nakatsuji, Sohei Okui NTT Resonant Inc. Granparktower, 3-4-1 Shibaura, Minato-ku, Tokyo 108-0023, Japan nakatsuji.makoto@gmail.com, okui@nttr.co.jp Abstract This paper tackles the goal of conclusion-supplement answer generation for non-factoid questions, which is a critical is- sue in the \ufb01eld of Natural Language Processing (NLP) and Arti\ufb01cial Intelligence (AI), as users often require supplemen- tary information before accepting a conclusion. The current encoder-decoder framework, however, has dif\ufb01culty gener- ating such answers, since it may become confused when it tries to learn several different long answers to the same non- factoid question. Our solution, called an ensemble network, goes beyond single short sentences and fuses logically con- nected conclusion statements and supplementary statements.",
  "Our solution, called an ensemble network, goes beyond single short sentences and fuses logically con- nected conclusion statements and supplementary statements. It extracts the context from the conclusion decoder\u2019s output sequence and uses it to create supplementary decoder states on the basis of an attention mechanism. It also assesses the closeness of the question encoder\u2019s output sequence and the separate outputs of the conclusion and supplement decoders as well as their combination. As a result, it generates answers that match the questions and have natural-sounding supple- mentary sequences in line with the context expressed by the conclusion sequence. Evaluations conducted on datasets in- cluding \u201cLove Advice\u201d and \u201cArts & Humanities\u201d categories indicate that our model outputs much more accurate results than the tested baseline models do. Introduction Question Answering (QA) modules play particularly impor- tant roles in recent dialog-based Natural Language Under- standing (NLU) systems, such as Apple\u2019s Siri and Amazon\u2019s Echo. Users chat with AI systems in natural language to get the answers they are seeking. QA systems can deal with two types of question: factoid and non-factoid ones.",
  "Users chat with AI systems in natural language to get the answers they are seeking. QA systems can deal with two types of question: factoid and non-factoid ones. The former sort asks, for instance, for the name of a thing or person such as \u201cWhat/Who is X?\u201d. The latter sort includes more diverse questions that cannot be answered by a short fact. For instance, users may ask for advice on how to make a long-distance relationship work well or for opinions on pub- lic issues. Signi\ufb01cant progress has been made in answer- ing factoid questions (Wang, Smith, and Mitamura 2007; Yu et al. 2014); however, answering non-factoid questions remains a challenge for QA modules. Copyright c\u20dd2020, Association for the Advancement of Arti\ufb01cial Intelligence (www.aaai.org). All rights reserved.",
  "2014); however, answering non-factoid questions remains a challenge for QA modules. Copyright c\u20dd2020, Association for the Advancement of Arti\ufb01cial Intelligence (www.aaai.org). All rights reserved. Long short term memory (LSTM) sequence-to- sequence models (Sutskever, Vinyals, and Le 2014; Vinyals and Le 2015; Bahdanau, Cho, and Bengio 2014) try to generate short replies to the short utterances often seen in chat systems. Evaluations have indicated that these models have the possibility of supporting simple forms of general knowledge QA, e.g. \u201cIs the sky blue or black?\u201d, since they learn commonly occurring sen- tences in the training corpus. Recent machine reading comprehension (MRC) methods (Nguyen et al. 2016; Rajpurkar et al. 2016) try to return a single short an- swer to a question by extracting answer spans from the provided passages.",
  "Recent machine reading comprehension (MRC) methods (Nguyen et al. 2016; Rajpurkar et al. 2016) try to return a single short an- swer to a question by extracting answer spans from the provided passages. Unfortunately, they may generate unsatisfying answers to regular non-factoid questions because they can easily become confused when learn- ing several different long answers to the same non- factoid question, as pointed out by (Jia and Liang 2017; Wang et al. 2018). This paper tackles a new problem: conclusion-supplement answer generation for non-factoid questions. Here, the con- clusion consists of sentences that directly answer the ques- tion, while the supplement consists of information sup- porting the conclusion, e.g., reasons or examples. Such conclusion-supplement answers are important for helping questioners decide their actions, especially in NLU. As de- scribed in (Ennis 1991), users prefer a supporting supple- ment before accepting an instruction (i.e., a conclusion).",
  "Such conclusion-supplement answers are important for helping questioners decide their actions, especially in NLU. As de- scribed in (Ennis 1991), users prefer a supporting supple- ment before accepting an instruction (i.e., a conclusion). Good debates also include claims (i.e., conclusions) about a topic and supplements to support them that will allow users to reach decisions (Rinott et al. 2015). The following exam- ple helps to explain how conclusion-supplement answers are useful to users: \u201cDoes separation by a long distance ruin love?\u201d Current methods tend to answer this question with short and generic replies, such as, \u201cDistance cannot ruin true love\u201d. The questioner, however, is not likely to be satis\ufb01ed with such a trite answer and will want to know how the conclusion was reached. If a supplemental statement like \u201cseparations certainly test your love\u201d is presented with the conclusion, the questioner is more likely to accept the an- swer and use it to reach a decision. Furthermore, there may be multiple answers to a non-factoid question. For example, the following answer is also a potential answer to the ques-",
  "tion: \u201cdistance ruins most relationships. You should keep in contact with him\u201d. The current methods, however, have dif- \ufb01culty generating such conclusion-supplement answers be- cause they can become easily confused when they try to learn several different and long answers to a non-factoid question. To address the above problem, we propose a novel archi- tecture, called the ensemble network. It is an extension of existing encoder-decoder models, and it generates two types of decoder output sequence, conclusion and supplement. It uses two viewpoints for selecting the conclusion state- ments and supplementary statements. (Viewpoint 1) The context present in the conclusion decoder\u2019s output is linked to supplementary-decoderoutput states on the basis of an at- tention mechanism. Thus, the context of the conclusion se- quence directly impacts the decoder states of the supplement sequences. This, as a result, generates natural-sounding sup- plementary sequences. (Viewpoint 2) The closeness of the question sequence and conclusion (or supplement) sequence as well as the closeness of the question sequence with the combination of conclusion and supplement sequences is considered.",
  "This, as a result, generates natural-sounding sup- plementary sequences. (Viewpoint 2) The closeness of the question sequence and conclusion (or supplement) sequence as well as the closeness of the question sequence with the combination of conclusion and supplement sequences is considered. By assessing the closeness at the sentence level and sentence-combination level in addition to at the word level, it can generate answers that include good supple- mentary sentences following the context of the conclusion. This avoids having to learn several different conclusion- supplement answers assigned to a single non-factoid ques- tion and generating answers whose conclusions and supple- ments are logically inconsistent with each other. Community-based QA (CQA) websites tend to provide answers composed of conclusion and supplementary state- ments; from our investigation, 77% of non-factoid answers (love advice) in the Oshiete-goo (https://oshiete.goo.ne.jp) dataset consist of these two statement types. The same is true for 82% of the answers in the Yahoo non-factoid dataset1 re- lated to the \ufb01elds of social science, society & culture and arts & humanities.",
  "The same is true for 82% of the answers in the Yahoo non-factoid dataset1 re- lated to the \ufb01elds of social science, society & culture and arts & humanities. We used the above-mentioned CQA datasets in our evaluations, since they provide diverse answers given by many responders. The results showed that our method outperforms existing ones at generating correct and natural answers. We also conducted an love advice service2 in Oshi- ete goo to evaluate the usefulness of our ensemble network. Related work The encoder-decoder framework learns how to trans- form one representation into another. Contextual LSTM (CLSTM) incorporates contextual features (e.g., topics) into the encoder-decoder framework (Ghosh et al. 2016; Serban et al. 2016). It can be used to make the context of the question a part of the answer generation process. Hi- eRarchical Encoder Decoder (HRED) (Serban et al. 2016) extends the hierarchical recurrent encoder-decoder neural network into the dialogue domain; each question can be encoded into a dense context vector, which is used to recurrently decode the tokens in the answer sentences.",
  "Hi- eRarchical Encoder Decoder (HRED) (Serban et al. 2016) extends the hierarchical recurrent encoder-decoder neural network into the dialogue domain; each question can be encoded into a dense context vector, which is used to recurrently decode the tokens in the answer sentences. 1https://ciir.cs.umass.edu/downloads/nfL6/ 2http://oshiete.goo.ne.jp/ai Such sequential generation of next statement tokens, how- ever, weakens the original meaning of the \ufb01rst statement (question). Recently, several models based on the Trans- former (Vaswani et al. 2017), such as for passage ranking (Nogueira et al. 2019; Liu, Duh, and Gao 2018) and answer selection (Shao et al. 2019), have been proposed to evalu- ate question-answering systems. There are, however, few Transformer-based methods that generate non-factoid an- swers. Recent neural answer selection methods for non-factoid questions (dos Santos et al. 2015; Qiu and Huang 2015; Tan et al.",
  "There are, however, few Transformer-based methods that generate non-factoid an- swers. Recent neural answer selection methods for non-factoid questions (dos Santos et al. 2015; Qiu and Huang 2015; Tan et al. 2016) learn question and answer representations and then match them using certain similarity metrics. They use open datasets stored at CQA sites like Yahoo! Answers since they include many diverse answers given by many responders and thus are good sources of non-factoid QA training data. The above methods, however, can only select and extract answer sentences, they do not generate them. Recent machine reading comprehension meth- ods try to answer a question with exact text spans taken from provided passages (Yu et al. 2018; Rajpurkar et al. 2016; Yang, Yih, and Meek 2015; Joshi et al. 2017). Several studies on the MS- MARCO dataset (Tan et al. 2017; Nguyen et al. 2016; Wang et al.",
  "2016; Yang, Yih, and Meek 2015; Joshi et al. 2017). Several studies on the MS- MARCO dataset (Tan et al. 2017; Nguyen et al. 2016; Wang et al. 2018) de\ufb01ne the task as using multiple passages to answer a question where the words in the answer are not necessarily present in the passages. Their models, however, require passages other than QA pairs for both training and testing. Thus, they cannot be applied to CQA datasets that do not have such passages. Furthermore, most of the questions in their datasets only have a single answer. Thus, we think their purpose is different from ours; generating answers for non-factoid questions that tend to demand diverse answers. There are several complex QA tasks such as those present in the TREC complex interactive QA tasks3 or DUC4 com- plex QA tasks. Our method can be applied to those non- factoid datasets if an access fee is paid. Model This section describes our conclusion-supplement answer generation model in detail. An overview of its architecture is shown in Figure 1.",
  "Our method can be applied to those non- factoid datasets if an access fee is paid. Model This section describes our conclusion-supplement answer generation model in detail. An overview of its architecture is shown in Figure 1. Given an input question sequence Q = {q1, \u00b7 \u00b7 \u00b7 , qi, \u00b7 \u00b7 \u00b7 , qNq}, the proposal outputs a conclu- sion sequence C = {c1, \u00b7 \u00b7 \u00b7 , ct, \u00b7 \u00b7 \u00b7 , cNc}, and supplement sequence S = {s1, \u00b7 \u00b7 \u00b7 , st, \u00b7 \u00b7 \u00b7 , sNs}. The goal is to learn a function mapping from Q to C and S. Here, qi denotes a one-of-K embedding of the i-th word in an input sequence of length Nq. ct (st) denotes a one-of-K embedding of the t-th word in an input sequence of length Nc (Ns). Encoder The encoder converts the input Q into a question embed- ding, Oq, and hidden states, H = {hi}i. 3https://cs.uwaterloo.ca/ jimmylin/ciqa/ 4http://www-nlpir.nist.gov/projects/duc/guidelines.html",
  "!\"# $%%&'() !\"# $%%&'() *%++,-%.,/&%+0(0++,\"(1,/%(20#2,\"3%(),+0450(/0+ +$\"2'\"& .5'( +0$\".\"2'%( &%60 7'&& 8 2.50 .5'( 9'+2\"(/0 /\"((%2 &%60 /0.2\"'(&: 9'+2\"(/0 20+2+ :%5. &%60 !\"# $%%&'() ;0%+< ;0%+< !\"#$%&' !\"(&)*+&,\"&-.$'/ = = = = = = >.%++,0(2.%$:,&%++ = = = = = = = = = = = = Oq c Oq =[Oq c,Oq s ] Oq s Oc Os 0&#$%&' !\"#$\"% !\"#$\"% !\"#$\"% !\"#$\"% !\"#$\"% !\"#$\"% ! ! ! ! ! !",
  "\"#$\"% !\"#$\"% !\"#$\"% !\"#$\"% !\"#$\"% !\"#$\"% ! ! ! ! ! ! % % % % % % Figure 1: Neural conclusion-supplement answer generation model. Since the question includes several pieces of background information on the question, e.g. on the users\u2019 situation, as well as the question itself, it can be very long and com- posed of many sentences. For this reason, we use the BiL- STM encoder, which encodes the question in both direc- tions, to better capture the overall meaning of the question. It processes both directions of the input, {q1, \u00b7 \u00b7 \u00b7 , qNq} and {qNq, \u00b7 \u00b7 \u00b7 , q1}, sequentially. At time step t, the encoder up- dates the hidden state by: hi = [hf i , hb i]T s.t.",
  "At time step t, the encoder up- dates the hidden state by: hi = [hf i , hb i]T s.t. hf i = f(qi\u22121, hf i\u22121), hb i = f(qi+1, hb i+1), where f() is an LSTM unit, and hf i and hb i are hidden states output by the forward-direction LSTM and backward- direction LSTM, respectively. We also want to re\ufb02ect sentence-type information such as conclusion type or supplement type in sequence-to-sequence learning to better understand the conclusion or supplement sequences. We achieve this by adding a sentence type vec- tor for conclusion C or for supplement S to the input gate, forget gate output gate, and cell memory state in the LSTM model. This is equivalent to processing a composite input [qi, C] or [qi, S] in the LSTM cell that concatenates the word embedding and sentence-type embedding vectors. We use this modi\ufb01ed LSTM in the above BiLSTM model as: hi = [hf i , hb i]T s.t.",
  "We use this modi\ufb01ed LSTM in the above BiLSTM model as: hi = [hf i , hb i]T s.t. hf i = f([qi\u22121, C], hf i\u22121), hb i = f([qi+1, C], hb i+1). When encoding the question to decode the supplement se- quence, S is input instead of C in the above equation. The BiLSTM encoder then applies a max-pooling layer to all hidden vectors to extract the most salient signal for each word. As a result, it generates a \ufb01xed-sized distributed vector representation for the conclusion, Oc q, and another for the supplement, Os q. Oc q and Os q are different since the encoder is biased by the corresponding sentence-type vector, C or S. As depicted in Figure 1, the BiLSTM encoder processes each word with a sentence-type vector (i.e. C or S) and the max-pooling layer to produce the question embedding Oc q or Os q. These embeddings are used as context vectors in the decoder network for the conclusion and supplement. Decoder The decoder is composed of a conclusion decoder and sup- plement decoder.",
  "C or S) and the max-pooling layer to produce the question embedding Oc q or Os q. These embeddings are used as context vectors in the decoder network for the conclusion and supplement. Decoder The decoder is composed of a conclusion decoder and sup- plement decoder. Here, let h\u2032 t be the hidden state of the t- th LSTM unit in the conclusion decoder. Similar to the en- coder, the decoder also decodes a composite input [ct, C] in an LSTM cell that concatenates the conclusion word embed- ding and sentence-type embedding vectors. It is formulated as follows: h\u2032 t = f \u2032([ct\u22121, C], h\u2032 t\u22121) s.t. ct\u22121 = argmax c softmax c (h\u2032 t\u22121), where f \u2032() denotes the conclusion decoder LSTM, softmaxc the probability of word c given by a softmax layer, ct the t-th conclusion decoded token, and ct the word em- bedding of ct. The supplement decoder\u2019s hidden state h\u2032\u2032 t is computed in the same way with h\u2032 t; however, it is updated in the ensemble network described in the next subsection.",
  "The supplement decoder\u2019s hidden state h\u2032\u2032 t is computed in the same way with h\u2032 t; however, it is updated in the ensemble network described in the next subsection. As depicted in Figure 1, the LSTM decoder processes tokens according to question embedding Oc q or Os q, which yields a bias corresponding to the sentence-type vector, C or S. The output states are then input to the ensemble net- work. Ensemble network The conventional encoder-decoder framework often gener- ates short and simple sentences that fail to adequately an- swer non-factoid questions. Even if we force it to generate longer answers, the decoder output sequences become inco- herent when read from the beginning to the end. The ensemble network solves the above problem by (1) passing the context from the conclusion decoder\u2019s output se- quence to the supplementary decoder hidden states via an at- tention mechanism, and (2) considering the closeness of the",
  "encoder\u2019s input sequence to the decoders\u2019 output sequences as well as the closeness of the encoder\u2019s input sequence to the combination of decoded output sequences. (1) To control the context, we assess all the information output by the conclusion decoder and compute the conclu- sion vector, Oc. Oc is a sentence-level representation that is more compact, abstractive, and global than the original decoder output sequence. To get it, we apply BiLSTM to the conclusion decoder\u2019s output states {\u02dcyc t}t; i.e., {\u02dcyc t}t = {U \u00b7 softmax(h\u2032 t)}t, where word representation matrix U holds the word representations in its columns. At time step t, the BiLSTM encoder updates the hidden state by: hc t = [hc,f t , hc,b t ]T s.t. hc,f t = f(\u02dcyc t\u22121, hc,f t\u22121), hc,b t = f(\u02dcyc t+1, hc,b t+1), where hc,f t and hc,b t are the hidden states output by the for- ward LSTM and backward LSTM in the conclusion encoder, respectively.",
  "It applies a max-pooling layer to all hidden vec- tors to extract the most salient signal for each word to com- pute the embedding for conclusion Oc. Next, it computes the context vector cxt at the t-th step by using the (t\u22121)-th output hidden state of the supplement decoder, h\u2032\u2032 t\u22121, weight matrices, Va and Wa, and a sigmoid function, \u03c3: cxt = \u03b1tOc s.t. \u03b1t = \u03c3(VT a tanh(Wah\u2032\u2032 t\u22121 + Oc)). This computation lets our ensemble network extract a conclusion-sentence level context. The resulting supplement sequences follow the context of the conclusion sequence.",
  "\u03b1t = \u03c3(VT a tanh(Wah\u2032\u2032 t\u22121 + Oc)). This computation lets our ensemble network extract a conclusion-sentence level context. The resulting supplement sequences follow the context of the conclusion sequence. Fi- nally, h\u2032\u2032 t is computed as: zt = \u03c3(Wz[yt\u22121, T] + Uzh\u2032\u2032 t\u22121 + Wa zcxt + bz) (1) elt = tanh(Wl[yt\u22121, T] + Ulh\u2032\u2032 t\u22121 + Wa l cxt + bl) lt = it \u2217elt + ft \u2217lt\u22121 h\u2032\u2032 t = ot \u2217tanh(lt) z can be i, f, or o, which represent three gates (e.g., input it, forget ft, and output ot). lt denotes a cell memory vector. Wa z and Wa l denote attention parameters. (2) To control the closeness at the sentence level and sentence-combination level, it assesses all the information output by the supplement decoder and computes the supple- ment vector, Os, in the same way as it computes Oc.",
  "Wa z and Wa l denote attention parameters. (2) To control the closeness at the sentence level and sentence-combination level, it assesses all the information output by the supplement decoder and computes the supple- ment vector, Os, in the same way as it computes Oc. That is, it applies BiLSTM to the supplement decoder\u2019s output states {\u02dcys t}t; i.e., {\u02dcys t}t = {U\u00b7softmax(h\u2032\u2032 t )}t, where the word representations are found in the columns of U. Next, it applies a max-pooling layer to all hidden vectors in order to compute the embeddings for supplement Os. Finally, to generate the conclusion-supplement answers, it assesses the closeness of the embeddings for the question Oq to those for the answer sentences (Oc or Os) and their combination Oc and Os. The loss function for the above metrics is described in the next subsection. As depicted in Figure 1, the ensemble network com- putes the conclusion embedding Oc, the attention param- eter weights from Oc to the decoder output supplement states (dotted lines represent attention operations), and the supplement embedding Os.",
  "The loss function for the above metrics is described in the next subsection. As depicted in Figure 1, the ensemble network com- putes the conclusion embedding Oc, the attention param- eter weights from Oc to the decoder output supplement states (dotted lines represent attention operations), and the supplement embedding Os. Then, Oc and Os are input to the loss function together with the question embedding Oq = [Oc q, Os q]. Loss function of ensemble network Our model uses a new loss function rather than generative supervision, which aims to maximize the conditional prob- ability of generating the sequential output p(y|q). This is because we think that assessing the closeness of the ques- tion and an answer sequence as well as the closeness of the question to two answer sequences is useful for generating natural-sounding answers. The loss function is for optimizing the closeness of the question and conclusion and that of the question and sup- plement as well as for optimizing the closeness of the ques- tion with the combination of the conclusion and supplement.",
  "The loss function is for optimizing the closeness of the question and conclusion and that of the question and sup- plement as well as for optimizing the closeness of the ques- tion with the combination of the conclusion and supplement. The training loss Ls is expressed as the following hinge loss, where O+ is the output decoder vector for the ground-truth answer, O\u2212is that for an incorrect answer randomly chosen from the entire answer space, M is a constant margin, and A is set equal to {[O+ c , O\u2212 s ], [O\u2212 c , O+ s ], [O\u2212 c , O\u2212 s ]}: Ls = X Oa\u2208A max{0, M\u2212(cos(Oq, [O+ c , O+ s ])\u2212cos(Oq, Oa))} The key idea is that Ls checks whether or not the con- clusion, supplement, and their combination have been well predicted. In so doing, Ls can optimize not only the predic- tion of the conclusion or supplement but also the prediction of the combination of conclusion and supplement.",
  "In so doing, Ls can optimize not only the predic- tion of the conclusion or supplement but also the prediction of the combination of conclusion and supplement. The model is illustrated in the upper part of Figure 1; (Oq, Oc, Os) is input to compute the closeness and se- quence combination losses. Training The training loss Lw is used to check Ls and the cross- entropy loss in the encoder-decoder model. In the follow- ing equation, the conclusion and supplement sequences are merged into one sequence Y of length T , where T =Nc+Ns. Lw = \u03b1 \u00b7 Ls \u2212ln T Y t=1 p(yt|Q, y1, . . . , yt\u22121). (2) \u03b1 is a parameter to control the weighting of the two losses. We use adaptive stochastic gradient descent (AdaGrad) to train the model in an end-to-end manner. The loss of a train- ing batch is averaged over all instances in the batch. Figure 1 illustrates the loss for the ensemble network and the cross-entropy loss.",
  "We use adaptive stochastic gradient descent (AdaGrad) to train the model in an end-to-end manner. The loss of a train- ing batch is averaged over all instances in the batch. Figure 1 illustrates the loss for the ensemble network and the cross-entropy loss. Evaluation Compared methods We compared the performance of our method with those of (1) Seq2seq, a seq2seq attention model proposed by (Bahdanau, Cho, and Bengio 2014); (2) CLSTM, i.e., the CLSTM model (Ghosh et al. 2016); (3) Trans, the Trans- former (Vaswani et al. 2017), which has proven effective for common NLP tasks. In these three methods, conclusion se- quences and supplement sequences are decoded separately and then joined to generate answers. They give more accu- rate results than methods in which the conclusion sequences",
  "and supplement sequences are decoded sequentially. We also compared (4) HRED, a hierarchical recurrent encoder- decoder model (Serban et al. 2016) in which conclusion se- quences and supplement sequences are decoded sequentially to learn the context from conclusion to supplement; (5) NAGMWA, i.e., our neural answer generation model with- out an attention mechanism. This means that NAGMWA does not pass cxt in Eq. (1) to the decoder, and conclusion de- coder and supplement decoder are connected only via the loss function Ls. In the tables and \ufb01gures that follow, NAGM means our full model. Dataset Our evaluations used the following two CQA datasets: Oshiete-goo The Oshiete-goo dataset includes questions stored in the \u201clove advice\u201d category of the Japanese QA site, Oshiete-goo. It has 771,956 answers to 189,511 questions. We \ufb01ne-tuned the model using a corpus containing about 10,032 question-conclusion-supplement (q-c-s) triples. We used 2,824 questions from the Oshiete-goo dataset.",
  "It has 771,956 answers to 189,511 questions. We \ufb01ne-tuned the model using a corpus containing about 10,032 question-conclusion-supplement (q-c-s) triples. We used 2,824 questions from the Oshiete-goo dataset. On aver- age, the answers to these questions consisted of about 3.5 conclusions and supplements selected by human experts. The questions, conclusions, and supplements had average lengths of 482, 41, and 46 characters, respectively. There were 9,779 word tokens in the questions and 6,317 tokens in answers; the overlap was 4,096. nfL6 We also used the Yahoo nfL6 dataset, the largest publicly available English non-factoid CQA dataset. It has 499,078 answers to 87,361 questions. We \ufb01ne-tuned the model by using questions in the \u201csocial science\u201d, \u201csociety & culture\u201d, and \u201carts & humanities\u201d categories, since they require diverse answers. This yielded 114,955 answers to 13,579 questions. We removed answers that included some stop words, e.g.",
  "This yielded 114,955 answers to 13,579 questions. We removed answers that included some stop words, e.g. slang words, or those that only refer to some URLs or descriptions in literature, since such answers often become noise when an answer is generated. Human experts annotated 10,299 conclusion-supplement sentences pairs in the answers. In addition, we used a neural answer-sentence classi- \ufb01er to classify the sentences into conclusion or supplement classes. It \ufb01rst classi\ufb01ed the sentences into supplements if they started with phrases such as \u201cthis is because\u201d or \u201cthere- fore\u201d. Then, it applied a BiLSTM with max-pooling to the remaining unclassi\ufb01ed sentences, A = {a1, a2, \u00b7 \u00b7 \u00b7 , aNa}, and generated embeddings for the un-annotated sentences, Oa. After that, it used a logistic sigmoid function to return the probabilities of mappings to two discrete classes: conclu- sion and supplement. This mapping was learned by minimiz- ing the classi\ufb01cation errors using the above 10,299 labeled sentences.",
  "After that, it used a logistic sigmoid function to return the probabilities of mappings to two discrete classes: conclu- sion and supplement. This mapping was learned by minimiz- ing the classi\ufb01cation errors using the above 10,299 labeled sentences. As a result, we automatically acquired 70,000 question-conclusion-supplement triples from the entire an- swers. There were 11,768 questions and 70,000 answers. Thus, about 6 conclusions and supplements on average were assigned to a single question. The questions, conclusions, and supplements had average lengths of 46, 87, and 71 char- acters, respectively. We checked the performance of the clas- Table 1: Results when changing \u03b1. Oshiete-goo nfL6 \u03b1 0 1 2 0 1 2 ROUGE-L 0.251 0.299 0.211 0.330 0.402 0.295 BLEU-4 0.098 0.158 0.074 0.062 0.181 0.023 Table 2: Results when using sentence-type embeddings.",
  "Oshiete-goo nfL6 NAGM w/o ste NAGM w/o ste ROUGE-L 0.299 0.235 0.402 0.349 BLEU-4 0.158 0.090 0.181 0.067 si\ufb01er; human experts checked whether the annotation results were correct or not. They judged that it was about 81% ac- curate (it classi\ufb01ed 56,762 of 70,000 sentences into correct classes). There were 15,690 word tokens in questions and 124,099 tokens in answers; the overlap was 11,353. Methodology We conducted three evaluations using the Oshiete-goo dataset; we selected three different sets of 500 human- annotated test pairs from the full dataset. In each set, we trained the model by using training pairs and input questions in test pairs to the model. We repeated the experiments three times by randomly shuf\ufb02ing the train/test sets. For the evaluations using the nfL6 dataset, we prepared three different sets of 500 human-annotated test q-c-s triples from the full dataset.",
  "We repeated the experiments three times by randomly shuf\ufb02ing the train/test sets. For the evaluations using the nfL6 dataset, we prepared three different sets of 500 human-annotated test q-c-s triples from the full dataset. We used 10,299 human-annotated triples to train the neural sentence-type classi\ufb01er. Then, we applied the classi\ufb01er to the unlabeled answer sentences. Fi- nally, we evaluated the answer generation performance by using three sets of machine-annotated 69,500 triples and 500 human-annotated test triples. After training, we input the questions in the test triples to the model to generate answers for both datasets. We com- pared the generated answers with the correct answers. The results described below are average values of the results of three evaluations. The softmax computation was slow since there were so many word tokens in both datasets. Many studies (Yin et al. 2016; Yang et al. 2016; Vinyals and Le 2015) re- stricted the word vocabulary to one based on frequency.",
  "The softmax computation was slow since there were so many word tokens in both datasets. Many studies (Yin et al. 2016; Yang et al. 2016; Vinyals and Le 2015) re- stricted the word vocabulary to one based on frequency. This, however, narrows the diversity of the generated an- swers. Since diverse answers are necessary to properly reply to non-factoid questions, we used bigram tokens instead of word tokens to speed up the computation without restricting the vocabulary. Accordingly, we put 4,087 bigram tokens in the Oshiete-goo dataset and 11,629 tokens in the nfL6 dataset. To measure performance, we used hu- man judgment as well as two popular metrics (Sutskever, Vinyals, and Le 2014; Yang et al. 2016; Bahdanau, Cho, and Bengio 2014) for measuring the \ufb02uency of computer-generated text: ROUGE-L (Lin 2004) and BLEU-4 (Papineni et al. 2002). ROUGE-L is used for measuring the performance for evaluating non-factoid",
  "Table 3: ROUGE-L/BLEU-4 for Oshiete-goo. Seq2seq CLSTM Trans HRED NAGMWA NAGM ROUGE-L 0.238 0.260 0.278 0.210 0.291 0.299 BLEU-4 0.092 0.121 0.087 0.042 0.147 0.158 Table 4: ROUGE-L/BLEU-4 for nfL6. Seq2seq CLSTM Trans HRED NAGMWA NAGM ROUGE-L 0.291 0.374 0.338 0.180 0.383 0.402 BLEU-4 0.081 0.141 0.122 0.055 0.157 0.181 QAs (Song et al. 2017), however, we also think human judgement is important in this task.",
  "2017), however, we also think human judgement is important in this task. Parameter setup For both datasets, we tried different parameter values and set the size of the bigram token embedding to 500, the size of LSTM output vectors for the BiLSTMs to 500\u00d72, and num- ber of topics in the CLSTM model to 15. We tried different margins, M, in the hinge loss function and settled on 0.2. The iteration count N was set to 100. We varied \u03b1 in Eq. (2) from 0 to 2.0 and checked the im- pact of Ls by changing \u03b1. Table 1 shows the results. When \u03b1 is zero, the results are almost as poor as those of the seq2seq model. On the other hand, while raising the value of \u03b1 places greater emphasis on our ensemble network, it also degrades the grammaticality of the generated results. We set \u03b1 to 1.0 after determining that it yielded the best performance. This result clearly indicates that our ensemble network con- tributes to the accuracy of the generated answers.",
  "We set \u03b1 to 1.0 after determining that it yielded the best performance. This result clearly indicates that our ensemble network con- tributes to the accuracy of the generated answers. A comparison of our full method NAGM with the one without the sentence-type embedding (we call this method w/o ste) that trains separate decoders for two types of sen- tences is shown in Table 2. The result indicated that the ex- istence of the sentence type vector, C or S, contributes the accuracy of the results since it distinguishes between sen- tence types. Results Performance The results for Oshiete-goo are shown in Table 3 and those for nfL6 are shown in Table 4. They show that CLSTM is better than Seq2seq. This is because it incor- porates contextual features, i.e. topics, and thus can gener- ate answers that track the question\u2019s context. Trans is also better than Seq2seq, since it uses attention from the ques- tion to the conclusion or supplement more effectively than Seq2seq. HRED failed to attain a reasonable level of perfor- mance.",
  "topics, and thus can gener- ate answers that track the question\u2019s context. Trans is also better than Seq2seq, since it uses attention from the ques- tion to the conclusion or supplement more effectively than Seq2seq. HRED failed to attain a reasonable level of perfor- mance. These results indicate that sequential generation has dif\ufb01culty generating subsequent statements that follow the original meaning of the \ufb01rst statement (question). NAGMWA is much better than the other methods except NAGM, since it generates answers whose conclusions and supplements as well as their combinations closely match the questions. Thus, conclusions and supplements in the answers are consistent with each other and avoid confu- sion made by several different conclusion-supplement an- Table 5: Human evaluation (Oshiete-goo). CLSTM NAGM (1) (2) (3) (4) (1) (2) (3) (4) 21 18 27 34 47 32 11 10 Table 6: Human evaluation (nfL6).",
  "CLSTM NAGM (1) (2) (3) (4) (1) (2) (3) (4) 21 18 27 34 47 32 11 10 Table 6: Human evaluation (nfL6). CLSTM NAGM (1) (2) (3) (4) (1) (2) (3) (4) 30 3 27 40 50 23 16 11 swers assigned to a single non-factoid questions. Finally, NAGM is consistently superior to the conventional atten- tive encoder-decoders regardless of the metric. Its ROUGE- L and BLEU-4 scores are much higher than those of CLSTM. Thus, NAGM generates more \ufb02uent sentences by assessing the context from conclusion to supplement sentences in ad- dition to the closeness of the question and sentences as well as that of the question and sentence combinations. Human evaluation Following evaluations made by crowdsourced evaluators (Li et al. 2016), we conducted hu- man evaluations to judge the outputs of CLSTM and those of NAGM.",
  "Human evaluation Following evaluations made by crowdsourced evaluators (Li et al. 2016), we conducted hu- man evaluations to judge the outputs of CLSTM and those of NAGM. Different from (Li et al. 2016), we hired human experts who had experience in Oshiete-goo QA community service. Thus, they were familiar with the sorts of answers provided by and to the QA community. The experts asked questions, which were not included in our training datasets, to the AI system and rated the answers; one answer per question. The experts rated the answers as follows: (1) the content of the answer matched the question, and the grammar was okay; (2) the content was suitable, but the grammar was poor; (3) the content was not suitable, but the grammar was okay; (4) both the content and grammar were poor. Note that our evaluation followed the DUC-style strategy5.",
  "Note that our evaluation followed the DUC-style strategy5. Here, we mean \u201cgrammar\u201d to cover grammatical- ity, non-redundancy,and referential clarity in the DUC strat- egy, whereas we mean the \u201ccontent matched the questions\u201d to refer to \u201cfocus\u201d and \u201cstructure and coherence\u201d in the DUC strategy. The evaluators were given more than a week to carefully evaluate the generated answers, so we consider that their judgments are reliable. Each expert evaluated 50 ques- tions. We combined the scores of the experts by summing them. They did not know the identity of the system in the evaluation and reached their decisions independently. Table 5 and Table 6 present the results. The numbers are percentages. Table 7 presents examples of questions and an- swers. For Oshiete-goo results, the original Japanese and translated English are presented. The questions are very long and include long background descriptions before the ques- tions themselves. These results indicate that the experts were much more satis\ufb01ed with the outputs of NAGM than those of CLSTM.",
  "The questions are very long and include long background descriptions before the ques- tions themselves. These results indicate that the experts were much more satis\ufb01ed with the outputs of NAGM than those of CLSTM. This is because, as can be seen in Table 7, NAGM generated longer and better question-related sentences than CLSTM did. NAGM generated grammatically good answers whose 5http://www-nlpir.nist.gov/projects/duc/duc2007/quality- questions.txt",
  "Table 7: Example answers generated by CLSTM and NAGM. #1 is for Oshiete-goo and #2 for nfL6. conclusion and supplement statements are well matched with the question and the supplement statement naturally follows the conclusion statement. Generating answers missing from the corpus The encoder-decodernetwork tends to re-generate answers in the training corpus. On the other hand, NAGM can generate an- swers not present in the corpus by virtue of its ensemble network that considers contexts and sentence combinations. Table 7 lists some examples. For example, answer #1 gen- erated by NAGM is not in the training corpus. We think it was generated from the parts in italics in the following three sen- tences that are in the corpus: (1) \u201cI think that it is better not to do anything from your side. If there is no reaction from him, it is better not to do anything even if there is opportu- nity to meet him next.\u201d (2) \u201cI think it may be good for you to approach your lover.",
  "If there is no reaction from him, it is better not to do anything even if there is opportu- nity to meet him next.\u201d (2) \u201cI think it may be good for you to approach your lover. Why don\u2019t you think positively about it without thinking too pessimistically?\u201d (3) \u201cWhy don\u2019t you tell your lover that you usually do not say what you are thinking. \u00b7 \u00b7 \u00b7 I think that it is important to communicate the feelings to your lover; how you like or care about him/her especially when you are quarreling with each other.\u201d The generation of new answers is important for non- factoid answer systems, since they must cope with slight dif- ferences in question contexts from those in the corpus. Online evaluation in \u201cLove Advice\u201d service Our ensem- ble network is currently being used in the love advice ser- vice of Oshiete goo (Nakatsuji 2018). The service uses only the ensemble network to ensure that the service offers high- quality output free from grammar errors. We input the se- quences in our evaluation corpus instead of the decoder out- put sequences into the ensemble network.",
  "The service uses only the ensemble network to ensure that the service offers high- quality output free from grammar errors. We input the se- quences in our evaluation corpus instead of the decoder out- put sequences into the ensemble network. Our ensemble net- work then learned the optimum combination of answer se- quences as well as the closeness of the question and those sequences. As a result, it can construct an answer that cor- responds to the situation underlying the question. In partic- ular, 5,702 answers created by the AI, whose name is Oshi- el (Oshi-el means teaching angel), using our ensemble net- work in reply to 33,062 questions entered from September 6th, 2016 to November 17th, 2019, were judged by users of the service as good answers. Oshi-el output good answers at about twice the rate of the average human responder in Oshiete-goo who answered more than 100 questions in the love advice category. Thus, we think this is a good result.",
  "Oshi-el output good answers at about twice the rate of the average human responder in Oshiete-goo who answered more than 100 questions in the love advice category. Thus, we think this is a good result. Furthermore, to evaluate the effectiveness of the supple- mental information, we prepared 100 answers that only con- tained conclusion sentences during the same period of time. As a result, users rated the answers that contained both con- clusion and supplement sentences as good 1.6 times more often than those that contained only conclusion sentences. This shows that our method successfully incorporated sup- plemental information in answering non-factoid questions. Conclusion We tackled the problem of conclusion-supplement answer generation for non-factoid questions, an important task in NLP. We presented an architecture, ensemble network, that uses an attention mechanism to re\ufb02ect the context of the conclusion decoder\u2019s output sequence on the supplement decoder\u2019s output sequence. The ensemble network also as- sesses the closeness of the encoder input sequence to the output of each decoder and the combined output sequences of both decoders.",
  "The ensemble network also as- sesses the closeness of the encoder input sequence to the output of each decoder and the combined output sequences of both decoders. Evaluations showed that our architecture was consistently superior to conventional encoder-decoders in this task. The ensemble network is now being used in the \u201cLove Advice,\u201d service as mentioned in the Evaluation sec- tion. Furthermore, our method, NAGM, can be generalized to generate much longer descriptions other than conclusion- supplement answers. For example, it is being used to gen- erate Tanka, which is a genre of classical Japanese poetry that consists of \ufb01ve lines of words6, in the following way. The \ufb01rst line is input by a human user to NAGM as a ques- tion, and NAGM generates second line (like a conclusion) and third line (like a supplement). The third line is again in- put to NAGM as a question, and NAGM generates the fourth line (like a conclusion) and \ufb01fth line (like a supplement). 6https://www.tankakenkyu.co.jp/ai/",
  "References [Bahdanau, Cho, and Bengio 2014] Bahdanau, D.; Cho, K.; and Bengio, Y. 2014. Neural machine translation by jointly learning to align and translate. CoRR abs/1409.0473. [dos Santos et al. 2015] dos Santos, C.; Barbosa, L.; Bog- danova, D.; and Zadrozny, B. 2015. Learning hybrid repre- sentations to retrieve semantically equivalent questions. In Proc. ACL-IJCNLP\u201915, 694\u2013699. [Ennis 1991] Ennis, R. 1991. Critical thinking: A stream- lined conception. In Teaching philosophy, 5\u201325. [Ghosh et al. 2016] Ghosh, S.; Vinyals, O.; Strope, B.; Roy, S.; Dean, T.; and Heck, L. 2016. Contextual LSTM (CLSTM) models for large scale NLP tasks. CoRR abs/1602.06291.",
  "2016. Contextual LSTM (CLSTM) models for large scale NLP tasks. CoRR abs/1602.06291. [Jia and Liang 2017] Jia, R., and Liang, P. 2017. Adversarial examples for evaluating reading comprehension systems. In Proc. EMNLP\u201917, 2021\u20132031. [Joshi et al. 2017] Joshi, M.; Choi, E.; Weld, D. S.; and Zettlemoyer, L. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. CoRR abs/1705.03551. [Li et al. 2016] Li, J.; Monroe, W.; Ritter, A.; Jurafsky, D.; Galley, M.; and Gao, J. 2016. Deep reinforcement learning for dialogue generation. In Proc. EMNLP\u201916, 1192\u20131202. [Lin 2004] Lin, C.-Y. 2004. Rouge: A package for automatic evaluation of summaries.",
  "2016. Deep reinforcement learning for dialogue generation. In Proc. EMNLP\u201916, 1192\u20131202. [Lin 2004] Lin, C.-Y. 2004. Rouge: A package for automatic evaluation of summaries. In Text Summarization Branches Out: In: Proc. ACL-04 Workshop, 74\u201381. [Liu, Duh, and Gao 2018] Liu, X.; Duh, K.; and Gao, J. 2018. Stochastic answer networks for natural language in- ference. CoRR abs/1804.07888. [Nakatsuji 2018] Nakatsuji, M. 2018. Can ai gen- erate love advice? neural conclusion-supplement answer construction for non-factoid questions. on-demand.gputechconf.com/gtc/2018/video/S8301/. In GPU Technology Conference 2018 San Jose, CA. [Nguyen et al.",
  "Can ai gen- erate love advice? neural conclusion-supplement answer construction for non-factoid questions. on-demand.gputechconf.com/gtc/2018/video/S8301/. In GPU Technology Conference 2018 San Jose, CA. [Nguyen et al. 2016] Nguyen, T.; Rosenberg, M.; Song, X.; Gao, J.; Tiwary, S.; Majumder, R.; and Deng, L. 2016. MS MARCO: A human generated machine reading comprehen- sion dataset. In Proceedings of the Workshop on Cognitive Computation: Integrating neural and symbolic approaches 2016 co-located with NIPS 2016. [Nogueira et al. 2019] Nogueira, R.; Yang, W.; Lin, J.; and Cho, K. 2019. Document expansion by query prediction. CoRR abs/1904.08375. [Papineni et al. 2002] Papineni, K.; Roukos, S.; Ward, T.; and Zhu, W.-J. 2002.",
  "2019. Document expansion by query prediction. CoRR abs/1904.08375. [Papineni et al. 2002] Papineni, K.; Roukos, S.; Ward, T.; and Zhu, W.-J. 2002. Bleu: A method for automatic evalua- tion of machine translation. In Proc. ACL\u201902, 311\u2013318. [Qiu and Huang 2015] Qiu, X., and Huang, X. 2015. Convo- lutional neural tensor network architecture for community- based question answering. In Proc. IJCAI\u201915, 1305\u20131311. [Rajpurkar et al. 2016] Rajpurkar, P.; Zhang, J.; Lopyrev, K.; and Liang, P. 2016. Squad: 100, 000+ questions for machine comprehension of text. CoRR abs/1606.05250. [Rinott et al.",
  "2016. Squad: 100, 000+ questions for machine comprehension of text. CoRR abs/1606.05250. [Rinott et al. 2015] Rinott, R.; Dankin, L.; Perez, C. A.; Khapra, M. M.; Aharoni, E.; and Slonim, N. 2015. Show me your evidence - an automatic method for context dependent evidence detection. In Proc. EMNLP\u201915, 440\u2013450. [Serban et al. 2016] Serban, I. V.; Sordoni, A.; Bengio, Y.; Courville, A. C.; and Pineau, J. 2016. Building end-to- end dialogue systems using generative hierarchical neural network models. In Proc. AAAI\u201916, 3776\u20133784. [Shao et al. 2019] Shao, T.; Guo, Y.; Hao, Z.; and Chen, H. 2019. Transformer-based neural network for answer selec- tion in question answering. IEEE Access PP:1\u20131.",
  "[Shao et al. 2019] Shao, T.; Guo, Y.; Hao, Z.; and Chen, H. 2019. Transformer-based neural network for answer selec- tion in question answering. IEEE Access PP:1\u20131. [Song et al. 2017] Song, H.; Ren, Z.; Liang, S.; Li, P.; Ma, J.; and de Rijke, M. 2017. Summarizing answers in non-factoid community question-answering. In Proc. WSDM \u201917, 405\u2013 414. [Sutskever, Vinyals, and Le 2014] Sutskever, I.; Vinyals, O.; and Le, Q. V. 2014. Sequence to sequence learning with neural networks. In Proc. NIPS\u201914, 3104\u20133112. [Tan et al. 2016] Tan, M.; dos Santos, C. N.; Xiang, B.; and Zhou, B. 2016. Improved representation learning for ques- tion answer matching. In Proc.",
  "NIPS\u201914, 3104\u20133112. [Tan et al. 2016] Tan, M.; dos Santos, C. N.; Xiang, B.; and Zhou, B. 2016. Improved representation learning for ques- tion answer matching. In Proc. ACL\u201916, 464\u2013473. [Tan et al. 2017] Tan, C.; Wei, F.; Yang, N.; Lv, W.; and Zhou, M. 2017. S-net: From answer extraction to an- swer generation for machine reading comprehension. CoRR abs/1706.04815. [Vaswani et al. 2017] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, L.; and Polo- sukhin, I. 2017. Attention is all you need. [Vinyals and Le 2015] Vinyals, O., and Le, Q. V. 2015. A neural conversational model. CoRR abs/1506.05869.",
  "2017. Attention is all you need. [Vinyals and Le 2015] Vinyals, O., and Le, Q. V. 2015. A neural conversational model. CoRR abs/1506.05869. [Wang et al. 2018] Wang, Y.; Liu, K.; Liu, J.; He, W.; Lyu, Y.; Wu, H.; Li, S.; and Wang, H. 2018. Multi-passage machine reading comprehension with cross-passage answer veri\ufb01cation. In Proc. ACL\u201918, 1918\u20131927. [Wang, Smith, and Mitamura 2007] Wang, M.; Smith, N. A.; and Mitamura, T. 2007. What is the jeopardy model? a quasi-synchronous grammar for qa. In Proc. EMNLP- CoNLL\u201907, 22\u201332. [Yang et al. 2016] Yang, Z.; Yuan, Y.; Wu, Y.; Cohen, W. W.; and Salakhutdinov, R. 2016. Review networks for caption generation.",
  "EMNLP- CoNLL\u201907, 22\u201332. [Yang et al. 2016] Yang, Z.; Yuan, Y.; Wu, Y.; Cohen, W. W.; and Salakhutdinov, R. 2016. Review networks for caption generation. In Proc. NIPS\u201916, 2361\u20132369. [Yang, Yih, and Meek 2015] Yang, Y.; Yih, W.; and Meek, C. 2015. Wikiqa: A challenge dataset for open-domain ques- tion answering. In Proc. EMNLP\u201915, 2013\u20132018. [Yin et al. 2016] Yin, J.; Jiang, X.; Lu, Z.; Shang, L.; Li, H.; and Li, X. 2016. Neural generative question answering. In Proc. IJCAI\u201916, 2972\u20132978. [Yu et al. 2014] Yu, L.; Hermann, K. M.; Blunsom, P.; and Pulman, S. 2014.",
  "Neural generative question answering. In Proc. IJCAI\u201916, 2972\u20132978. [Yu et al. 2014] Yu, L.; Hermann, K. M.; Blunsom, P.; and Pulman, S. 2014. Deep learning for answer sentence selec- tion. CoRR abs/1412.1632. [Yu et al. 2018] Yu, A. W.; Dohan, D.; Luong, M.-T.; Zhao, R.; Chen, K.; Norouzi, M.; and Le, Q. V. 2018. Qanet: Combining local convolution with global self-attention for reading comprehension. In Proc. ICLR\u201918."
]