{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "arXiv:1612.08205v1  [cs.CL]  24 Dec 2016 Predicting the Industry of Users on Social Media Konstantinos Pappas University of Michigan Computer Science and Engineering Ann Arbor, MI 48109, USA pappus@umich.edu Rada Mihalcea University of Michigan Computer Science and Engineering Ann Arbor, MI 48109, USA mihalcea@umich.edu ABSTRACT Automatic pro\ufb01ling of social media users is an important task for supporting a multitude of downstream applications. While a num- ber of studies have used social media content to extract and study collective social attributes, there is a lack of substantial research that addresses the detection of a user\u2019s industry. We frame this task as classi\ufb01cation using both feature engineering and ensemble learning. Our industry-detection system uses both posted content and pro\ufb01le information to detect a user\u2019s industry with 64.3% accu- racy, signi\ufb01cantly outperforming the majority baseline in a taxon- omy of fourteen industry classes.",
            "Our industry-detection system uses both posted content and pro\ufb01le information to detect a user\u2019s industry with 64.3% accu- racy, signi\ufb01cantly outperforming the majority baseline in a taxon- omy of fourteen industry classes. Our qualitative analysis suggests that a person\u2019s industry not only affects the words used and their perceived meanings, but also the number and type of emotions be- ing expressed. CCS Concepts \u2022Social and professional topics \u2192User characteristics; \u2022Human- centered computing \u2192Social media; \u2022Applied computing \u2192 Document analysis; Sociology; Keywords User Pro\ufb01ling; Social Media; Sociolinguistics 1. INTRODUCTION Over the past two decades, the emergence of social media has en- abled the proliferation of traceable human behavior. The content posted by users can re\ufb02ect who their friends are, what topics they are interested in, or which company they are working for. At the same time, users are listing a number of pro\ufb01le \ufb01elds to de\ufb01ne themselves to others.",
            "The content posted by users can re\ufb02ect who their friends are, what topics they are interested in, or which company they are working for. At the same time, users are listing a number of pro\ufb01le \ufb01elds to de\ufb01ne themselves to others. The utilization of such metadata has proven important in facilitating further developments of applications in ad- vertising [6], personalization [9], and recommender systems [1]. However, pro\ufb01le information can be limited, depending on the plat- form, or it is often deliberately omitted [18]. To uncloak this in- formation, a number of studies have utilized social media users\u2019 footprints to approximate their pro\ufb01les. This paper explores the potential of predicting a user\u2019s industry \u2013the aggregate of enterprises in a particular \ufb01eld\u2013 by identifying indus- try indicative text in social media. The accurate prediction of users\u2019 industry can have a big impact on targeted advertising by minimiz- ing wasted advertising [20] and improved personalized user expe- rience.",
            "The accurate prediction of users\u2019 industry can have a big impact on targeted advertising by minimiz- ing wasted advertising [20] and improved personalized user expe- rience. A number of studies in the social sciences have associated language use with social factors such as occupation, social class, education, and income [4, 23, 5, 24]. An additional goal of this pa- per is to examine such \ufb01ndings, and in particular the link between language and occupational class, through a data-driven approach. In addition, we explore how meaning changes depending on the occupational context. By leveraging word embeddings, we seek to quantify how, for example, cloud might mean a separate concept (e.g., condensed water vapor) in the text written by users that work in environmental jobs while it might be used differently by users in technology occupations (e.g., Internet-based computing). Speci\ufb01cally, this paper makes four main contributions. First, we build a large, industry-annotated dataset that contains over 20,000 blog users. In addition to their posted text, we also link a num- ber of user metadata including their gender, location, occupation, introduction and interests.",
            "First, we build a large, industry-annotated dataset that contains over 20,000 blog users. In addition to their posted text, we also link a num- ber of user metadata including their gender, location, occupation, introduction and interests. Second, we build content-based classi\ufb01ers for the industry predic- tion task and study the effect of incorporating textual features from the users\u2019 pro\ufb01le metadata using various meta-classi\ufb01cation tech- niques, signi\ufb01cantly improving both the overall accuracy and the average per industry accuracy. Next, after examining which words are indicative for each indus- try, we build vector-space representations of word meanings and calculate one deviation for each industry, illustrating how meaning is differentiated based on the users\u2019 industries. We qualitatively ex- amine the resulting industry-informed semantic representations of words by listing the words per industry that are most similar to job related and general interest terms.",
            "We qualitatively ex- amine the resulting industry-informed semantic representations of words by listing the words per industry that are most similar to job related and general interest terms. Finally, we rank the different industries based on the normalized relative frequencies of emotionally charged words (positive and negative) and, in addition, discover that, for both genders, these frequencies do not statistically signi\ufb01cantly correlate with an in- dustry\u2019s gender dominance ratio. After discussing related work in Section 2, we present the dataset used in this study in Section 3. In Section 4 we evaluate two fea- ture selection methods and examine the industry inference problem using the text of the users\u2019 postings. We then augment our content- based classi\ufb01er by building an ensemble that incorporates several metadata classi\ufb01ers. We list the most industry indicative words and expose how each industrial semantic \ufb01eld varies with respect to a variety of terms in Section 5. We explore how the frequencies of emotionally charged words in each gender correlate with the in- dustries and their respective gender dominance ratio and, \ufb01nally, conclude in Section 6.",
            "Technology 4,175 Law 1,520 Religion 3,165 Security\/Military 933 Fashion 2,119 Tourism 840 Publishing 2,102 Construction 837 Sports or Recreation 1,779 Museums or Libraries 823 Real Estate 1,726 Banking\/Investment Banking 735 Agriculture\/Environment 1,620 Automotive 506 Table 1: Industry categories and number of users per category. Data per User max mean \u03c3 median Blogs 97 1.8 2.9 1 Blog Posts 1356 24.5 30.4 21 Characters 4,939,258 56,948 112,048.1 33,404 Table 2: Statistics on the Blogger dataset. 2. RELATED WORK Alongside the wide adoption of social media by the public, re- searchers have been leveraging the newly available data to create and re\ufb01ne models of users\u2019 behavior and pro\ufb01ling. There exists a myriad research that analyzes language in order to pro\ufb01le social media users.",
            "RELATED WORK Alongside the wide adoption of social media by the public, re- searchers have been leveraging the newly available data to create and re\ufb01ne models of users\u2019 behavior and pro\ufb01ling. There exists a myriad research that analyzes language in order to pro\ufb01le social media users. Some studies sought to characterize users\u2019 personality [30, 7], while others sequenced the expressed emotions [13], stud- ied mental disorders [8], and the progression of health conditions [21]. At the same time, a number of researchers sought to predict the social media users\u2019 age and\/or gender [34, 33, 22], while oth- ers targeted and analyzed the ethnicity, nationality, and race of the users [14, 32, 29]. One of the pro\ufb01le \ufb01elds that has drawn a great deal of attention is the location of a user. Among others, Hecht et al. [17] predicted Twitter users\u2019 locations using machine learning on nationwide and state levels. Later, Han et al. [16] identi\ufb01ed location indicative words to predict the location of Twitter users down to the city level.",
            "Among others, Hecht et al. [17] predicted Twitter users\u2019 locations using machine learning on nationwide and state levels. Later, Han et al. [16] identi\ufb01ed location indicative words to predict the location of Twitter users down to the city level. As a separate line of research, a number of studies have focused on discovering the political orientation of users [33, 25, 37]. Fi- nally, Li et al. [26] proposed a way to model major life events such as getting married, moving to a new place, or graduating. In a subsequent study, [27] described a weakly supervised information extraction method that was used in conjunction with social network information to identify the name of a user\u2019s spouse, the college they attended, and the company where they are employed. The line of work that is most closely related to our research is the one concerned with understanding the relation between people\u2019s language and their industry. Previous research from the \ufb01elds of psychology and economics have explored the potential for predict- ing one\u2019s occupation from their ability to use math and verbal sym- bols [11] and the relationship between job-types and demograph- ics [35].",
            "Previous research from the \ufb01elds of psychology and economics have explored the potential for predict- ing one\u2019s occupation from their ability to use math and verbal sym- bols [11] and the relationship between job-types and demograph- ics [35]. More recently, Huang et al. [19] used machine learning to classify Sina Weibo users to twelve different platform-de\ufb01ned occupational classes highlighting the effect of homophily in user interactions. This work examined only users that have been veri- \ufb01ed by the Sina Weibo platform, introducing a potential bias in the resulting dataset. Finally, Preotiuc-Pietro et al. [31] predicted the occupational class of Twitter users using the Standard Occupational Classi\ufb01cation (SOC) system, which groups the different jobs based on skill requirements. In that work, the data collection process was limited to only users that speci\ufb01cally mentioned their occupation in their self-description in a way that could be directly mapped to a SOC occupational class. The mapping between a substring of their self-description and a SOC occupational class was done manually.",
            "In that work, the data collection process was limited to only users that speci\ufb01cally mentioned their occupation in their self-description in a way that could be directly mapped to a SOC occupational class. The mapping between a substring of their self-description and a SOC occupational class was done manually. Because of the manual annotation step, their method was not scal- able; moreover, because they identi\ufb01ed the occupation class inside a user self-description, only a very small fraction of the Twitter users could be included (in their case, 5,191 users). Both of these recent studies are based on micro-blogging platforms, which inherently restrict the number of characters that a post can have, and consequently the way that users can express themselves. Moreover, both studies used off-the-shelf occupational taxonomies (rather than self-declared occupation categories), resulting in classes that are either too generic (e.g., media, welfare and electronic are three of the twelve Sina Weibo categories), or too intermixed (e.g., an assistant accountant is in a different class from an accountant in SOC).",
            "To address these limitations, we investigate the industry pre- diction task in a large blog corpus consisting of over 20K American users, 40K web-blogs, and 560K blog posts. 3. DATASET We compile our industry-annotated dataset by identifying blogger pro\ufb01les located in the U.S. on the pro\ufb01le \ufb01nder on http:\/\/www. blogger.com, and scraping only those users that had the industry pro\ufb01le element completed.1 For each of these bloggers, we retrieve all their blogs, and for each of these blogs we download the 21 most recent blog postings. We then clean these blog posts of HTML tags and tokenize them, and drop those bloggers whose cumulative textual content in their posts is less than 600 characters. Following these guidelines, we identi- \ufb01ed all the U.S. bloggers with completed industry information. Traditionally, standardized industry taxonomies organize economic activities into groups based on similar production processes, prod- ucts or services, delivery systems or behavior in \ufb01nancial markets.",
            "Following these guidelines, we identi- \ufb01ed all the U.S. bloggers with completed industry information. Traditionally, standardized industry taxonomies organize economic activities into groups based on similar production processes, prod- ucts or services, delivery systems or behavior in \ufb01nancial markets. Following such assumptions and regardless of their many similari- ties, a tomato farmer would be categorized into a distinct industry from a tobacco farmer. As demonstrated in Preotiuc-Pietro et al. [31] such groupings can cause unwarranted misclassi\ufb01cations. The Blogger platform provides a total of 39 different industry op- tions. Even though a completed industry value is an implicit text 1This data collection was performed between May and July 2015.",
            "0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 0 0.1 0.2 0.3 0.4 0.5 Attributes (%) Accuracy AFR(mAcc) AFR(MAcc) IGR(mAcc) IGR(MAcc) AllWords(mAcc) AllWords(MAcc) Majority(mAcc) Majority(MAcc) Figure 1: Feature evaluation on the industry prediction task using Information Gain Ratio (IGR) and our Aggressive Feature Rank- ing (AFR). The performance is measured using both accuracy (mAcc) and average per-class accuracy (MAcc). annotation, we acknowledge the same problem noted in previous studies: some categories are too broad, while others are very sim- ilar. To remedy this and following Guibert et al. [15], who argued that the denominations used in a classi\ufb01cation must re\ufb02ect the pur- pose of the study, we group the different Blogger industries based on similar educational background and similar technical terminol- ogy.",
            "To remedy this and following Guibert et al. [15], who argued that the denominations used in a classi\ufb01cation must re\ufb02ect the pur- pose of the study, we group the different Blogger industries based on similar educational background and similar technical terminol- ogy. To do that, we exclude very general categories and merge conceptually similar ones2. Examples of broad categories are the Education and the Student options: a teacher could be teaching in any concentration, while a student could be enrolled in any disci- pline. Examples of conceptually similar categories are the Invest- ment Banking and the Banking options. The \ufb01nal set of categories is shown in Table 1, along with the num- ber of users in each category. The resulting dataset consists of 22,880 users, 41,094 blogs, and 561,003 posts. Table 2 presents additional statistics of our dataset. 4. TEXT-BASED INDUSTRY MODELING After collecting our dataset, we split it into three sets: a train set, a development set, and a test set.",
            "Table 2 presents additional statistics of our dataset. 4. TEXT-BASED INDUSTRY MODELING After collecting our dataset, we split it into three sets: a train set, a development set, and a test set. The sizes of these sets are 17,880, 2,500, and 2,500 users, respectively, with users randomly assigned to these sets. In all the experiments that follow, we evaluate our classi\ufb01ers by training them on the train set, con\ufb01gure the parame- ters and measure performance on the development set, and \ufb01nally report the prediction accuracy and results on the test set. Note that all the experiments are performed at user level, i.e., all the data for one user is compiled into one instance in our data sets. To measure the performance of our classi\ufb01ers, we use the predic- tion accuracy. However, as shown in Table 1, the available data is skewed across categories, which could lead to somewhat distorted accuracy numbers depending on how well a model learns to pre- dict the most populous classes.",
            "To measure the performance of our classi\ufb01ers, we use the predic- tion accuracy. However, as shown in Table 1, the available data is skewed across categories, which could lead to somewhat distorted accuracy numbers depending on how well a model learns to pre- dict the most populous classes. Moreover, accuracy alone does not provide a great deal of insight into the individual performance per industry, which is one of the main objectives in this study. There- fore, in our results below, we report: (1) micro-accuracy (mAcc), 2Merged categories are denoted with the \u2019\/\u2019 character in Table 1. calculated as the percentage of correctly classi\ufb01ed instances out of all the instances in the development (test) data; and (2) macro- accuracy (MAcc), calculated as the average of the per-category accuracies, where the per-category accuracy is the percentage of correctly classi\ufb01ed instances out of the instances belonging to one category in the development (test) data. 4.1 Leveraging Blog Content In this section, we seek the effectiveness of using solely textual features obtained from the users\u2019 postings to predict their industry.",
            "4.1 Leveraging Blog Content In this section, we seek the effectiveness of using solely textual features obtained from the users\u2019 postings to predict their industry. The industry prediction baseline Majority is set by discovering the most frequently featured class in our training set and picking that class in all predictions in the respective development or testing set. After excluding all the words that are not used by at least three separate users in our training set, we build our AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classi\ufb01er. As seen in Figure 1, we can far exceed the Majority baseline performance by incorporating basic language signals into machine learning algorithms (173% mAcc improvement). We additionally explore the potential of improving our text classi- \ufb01cation task by applying a number of feature ranking methods and selecting varying proportions of top ranked features in an attempt to exclude noisy features. We start by ranking the different features, w, according to their Information Gain Ratio score (IGR) with re- spect to every industry, i, and training our classi\ufb01er using different proportions of the top features.",
            "We start by ranking the different features, w, according to their Information Gain Ratio score (IGR) with re- spect to every industry, i, and training our classi\ufb01er using different proportions of the top features. IGR(w) = IG(w) IV (w) \u221d \u2212H(i|w) \u2212P (w)logP (w)\u2212P (w)logP (w) \u221d P (w) P i\u2208I P (i|w)logP (i|w)+P (w) P i\u2208I P (i|w)logP (i|w) \u2212P (w)logP (w)\u2212P (w)logP (w) Even though we \ufb01nd that using the top 95% of all the features al-",
            "Data Gender Occupation City State Introduction Interests Train 0.806 0.753 0.862 1.00 0.692 0.535 Dev 0.814 0.712 0.788 1.00 0.671 0.549 Test 0.812 0.709 0.768 1.00 0.686 0.533 Table 3: Proportion of users with non-empty metadata \ufb01elds. ready exceeds the performance of the All Words model on the de- velopment data, we further experiment with ranking our features with a more aggressive formula that heavily promotes the features that are tightly associated with any industry category. Therefore, for every word in our training set, we de\ufb01ne our newly introduced ranking method, the Aggressive Feature Ranking (AFR), as: AFR(w) = max i\u2208I P(w|i) P(w) In Figure 1 we illustrate the performance of all four methods in our industry prediction task on the development data. Note that for each method, we provide both the accuracy (mAcc) and the average per-class accuracy (MAcc).",
            "Note that for each method, we provide both the accuracy (mAcc) and the average per-class accuracy (MAcc). The Majority and All Words methods apply to all the features; therefore, they are represented as a straight line in the \ufb01gure. The IGR and AFR methods are applied to varying subsets of the features using a 5% step. Our experiments demonstrate that the word choice that the users make in their posts correlates with their industry. The \ufb01rst obser- vation in Figure 1 is that the mAcc is proportional to MAcc; as mAcc increases, so does MAcc. Secondly, the best result on the development set is achieved by using the top 90% of the features using the AFR method. Lastly, the improvements of the IGR and AFR feature selections are not substantially better in comparison to All Words (at most 5% improvement between All Words and AFR), which suggest that only a few noisy features exist and most of the words play some role in shaping the \u201clanguage\" of an industry.",
            "Lastly, the improvements of the IGR and AFR feature selections are not substantially better in comparison to All Words (at most 5% improvement between All Words and AFR), which suggest that only a few noisy features exist and most of the words play some role in shaping the \u201clanguage\" of an industry. As a \ufb01nal evaluation, we apply on the test data the classi\ufb01er found to work best on the development data (AFR feature selection, top 90% features), for an mAcc of 0.534 and MAcc of 0.477. 4.2 Leveraging User Metadata Together with the industry information and the most recent post- ings of each blogger, we also download a number of accompanying pro\ufb01le elements. Using these additional elements, we explore the potential of incorporating users\u2019 metadata in our classi\ufb01ers. Table 3 shows the different user metadata we consider together with their coverage percentage (not all users provide a value for all of the pro\ufb01le elements). With the exception of the gender \ufb01eld, the re- maining metadata elements shown in Table 3 are completed by the users as a freely editable text \ufb01eld.",
            "With the exception of the gender \ufb01eld, the re- maining metadata elements shown in Table 3 are completed by the users as a freely editable text \ufb01eld. This introduces a considerable amount of noise in the set of possible metadata values. Examples of noise in the occupation \ufb01eld include values such as \u201cRetired\u201d, \u201cI work.\u201d, or \u201cmomma\u201d which are not necessarily informative for our industry prediction task. To examine whether the metadata \ufb01elds can help in the prediction of a user\u2019s industry, we build classi\ufb01ers using the different metadata elements. For each metadata element that has a textual value, we use all the words in the training set for that \ufb01eld as features. The only two exceptions are the state \ufb01eld, which is encoded as one Classi\ufb01er mAcc MAcc OCCU 0.566 0.431 INTRO 0.406 0.247 INTER 0.287 0.157 GLOC 0.199 0.090 Table 4: Accuracy (mAcc) and average per-class accuracy (MAcc) of the base metadata classi\ufb01ers on the development set.",
            "TEXT 0.245 0.338 0.357 0.366 0.270 OCCU 0.348 0.386 0.409 0.186 0.303 TEXT 0.535 0.554 0.019 0.153 0.216 INTER 0.668 -0.129 -0.005 0.005 0.020 GLOC Table 5: Kappa scores and double fault results of the base clas- si\ufb01ers on development data. feature that can take one out of 50 different values representing the 50 U.S. states; and the gender \ufb01eld, which is encoded as a feature with a distinct value for each user gender option: unde\ufb01ned, male, or female. As shown in Table 4, we build four different classi\ufb01ers using the multinomial NB algorithm: OCCU (which uses the words found in the occupation pro\ufb01le element), INTRO (introduction), INTER (interests), and GLOC (combined gender, city, state).",
            "As shown in Table 4, we build four different classi\ufb01ers using the multinomial NB algorithm: OCCU (which uses the words found in the occupation pro\ufb01le element), INTRO (introduction), INTER (interests), and GLOC (combined gender, city, state). In general, all the metadata classi\ufb01ers perform better than our ma- jority baseline (mAcc of 18.88%). For the GLOC classi\ufb01er, this result is in alignment with previous studies [35]. However, the only metadata classi\ufb01er that outperforms the content classi\ufb01er is the OCCU classi\ufb01er, which despite missing and noisy occupation values exceeds the content classi\ufb01er\u2019s performance by an absolute 3.2%. To investigate the promise of combining the \ufb01ve different classi- \ufb01ers we have built so far, we calculate their inter-prediction agree- ment using Fleiss\u2019s Kappa [10], as well as the lower prediction bounds using the double fault measure [12].",
            "To investigate the promise of combining the \ufb01ve different classi- \ufb01ers we have built so far, we calculate their inter-prediction agree- ment using Fleiss\u2019s Kappa [10], as well as the lower prediction bounds using the double fault measure [12]. The Kappa values, presented in the lower left side of Table 5, express the classi\ufb01cation agreement for categorical items, in this case the users\u2019 industry. Lower values, especially values below 30%, mean smaller agree- ment. Since all \ufb01ve classi\ufb01ers have better-than-baseline accuracy, this low agreement suggests that their predictions could potentially be combined to achieve a better accumulated result. Moreover, the double fault measure values, which are presented in the top-right hand side of Table 5, express the proportion of test cases for which both of the two respective classi\ufb01ers make false predictions, essentially providing the lowest error bound for the pairwise ensemble classi\ufb01er performance. The lower those num-",
            "Feature Concatenation Stacking Meta-classi\ufb01ers mAcc MAcc mAcc MAcc 1. TEXT + OCCU 0.545 0.489 0.640 0.557 2. {1} + INTRO 0.546 0.487 0.648 0.560 3. {2} + INTER 0.546 0.482 0.653 0.569 4. {3} + GLOC 0.545 0.478 0.650 0.566 Table 6: Performance of feature concatenation (early fusion) and stacking (late fusion) on the development set. bers are, the greater the accuracy potential of any meta-classi\ufb01cation scheme that combines those classi\ufb01ers. Once again, the low double fault measure values suggest potential gain from a combination of the base classi\ufb01ers into an ensemble of models. After establishing the promise of creating an ensemble of classi- \ufb01ers, we implement two meta-classi\ufb01cation approaches. First, we combine our classi\ufb01ers using features concatenation (or early fu- sion).",
            "After establishing the promise of creating an ensemble of classi- \ufb01ers, we implement two meta-classi\ufb01cation approaches. First, we combine our classi\ufb01ers using features concatenation (or early fu- sion). Starting with our content-based classi\ufb01er (TEXT), we suc- cessively add the features derived from each metadata element. The results, both micro- and macro-accuracy, are presented in Table 6. Even though all these four feature concatenation ensembles outper- form the content-based classi\ufb01er in the development set, they fail to outperform the OCCU classi\ufb01er. Second, we explore the potential of using stacked generalization (or late fusion) [38]. The base classi\ufb01ers, referred to as L0 classi\ufb01ers, are trained on different folds of the training set and used to predict the class of the remaining instances.",
            "Second, we explore the potential of using stacked generalization (or late fusion) [38]. The base classi\ufb01ers, referred to as L0 classi\ufb01ers, are trained on different folds of the training set and used to predict the class of the remaining instances. Those predictions are then used together with the true label of the training instances to train a second classi\ufb01er, referred to as the L1 classi\ufb01er: this L1 is used to produce the \ufb01nal prediction on both the development data and the test data. Traditionally, stacking uses different machine learning algorithms on the same training data. However in our case, we use the same algorithm (multinomial NB) on heterogeneous data (i.e., different types of data such as content, occupation, introduction, interests, gender, city and state) in order to exploit all available sources of information. The ensemble learning results on the development set are shown in Table 6. We notice a constant improvement for both metrics when adding more classi\ufb01ers to our ensemble except for the GLOC classi\ufb01er, which slightly reduces the performance.",
            "The ensemble learning results on the development set are shown in Table 6. We notice a constant improvement for both metrics when adding more classi\ufb01ers to our ensemble except for the GLOC classi\ufb01er, which slightly reduces the performance. The best result is achieved using an ensemble of the TEXT, OCCU, INTRO, and INTER L0 classi\ufb01ers; the respective performance on the test set is an mAcc of 0.643 and an MAcc of 0.564. Finally, we present in Figure 2 the prediction accuracy for the \ufb01nal classi\ufb01er for each of the different industries in our test dataset. Ev- idently, some industries are easier to predict than others. For exam- ple, while the Real Estate and Religion industries achieve accuracy \ufb01gures above 80%, other industries, such as the Banking industry, are predicted correctly in less than 17% of the time. Anecdotal ev- idence drawn from the examination of the confusion matrix does not encourage any strong association of the Banking class with any other.",
            "Anecdotal ev- idence drawn from the examination of the confusion matrix does not encourage any strong association of the Banking class with any other. The misclassi\ufb01cations are roughly uniform across all other classes, suggesting that the users in the Banking industry use lan- guage in a non-distinguishing way. 5. QUALITATIVE ANALYSIS In this section, we provide a qualitative analysis of the language of the different industries. 5.1 Top-Ranked Words To conduct a qualitative exploration of which words indicate the in- Technology Religion Fashion Publishing Sports Real Estate Law Environment Tourism Construction Museums Banking Security Automotive 0.2 0.4 0.6 0.8 Accuracy Figure 2: Accuracy per-class using stacking meta-classi\ufb01cation.",
            "dustry of a user, Table 7 shows the three top-ranking content words for the different industries using the AFR method. Industry Top-Ranked Words Technology software, \ufb01le, data Religion ministry, jesus, pastor Fashion fashion, dress, hair Publishing writers, novel, writer Sports coach, weight, exercise Real Estate estate, details, homes Law court, trial, agreement Environment farm, plants, plant Tourism guests, travel, hotel Construction roof, construction, union Museums library, museum, novel Banking secret, agent, bank Security of\ufb01cer, army, military Automotive vehicle, cars, insurance Table 7: Three top-ranked words for each industry. Not surprisingly, the top ranked words align well with what we would intuitively expect for each industry. Even though most of these words are potentially used by many users regardless of their industry in our dataset, they are still distinguished by the AFR method because of the different frequencies of these words in the text of each industry. 5.2 Industry-speci\ufb01c Word Similarities Next, we examine how the meaning of a word is shaped by the context in which it is uttered.",
            "5.2 Industry-speci\ufb01c Word Similarities Next, we examine how the meaning of a word is shaped by the context in which it is uttered. In particular, we qualitatively in- vestigate how the speakers\u2019 industry affects meaning by learning vector-space representations of words that take into account such contextual information. To achieve this, we apply the contextual- ized word embeddings proposed by Bamman et al. [2], which are based on an extension of the \u201cskip-gram\" language model [28]. Technology Tourism term cosine term cosine customers 1.000 customers 1.000 clients 0.870 guests 0.816 consumers 0.858 opportunities 0.789 companies 0.832 clients 0.783 employees 0.822 itineraries 0.778 users 0.820 choices 0.769 developers 0.818 patrons 0.767 providers 0.817 employees 0.760 businesses 0.813 projects 0.757 customer 0.811 provide 0.753 Table 8: Terms with the highest cosine similarity to the term customers.",
            "In addition to learning a global representation for each word, these contextualized embeddings compute one deviation from the com- mon word embedding representation for each contextual variable, in this case, an industry option. These deviations capture the terms\u2019 meaning variations (shifts in the k-dimensional space of the repre- sentations, where k = 100 in our experiments) in the text of the different industries, however all the embeddings are in the same vector space to allow for comparisons to one another. Environment Tourism term cosine term cosine food 1.000 food 1.000 local 0.824 delicious 0.843 produce 0.812 treats 0.822 meat 0.807 pastries 0.814 wholesome 0.805 sandwiches 0.808 processed 0.785 burgers 0.806 consumers 0.777 dishes 0.801 meals 0.774 selections 0.796 nutritionally 0.774 eating 0.792 locally 0.765 hamburgers 0.791 Table 9: Terms with the highest cosine similarity to the term food.",
            "Using the word representations learned for each industry, we present in Table 8 the terms in the Technology and the Tourism industries that have the highest cosine similarity with a job-related word, cus- tomers. Similarly, Table 9 shows the words in the Environment and the Tourism industries that are closest in meaning to a general in- terest word, food. More examples are given in the Appendix A. The terms that rank highest in each industry are noticeably differ- ent. For example, as seen in Table 9, while food in the Environment industry is similar to nutritionally and locally, in the Tourism in- dustry the same word relates more to terms such as delicious and pastries. These results not only emphasize the existing differences in how people in different industries perceive certain terms, but they also demonstrate that those differences can effectively be captured in the resulting word embeddings. 5.3 Emotional Orientation per Industry and Gender As a \ufb01nal analysis, we explore how words that are emotionally charged relate to different industries. To quantify the emotional ori- entation of a text, we use the Positive Emotion and Negative Emo- tion categories in the Linguistic Inquiry and Word Count (LIWC) dictionary [36].",
            "To quantify the emotional ori- entation of a text, we use the Positive Emotion and Negative Emo- tion categories in the Linguistic Inquiry and Word Count (LIWC) dictionary [36]. The LIWC dictionary contains lists of words that have been shown to correlate with the psychological states of peo- ple that use them; for example, the Positive Emotion category con- tains words such as \u201chappy,\u201d \u201cpretty,\u201d and \u201cgood.\u201d For the text of all the users in each industry we measure the frequen- cies of Positive Emotion and Negative Emotion words normalized by the text\u2019s length. Table 10 presents the industries\u2019 ranking for both categories of words based on their relative frequencies in the text of each industry. We further perform a breakdown per-gender, where we once again calculate the proportion of emotionally charged words in each in- dustry, but separately for each gender. We \ufb01nd that the indus- try rankings of the relative frequencies fi of emotionally charged words for the two genders are statistically signi\ufb01cantly correlated,3 which suggests that regardless of their gender, users use positive (or negative) words with a relative frequency that correlates with their industry.",
            "We \ufb01nd that the indus- try rankings of the relative frequencies fi of emotionally charged words for the two genders are statistically signi\ufb01cantly correlated,3 which suggests that regardless of their gender, users use positive (or negative) words with a relative frequency that correlates with their industry. (In other words, even if e.g., Fashion has a larger number of women users, both men and women working in Fashion will tend to use more positive words than the corresponding gen- der in another industry with a larger number of men users such as Automotive.) 3\u03c1 >0.81 and p<0.001 for both categories of words.",
            "Positive fi \u00d7 103 Negative fi \u00d7 103 Fashion 35.93 Security 13.80 Religion 32.10 Religion 13.68 Tourism 30.61 Law 12.97 Banking 30.44 Publishing 12.66 Sports 30.05 Construction 11.77 Real Estate 29.25 Banking 11.74 Publishing 29.12 Sports 10.68 Security 28.92 Technology 10.65 Construction 28.84 Museums 10.55 Museums 28.82 Automotive 10.53 Environment 28.31 Environment 10.17 Law 27.63 Tourism 9.53 Automotive 27.17 Fashion 8.50 Technology 26.42 Real Estate 8.25 Table 10: Ranking of industries based on the relative frequen- cies fi of Positive Emotion and Negative Emotion words. Finally, motivated by previous \ufb01ndings of correlations between job satisfaction and gender dominance in the workplace [3], we explore the relationship between the usage of Positive Emotion and Nega- tive Emotion words and the gender dominance in an industry.",
            "Finally, motivated by previous \ufb01ndings of correlations between job satisfaction and gender dominance in the workplace [3], we explore the relationship between the usage of Positive Emotion and Nega- tive Emotion words and the gender dominance in an industry. Al- though we \ufb01nd that there are substantial gender imbalances in each industry (Appendix B), we did not \ufb01nd any statistically signi\ufb01cant correlation between the gender dominance ratio in the different in- dustries and the usage of positive (or negative) emotional words in either gender in our dataset. 6. CONCLUSION In this paper, we examined the task of predicting a social media user\u2019s industry. We introduced an annotated dataset of over 20,000 blog users and applied a content-based classi\ufb01er in conjunction with two feature selection methods for an overall accuracy of up to 0.534, which represents a large improvement over the majority class baseline of 0.188. We also demonstrated how the user metadata can be incorporated in our classi\ufb01ers.",
            "We also demonstrated how the user metadata can be incorporated in our classi\ufb01ers. Although concatenation of features drawn both from blog content and pro\ufb01le elements did not yield any clear im- provements over the best individual classi\ufb01ers, we found that stack- ing improves the prediction accuracy to an overall accuracy of 0.643, as measured on our test dataset. A more in-depth analysis showed that not all industries are equally easy to predict: while industries such as Real Estate and Religion are clearly distinguishable with accuracy \ufb01gures over 0.80, others such as Banking are much harder to predict. Finally, we presented a qualitative analysis to provide some insights into the language of different industries, which highlighted differ- ences in the top-ranked words in each industry, word semantic sim- ilarities, and the relative frequency of emotionally charged words. 7. ACKNOWLEDGMENTS This material is based in part upon work supported by the National Science Foundation (#1344257) and by the John Templeton Foun- dation (#48503).",
            "7. ACKNOWLEDGMENTS This material is based in part upon work supported by the National Science Foundation (#1344257) and by the John Templeton Foun- dation (#48503). Any opinions, \ufb01ndings, and conclusions or rec- ommendations expressed in this material are those of the authors and do not necessarily re\ufb02ect the views of the National Science Foundation or the John Templeton Foundation. 8. REFERENCES [1] G. Adomavicius and A. Tuzhilin. Context-aware recommender systems. In Recommender systems handbook, pages 217\u2013253. Springer, 2011. [2] D. Bamman, C. Dyer, and N. A. Smith. Distributed representations of geographically situated language. 2014. [3] K. A. Bender, S. M. Donohue, and J. S. Heywood. Job satisfaction and gender segregation. Oxford economic papers, 57(3):479\u2013496, 2005. [4] B. Bernstein. Language and social class.",
            "Job satisfaction and gender segregation. Oxford economic papers, 57(3):479\u2013496, 2005. [4] B. Bernstein. Language and social class. The British journal of sociology, 11(3):271\u2013276, 1960. [5] B. B. Bernstein. Class, codes and control: Applied studies towards a sociology of language, volume 2. Psychology Press, 2003. [6] K. Bharat, S. Lawrence, and M. Sahami. Generating user information for use in targeted advertising, Jan. 12 2016. US Patent 9,235,849. [7] F. Celli. Unsupervised personality recognition for social network sites. In Proc. of Sixth International Conference on Digital Society, 2012. [8] G. Coppersmith, M. Dredze, and C. Harman. Quantifying mental health signals in twitter. ACL 2014, page 51, 2014. [9] J. Fink and A. Kobsa.",
            "[8] G. Coppersmith, M. Dredze, and C. Harman. Quantifying mental health signals in twitter. ACL 2014, page 51, 2014. [9] J. Fink and A. Kobsa. A review and analysis of commercial user modeling servers for personalization on the world wide web. User Modeling and User-Adapted Interaction, 10(2-3):209\u2013249, 2000. [10] J. L. Fleiss. Measuring nominal scale agreement among many raters. Psychological bulletin, 76(5):378, 1971. [11] W. L. French. Can a man\u2019s occupation be predicted? Journal of Counseling Psychology, 6(2):95, 1959. [12] G. Giacinto and F. Roli. Design of effective neural network ensembles for image classi\ufb01cation purposes. Image and Vision Computing, 19(9):699\u2013707, 2001.",
            "[12] G. Giacinto and F. Roli. Design of effective neural network ensembles for image classi\ufb01cation purposes. Image and Vision Computing, 19(9):699\u2013707, 2001. [13] G. B. Gil, A. B. de Jes\u00fas, and J. M. M. Lop\u00e9z. Combining machine learning techniques and natural language processing to infer emotions using spanish twitter corpus. In Highlights on Practical Applications of Agents and Multi-Agent Systems, pages 149\u2013157. Springer, 2013. [14] A. Go, R. Bhayani, and L. Huang. Twitter sentiment classi\ufb01cation using distant supervision. CS224N Project Report, Stanford, 1:12, 2009. [15] B. Guibert, J. Laganier, and M. Volle. An essay on industrial classi\ufb01cations. Economie et statistique, 20:1\u201318, 1971. [16] B. Han, P. Cook, and T. Baldwin. Text-based twitter user geolocation prediction.",
            "An essay on industrial classi\ufb01cations. Economie et statistique, 20:1\u201318, 1971. [16] B. Han, P. Cook, and T. Baldwin. Text-based twitter user geolocation prediction. Journal of Arti\ufb01cial Intelligence Research, pages 451\u2013500, 2014. [17] B. Hecht, L. Hong, B. Suh, and E. H. Chi. Tweets from justin bieber\u2019s heart: the dynamics of the location \ufb01eld in user pro\ufb01les. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pages 237\u2013246. ACM, 2011. [18] M. Hernandez, K. Hildrum, P. Jain, R. Wagle, B. Alexe, R. Krishnamurthy, I. R. Stanoi, and C. Venkatramani. Constructing consumer pro\ufb01les from social media data. In Big Data, 2013 IEEE International Conference on, pages 710\u2013716. IEEE, 2013.",
            "Constructing consumer pro\ufb01les from social media data. In Big Data, 2013 IEEE International Conference on, pages 710\u2013716. IEEE, 2013. [19] Y. Huang, L. Yu, X. Wang, and B. Cui. A multi-source integration framework for user occupation inference in social media systems. World Wide Web, 18(5):1247\u20131267, 2015. [20] J. P. Johnson. Targeted advertising and advertising avoidance.",
            "The RAND Journal of Economics, 44(1):128\u2013144, 2013. [21] R. Kashyap and A. Nahapetian. Tweet analysis for user health monitoring. In Wireless Mobile Communication and Healthcare (Mobihealth), 2014 EAI 4th International Conference on, pages 348\u2013351. IEEE, 2014. [22] A. Kokkos and T. Tzouramanis. A robust gender inference model for online social networks and its application to linkedin and twitter. First Monday, 19(9), 2014. [23] W. Labov. Sociolinguistic patterns. Number 4. University of Pennsylvania Press, 1972. [24] W. Labov. The social strati\ufb01cation of English in New York city. Cambridge University Press, 2006. [25] V. Lampos, D. Preotiuc-Pietro, and T. Cohn. A user-centric model of voting intention from social media. In ACL (1), pages 993\u20131003, 2013.",
            "Cambridge University Press, 2006. [25] V. Lampos, D. Preotiuc-Pietro, and T. Cohn. A user-centric model of voting intention from social media. In ACL (1), pages 993\u20131003, 2013. [26] J. Li, A. Ritter, C. Cardie, and E. H. Hovy. Major life event extraction from twitter based on congratulations\/condolences speech acts. In EMNLP, pages 1997\u20132007, 2014. [27] J. Li, A. Ritter, and E. H. Hovy. Weakly supervised user pro\ufb01le extraction from twitter. In ACL (1), pages 165\u2013174, 2014. [28] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Ef\ufb01cient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013. [29] E. Mohammady and A. Culotta.",
            "Ef\ufb01cient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013. [29] E. Mohammady and A. Culotta. Using county demographics to infer attributes of twitter users. ACL 2014, page 7, 2014. [30] J. Oberlander and S. Nowson. Whose thumb is it anyway?: classifying author personality from weblog text. In Proceedings of the COLING\/ACL on Main conference poster sessions, pages 627\u2013634. Association for Computational Linguistics, 2006. [31] D. Preo\u00b8tiuc-Pietro, V. Lampos, and N. Aletras. An analysis of the user occupational class through twitter content. The Association for Computational Linguistics, 2015. [32] D. Rao, M. J. Paul, C. Fink, D. Yarowsky, T. Oates, and G. Coppersmith. Hierarchical bayesian models for latent attribute detection in social media. ICWSM, 11:598\u2013601, 2011.",
            "Hierarchical bayesian models for latent attribute detection in social media. ICWSM, 11:598\u2013601, 2011. [33] D. Rao, D. Yarowsky, A. Shreevats, and M. Gupta. Classifying latent user attributes in twitter. In Proceedings of the 2nd international workshop on Search and mining user-generated contents, pages 37\u201344. ACM, 2010. [34] J. Schler, M. Koppel, S. Argamon, and J. W. Pennebaker. Effects of age and gender on blogging. In AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs, volume 6, pages 199\u2013205, 2006. [35] P. Schmidt and R. P. Strauss. The prediction of occupation using multiple logit models. International Economic Review, pages 471\u2013486, 1975. [36] Y. R. Tausczik and J. W. Pennebaker. The psychological meaning of words: Liwc and computerized text analysis methods.",
            "The prediction of occupation using multiple logit models. International Economic Review, pages 471\u2013486, 1975. [36] Y. R. Tausczik and J. W. Pennebaker. The psychological meaning of words: Liwc and computerized text analysis methods. Journal of language and social psychology, 29(1):24\u201354, 2010. [37] S. Volkova, G. Coppersmith, and B. Van Durme. Inferring user political preferences from streaming communications. In ACL (1), pages 186\u2013196, 2014. [38] D. H. Wolpert. Stacked generalization. Neural networks, 5(2):241\u2013259, 1992.",
            "Inferring user political preferences from streaming communications. In ACL (1), pages 186\u2013196, 2014. [38] D. H. Wolpert. Stacked generalization. Neural networks, 5(2):241\u2013259, 1992. APPENDIX A. ADDITIONAL EXAMPLES OF WORD SIM- ILARITIES Religion Sports term cosine term cosine professional 1.000 professional 1.000 mentoring 0.774 sports 0.833 education 0.745 coaching 0.801 niche 0.724 active 0.795 conversational 0.722 competitive 0.793 vocational 0.721 becoming 0.789 learner 0.720 major 0.785 educational 0.714 fellow 0.778 lock-ins 0.714 having 0.775 thorough 0.713 coaches 0.768 Table 11: Terms with the highest cosine similarity to the term professional.",
            "Technology Fashion term cosine term cosine leisure 1.000 leisure 1.000 playrooms 0.651 presale 0.752 photo-editing 0.650 versona 0.750 multi-media 0.647 jewerly 0.748 match-making 0.646 high-end 0.748 pre-ordered 0.644 sketchers 0.747 tradeshows 0.643 craft 0.743 tfp 0.643 vintage-inspired 0.738 schmooze 0.641 spruill 0.737 upload\/download 0.640 baggu 0.733 Table 12: Terms with the highest cosine similarity to the term leisure. B. GENDER DOMINANCE IN INDUSTRIES 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 Technology Religion Fashion Publishing Sports Real Estate Law Environment Tourism Construction Museums Banking Security Automotive Female Male Figure 3: Gender dominance for the different industries."
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-1612.08205.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 9526.999893188477,
    "avg_doclen_est": 179.7547149658203
}
