[
  "Build Fast and Accurate Lemmatization for Arabic Hamdy Mubarak QCRI, Hamad Bin Khalifa University (HBKU), Doha, Qatar hmubarak@hbku.edu.qa Abstract In this paper we describe the complexity of building a lemmatizer for Arabic which has a rich and complex derivational morphology, and we discuss the need for a fast and accurate lammatization to enhance Arabic Information Retrieval (IR) results. We also introduce a new data set that can be used to test lemmatization accuracy, and an ef\ufb01cient lemmatization algorithm that outperforms state-of-the-art Arabic lemmatization in terms of accuracy and speed. We share the data set and the code for public. Keywords: Arabic NLP, Lemmatization, Information Retrieval, Text Mining, Diactitization 1. Introduction Lemmatization is the process of \ufb01nding the base form (or lemma) of a word by considering its in\ufb02ected forms. Lemma is also called dictionary form, or citation form, and it refers to all words having the same meaning.",
  "Introduction Lemmatization is the process of \ufb01nding the base form (or lemma) of a word by considering its in\ufb02ected forms. Lemma is also called dictionary form, or citation form, and it refers to all words having the same meaning. Lemmatization is an important preprocessing step for many applications of text mining and question-answering systems, and researches in Arabic Information Retrieval (IR) systems show the need for representing Arabic words at lemma level for many applications, including keyphrase extraction (El-Shishtawy and Al-Sammak, 2009) and machine translation (Dichy and Fargaly, 2003). In addi- tion, lemmatization provides a productive way to generate generic keywords for search engines (SE) or labels for concept maps (Plisson et al., 2004). Word stem is that core part of the word that never changes even with morphological in\ufb02ections; the part that remains after pre\ufb01x and suf\ufb01x removal.",
  "Word stem is that core part of the word that never changes even with morphological in\ufb02ections; the part that remains after pre\ufb01x and suf\ufb01x removal. Sometimes the stem of the word is different than its lemma, for example the words: believe, believed, believing, and unbelievable share the stem (believ-), and have the normalized word form (believe) standing for the in\ufb01nitive of the verb (believe). While stemming tries to remove pre\ufb01xes and suf\ufb01xes from words that appear with in\ufb02ections in free text, lemmatiza- tion tries to replace word suf\ufb01xes with (typically) different suf\ufb01x to get its lemma. This extended abstract is organized as follows: Section 2. shows some complexities in building Arabic lemmati- zation, and surveys prior work on Arabic stemming and lemmatization; Section 3. introduces the dataset that we created to test lemmatization accuracy; Section 4. describes the algorithm of the system that we built and report results and error analysis in section 5.; and Section 6. discusses the results and concludes the abstract. 2.",
  "2. Background Arabic is the largest Semitic language spoken by more than 400 million people. It\u2019s one of the six of\ufb01cial languages in the United Nations, and the \ufb01fth most widely spoken language after Chinese, Spanish, English, and Hindi. Arabic has a very rich morphology, both derivational and in\ufb02ectional. Generally, Arabic words are derived from a root that uses three or more consonants to de\ufb01ne a broad meaning or concept, and they follow some templatic morphological patterns. By adding vowels, pre\ufb01xes and suf\ufb01xes to the root, word in\ufb02ections are generated.",
  "By adding vowels, pre\ufb01xes and suf\ufb01xes to the root, word in\ufb02ections are generated. For instance, the word \t\u00e0\u00f1j\u0010J\t\u00aeJ \u0083\u00f0 (wsyftHwn)1 \u201cand they will open\u201d has the triliteral root i\u0010J\t\u00af (ftH), which has the basic meaning of opening, has pre\ufb01xes \u0080\u00f0 (ws) \u201cand will\u201d, suf\ufb01xes \t\u00e0\u00f0 (wn) \u201cthey\u201d, stem i\u0010J\t\u00aeK  (yftH) \u201copen\u201d, and lemma i\u0010J\t\u00af (ftH) \u201cthe concept of opening\u201d. IR systems typically cluster words together into groups according to three main levels: root, stem, or lemma. The root level is considered by many researchers in the IR \ufb01eld which leads to high recall but low precision due to lan- guage complexity, for example words H. A\u0010J\u00bb , \u0010\u00e9J.\u0010J\u00ba\u00d3 ,I. \u0010J\u00bb (ktb, mktbp, ktAb) \u201cwrote, library, book\u201d have the same root I.",
  "\u0010J\u00bb (ktb, mktbp, ktAb) \u201cwrote, library, book\u201d have the same root I. \u0010J\u00bb (ktb) with the basic meaning of writing, so searching for any of these words by root, yields getting the other words which may not be desirable for many users. Other researchers show the importance of using stem level for improving retrieval precision and recall as they capture semantic similarity between in\ufb02ected words. However, in Arabic, stem patterns may not capture similar words having the same semantic meaning. For example, stem patterns for broken plurals are different from their singular patterns, e.g. the plural \u00d0C\u0010\u00af @ (AqlAm) \u201cpens\u201d will not match the stem of its singular form \u00d5\u00ce\u0010\u00af (qlm) \u201cpen\u201d. The same applies to many imperfect verbs that have different stem patterns than their perfect verbs, e.g. the verbs \u00a9J \u00a2\u0010\u001c\u0082\u001d  ,\u00a8A\u00a2\u0010J\u0083@ (AstTAE, ystTyE) \u201che could, he can\u201d will not match because they have different stems.",
  "the verbs \u00a9J \u00a2\u0010\u001c\u0082\u001d  ,\u00a8A\u00a2\u0010J\u0083@ (AstTAE, ystTyE) \u201che could, he can\u201d will not match because they have different stems. Indexing using lemma- tization can enhance the performance of Arabic IR systems. A lot of work has been done in word stemming and lemmatization in different languages, for example the famous Porter stemmer for English, but for Arabic, there 1Words are written in Arabic, transliterated using Buckwalter transliteration, and translated. arXiv:1710.06700v1  [cs.CL]  18 Oct 2017",
  "are few work has been done especially in lemmatization, and there is no open-source code and new testing data that can be used by other researchers for word lemmatization. Xerox Arabic Morphological Analysis and Generation (Beesley, 1996) is one of the early Arabic stemmers, and it uses morphological rules to obtain stems for nouns and verbs by looking into a table of thousands of roots. Khoja\u2019s stemmer (Khoja, 1999) and Buckwalter morpho- logical analyzer (Buckwalter, 2002) are other root-based analyzers and stemmers which use tables of valid combi- nations between pre\ufb01xes and suf\ufb01xes, pre\ufb01xes and stems, and stems and suf\ufb01xes.",
  "Recently, MADAMIRA (Pasha et al., 2014) system has been evaluated using a blind testset (25K words for Modern Standard Arabic (MSA) selected from Penn Arabic Tree bank (PATB)), and the reported accuracy was 96.2% as the percentage of words where the chosen analysis (provided by SAMA morphological analyzer (Graff et al., 2009)) has the correct lemma. In this paper, we present an open-source Java code to ex- tract Arabic word lemmas, and a new publicly available testset for lemmatization allowing researches to evaluate using the same dataset that we used, and reproduce same experiments. 3. Data Description To make the annotated data publicly available, we se- lected 70 news articles from Arabic WikiNews site https://ar.wikinews.org/wiki. These articles cover recent news from year 2013 to year 2015 in multiple genres (politics, economics, health, science and technol- ogy, sports, arts, and culture.) Articles contain 18,300 words, and they are evenly distributed among these 7 genres with 10 articles per each.",
  "Articles contain 18,300 words, and they are evenly distributed among these 7 genres with 10 articles per each. Word are white-space and punctuation separated, and some spelling errors are corrected (1.33% of the total words) to have very clean test cases. Lemmatization is done by an expert Arabic linguist where spelling corrections are marked, and lemmas are provided with full diacritization as shown in Figure 1. As MSA is usually written without diacritics and IR sys- tems normally remove all diacritics from search queries and indexed data as a basic preprocessing step, so another col- umn for undiacritized lemma is added and it\u2019s used for eval- uating our lemmatizer and comparing with state-of-the-art system for lemmatization; MADAMIRA. 4. system Description We were inspired by the work done by (Darwish and Mubarak, 2016) for segmenting Arabic words out of context. They achieved an accuracy of almost 99%; slightly better than state-of-the-art system for segmentation (MADAMIRA) which considers surrounding context and many linguistic features.",
  "They achieved an accuracy of almost 99%; slightly better than state-of-the-art system for segmentation (MADAMIRA) which considers surrounding context and many linguistic features. This system shows enhancements in both Machine Translation, and Information Retrieval tasks (Abdelali et al., 2016). This work can be considered Figure 1: Lemmatization of WikiNews corpus as an extension to word segmentation. From a large diacritized corpus, we constructed a dictio- nary of words and their possible diacritizations ordered by number of occurrences of each diacritized form. This di- acritized corpus was created by a commercial vendor and contains 9.7 million words with almost 200K unique sur- face words. About 73% of the corpus is in MSA and cov- ers variety of genres like politics, economy, sports, soci- ety, etc. and the remaining part is mostly religious texts written in classical Arabic (CA).",
  "About 73% of the corpus is in MSA and cov- ers variety of genres like politics, economy, sports, soci- ety, etc. and the remaining part is mostly religious texts written in classical Arabic (CA). The effectiveness of us- ing this corpus in building state-of-the-art diacritizer was proven in (Darwish et al., 2017).For example, the word X\u00f1\tJK.\u00f0 (wbnwd) \u201cand items\u201d is found 4 times in this corpus with two full diacritization forms X\u0013\u00f1\f\tJ\fK. \u000b\u00f0 ,X\u000b\u00f1\f\tJ\fK. \u000b\u00f0 (wabunudi, wabunudK) \u201citems, with different grammatical case end- ings\u201d which appeared 3 times and once respectively. All unique undiacritized words in this corpus were analyzed using Buckwalter morphological analyzer which gives all possible word diacritizations, and their segmentation, POS tag and lemma as shown in Figure 2.",
  "All unique undiacritized words in this corpus were analyzed using Buckwalter morphological analyzer which gives all possible word diacritizations, and their segmentation, POS tag and lemma as shown in Figure 2. Figure 2: Buckwalter analysis (diacritization forms and lemmas are highlighted) The idea is to take the most frequent diacritized form for words appear in this corpus, and \ufb01nd the morpho- logical analysis with highest matching score between its diacritized form and the corpus word. This means that we search for the most common diacritization of the word regardless of its surrounding context. In the above example, the \ufb01rst solution is preferred and hence its lemma Y\tJK. (banod, bnd after diacritics removal) \u201citem\u201d. While comparing two diacritized forms from the corpus and Buckwalter analysis, special cases were applied",
  "to solve inconsistencies between the two diacritization schemas, for example while words are fully diacritized in the corpus, Buckwalter analysis gives diacritics without case ending (i.e. without context), and removes short vowels in some cases, for example before long vowels, and after the de\ufb01nite article \u00c8@ (Al) \u201cthe\u201d, etc. It worths mentioning that there are many cases in Buck- walter analysis where for the input word, there are two or more identical diacritizations with different lemmas, and the analyses of such words are provided without any meaningful order. For example the word \u0010\u00e8PAJ \u0083 (syArp) \u201ccar\u201d has two morphological analyses with different lemmas, namely PAJ \u0083 (syAr) \u201cwalker\u201d, and \u0010\u00e8PAJ \u0083 (syArp) \u201ccar\u201d in this order while the second lemma is the most common one. To solve tis problem, all these words are reported and the top frequent words are revised and order of lemmas were changed according to actual usage in modern language.",
  "To solve tis problem, all these words are reported and the top frequent words are revised and order of lemmas were changed according to actual usage in modern language. The lemmatization algorithm can be summarized in Figure 3, and the online system can be tested through the site http://alt.qcri.org/farasa/segmenter. html 5. Evaluation Data was formatted in a plain text format where sentences are written in separate lines and words are separated by spaces, and the outputs of MADAMIRA and our system are compared against the undiacritized lemma for each word. For accurate results, all differences were revised manually to accept cases that should not be counted as errors (different writings of foreign names entities for example as in l.\u001a\t'\u00f1\u00bb l.\u001a\t'\u00f1\u00eb , \t\u00a9\tK\u00f1\u00bb \t\u00a9\tK\u00f1\u00eb (hwng kwng, hwnj kwnj) \u201cHong Kong\u201d, or more than one accepted lemma for some function words, e.g the lemmas A\u00d2J \t\u00af ,\u00fa \t\u00af (fy, fymA) are both valid for the function word A\u00d2J \t\u00af (fymA) \u201cwhile\u201d).",
  "Table 1 shows results of testing our system and MADAMIRA on the WikiNews testset (for undiacritized lemmas). Our approach gives +7% relative gain above MADAMIRA in lemmatization task. System Accuracy Our System 97.32% MADAMIRA 96.61% Table 1: Lemmatization accuracy using WikiNews testset In terms of speed, our system was able to lemmatize 7.4 million words on a personal laptop in almost 2 minutes compared to 2.5 hours for MADAMIRA, i.e. 75 times faster. The code is written entirely in Java without any external dependency which makes its integration in other systems quite simple. 5.1.",
  "75 times faster. The code is written entirely in Java without any external dependency which makes its integration in other systems quite simple. 5.1. Error Analysis Most of the lemmatization errors in our system are due to fact that we use the most common diacritization of words without considering their contexts which cannot solve the ambiguity in cases like nouns and adjectives that share the same diacritization forms, for example the word \u0010\u00e9J \u00d6\u00df XA\u00bf @ (AkAdymyp) can be either a noun and its lemma is \u0010\u00e9J \u00d6\u00df XA\u00bf @ (AkAdymyp) \u201cacademy\u201d, or an adjective and its lemma is \u00f9 \u00d6\u00df XA\u00bf @ (AkAdymy) \u201cacademic\u201d. Also for MADAMIRA, errors in selecting the correct Part-of-Speech (POS) for ambiguous words, and foreign named entities. In the full paper, we will quantify error cases in our lem- matizer and MADAMIRA and give examples for each case which can help in enhancing both systems. 6.",
  "In the full paper, we will quantify error cases in our lem- matizer and MADAMIRA and give examples for each case which can help in enhancing both systems. 6. Discussion In this paper, we introduce a new dataset for Arabic lemma- tization and a very fast and accurate lemmatization al- gorithm that performs better than state-of-the art system; MADAMIRA. Both the dataset and the code will be pub- licly available. We show that to build an effective IR sys- tem for complex derivational languages like Arabic, there is a a big need for very fast and accurate lemmatization al- gorithms, and we show that this can be achieved by consid- ering only the most frequent diacritized form for words and matching this form with the morphological analysis with highest similarity score. We plan to study the performance if the algorithm was modi\ufb01ed to provide diacritized lemmas which can be useful for other applications. 7. Bibliographical References Abdelali, A., Darwish, K., Durrani, N., and Mubarak, H. (2016).",
  "7. Bibliographical References Abdelali, A., Darwish, K., Durrani, N., and Mubarak, H. (2016). Farasa: A fast and furious segmenter for arabic. In HLT-NAACL Demos, pages 11\u201316. Beesley, K. (1996). Arabic \ufb01nite-state morphological anal- ysis and generation. In In COLING-96: Proceedings of the 16th international, pages 89\u201394. Buckwalter, T. (2002). Arabic \ufb01nite-state morphological analysis and generation. In http://members.aol.com/ArabicLexicons/. Darwish, K. and Mubarak, H. (2016). Farasa: A new fast and accurate arabic word segmenter. In LREC. Darwish, K., Mubarak, H., and Abdelali, A. (2017). Ara- bic diacritization: Stats, rules, and hacks. In Proceedings of the Third Arabic Natural Language Processing Work- shop, pages 9\u201317.",
  "Darwish, K., Mubarak, H., and Abdelali, A. (2017). Ara- bic diacritization: Stats, rules, and hacks. In Proceedings of the Third Arabic Natural Language Processing Work- shop, pages 9\u201317. Dichy, J. and Fargaly, A. (2003). Roots and patterns vs. stems plus grammar-lexis speci\ufb01cations: on what basis should a multilingual lexical database centred on ara- bic be built? In Proceedings of the MTSummit, New- Orleans. El-Shishtawy, T. and Al-Sammak, A. (2009). Arabic keyphrase extraction using linguistic knowledge and ma- chine learning techniques. In Proceedings of the Second International Conference on Arabic Language Resources and Tools, The MEDAR Consortium. Graff, D., Maamouri, M., Bouziri, B., Krouna, S., Kulick, S., and Buckwalter, T. (2009). Standard arabic morpho- logical analyzer (sama) version 3.1.",
  "Graff, D., Maamouri, M., Bouziri, B., Krouna, S., Kulick, S., and Buckwalter, T. (2009). Standard arabic morpho- logical analyzer (sama) version 3.1. In Linguistic Data Consortium LDC2009E73.",
  "Figure 3: summary of lemmatization algorithm Khoja, S. (1999). Stemming arabic text. In Computing De- partment, Lancaster University. Pasha, A., Al-Badrashiny, M., Diab, M., El Kholy, A., Es- kander, R., Habash, N., Pooleery, M., Rambow, O., and Roth, R. M. (2014). Madamira: A fast, comprehensive tool for morphological analysis and disambiguation of Arabic. Proc. LREC. Plisson, J., Lavrac, N., and Mladenic, M. (2004). A rule based approach to word lemmatization. In research- gate.net."
]