[
  "Joint Entity Linking with Deep Reinforcement Learning Zheng Fang Institute of Information Engineering, Chinese Academy of Sciences & School of Cyber Security, University of Chinese Academy of Sciences fangzheng@iie.ac.cn Yanan Cao\u2217 Institute of Information Engineering, Chinese Academy of Sciences caoyanan@iie.ac.cn Dongjie Zhang Institute of Information Engineering, Chinese Academy of Sciences zhangdongjie@iie.ac.cn Qian Li University of Technology Sydeney Qian.Li@uts.edu.au Zhenyu Zhang Institute of Information Engineering, Chinese Academy of Sciences zhangzhenyu1996@iie.ac.cn Yanbing Liu Institute of Information Engineering, Chinese Academy of Sciences liuyanbing@iie.ac.cn ABSTRACT Entity linking is the task of aligning mentions to corresponding en- tities in a given knowledge base. Previous studies have highlighted the necessity for entity linking systems to capture the global co- herence. However, there are two common weaknesses in previous global models. First, most of them calculate the pairwise scores between all candidate entities and select the most relevant group of entities as the \ufb01nal result.",
  "Previous studies have highlighted the necessity for entity linking systems to capture the global co- herence. However, there are two common weaknesses in previous global models. First, most of them calculate the pairwise scores between all candidate entities and select the most relevant group of entities as the \ufb01nal result. In this process, the consistency among wrong entities as well as that among right ones are involved, which may introduce noise data and increase the model complexity. Sec- ond, the cues of previously disambiguated entities, which could contribute to the disambiguation of the subsequent mentions, are usually ignored by previous models. To address these problems, we convert the global linking into a sequence decision problem and propose a reinforcement learning model which makes decisions from a global perspective. Our model makes full use of the previous referred entities and explores the long-term in\ufb02uence of current selection on subsequent decisions. We conduct experiments on di\ufb00erent types of datasets, the results show that our model out- performs state-of-the-art systems and has beter generalization performance.",
  "We conduct experiments on di\ufb00erent types of datasets, the results show that our model out- performs state-of-the-art systems and has beter generalization performance. CCS CONCEPTS \u2022Information systems \u2192Information extraction; KEYWORDS Entity linking, reinforcement learning, joint disambiguation, knowl- edge base ACM Reference format: Zheng Fang, Yanan Cao, Dongjie Zhang, Qian Li, Zhenyu Zhang, and Yan- bing Liu. 2019. Joint Entity Linking with Deep Reinforcement Learning. In \u2217Corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro\ufb01t or commercial advantage and that copies bear this notice and the full citation on the \ufb01rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permited. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci\ufb01c permission and/or a fee. Request permissions from permissions@acm.org.",
  "Abstracting with credit is permited. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci\ufb01c permission and/or a fee. Request permissions from permissions@acm.org. WWW 2019, San Francisco, CA, USA \u00a9 2019 ACM. 978-x-xxxx-xxxx-x/YY/MM...$15.00 DOI: 10.1145/nnnnnnn.nnnnnnn Proceedings of Te Web Conference 2019, San Francisco, CA, USA, May 13-17, 2019 (WWW 2019), 10 pages. DOI: 10.1145/nnnnnnn.nnnnnnn 1 INTRODUCTION Entity Linking (EL), which is also called Entity Disambiguation (ED), is the task of mapping mentions in text to corresponding entities in a given knowledge Base (KB). Tis task is an important and challenging stage in text understanding because mentions are usually ambiguous, i.e., di\ufb00erent named entities may share the same surface form and the same entity may have multiple aliases.",
  "Tis task is an important and challenging stage in text understanding because mentions are usually ambiguous, i.e., di\ufb00erent named entities may share the same surface form and the same entity may have multiple aliases. EL is key for information retrieval (IE) and has many applications, such as knowledge base population (KBP), question answering (QA), etc. Existing EL methods can be divided into two categories: local model and global model. Local models concern mainly on contex- tual words surrounding the mentions, where mentions are disam- biguated independently. Tese methods are not work well when the context information is not rich enough. Global models take into ac- count the topical coherence among the referred entities within the same document, where mentions are disambiguated jointly. Most of previous global models [14, 27, 37] calculate the pairwise scores between all candidate entities and select the most relevant group of entities. However, the consistency among wrong entities as well as that among right ones are involved, which not only increases the model complexity but also introduces some noises.",
  "Most of previous global models [14, 27, 37] calculate the pairwise scores between all candidate entities and select the most relevant group of entities. However, the consistency among wrong entities as well as that among right ones are involved, which not only increases the model complexity but also introduces some noises. For example, in Figure 1, there are three mentions \u201dFrance\u201d, \u201dCroatia\u201d and \u201d2018 World Cup\u201d, and each mention has three candidate entities. Here, \u201dFrance\u201d may refer to French Republic, France national basketball team or France national football team in KB. It is di\ufb03cult to disam- biguate using local models, due to the scarce common information in the contextual words of \u201dFrance\u201d and the descriptions of its can- didate entities. Besides, the topical coherence among the wrong entities related to basketball team (linked by an orange dashed line) may make the global models mistakenly refer \u201dFrance\u201d to France national basketball team. So, how to solve these problems? We note that, mentions in text usually have di\ufb00erent disambigua- tion di\ufb03culty according to the quality of contextual information and the topical coherence.",
  "So, how to solve these problems? We note that, mentions in text usually have di\ufb00erent disambigua- tion di\ufb03culty according to the quality of contextual information and the topical coherence. Intuitively, if we start with mentions that are easier to disambiguate and gain correct results, it will be e\ufb00ective to utilize information provided by previously referred en- tities to disambiguate subsequent mentions. In the above example, arXiv:1902.00330v1  [cs.CL]  1 Feb 2019",
  "WWW 2019, May 13-17, 2019, San Francisco, CA, USAZheng Fang, Yanan Cao, Dongjie Zhang, Qian Li, Zhenyu Zhang, and Yanbing Liu France beat Croatia 4-2 in the 2018 World Cup final. France national football team: represents France in international  football and is controlled by the  French Football Federation ... Croatia national football team: represents Croatia in international association football matches, The  team is controlled by the ... 2018 FIFA World Cup: an international football tournament\u2026 the final between France and Croatia.  France won the match 4\u20132 to claim\u2026 Free Text KB French Republic France national  basketball team France national  football team Republic of  Croatia Croatia national  basketball team Croatia national  football team 2018 ITTF Team  World Cup 2018 FIFA World Cup 2018 FIBA Basketball World Cup Figure 1: Illustration of mentions in the free text and their candidate entities in the knowledge base. Solid black lines point to the correct target entities corresponding to the mentions and to the descriptions of these correct target entities.",
  "Solid black lines point to the correct target entities corresponding to the mentions and to the descriptions of these correct target entities. Solid red lines indicate the consistency between correct target entities and the orange dashed lines denote the consistency between wrong candidate entities. it is much easier to map \u201d2018 World Cup\u201d to 2018 FIFA World Cup based on their common contextual words \u201dFrance\u201d, \u201dCroatia\u201d, \u201d4-2\u201d. Ten, it is obvious that \u201dFrance\u201d and \u201dCroatia\u201d should be referred to the national football team because football-related terms are mentioned many times in the description of 2018 FIFA World Cup. Inspired by this intuition, we design the solution with three prin- ciples: (i) utilizing local features to rank the mentions in text and deal with them in a sequence manner; (ii) utilizing the information of previously referred entities for the subsequent entity disambigua- tion; (iii) making decisions from a global perspective to avoid the error propagation if the previous decision is wrong.",
  "In order to achieve these aims, we consider global EL as a se- quence decision problem and proposed a deep reinforcement learn- ing (RL) based model, RLEL for short, which consists of three mod- ules: Local Encoder, Global Encoder and Entity Selector. For each mention and its candidate entities, Local Encoder encodes the local features to obtain their latent vector representations. Ten, the mentions are ranked according to their disambiguation di\ufb03culty, which is measured by the learned vector representations. In order to enforce global coherence between mentions, Global Encoder encodes the local representations of mention-entity pairs in a se- quential manner via a LSTM network, which maintains a long-term memory on features of entities which has been selected in previous states. Entity Selector uses a policy network to choose the target entities from the candidate set. For a single disambiguation deci- sion, the policy network not only considers the pairs of current mention-entity representations, but also concerns the features of referred entities in the previous states which is pursued by the Global Encoder. In this way, Entity Selector is able to take actions based on the current state and previous ones.",
  "In this way, Entity Selector is able to take actions based on the current state and previous ones. When eliminating the ambiguity of all mentions in the sequence, delayed rewards are used to adjust its policy in order to gain an optimized global decision. Deep RL model, which learns to directly optimize the overall evaluation metrics, works much beter than models which learn with loss functions that just evaluate a particular single decision. By this property, RL has been successfully used in many NLP tasks, such as information retrieval [28], dialogue system [10] and relation classi\ufb01cation [12], etc. To the best of our knowledge, we are the \ufb01rst to design a RL model for global entity linking. And in this paper, our RL model is able to produce more accurate results by exploring the long-term in\ufb02uence of independent decisions and encoding the entities disambiguated in previous states. In summary, the main contributions of our paper mainly include following aspects: \u2022 We are the \ufb01rst to consider EL as a sequence decision prob- lem and innovatively utilize a deep reinforcement learning model in this task. \u2022 Te proposed model takes into account both local con- text and global coherence.",
  "In summary, the main contributions of our paper mainly include following aspects: \u2022 We are the \ufb01rst to consider EL as a sequence decision prob- lem and innovatively utilize a deep reinforcement learning model in this task. \u2022 Te proposed model takes into account both local con- text and global coherence. In the process of global disam- biguation, we make full use of the previous selected entity information and make decisions from a global perspective. \u2022 We evaluate our model on several benchmark datasets and the experimental results showed that our model achieves signi\ufb01cant improvements over the state-of-the-art meth- ods. 2 METHODOLOGY Te overall structure of our RLEL model is shown in Figure 2. Te proposed framework mainly includes three parts: Local Encoder which encodes local features of mentions and their candidate enti- ties, Global Encoder which encodes the global coherence of men- tions in a sequence manner and Entity Selector which selects an",
  "Joint Entity Linking with Deep Reinforcement Learning WWW 2019, May 13-17, 2019, San Francisco, CA, USA Mention Context Entity Description Entity Embedding \ud835\udc49\" Concatenate \ud835\udc49# \ud835\udc38 (\ud835\udc49\", \ud835\udc49#) Reward Local Encoder Global Encoder Entity Selector Local Representations Policy Network \u2026 \u210e* \u210e* \ud835\udc49+, LSTM \ud835\udc46* \u2026 (\ud835\udc49\",, \ud835\udc49#,, ) (\ud835\udc49\",, \ud835\udc49#,. ) \ud835\udc640 * \u2026 \ud835\udc640 1 LSTM \u210e2 \u210e2 \ud835\udc49+3 LSTM \ud835\udc462 \u2026 (\ud835\udc49\"3, \ud835\udc49#3, ) (\ud835\udc49\"3, \ud835\udc49#3. ) \ud835\udc49+4 LSTM \ud835\udc465 \u2026 (\ud835\udc49\"4, \ud835\udc49#4 , ) (\ud835\udc49\"4, \ud835\udc49#4 . ) \u2026 \u210e56* \u210e56* \ud835\udc647 * \u2026 \ud835\udc647 1 LSTM Figure 2: Te overall structure of our RLEL model.",
  "\u2026 \u210e56* \u210e56* \ud835\udc647 * \u2026 \ud835\udc647 1 LSTM Figure 2: Te overall structure of our RLEL model. It contains three parts: Local Encoder, Global Encoder and Entity Selector. In this framework, (Vmt ,Vek t ) denotes the concatenation of the mention context vectorVmt and one candidate entity vectorVek t . Te policy network selects one entity from the candidate set, and Vat denotes the concatenation of the mention context vector Vmt and the selected entity vector Ve\u2217 t . ht represents the hidden status of Vat , and it will be input into St+1. entity from the candidate set. As the Entity Selector and the Global Encoder are correlated mutually, we train them jointly. Moreover, the Local Encoder as the basis of the entire framework will be in- dependently trained before the joint training process starts. In the following, we will introduce the technical details of these modules. 2.1 Preliminaries Before introducing our model, we \ufb01rstly de\ufb01ne the entity link- ing task.",
  "In the following, we will introduce the technical details of these modules. 2.1 Preliminaries Before introducing our model, we \ufb01rstly de\ufb01ne the entity link- ing task. Formally, given a document D with a set of mentions M = {m1,m2, ...,mk }, each mention mt \u2208D has a set of candidate entities Cmt = {e1 t ,e2 t , ...,en t }. Te task of entity linking is to map each mention mt to its corresponding correct target entity e+ t or re- turn \u201dNIL\u201d if there is not correct target entity in the knowledge base. Before selecting the target entity, we need to generate a certain number of candidate entities for model selection. Inspired by the previous works [29, 31, 42], we use the men- tion\u2019s redirect and disambiguation pages in Wikipedia to generate candidate sets. For those mentions without corresponding disam- biguation pages, we use its n-grams to retrieve the candidates [31]. In most cases, the disambiguation page contains many entities, sometimes even hundreds.",
  "For those mentions without corresponding disam- biguation pages, we use its n-grams to retrieve the candidates [31]. In most cases, the disambiguation page contains many entities, sometimes even hundreds. To optimize the model\u2019s memory and avoid unnecessary calculations, the candidate sets need to be \ufb01l- tered [1, 14, 37]. Here we utilize the XGBoost model [3] as an entity ranker to reduce the size of candidate set. Te features used in XGBoost can be divided into two aspects, the one is string simi- larity like the Jaro-Winkler distance between the entity title and the mention, the other is semantic similarity like the cosine dis- tance between the mention context representation and the entity embedding. Furthermore, we also use the statistical features based on the pageview and hyperlinks in Wikipedia. Empirically, we get the pageview of the entity from the Wikipedia Tool Labs1 which counts the number of visits on each entity page in Wikipedia.",
  "Furthermore, we also use the statistical features based on the pageview and hyperlinks in Wikipedia. Empirically, we get the pageview of the entity from the Wikipedia Tool Labs1 which counts the number of visits on each entity page in Wikipedia. Afer 1Te url of the website is: htps://tools.wm\ufb02abs.org/pageviews/ ranking the candidate sets based on the above features, we take the top k scored entities as \ufb01nal candidate set for each mention. 2.2 Local Encoder Given a mentionmt and the corresponding candidate set {e1 t ,e2 t , ..., ek t }, we aim to get their local representation based on the mention context and the candidate entity description. For each mention, we \ufb01rstly select its n surrounding words, and represent them as word embedding using a pre-trained lookup table [24]. Ten, we use Long Short-Term Memory (LSTM) networks to encode the contextual word sequence {w1c,w2c, ...,wnc } as a \ufb01xed-size vector Vmt . Te description of entity is encoded as Dei t in the same way.",
  "Ten, we use Long Short-Term Memory (LSTM) networks to encode the contextual word sequence {w1c,w2c, ...,wnc } as a \ufb01xed-size vector Vmt . Te description of entity is encoded as Dei t in the same way. Apart from the description of entity, there are many other valuable information in the knowledge base. To make full use of these information, many researchers trained entity embeddings by combining the description, category, and relationship of entities. As shown in [14], entity embeddings compress the semantic meaning of entities and drastically reduce the need for manually designed features or co-occurrence statistics. Terefore, we use the pre-trained entity embedding Eei t and concatenate it with the description vector Dei t to enrich the entity representation. Te concatenation result is denoted by Vei t . Afer geting Vei t , we concatenate it with Vmt and then pass the concatenation result to a multilayer perceptron (MLP). Te MLP outputs a scalar to represent the local similarity between the mention mt and the candidate entity ei t .",
  "Afer geting Vei t , we concatenate it with Vmt and then pass the concatenation result to a multilayer perceptron (MLP). Te MLP outputs a scalar to represent the local similarity between the mention mt and the candidate entity ei t . Te local similarity is calculated by the following equations: \u03a8(mt,ei t ) = MLP(Vmt \u2295Vei t ) (1) Where \u2295indicates vector concatenation. With the purpose of dis- tinguishing the correct target entity and wrong candidate entities when training the local encoder model, we utilize a hinge loss that",
  "WWW 2019, May 13-17, 2019, San Francisco, CA, USAZheng Fang, Yanan Cao, Dongjie Zhang, Qian Li, Zhenyu Zhang, and Yanbing Liu ranks ground truth higher than others. Te rank loss function is de\ufb01ned as follows: Llocal = max(0,\u03b3 \u2212\u03a8(mt,e+ t ) + \u03a8(mt,e\u2212 t )) (2) When optimizing the objective function, we minimize the rank loss similar to [14, 37]. In this ranking model, a training instance is constructed by pairing a positive target entity e+ t with a negative entity e\u2212 t . Where \u03b3 > 0 is a margin parameter and our purpose is to make the score of the positive target entity e+ t is at least a margin \u03b3 higher than that of negative candidate entity e\u2212 t . With the local encoder, we obtain the representation of mention context and candidate entities, which will be used as the input into the global encoder and entity selector. In addition, the similarity scores calculated by MLP will be utilized for ranking mentions in the global encoder.",
  "With the local encoder, we obtain the representation of mention context and candidate entities, which will be used as the input into the global encoder and entity selector. In addition, the similarity scores calculated by MLP will be utilized for ranking mentions in the global encoder. 2.3 Global Encoder In the global encoder module, we aim to enforce the topical co- herence among the mentions and their target entities. So, we use an LSTM network which is capable of maintaining the long-term memory to encode the ranked mention sequence. What we need to emphasize is that our global encoder just encode the mentions that have been disambiguated by the entity selector which is denoted as Vat . As mentioned above, the mentions should be sorted according to their contextual information and topical coherence. So, we \ufb01rstly divide the adjacent mentions into a segment by the order they ap- pear in the document based on the observation that the topical consistency atenuates along with the distance between the men- tions. Ten, we sort mentions in a segment based on the local similarity and place the mention that has a higher similarity value in the front of the sequence.",
  "Ten, we sort mentions in a segment based on the local similarity and place the mention that has a higher similarity value in the front of the sequence. In Equation 1, we de\ufb01ne the local similarity of mi and its corresponding candidate entity ei t . On this basis, we de\ufb01ne \u03a8max(mi,ea i ) as the the maximum local similarity between the mi and its candidate set Cmi = {e1 i ,e2 i , ...,en i }. We use \u03a8max(mi,ea i ) as criterion when sorting mentions. For instance, if \u03a8max(mi,ea i ) > \u03a8max(mj,eb j ) then we place mi before mj. Under this circumstances, the mentions in the front positions may not be able to make beter use of global consistency, but their target entities have a high degree of similarity to the context words, which allows them to be disambiguated without relying on additional in- formation. In the end, previous selected target entity information is encoded by global encoder and the encoding result will be served as input to the entity selector. Before using entity selector to choose target entities, we pre- trained the global LSTM network.",
  "In the end, previous selected target entity information is encoded by global encoder and the encoding result will be served as input to the entity selector. Before using entity selector to choose target entities, we pre- trained the global LSTM network. During the training process, we input not only positive samples but also negative ones to the LSTM. By doing this, we can enhance the robustness of the network. In the global encoder module, we adopt the following cross entropy loss function to train the model. L\u0434lobal = \u22121 n \u00d5 x h y lny \u2032 + (1 \u2212y) ln(1 \u2212y \u2032) i (3) Where y \u2208{0, 1} represents the label of the candidate entity. If the candidate entity is correct y = 1, otherwise y = 0. y \u2032 \u2208(0, 1) indicates the output of our model. Afer pre-training the global Mention Context Candidate Entity Features Previous Decisions Multilayer Perceptron Softmax Concatenate Figure 3: Te architecture of policy network.",
  "Afer pre-training the global Mention Context Candidate Entity Features Previous Decisions Multilayer Perceptron Softmax Concatenate Figure 3: Te architecture of policy network. It is a feedfor- ward neural network and the input consists of four parts: mention context representation, candidate entity represen- tation, feature representation, and encoding of the previous decisions. encoder, we start using the entity selector to choose the target entity for each mention and encode these selections. 2.4 Entity Selector In the entity selector module, we choose the target entity from candidate set based on the results of local and global encoder. In the process of sequence disambiguation, each selection result will have an impact on subsequent decisions. Terefore, we transform the choice of the target entity into a reinforcement learning problem and view the entity selector as an agent. In particular, the agent is designed as a policy network which can learn a stochastic policy and prevents the agent from geting stuck at an intermediate state [39]. Under the guidance of policy, the agent can decide which action (choosing the target entity from the candidate set)should be taken at each state, and receive a delay reward when all the selections are made.",
  "Under the guidance of policy, the agent can decide which action (choosing the target entity from the candidate set)should be taken at each state, and receive a delay reward when all the selections are made. In the following part, we \ufb01rst describe the state, action and reward. Ten, we detail how to select target entity via a policy network. State. Te result of entity selection is based on the current state information. For time t, the state vector St is generated as follows: St = V t mi \u2295V t ei \u2295V t f eature \u2295V t\u22121 e\u2217 (4) Where \u2295indicates vector concatenation. Te V tmi and V tei respec- tively denote the vector of mi and ei at time t. For each mention, there are multiple candidate entities correspond to it. With the purpose of comparing the semantic relevance between the men- tion and each candidate entity at the same time, we copy multiple copies of the mention vector. Formally, we extend V tmi \u2208R1\u00d7n to V tmi \u2032 \u2208Rk\u00d7n and then combine it with V tei \u2208Rk\u00d7n.",
  "Formally, we extend V tmi \u2208R1\u00d7n to V tmi \u2032 \u2208Rk\u00d7n and then combine it with V tei \u2208Rk\u00d7n. Since V tmi and V tei are mainly to represent semantic information, we add feature vector V t f eature to enrich lexical and statistical features. Tese fea- tures mainly include the popularity of the entity, the edit distance between the entity description and the mention context, the num- ber of identical words in the entity description and the mention context etc. Afer geting these feature values, we combine them",
  "Joint Entity Linking with Deep Reinforcement Learning WWW 2019, May 13-17, 2019, San Francisco, CA, USA into a vector and add it to the current state. In addition, the global vector V t\u22121 e\u2217 is also added to St . As mentioned in global encoder module, V t\u22121 e\u2217 is the output of global LSTM network at time t \u22121, which encodes the mention context and target entity information from m0 to mt\u22121. Tus, the state St contains current information and previous decisions, while also covering the semantic represen- tations and a variety of statistical features. Next, the concatenated vector will be fed into the policy network to generate action. Action. According to the status at each time step, we take corre- sponding action. Speci\ufb01cally, we de\ufb01ne the action at time step t is to select the target entity e\u2217 t formt . Te size of action space is the num- ber of candidate entities for each mention, where ai \u2208{0, 1, 2...k} indicates the position of the selected entity in the candidate entity list.",
  "Te size of action space is the num- ber of candidate entities for each mention, where ai \u2208{0, 1, 2...k} indicates the position of the selected entity in the candidate entity list. Clearly, each action is a direct indicator of target entity selec- tion in our model. Afer completing all the actions in the sequence we will get a delayed reward. Reward. Te agent takes the reward value as the feedback of its action and learns the policy based on it. Since current selection result has a long-term impact on subsequent decisions, we don\u2019t give an immediate reward when taking an action. Instead, a delay reward is given by follows, which can re\ufb02ect whether the action improves the overall performance or not. R(at ) = p(at ) T \u00d5 j=t p(aj) + (1 \u2212p(at ))( T \u00d5 j=t p(aj) + t \u2212T) (5) where p(at ) \u2208{0, 1} indicates whether the current action is correct or not. When the action is correct p(at ) = 1 otherwise p(at ) = 0.",
  "When the action is correct p(at ) = 1 otherwise p(at ) = 0. Hence \u00cdT j=t p(aj) and \u00cdT j=t p(aj) +t \u2212T respectively represent the number of correct and wrong actions from time t to the end of episode. Based on the above de\ufb01nition, our delayed reward can be used to guide the learning of the policy for entity linking. Policy Network. Afer de\ufb01ning the state, action, and reward, our main challenge becomes to choose an action from the action space. To solve this problem, we sample the value of each action by a policy network \u03c0\u0398(a|s). Te structure of the policy network is shown in Figure 3. Te input of the network is the current state, including the mention context representation, candidate entity representation, feature representation, and encoding of the previous decisions.",
  "Te structure of the policy network is shown in Figure 3. Te input of the network is the current state, including the mention context representation, candidate entity representation, feature representation, and encoding of the previous decisions. We concatenate these representations and fed them into a multilayer perceptron, for each hidden layer, we generate the output by: hi(St ) = Relu(Wi \u2217hi\u22121(St ) + bi) (6) WhereWi andbi are the parameters of the ith hidden layer, through the relu activation function we get the hi(St ). Afer geting the output of the last hidden layer, we feed it into a sofmax layer which generates the probability distribution of actions. Te probability distribution is generated as follows: \u03c0(a|s) = Sof tmax(W \u2217hl(S) + b) (7) Where the W and b are the parameters of the sofmax layer. For each mention in the sequence, we will take action to select the target entity from its candidate set. Afer completing all decisions in the episode, each action will get an expected reward and our goal is to maximize the expected total rewards. Formally,",
  "For each mention in the sequence, we will take action to select the target entity from its candidate set. Afer completing all decisions in the episode, each action will get an expected reward and our goal is to maximize the expected total rewards. Formally, the objective Algorithm 1 Te Policy Learning for Entity Selector Require: Training data include multiple documents D = {D1, D2, ..., DN } Ensure: Te target entity for mentions \u0393 = {T1,T2, ...,TN } 1: Initialize the policy network parameter \u0398, global LSTM net- work parameter \u03a6; 2: for Dk in D do 3: Generate the candidate set for each mention 4: Divide the mentions in Dk into multiple sequences S = {S1,S2, ...,SN }; 5: for Sk in S do 6: Rank the mentions M = {m1,m2, ...,mn} in Sk based on the local similarity; 7: for mk in M do 8: Sample the target entity e\u2217 k for mk with \u0398; 9: Input the V tmk and V t e\u2217 k to global LSTM network;",
  "m2, ...,mn} in Sk based on the local similarity; 7: for mk in M do 8: Sample the target entity e\u2217 k for mk with \u0398; 9: Input the V tmk and V t e\u2217 k to global LSTM network; 10: end for 11: // End of sampling, update parameters 12: Compute delayed reward R(at ) for each action; 13: Update the parameter \u0398 \u2032 of policy network: \u0398 \u2190\u0398 + \u03b1 \u00cd t R(at )\u2207\u0398 log \u03c0\u0398(a|s) 14: end for 15: Update the parameter \u03a6 in the global LSTM network 16: end for function is de\ufb01ned as: J(\u0398) = E(st,at )\u223cP\u0398(st,at )R(s1a1...sLaL) = \u00d5 t \u00d5 a \u03c0\u0398(a|s)R(at ) (8) Where P\u0398(st,at ) is the state transfer function, \u03c0\u0398(a|s) indicates the probability of taking action a under the state s,",
  "..sLaL) = \u00d5 t \u00d5 a \u03c0\u0398(a|s)R(at ) (8) Where P\u0398(st,at ) is the state transfer function, \u03c0\u0398(a|s) indicates the probability of taking action a under the state s, R(at ) is the expected reward of action a at time step t. According to REINFORCE policy gradient algorithm[38], we update the policy gradient by the way of equation 9. \u0398 \u2190\u0398 + \u03b1 \u00d5 t R(at )\u2207\u0398 log \u03c0\u0398(a|s) (9) As the global encoder and the entity selector are correlated mutually, we train them jointly afer pre-training the two networks. Te details of the joint learning are presented in Algorithm 1. 3 EXPERIMENT In order to evaluate the e\ufb00ectiveness of our method, we train the RLEL model and validate it on a series of popular datasets that are also used by [14, 37]. To avoid over\ufb01ting with one dataset, we use both AIDA-Train and Wikipedia data in the training set.",
  "To avoid over\ufb01ting with one dataset, we use both AIDA-Train and Wikipedia data in the training set. Further- more, we compare the RLEL with some baseline methods, where our model achieves the state-of-the-art results. We implement our models in Tensor\ufb02ow and run experiments on 4 Tesla V100 GPU. 3.1 Experiment Setup Datasets. We conduct experiments on several di\ufb00erent types of public datasets including news and encyclopedia corpus. Te train- ing set is AIDA-Train and Wikipedia datasets, where AIDA-Train contains 18448 mentions and Wikipedia contains 25995 mentions.",
  "WWW 2019, May 13-17, 2019, San Francisco, CA, USAZheng Fang, Yanan Cao, Dongjie Zhang, Qian Li, Zhenyu Zhang, and Yanbing Liu Table 1: Statistics of document and mention numbers on ex- perimental datasets. Dataset Doc Num Mention Num Mentions Per Doc AIDA-Train 946 18448 19.5 AIDA-A 216 4791 22.1 AIDA-B 231 4485 19.4 ACE2004 36 251 7.1 MSNBC 20 656 32.8 AQUAINT 50 727 14.5 WNED-CWEB 320 11154 34.8 WNED-WIKI 320 6821 21.3 OURSELF-WIKI 460 25995 56.5 In order to compare with the previous methods, we evaluate our model on AIDA-B and other datasets. Tese datasets are well- known and have been used for the evaluation of most entity linking systems. Te statistics of the datasets are shown in Table 1.",
  "Tese datasets are well- known and have been used for the evaluation of most entity linking systems. Te statistics of the datasets are shown in Table 1. \u2022 AIDA-CoNLL [20] is annotated on Reuters news articles. It contains training (AIDA-Train), validation (AIDA-A) and test (AIDA-B) sets. \u2022 ACE2004 [34] is a subset of the ACE2004 Coreference doc- uments. \u2022 MSNBC [9] contains top two stories in the ten news cate- gories(Politics, Business, Sports etc.) \u2022 AQUAINT [25] is a news corpus from the Xinhua News Service, the New York Times, and the Associated Press. \u2022 WNED-CWEB [16] is randomly picked from the FACC1 annotated ClueWeb 2012 dataset. \u2022 WNED-WIKI [16] is crawled from Wikipedia pages with its original hyperlink annotation. \u2022 OURSELF-WIKI is crawled by ourselves from Wikipedia pages. Training Details. During the training of our RLEL model, we select top K candidate entities for each mention to optimize the memory and run time.",
  "\u2022 OURSELF-WIKI is crawled by ourselves from Wikipedia pages. Training Details. During the training of our RLEL model, we select top K candidate entities for each mention to optimize the memory and run time. In the top K candidate list, we de\ufb01ne the recall of correct target entity is Rt . According to our statistics, when K is set to 1, Rt is 0.853, when K is 5, Rt is 0.977, when K increases to 10, Rt is 0.993. Empirically, we choose top 5 candidate entities as the input of our RLEL model. For the entity description, there are lots of redundant information in the wikipedia page, to reduce the impact of noise data, we use TextRank algorithm [23] to select 15 keywords as description of the entity. Simultaneously, we choose 15 words around mention as its context. In the global LSTM network, when the number of mentions does not reach the set length, we adopt the mention padding strategy. In short, we copy the last mention in the sequence until the number of mentions reaches the set length. Hyper-parameter seting.",
  "In the global LSTM network, when the number of mentions does not reach the set length, we adopt the mention padding strategy. In short, we copy the last mention in the sequence until the number of mentions reaches the set length. Hyper-parameter seting. We set the dimensions of word embed- ding and entity embedding to 300, where the word embedding and entity embedding are released by [30] and [14] respectively. For parameters of the local LSTM network, the number of LSTM cell units is set to 512, the batch size is 64, and the rank margin \u03b3 is 0.1. Similarly, in global LSTM network, the number of LSTM cell units is 700 and the batch size is 16. In the above two LSTM networks, Table 2: In-KB accuracy result on AIDA-B dataset. Methods AIDA-B Huang and Heck (2015)[21] 86.6% Chisholm and Hachey (2015)[6] 88.7% Guo and Barbosa (2016)[16] 89.0% Globerson et al. (2016)[15] 91.0% Yamada et al.",
  "(2016)[15] 91.0% Yamada et al. (2016)[40] 91.5% Ganea and Hofmann (2017)[14] 92.2% Phong and Titov (2018)[37] 93.1% our 94.3% the learning rate is set to 1e-3, the probability of dropout is set to 0.8, and the Adam is utilized as optimizer. In addition, we set the number of MLP layers to 4 and extend the priori feature dimension to 50 in the policy network. 3.2 Comparing with Previous Work Baselines. We compare RLEL with a series of EL systems which report state-of-the-art results on the test datasets. Tere are various methods including classi\ufb01cation model [25], rank model [6, 34] and probability graph model [14, 16, 20, 21, 37]. Except that, Cheng et al.[5] formulate their global decision problem as an Integer Linear Program (ILP) which incorporates the entity-relation inference. Globerson et al.",
  "Except that, Cheng et al.[5] formulate their global decision problem as an Integer Linear Program (ILP) which incorporates the entity-relation inference. Globerson et al. [15] introduce a multi-focal atention model which allows each candidate to focus on limited mentions, Yamada et al.[40] propose a word and entity embedding model speci\ufb01cally designed for EL. Evaluation Metric. We use the standard Accuracy, Precision, Re- call and F1 at mention level (Micro) as the evaluation metrics: Accuracy = |M \u2229M\u2217| |M \u222aM\u2217| (10) Precision = |M \u2229M\u2217| |M| (11) Recall = |M \u2229M\u2217| |M\u2217| (12) F1 = 2 \u2217Precision \u2217Recall Precision + Recall (13) where M\u2217is the golden standard set of the linked name mentions, M is the set of linked name mentions outputed by an EL method. Results. Same as previous work, we use in-KB accuracy and micro F1 to evaluate our method.",
  "Results. Same as previous work, we use in-KB accuracy and micro F1 to evaluate our method. We \ufb01rst test the model on the AIDA-B dataset. From Table 2, we can observe that our model achieves the best result. Previous best results on this dataset are generated by [14, 37] which both built CRF models. Tey calcu- late the pairwise scores between all candidate entities. Di\ufb00erently, our model only considers the consistency of the target entities and ignores the relationship between incorrect candidates. Te experimental results show that our model can reduce the impact of noise data and improve the accuracy of disambiguation. Apart from experimenting on AIDA-B, we also conduct experiments on several di\ufb00erent datasets to verify the generalization performance of our model.",
  "Joint Entity Linking with Deep Reinforcement Learning WWW 2019, May 13-17, 2019, San Francisco, CA, USA Table 3: Compare our model with other baseline methods on di\ufb00erent types of datasets. Te evaluation metric is micro F1. Methods MSNBC AQUAINT ACE2004 CWEB WIKI Avg Milne and Witen (2008)[25] 78% 85% 81% 64.1% 81.7% 77.96% Ho\ufb00art and Johannes(2011)[20] 79% 56% 80% 58.6% 63% 67.32% Ratinov and Lev[34] 75% 83% 82% 56.2% 67.2% 72.68% Cheng and Roth (2013)[5] 90% 90% 86% 67.5% 73.4% 81.38% Guo and Barbosa (2016)[16] 92% 87% 88% 77% 84.5% 85.",
  "5% 73.4% 81.38% Guo and Barbosa (2016)[16] 92% 87% 88% 77% 84.5% 85.7% Ganea and Hofmann (2017)[14] 93.7% 88.5% 88.5% 77.9% 77.5% 85.22% Phong and Titov (2018)[37] 93.9% 88.3% 89.9% 77.5% 78.0% 85.51% our 92.8% 87.5% 91.2% 78.5% 82.8% 86.56% Table 4: Te micro F1 of gold entities with di\ufb00erent pageviews on part of AIDA-B dataset.",
  "51% our 92.8% 87.5% 91.2% 78.5% 82.8% 86.56% Table 4: Te micro F1 of gold entities with di\ufb00erent pageviews on part of AIDA-B dataset. Pageview/million Mention Num Micro F1 < 0.01 307 91.93% 0.01-0.1 612 86.06% 0.1-1 968 88.97% 1-5 1006 96.03% 5-10 493 96.43% > 10 825 99.39% From Table 3, we can see that RLEL has achieved relatively good performances on ACE2004, CWEB and WIKI. At the same time, previous models [5, 14, 37] achieve beter performances on the news datasets such as MSNBC and AQUINT, but their results on encyclopedia datasets such as WIKI are relatively poor.",
  "At the same time, previous models [5, 14, 37] achieve beter performances on the news datasets such as MSNBC and AQUINT, but their results on encyclopedia datasets such as WIKI are relatively poor. To avoid over\ufb01ting with some datasets and improve the robustness of our model, we not only use AIDA-Train but also add Wikipedia data to the training set. In the end, our model achieve the best overall performance. For most existing EL systems, entities with lower frequency are di\ufb03cult to disambiguate. To gain further insight, we analyze the accuracy of the AIDA-B dataset for situations where gold entities have low popularity. We divide the gold entities according to their pageviews in wikipedia, the statistical disambiguation results are shown in Table 4. Since some pageviews can not be obtained, we only count part of gold entities. Te result indicates that our model is still able to work well for low-frequency entities. But for medium-frequency gold entities, our model doesn\u2019t work well enough.",
  "Since some pageviews can not be obtained, we only count part of gold entities. Te result indicates that our model is still able to work well for low-frequency entities. But for medium-frequency gold entities, our model doesn\u2019t work well enough. Te most important reason is that other candidate entities corresponding to these medium-frequency gold entities have higher pageviews and local similarities, which makes the model di\ufb03cult to distinguish. 3.3 Discussion on di\ufb00erent RLEL variants To demonstrate the e\ufb00ects of RLEL, we evaluate our model under di\ufb00erent conditions. First, we evaluate the e\ufb00ect of sequence length on global decision making. Second, we assess whether sorting the mentions have a positive e\ufb00ect on the results. Tird, we analysis the results of not adding globally encoding during entity selection. Last, we compare our RL selection strategy with the greedy choice.",
  "Second, we assess whether sorting the mentions have a positive e\ufb00ect on the results. Tird, we analysis the results of not adding globally encoding during entity selection. Last, we compare our RL selection strategy with the greedy choice. 2 3 4 5 6 7 8 9 sequence length 0.75 0.80 0.85 0.90 0.95 micro F1 Figure 4: Te performance of models with di\ufb00erent se- quence lengths on AIDA-B dataset. Sequence in di\ufb00erent length. A document may contain multiple topics, so we do not add all mentions to a single sequence. In practice, we add some adjacent mentions to the sequence and use reinforcement learning to select entities from beginning to end. To analysis the impact of the number of mentions on joint disam- biguation, we experiment with sequences on di\ufb00erent lengths. Te results on AIDA-B are shown in Figure 4. We can see that when the sequence is too short or too long, the disambiguation results are both very poor.",
  "Te results on AIDA-B are shown in Figure 4. We can see that when the sequence is too short or too long, the disambiguation results are both very poor. When the sequence length is less than 3, delay re- ward can\u2019t work in reinforcement learning, and when the sequence length reaches 5 or more, noise data may be added. Finally, we choose the 4 adjacent mentions to form a sequence. Influence of ranking mentions. In this section, we test whether ranking mentions is helpful for entity selections. At \ufb01rst, we directly input them into the global encoder by the order they appear in the text. We record the disambiguation results and compare them with the method which adopts ranking mentions. As shown in Figure 5a, the model with ranking mentions has achieved beter performances on most of datasets, indicating that it is e\ufb00ective to place the mention that with a higher local similarity in front of the sequence.",
  "As shown in Figure 5a, the model with ranking mentions has achieved beter performances on most of datasets, indicating that it is e\ufb00ective to place the mention that with a higher local similarity in front of the sequence. It is worth noting that the e\ufb00ect of ranking mentions is not obvious on the MSNBC dataset, the reason is that most of mentions in MSNBC have similar local similarities, the order of disambiguation has litle e\ufb00ect on the \ufb01nal result. E\ufb00ect of global encoding. Most of previous methods mainly use the similarities between entities to correlate each other, but our model associates them by encoding the selected entity information.",
  "WWW 2019, May 13-17, 2019, San Francisco, CA, USAZheng Fang, Yanan Cao, Dongjie Zhang, Qian Li, Zhenyu Zhang, and Yanbing Liu a.The influence of ranking mentions  for entity selection. \ud835\udc4f. The effect of the global encoding  for entity selection. \ud835\udc50. Comparison of reinforcement learning  selection with greedy choice. Figure 5: Te comparative experiments of RLEL model. Table 5: Entity selection examples by our RLEL model.",
  "\ud835\udc4f. The effect of the global encoding  for entity selection. \ud835\udc50. Comparison of reinforcement learning  selection with greedy choice. Figure 5: Te comparative experiments of RLEL model. Table 5: Entity selection examples by our RLEL model. Document Content Mentions afer ranking Selected Target Entity(is correct) Australia beat West Indies by \ufb01ve wickets in a World Series limited overs match at the Melbourne Cricket Groundon Friday\u2026 1.Melbourne Cricket Ground 2.World Series 3.West Indies 4.Australia 1.Melbourne Cricket Ground(correct) 2.World Series Cricket(correct) 3.West Indies cricket team(correct) 4.Australia national cricket team(correct) Instead of Los Angeles International, \u2026, consider \ufb02ying into Burbank or John Wayne Airport in Orange County, Calif\u2026 1.John Wayne Airport 2.Orange County 3.Los Angeles International 4.Burbank 1.John Wayne Airport(correct) 2.Orange County, California(correct) 3.Los Angeles International Airport(correct) 4.Burbank, California (wrong, the correct is \u201dHollywood Burbank Airport\u201d) To assess whether the global encoding contributes to disambigua- tion rather than add noise, we compare the performance with and without adding the global information.",
  "When the global encoding is not added, the current state only contains the mention context representation, candidate entity representation and feature rep- resentation, notably, the selected target entity information is not taken into account. From the results in Figure 5b, we can see that the model with global encoding achieves an improvement of 4% accuracy over the method that without global encoding. Di\ufb00erent entity selection strategies. To illustrate the necessity for adopting the reinforcement learning for entity selection, we compare two entity selection strategies like [12]. Speci\ufb01cally, we perform entity selection respectively with reinforcement learning and greedy choice. Te greedy choice is to select the entity with largest local similarity from candidate set. But the reinforcement learning selection is guided by delay reward, which has a global perspective. In the comparative experiment, we keep the other conditions consistent, just replace the RL selection with a greedy choice. Based on the results in Figure 5c, we can draw a conclusion that our entity selector perform much beter than greedy strategies. 3.4 Case Study Table 5 shows two entity selection examples by our RLEL model.",
  "Based on the results in Figure 5c, we can draw a conclusion that our entity selector perform much beter than greedy strategies. 3.4 Case Study Table 5 shows two entity selection examples by our RLEL model. For multiple mentions appearing in the document, we \ufb01rst sort them according to their local similarities, and select the target entities in order by the reinforcement learning model. From the results of sorting and disambiguation, we can see that our model is able to utilize the topical consistency between mentions and make full use of the selected target entity information. 4 RELATED WORK Te related work can be roughly divided into two groups: entity linking and reinforcement learning. 4.1 Entity Linking Entity linking falls broadly into two major approaches: local and global disambiguation. Early studies use local models to resolve mentions independently, they usually disambiguate mentions based on lexical matching between the mention\u2019s surrounding words and the entity pro\ufb01le in the reference KB. Various methods have been proposed to model mention\u2019s local context ranging from binary classi\ufb01cation [25] to rank models [4, 11]. In these methods, a large number of hand-designed features are applied.",
  "Various methods have been proposed to model mention\u2019s local context ranging from binary classi\ufb01cation [25] to rank models [4, 11]. In these methods, a large number of hand-designed features are applied. For some marginal mentions that are di\ufb03cult to extract features, researchers also ex- ploit the data retrieved by search engines [7, 8] or Wikipedia sen- tences [36]. However, the feature engineering and search engine methods are both time-consuming and laborious. Recently, with the popularity of deep learning models, representation learning is utilized to automatically \ufb01nd semantic features [2, 17]. Te learned entity representations which by jointly modeling textual contexts",
  "Joint Entity Linking with Deep Reinforcement Learning WWW 2019, May 13-17, 2019, San Francisco, CA, USA and knowledge base are e\ufb00ective in combining multiple sources of information. To make full use of the information contained in representations, we also utilize the pre-trained entity embeddings in our model. In recent years, with the assumption that the target entities of all mentions in a document shall be related, many novel global models for joint linking are proposed. Assuming the topical coherence among mentions, authors in [13, 33] construct factor graph models, which represent the mention and candidate entities as variable nodes, and exploit factor nodes to denote a series of features. Two recent studies [14, 37] use fully-connected pairwise Conditional Random Field(CRF) model and exploit loopy belief propagation to estimate the max-marginal probability. Moreover, PageRank or Random Walk [16, 19, 42] are utilized to select the target entity for each mention. Te above probabilistic models usually need to prede\ufb01ne a lot of features and are di\ufb03cult to calculate the max- marginal probability as the number of nodes increases.",
  "Te above probabilistic models usually need to prede\ufb01ne a lot of features and are di\ufb03cult to calculate the max- marginal probability as the number of nodes increases. In order to automatically learn features from the data, Cao et al. [1] applies Graph Convolutional Network to \ufb02exibly encode entity graphs. However, the graph-based methods are computationally expensive because there are lots of candidate entity nodes in the graph. To reduce the calculation between candidate entity pairs, Glober- son et al. [15] introduce a coherence model with an atention mechanism, where each mention only focus on a \ufb01xed number of mentions. Unfortunately, choosing the number of atention mentions is not easy in practice. Two recent studies [31, 32] \ufb01nish linking all mentions by scanning the pairs of mentions at most once, they assume each mention only needs to be consistent with one another mention in the document. Te limitation of their method is that the consistency information is too sparse, resulting in low con\ufb01dence. Similar to us, Guo et al.",
  "Te limitation of their method is that the consistency information is too sparse, resulting in low con\ufb01dence. Similar to us, Guo et al. [16] also sort mentions accord- ing to the di\ufb03culty of disambiguation, but they did not make full use of the information of previously referred entities for the subse- quent entity disambiguation. Nguyen et al. [27] use the sequence model, but they simply encode the results of the greedy choice, and measure the similarities between the global encoding and the candidate entity representations. Teir model does not consider the long-term impact of current decisions on subsequent choices, nor does they add the selected target entity information to the current state to help disambiguation. 4.2 Reinforcement Learning In the last few years, reinforcement learning has emerged as a pow- erful tool for solving complex sequential decision-making problems. It is well known for its great success in the game \ufb01eld, such as Go [35] and Atari games [26]. Recently, reinforcement learning has also been successfully applied to many natural language processing tasks and achieved good performance [12, 22, 39].",
  "It is well known for its great success in the game \ufb01eld, such as Go [35] and Atari games [26]. Recently, reinforcement learning has also been successfully applied to many natural language processing tasks and achieved good performance [12, 22, 39]. Feng et al.[12] used reinforcement learning for relation classi\ufb01cation task by \ufb01l- tering out the noisy data from the sentence bag and they achieved huge improvements compared with traditional classi\ufb01ers. Zhang et al. [41] applied the reinforcement learning on sentence repre- sentation by automatically discovering task-relevant structures. To automatic taxonomy induction from a set of terms, Han et al. [18] designed an end-to-end reinforcement learning model to determine which term to select and where to place it on the taxonomy, which e\ufb00ectively reduced the error propagation between two phases. In- spired by the above works, we also add reinforcement learning to our framework. 5 CONCLUSIONS In this paper we consider entity linking as a sequence decision problem and present a reinforcement learning based model.",
  "In- spired by the above works, we also add reinforcement learning to our framework. 5 CONCLUSIONS In this paper we consider entity linking as a sequence decision problem and present a reinforcement learning based model. Our model learns the policy on selecting target entities in a sequential manner and makes decisions based on current state and previous ones. By utilizing the information of previously referred entities, we can take advantage of global consistency to disambiguate mentions. For each selection result in the current state, it also has a long- term impact on subsequent decisions, which allows learned policy strategy has a global view. In experiments, we evaluate our method on AIDA-B and other well-known datasets, the results show that our system outperforms state-of-the-art solutions. In the future, we would like to use reinforcement learning to detect mentions and determine which mention should be \ufb01rstly disambiguated in the document. ACKNOWLEDGMENTS Tis research is supported by the National Key Research and De- velopment Program of China (No. 2018YFB1004703), the Beijing Municipal Science and Technology Project under grant (No.",
  "ACKNOWLEDGMENTS Tis research is supported by the National Key Research and De- velopment Program of China (No. 2018YFB1004703), the Beijing Municipal Science and Technology Project under grant (No. Z181100002718004), and the National Natural Science Foundation of China grants(No. 61602466). REFERENCES [1] Yixin Cao, Lei Hou, Juanzi Li, and Zhiyuan Liu. 2018. Neural Collective Entity Linking. In Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018, Santa Fe, New Mexico, USA, August 20-26, 2018. 675\u2013 686. [2] Yixin Cao, Lifu Huang, Heng Ji, Xu Chen, and Juanzi Li. 2017. Bridge Text and Knowledge by Learning Multi-Prototype Entity Mention Embedding. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers. 1623\u20131633.",
  "Bridge Text and Knowledge by Learning Multi-Prototype Entity Mention Embedding. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers. 1623\u20131633. [3] Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting System. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016. 785\u2013794. [4] Zheng Chen and Heng Ji. 2011. Collaborative Ranking: A Case Study on Entity Linking. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John McIntyre Conference Centre, Edinburgh, UK, A meeting of SIGDAT, a Special Interest Group of the ACL. 771\u2013781. [5] Xiao Cheng and Dan Roth. 2013. Relational Inference for Wiki\ufb01cation.",
  "771\u2013781. [5] Xiao Cheng and Dan Roth. 2013. Relational Inference for Wiki\ufb01cation. In Proceed- ings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013, Grand Hyat Seatle, Seatle, Washington, USA, A meeting of SIGDAT, a Special Interest Group of the ACL. 1787\u20131796. [6] Andrew Chisholm and Ben Hachey. 2015. Entity Disambiguation with Web Links. TACL 3 (2015), 145\u2013156. [7] Marco Cornolti, Paolo Ferragina, Massimiliano Ciaramita, Stefan R\u00a8ud, and Hin- rich Sch\u00a8utze. 2016. A Piggyback System for Joint Entity Mention Detection and Linking in Web Qeries. In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016. 567\u2013578.",
  "2016. A Piggyback System for Joint Entity Mention Detection and Linking in Web Qeries. In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016. 567\u2013578. [8] Marco Cornolti, Paolo Ferragina, Massimiliano Ciaramita, Hinrich Sch\u00a8utze, and Stefan R\u00a8ud. 2014. Te SMAPH system for query entity recognition and dis- ambiguation. In ERD\u201914, Proceedings of the First ACM International Workshop on Entity Recognition & Disambiguation, July 11, 2014, Gold Coast, Qeensland, Australia. 25\u201330. [9] Silviu Cucerzan. 2007. Large-Scale Named Entity Disambiguation Based on Wikipedia Data. In EMNLP-CoNLL 2007, Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, June 28-30, 2007, Prague, Czech Republic. 708\u2013716.",
  "WWW 2019, May 13-17, 2019, San Francisco, CA, USAZheng Fang, Yanan Cao, Dongjie Zhang, Qian Li, Zhenyu Zhang, and Yanbing Liu [10] Bhuwan Dhingra, Lihong Li, Xiujun Li, Jianfeng Gao, Yun-Nung Chen, Faisal Ahmed, and Li Deng. 2017. Towards End-to-End Reinforcement Learning of Dia- logue Agents for Information Access. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers. 484\u2013495. [11] Mark Dredze, Paul McNamee, Delip Rao, Adam Gerber, and Tim Finin. 2010. Entity Disambiguation for Knowledge Base Population. In COLING 2010, 23rd In- ternational Conference on Computational Linguistics, Proceedings of the Conference, 23-27 August 2010, Beijing, China. 277\u2013285.",
  "2010. Entity Disambiguation for Knowledge Base Population. In COLING 2010, 23rd In- ternational Conference on Computational Linguistics, Proceedings of the Conference, 23-27 August 2010, Beijing, China. 277\u2013285. [12] Jun Feng, Minlie Huang, Li Zhao, Yang Yang, and Xiaoyan Zhu. 2018. Reinforce- ment Learning for Relation Classi\ufb01cation From Noisy Data. In Proceedings of the Tirty-Second AAAI Conference on Arti\ufb01cial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018. [13] Octavian-Eugen Ganea, Marina Ganea, Aur\u00b4elien Lucchi, Carsten Eickho\ufb00, and Tomas Hofmann. 2016. Probabilistic Bag-Of-Hyperlinks Model for Entity Linking. In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016. 927\u2013938. [14] Octavian-Eugen Ganea and Tomas Hofmann.",
  "In Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Montreal, Canada, April 11 - 15, 2016. 927\u2013938. [14] Octavian-Eugen Ganea and Tomas Hofmann. 2017. Deep Joint Entity Disam- biguation with Local Neural Atention. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017. 2619\u20132629. [15] Amir Globerson, Nevena Lazic, Soumen Chakrabarti, Amarnag Subramanya, Michael Ringgaard, and Fernando Pereira. 2016. Collective Entity Resolution with Multi-Focal Atention. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers. [16] Zhaochen Guo and Denilson Barbosa. 2018. Robust named entity disambiguation with random walks.",
  "[16] Zhaochen Guo and Denilson Barbosa. 2018. Robust named entity disambiguation with random walks. Semantic Web 9, 4 (2018), 459\u2013479. [17] Nitish Gupta, Sameer Singh, and Dan Roth. 2017. Entity Linking via Joint Encod- ing of Types, Descriptions, and Context. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017. 2681\u20132690. [18] Jiawei Han, Xiang Ren, Jiaming Shen, Yuning Mao, and Xiaotao Gu. 2018. End-to- End Reinforcement Learning for Automatic Taxonomy Induction. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers. 2462\u20132472. [19] Xianpei Han, Le Sun, and Jun Zhao. 2011.",
  "2462\u20132472. [19] Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective entity linking in web text: a graph-based method. In Proceeding of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2011, Beijing, China, July 25-29, 2011. 765\u2013774. [20] Johannes Ho\ufb00art, Mohamed Amir Yosef, Ilaria Bordino, Hagen F\u00a8urstenau, Man- fred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Tater, and Gerhard Weikum. 2011. Robust Disambiguation of Named Entities in Text. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John McIntyre Conference Centre, Edinburgh, UK, A meeting of SIGDAT, a Special Interest Group of the ACL. 782\u2013792. [21] Hongzhao Huang, Larry P. Heck, and Heng Ji. 2015.",
  "782\u2013792. [21] Hongzhao Huang, Larry P. Heck, and Heng Ji. 2015. Leveraging Deep Neural Net- works and Knowledge Graphs for Entity Disambiguation. CoRR abs/1504.07678 (2015). arXiv:1504.07678 [22] Ting Liu, William Yang Wang, Yu Zhang, Qingyu Yin, and Weinan Zhang. 2018. Deep Reinforcement Learning for Chinese Zero Pronoun Resolution. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers. 569\u2013578. [23] Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing Order into Text. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing , EMNLP 2004, A meeting of SIGDAT, a Special Interest Group of the ACL, held in conjunction with ACL 2004, 25-26 July 2004, Barcelona, Spain. 404\u2013411.",
  "404\u2013411. [24] Tomas Mikolov, Kai Chen, Greg Corrado, and Je\ufb00rey Dean. 2013. E\ufb03cient Estimation of Word Representations in Vector Space. CoRR abs/1301.3781 (2013). arXiv:1301.3781 [25] David N. Milne and Ian H. Witen. 2008. Learning to link with wikipedia. In Pro- ceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM 2008, Napa Valley, California, USA, October 26-30, 2008. 509\u2013518.",
  "2008. Learning to link with wikipedia. In Pro- ceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM 2008, Napa Valley, California, USA, October 26-30, 2008. 509\u2013518. [26] Volodymyr Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Belle- mare, A. Graves, M. A. Riedmiller, A. Fidjeland, G. Ostrovski, S. Petersen, C. Beatie, A. Sadik, I. Antonoglou, H. King, D. Kumaran, D. Wierstra, S. Legg, and D. Hassabis. 2015. Human-level control through deep reinforcement learning. Nature 518, 7540 (2015), 529\u2013533.",
  "2015. Human-level control through deep reinforcement learning. Nature 518, 7540 (2015), 529\u2013533. [27] Tien Huu Nguyen, Nicolas R. Fauceglia, Mariano Rodriguez-Muro, Oktie Has- sanzadeh, Al\ufb01o Massimiliano Gliozzo, and Mohammad Sadoghi. 2016. Joint Learning of Local and Global Features for Entity Linking via Neural Networks. In COLING 2016, 26th International Conference on Computational Linguistics, Pro- ceedings of the Conference: Technical Papers, December 11-16, 2016, Osaka, Japan. 2310\u20132320. [28] Rodrigo Nogueira and Kyunghyun Cho. 2017. Task-Oriented Qery Reformu- lation with Reinforcement Learning. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017. 574\u2013583.",
  "Task-Oriented Qery Reformu- lation with Reinforcement Learning. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017. 574\u2013583. [29] Aasish Pappu, Roi Blanco, Yashar Mehdad, Amanda Stent, and Kapil Tadani. 2017. Lightweight Multilingual Entity Extraction and Linking. In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining, WSDM 2017, Cambridge, United Kingdom, February 6-10, 2017. 365\u2013374. [30] Je\ufb00rey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global Vectors for Word Representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL. 1532\u20131543.",
  "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL. 1532\u20131543. [31] Minh C. Phan, Aixin Sun, Yi Tay, Jialong Han, and Chenliang Li. 2017. NeuPL: Atention-based Semantic Matching and Pair-Linking for Entity Disambiguation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM 2017, Singapore, November 06 - 10, 2017. 1667\u20131676. [32] Minh C. Phan, Aixin Sun, Yi Tay, Jialong Han, and Chenliang Li. 2018. Pair- Linking for Collective Entity Disambiguation: Two Could Be Beter Tan All. CoRR abs/1802.01074 (2018). arXiv:1802.01074 [33] Chenwei Ran, Wei Shen, and Jianyong Wang. 2018.",
  "CoRR abs/1802.01074 (2018). arXiv:1802.01074 [33] Chenwei Ran, Wei Shen, and Jianyong Wang. 2018. An Atention Factor Graph Model for Tweet Entity Linking. In Proceedings of the 2018 World Wide Web Conference on World Wide Web, WWW 2018, Lyon, France, April 23-27, 2018. 1135\u20131144. [34] Lev-Arie Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and Global Algorithms for Disambiguation to Wikipedia. In Te 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference, 19-24 June, 2011, Portland, Oregon, USA. 1375\u20131384.",
  "Local and Global Algorithms for Disambiguation to Wikipedia. In Te 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference, 19-24 June, 2011, Portland, Oregon, USA. 1375\u20131384. [35] David Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. v. d. Driessche, J. Schritwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. P. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, and D. Hassabis. 2016. Mastering the game of Go with deep neural networks and tree search. Nature 529, 7587 (2016), 484\u2013489.",
  "2016. Mastering the game of Go with deep neural networks and tree search. Nature 529, 7587 (2016), 484\u2013489. [36] Chuanqi Tan, Furu Wei, Pengjie Ren, Weifeng Lv, and Ming Zhou. 2017. Entity Linking for Qeries by Searching Wikipedia Sentences. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017. 68\u201377. [37] Ivan Titov and Phong Le. 2018. Improving Entity Linking by Modeling Latent Relations between Mentions. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers. 1595\u20131604. [38] Ronald J. Williams. 1992. Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning. Machine Learning 8 (1992), 229\u2013256.",
  "1595\u20131604. [38] Ronald J. Williams. 1992. Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning. Machine Learning 8 (1992), 229\u2013256. [39] Wenhan Xiong, Tien Hoang, and William Yang Wang. 2017. DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017. 564\u2013573. [40] Ikuya Yamada, Hiroyuki Shindo, Hideaki Takeda, and Yoshiyasu Takefuji. 2016. Joint Learning of the Embedding of Words and Entities for Named Entity Dis- ambiguation. In Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning, CoNLL 2016, Berlin, Germany, August 11-12, 2016. 250\u2013259. [41] Tianyang Zhang, Minlie Huang, and Li Zhao. 2018.",
  "In Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning, CoNLL 2016, Berlin, Germany, August 11-12, 2016. 250\u2013259. [41] Tianyang Zhang, Minlie Huang, and Li Zhao. 2018. Learning Structured Rep- resentation for Text Classi\ufb01cation via Reinforcement Learning. In Proceedings of the Tirty-Second AAAI Conference on Arti\ufb01cial Intelligence, (AAAI-18), the 30th innovative Applications of Arti\ufb01cial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Arti\ufb01cial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018. 6053\u20136060. [42] Stefan Zwicklbauer, Christin Seifert, and Michael Granitzer. 2016. Robust and Collective Entity Disambiguation through Semantic Embeddings.",
  "6053\u20136060. [42] Stefan Zwicklbauer, Christin Seifert, and Michael Granitzer. 2016. Robust and Collective Entity Disambiguation through Semantic Embeddings. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016, Pisa, Italy, July 17-21, 2016. 425\u2013434."
]