{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "The Effect of Heterogeneous Data for Alzheimer\u2019s Disease Detection from Speech Aparna Balagopalan1,2, Jekaterina Novikova1, Frank Rudzicz1,2,3,4,5 and Marzyeh Ghassemi2,3 1Winterlight Labs, Toronto, ON 2Department of Computer Science, University of Toronto, ON 3Vector Institute for Arti\ufb01cial Intelligence, Toronto, ON 4Li Ka Shing Knowledge Institute, St Michael\u2019s Hospital, Toronto, ON 5Surgical Safety Technologies Inc., Toronto, ON {aparna,jekaterina}@winterlightlabs.com,{frank,marzyeh}@cs.toronto.edu Abstract Speech datasets for identifying Alzheimer\u2019s disease (AD) are generally restricted to participants performing a single task, e.g. describing an image shown to them. As a result, models trained on linguistic features derived from such datasets may not be generalizable across tasks. Building on prior work demonstrating that same- task data of healthy participants helps improve AD detection on a single-task dataset of pathological speech, we augment an AD-speci\ufb01c dataset consisting of subjects describing a picture with multi-task healthy data.",
            "Building on prior work demonstrating that same- task data of healthy participants helps improve AD detection on a single-task dataset of pathological speech, we augment an AD-speci\ufb01c dataset consisting of subjects describing a picture with multi-task healthy data. We demonstrate that normative data from multiple speech-based tasks helps improve AD detection by up to 9%.Visualization of decision boundaries reveals that models trained on a combination of structured picture descriptions and unstructured conversational speech have the least out-of-task error and show the most potential to generalize to multiple tasks. We analyze the impact of age of the added samples and if they affect fairness in classi\ufb01cation. We also provide explanations for a possible inductive bias effect across tasks using model-agnostic feature anchors. This work highlights the need for heterogeneous datasets for encoding changes in multiple facets of cognition and for developing a task-independent AD detection model. 1 Introduction Alzheimer\u2019s disease (AD) is a neurodegenerative disease affecting over 40 million people world- wide with high costs of acute and long-term care [17]. Recruitment of participants with cognitive impairment has historically been a bottleneck in clinical trials [24], making AD datasets relatively small.",
            "1 Introduction Alzheimer\u2019s disease (AD) is a neurodegenerative disease affecting over 40 million people world- wide with high costs of acute and long-term care [17]. Recruitment of participants with cognitive impairment has historically been a bottleneck in clinical trials [24], making AD datasets relatively small. Additionally, though cognitive assessments test domains of cognition through multiple tasks, most available datasets of pathological speech are restricted to participants performing a single task. Picture description using an image to elicit narrative discourse samples is one such task that has proved to be successful in detecting AD [7]. However, it is important to develop ML models of high performance that would produce results generalizable across different tasks. Several studies have used natural language processing and machine learning to distinguish between healthy and cognitively impaired speech of participants describing a picture. Fraser et al. [8] used linguistic and acoustic features to classify healthy and pathological speech transcripts with an accuracy of 82%. Similarly, Karlekar et al. [10] classi\ufb01ed utterances of speakers as AD or healthy (HC) with an accuracy of 91.1% using an enlarged, utterance-level view of transcripts of picture descriptions.",
            "Similarly, Karlekar et al. [10] classi\ufb01ed utterances of speakers as AD or healthy (HC) with an accuracy of 91.1% using an enlarged, utterance-level view of transcripts of picture descriptions. In line with previous research, we use linguistic and acoustic features of speech as input to our ML model. Furthermore, we extend the model to using data from several different tasks. Machine Learning for Health (ML4H) Workshop at NeurIPS 2018. arXiv:1811.12254v1  [cs.LG]  29 Nov 2018",
            "Noorian et al. [14] demonstrated that using within-task data of healthy participants describing a picture improved AD detection performance by up to 13%. In this paper, we evaluate if model performance improves with the addition of data from healthy participants, with varying ages, performing either the same or different tasks. We \ufb01nd that models trained on datasets of picture description tasks augmented with conversational speech of healthy speakers learn decision boundaries that are more generalizable across activities with lower out-of-task errors. We observe a 9% increase in AD detection performance when normative data from different tasks are utilized. We also analyze if each task provides domain- speci\ufb01c inductive bias for other tasks to obtain a model setting capable of detecting AD from any sample of speech using high-precision model-agnostic explanations proposed by Ribeiro et al. [18] and computation of various error metrics related to classi\ufb01cation.",
            "[18] and computation of various error metrics related to classi\ufb01cation. 2 Data Dataset Samples Subjects Age Tasks in Dataset Dementia Bank[3](DB) 409 (180 AD) 210 45 - 90 Picture Description Healthy Aging Picture Description (HAPD) 122 50 50 - 95 Picture Description Healthy Aging Fluency & Paragraph tasks (HAFP) 427 Verbal Fluency, Reading Famous People[15] (FP) 231 9 30 - 88 Conversational Speech Table 1: Speech datasets used. Note that HAPD, HAFP and FP only have samples from healthy subjects. Detailed description in App. 2. All datasets shown in Tab. 2 were transcribed manually by trained transcriptionists, employing the same list of annotations and protocols, with the same set of features extracted from the transcripts (see Sec. 3). HAPD and HAFP are jointly referred to as HA. 3 Methods Feature Extraction: We extract 297 linguistic features from the transcripts and 183 acoustic features from the associated audio \ufb01les, all task-independent. Linguistic features encompass syntactic features (e.g.",
            "3). HAPD and HAFP are jointly referred to as HA. 3 Methods Feature Extraction: We extract 297 linguistic features from the transcripts and 183 acoustic features from the associated audio \ufb01les, all task-independent. Linguistic features encompass syntactic features (e.g. syntactic complexity [12]), lexical features (e.g. occurrence of production rules). Acoustic features include Mel-frequency Cepstral Coef\ufb01cients (MFCCs) & pause-related features (e.g., mean pause duration). We also use sentiment lexical norms [23], local, and global coherence features [4]. Feature Predicates as Anchors for Prediction: Given a black box classi\ufb01er f with interpretable input representation, Ribeiro et al. [18] de\ufb01ne anchors A as a set of input rules such that when conditions in the rule are met, humans can con\ufb01dently predict the behavior of a model with high precision.",
            "[18] de\ufb01ne anchors A as a set of input rules such that when conditions in the rule are met, humans can con\ufb01dently predict the behavior of a model with high precision. Since the inputs to the classi\ufb01er are engineered features with \ufb01nite ranges,we can obtain suf\ufb01cient conditions for the prediction f(x) in terms of interpretable feature thresholds for an unseen instance x . Anchors are found by maximizing the metric of coverage, de\ufb01ned as the probability of anchors holding true to samples in the data distribution p, in [18]. Hence, cov(A) = Ep(z)[A(z)] is maximized, where precision(A) > \u03c4. We show in Sec. 5.4 that anchors identi\ufb01ed from a model trained on multiple tasks have more coverage over the data distribution than those obtained from a model trained on a single task. Such a scenario is possible when task-independant, clinically relevant speech features are selected as anchors (e.g., fraction of \ufb01lled pauses in speech [11], acoustic features [20] etc. ).",
            "Such a scenario is possible when task-independant, clinically relevant speech features are selected as anchors (e.g., fraction of \ufb01lled pauses in speech [11], acoustic features [20] etc. ). Additionally, such selected anchors must also be associated with thresholds applicable across multiple types of speech. 4 Experiments Binary classi\ufb01cation of each speech transcript as AD or HC is performed. We do 5-fold cross- validation, strati\ufb01ed by subject so that each subject\u2019s samples do not occur in both training and testing sets in each fold. The minority class is oversampled in the training set using SMOTE [6] to deal with the class imbalance. We consider a Random Forest (100 trees), Na\u00efve Bayes (with equal priors), SVM (with RBF kernel), and a 2-layer neural network (10 units, Adam optimizer, 500 epochs)[16]. Additionally, we augment the DB data with healthy samples from FP with varied ages. 2",
            "5 Results and Discussion 5.1 Visualization of Class Boundaries Since data of different tasks have different noise patterns, the probability of over\ufb01tting to noise is reduced with samples from different tasks. This can also be visualized as decision boundaries of models trained on various dataset combinations. For Fig.5.1, we embed the 480-dimensional feature vector into 2 dimensions using Locally Linear Embeddings [22] trained on DB. (a) Pic. descriptions (PD); 28.6% (b) PD + structured tasks; 17.8% (c) PD + general speech; 3.6% Figure 1: Decision boundaries with RF classi\ufb01er for datasets with their out-of-task error shown in bold; scattered points shown belong to the train set in each case. For models trained using general, task-independent features on picture description (Fig.1a) & other structured tasks from HAFP such as \ufb02uency (Fig.1b), decision boundaries are patchy as a result of few, far-lying points from the classes (e.g, in the fourth quadrant), leading to misclassi\ufb01cations on other tasks with varying feature ranges.",
            "However, on datasets consisting of general, unstructured conversations, this does not happen Fig.1c. In datasets consisting of picture descriptions and conversational speech (DB + FP), the feature ranges increase as compared to picture description tasks, so it is expected that a classi\ufb01er trained on structured tasks only (DB + HAFP) would incorrectly classify healthy samples in the fourth quadrant (error rates for tasks not in dataset is 17.8%). However, decision boundaries for models trained on a mix of structured tasks and unstructured conversational speech seem to be more generalizable across tasks. E.g., decision boundaries obtained from DB + FP could apply to most datapoints in HAFP (out of task error rate is 3.6%). Clinically, some of the features used such as the patterns in usage of function words like pronouns have shown to re\ufb02ect stress-related changes in gene expression, possibly caused due to dementia [13] which would not depend on the task type and could explain such a common underlying structure to features. 5.2 Classi\ufb01cation Performance Results of binary classi\ufb01cation with different dataset combinations (i.e., the proportion of each dataset used) are in Tab.",
            "5.2 Classi\ufb01cation Performance Results of binary classi\ufb01cation with different dataset combinations (i.e., the proportion of each dataset used) are in Tab. 5.2. The highest F1 score on DB is 80.5% with SVM as obtained by Noorian et al. [14], enabling similar comparisons. Data Size Na\u00efve Bayes SVM RF NN F1 F1 F1 F1 F1 F1 F1 F1 (mi.) (ma.) (mi.) (ma.) (mi.) (ma.) (mi.) (ma.) DB 229 HC 62.90 60.01 80.52 73.01 73.52 67.82 75.92 72.76 DB + HAPD 351 HC 63.99 63.37 82.97 78.65 79.00 74.76 81.39 78.07 DB + 0.29*HAFP 352 HC 60.00 58.62 82.53 77.26 78.94 72.80 82.24 78.54 DB + 0.",
            "00 74.76 81.39 78.07 DB + 0.29*HAFP 352 HC 60.00 58.62 82.53 77.26 78.94 72.80 82.24 78.54 DB + 0.42*HA 460 HC 65.06 63.90 82.74 78.58 78.09 73.70 84.69 80.02 DB + FP 460 HC 56.05 52.38 83.71 80.21 77.41 73.92 82.19 79.26 DB + HAFP 656 HC 74.08 70.97 87.43 80.21 82.59 77.60 86.53 79.53 DB + HA 778 HC 74.63 70.33 89.31 82.32 85.62 76.44 88.08 80.50 Table 2: AD vs HC classi\ufb01cation. Highest F1 scores are shown in bold for datasets of similar size.",
            "63 70.33 89.31 82.32 85.62 76.44 88.08 80.50 Table 2: AD vs HC classi\ufb01cation. Highest F1 scores are shown in bold for datasets of similar size. We see the same trend of increasing model performance with normative data from the picture description task, as shown by Noorian et al. [14]. We observe that this increase is independent of the nature of the task performed \u2013 normative picture description task data of similar size as in [14] and the same amount of normative data from different structured tasks of \ufb02uency tests and paragraph reading prove to be helpful, bringing about a similar increase in scores (+2%, +5% absolute F1 micro 3",
            "and macro)1. Interestingly, performance of detecting the majority (healthy) class (re\ufb02ected in F1 micro) as well as the minority (AD) class (re\ufb02ected in F1 macro) increases with additional data. Augmenting DB with same amount of samples from structured tasks (HA) and from conversational speech (FP) brings about similar performance2. Doubling the initial amount of control data with data from a different structured task (HA, HAFP) results in an increase of up to 9% in F1 scores. 5.3 Impact of Age Age bin Number of samples F1(mi.) F1(ma.) 30 - 45 years 50 72.37 68.36 45 - 60 years 50 77.20 74.49 60 - 75 years 50 81.45 79.47 75 - 90 years 50 81.48 79.38 Table 3: Augmenting DB with healthy data of varied ages. Scores averaged across 4 classi\ufb01ers.",
            "Scores averaged across 4 classi\ufb01ers. We augment DB with healthy samples from FP with varying ages (Tab.5.3), considering 50 samples for each 15 year duration starting from age 30. Adding the same number of samples from bins of age greater than 60 leads to greater increase in performance. This could be because the average age of participants in the datasets (DB, HA etc.) we use are greater than 60. Note that despite such a trend, addition of healthy data produces fair classi\ufb01ers with respect to samples with age<60 and those with age>60 (balanced F1 scores of 75.6% and 76.1% respectively; further details in App. A.5.) 5.4 Inductive Bias of Tasks Each task performed in the datasets is designed to assess different cognitive functions, e.g. \ufb02uency task is used to evaluate the ability to organize and plan [25] and picture description task \u2013 for detecting discourse-related impairments [9]. As a result, it is expected that the nature of decision functions and feature predicates learned on data of each of these tasks would be different.",
            "\ufb02uency task is used to evaluate the ability to organize and plan [25] and picture description task \u2013 for detecting discourse-related impairments [9]. As a result, it is expected that the nature of decision functions and feature predicates learned on data of each of these tasks would be different. Performance of AD identi\ufb01cation with addition of normative data from multiple tasks (Tab. 5.2), despite the possibly different nature of decision functions, suggests that training the model with samples from each task provides domain-speci\ufb01c inductive bias for other tasks. We study possible underlying mechanisms responsible for this, suggested by Caruana et al.[5] and Ruder et al. [19]. Attention-focusing on Relevant Features: Ruder et al.[19] claim that in a small, high-dimensional dataset, information regarding relevance or irrelevance of particular features is dif\ufb01cult to capture. However, data related to multiple tasks can help identify features relevant across different activities. We can use anchor variables [18] to show this effect.",
            "[19] claim that in a small, high-dimensional dataset, information regarding relevance or irrelevance of particular features is dif\ufb01cult to capture. However, data related to multiple tasks can help identify features relevant across different activities. We can use anchor variables [18] to show this effect. The coverage of features anchoring the prediction of an instance indicates the applicability of the feature predicate to the rest of the data distribution and hence the importance of the feature across the data distribution. The coverage of the anchors selected for a test set which is 10% (50 samples) of DB changes by 40.8% (from 0.05 to 0.07) on the addition of the HA, which indicates that there is an attention focusing effect. Representation bias: As shown by Schulz et al.[21], models trained on data from multiple tasks perform better than with single-task information when little training data is available for the main task. The non-linear trend of increase in model performance with the addition of different amounts of data is shown in App.A.4.",
            "[21], models trained on data from multiple tasks perform better than with single-task information when little training data is available for the main task. The non-linear trend of increase in model performance with the addition of different amounts of data is shown in App.A.4. The F1 micro score of the best performing model trained on DB + HA is 82.28% for picture description tasks, 95.4% for paragraph reading and 97.01% for \ufb02uency tasks. This shows greater than trivial performance for each task and improvement in performance for picture description task from training a model purely on DB. Such an effect helps the model achieve non-trivial performance on AD detection for novel tasks measuring multiple domains of cognition, given a suf\ufb01ciently large number of training tasks according to algorithms provided by Baxter et al.[1]. Hence, training models on many speech-based tasks could help develop an algorithm capable of detecting AD from any sample of spontaneous speech. Ongoing work is on detailed analysis of nature and polarity of feature trends across various speech tasks. Future work will focus on learning interpretable latent representations based on the observations made, capable of good predictive performance across a multitude of tasks.",
            "Ongoing work is on detailed analysis of nature and polarity of feature trends across various speech tasks. Future work will focus on learning interpretable latent representations based on the observations made, capable of good predictive performance across a multitude of tasks. 1Friedman chi-squared = 2, df = 1, p-value = 0.1573; not signi\ufb01cant difference 2Friedman chi-squared = 0, df = 1, p-value = 1; not signi\ufb01cant difference 4",
            "References [1] Jonathan Baxter. A model of inductive bias learning. Journal of Arti\ufb01cial Intelligence Research, 12:149\u2013198, 2000. [2] James T Becker, Fran\u00e7ois Boiler, Oscar L Lopez, Judith Saxton, and Karen L McGonigle. The natural history of Alzheimer\u2019s disease: description of study cohort and accuracy of diagnosis. Archives of Neurology, 51(6):585\u2013594, 1994. [3] Francois Boller and James Becker. Dementiabank database guide. University of Pittsburgh, 2005. [4] Lenisa Brand\u00e3o, Tatiane Machado Lima, Maria Alice de Mattos Pimenta Parente, and Jordi Pe\u00f1a-Casanova. Discourse coherence and its relation with cognition in Alzheimer\u2019s disease. Revista Psicologia em Pesquisa, 7(1), 2017. [5] R Caruna. Multitask learning: A knowledge-based source of inductive bias. In Machine Learning: Proceedings of the Tenth International Conference, pages 41\u201348, 1993.",
            "[5] R Caruna. Multitask learning: A knowledge-based source of inductive bias. In Machine Learning: Proceedings of the Tenth International Conference, pages 41\u201348, 1993. [6] Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. SMOTE: synthetic minority over-sampling technique. Journal of arti\ufb01cial intelligence research, 16:321\u2013 357, 2002. [7] Katrina E Forbes-McKay and Annalena Venneri. Detecting subtle spontaneous language decline in early Alzheimer\u2019s disease with a picture description task. Neurological sciences, 26(4):243\u2013254, 2005. [8] Kathleen C Fraser, Jed A Meltzer, and Frank Rudzicz. Linguistic features identify Alzheimer\u2019s disease in narrative speech. Journal of Alzheimer\u2019s Disease, 49(2):407\u2013422, 2016.",
            "[8] Kathleen C Fraser, Jed A Meltzer, and Frank Rudzicz. Linguistic features identify Alzheimer\u2019s disease in narrative speech. Journal of Alzheimer\u2019s Disease, 49(2):407\u2013422, 2016. [9] Zahra Ghayoumi, Fariba Yadegari, Behrooz Mahmoodi-Bakhtiari, Esmaeil Fakharian, Mehdi Rahgozar, and Maryam Rasouli. Persuasive discourse impairments in traumatic brain injury. Archives of trauma research, 4(1), 2015. [10] Sweta Karlekar, Tong Niu, and Mohit Bansal. Detecting linguistic characteristics of Alzheimer\u2019s dementia by interpreting neural models. arXiv preprint arXiv:1804.06440, 2018. [11] Hyeran Lee, Frederique Gayraud, Fabrice Hirsch, and Melissa Barkat-Defradas. Speech dys\ufb02uencies in normal and pathological aging: a comparison between Alzheimer patients and healthy elderly subjects.",
            "[11] Hyeran Lee, Frederique Gayraud, Fabrice Hirsch, and Melissa Barkat-Defradas. Speech dys\ufb02uencies in normal and pathological aging: a comparison between Alzheimer patients and healthy elderly subjects. In the 17th International Congress of Phonetic Sciences (ICPhS), pages 1174\u20131177, 2011. [12] Xiaofei Lu. Automatic analysis of syntactic complexity in second language writing. Interna- tional journal of corpus linguistics, 15(4):474\u2013496, 2010. [13] Matthias R Mehl, Charles L Raison, Thaddeus WW Pace, Jesusa MG Arevalo, and Steve W Cole. Natural language indicators of differential gene regulation in the human immune system. Proceedings of the National Academy of Sciences, 114(47):12554\u201312559, 2017. [14] Zeinab Noorian, Chlo\u00e9 Pou-Prom, and Frank Rudzicz. On the importance of normative data in speech-based assessment. arXiv preprint arXiv:1712.00069, 2017.",
            "[14] Zeinab Noorian, Chlo\u00e9 Pou-Prom, and Frank Rudzicz. On the importance of normative data in speech-based assessment. arXiv preprint arXiv:1712.00069, 2017. [15] Jekaterina Novikova, Aparna Balagopalan, Maria Yancheva, and Frank Rudzicz. Early predic- tion of AD from spontaneous speech. Under Submission, 2018. [16] Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit- learn: Machine learning in Python. Journal of machine learning research, 12(Oct):2825\u20132830, 2011. [17] Martin Prince, Adelina Comas-Herrera, Martin Knapp, Ma\u00eblenn Guerchet, and Maria Karagian- nidou.",
            "Journal of machine learning research, 12(Oct):2825\u20132830, 2011. [17] Martin Prince, Adelina Comas-Herrera, Martin Knapp, Ma\u00eblenn Guerchet, and Maria Karagian- nidou. World Alzheimer report 2016: improving healthcare for people living with dementia: coverage, quality and costs now and in the future. 2016. 5",
            "[18] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Anchors: High-precision model- agnostic explanations. In AAAI Conference on Arti\ufb01cial Intelligence, 2018. [19] Sebastian Ruder. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098, 2017. [20] Frank Rudzicz, Leila Chan Currie, Andrew Danks, Tejas Mehta, and Shunan Zhao. Automati- cally identifying trouble-indicating speech behaviors in Alzheimer\u2019s disease. In Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility, pages 241\u2013242. ACM, 2014. [21] Claudia Schulz, Steffen Eger, Johannes Daxenberger, Tobias Kahse, and Iryna Gurevych. Multi- task learning for argumentation mining in low-resource settings.",
            "ACM, 2014. [21] Claudia Schulz, Steffen Eger, Johannes Daxenberger, Tobias Kahse, and Iryna Gurevych. Multi- task learning for argumentation mining in low-resource settings. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), volume 2, pages 35\u201341, 2018. [22] Jianzhong Wang. Locally linear embedding. In Geometric Structure of High-Dimensional Data and Dimensionality Reduction, pages 203\u2013220. Springer, 2012. [23] Amy Beth Warriner, Victor Kuperman, and Marc Brysbaert. Norms of valence, arousal, and dominance for 13,915 English lemmas. Behavior research methods, 45(4):1191\u20131207, 2013. [24] Jennifer L Watson, Laurie Ryan, Nina Silverberg, Vicky Cahan, and Marie A Bernard. Obstacles and opportunities in alzheimer\u2019s clinical trial recruitment.",
            "Behavior research methods, 45(4):1191\u20131207, 2013. [24] Jennifer L Watson, Laurie Ryan, Nina Silverberg, Vicky Cahan, and Marie A Bernard. Obstacles and opportunities in alzheimer\u2019s clinical trial recruitment. Health Affairs, 33(4):574\u2013579, 2014. [25] Douglas M Whiteside, Tammy Kealey, Matthew Semla, Hien Luu, Linda Rice, Michael R Basso, and Brad Roper. Verbal \ufb02uency: Language or executive function measure? Applied Neuropsychology: Adult, 23(1):29\u201334, 2016. 6",
            "A Appendix A.1 Detailed Description of Datasets DementiaBank (DB): The DementiaBank3 dataset is the largest available public dataset of speech for assessing cognitive impairments. It consists of narrative picture descriptions from participants aged between 45 to 90 [2]. In each sample, a participant describes the picture that they are shown. Out of the 210 participants in the study, 117 were diagnosed with AD (N = 180 samples of speech) and 93 were healthy (HC; N = 229 samples) with many subjects repeating the task with an interval of a year. Demographics of age, sex, and years of education are provided in the dataset. Healthy Aging (HA) : The Healthy Aging dataset consists of speech samples of cognitively healthy participants (N = 50) older than 50 years. Each participant performs three structured tasks \u2013 picture description (HAPD), verbal \ufb02uency test4, and a paragraph reading task. Fluency and paragraph tasks are jointly referred to as HAFP. The average number of samples per participant is 14.46. The dataset constitutes 8.5 hours of total audio.",
            "Fluency and paragraph tasks are jointly referred to as HAFP. The average number of samples per participant is 14.46. The dataset constitutes 8.5 hours of total audio. Famous People (FP): The Famous People dataset [15] consists of publicly available spontaneous speech samples from 9 famous individuals (e.g., Woody Allen & Clint Eastwood) over the period from 1956 to 2017, spanning periods from early adulthood to older age, with an average of 25 samples per person. We use speech samples of these subjects who are considered to be healthy (N = 231), given an absence of any reported diagnosis or subjective memory complaints. This healthy control (HC) group covers a variety of speaker ages, from 30 to 88 (\u00b5 = 60.9, \u03c3 = 15.4). A.2 Features A list of 480 features belonging to three groups - acoustic, semantic\/ syntactic and lexical. These features include constituency-parsing based features, syntactic complexity features extracted using Lu Syntactic Complexity analyzer [12], MFCC means, variances and other higher order moments.",
            "A.2 Features A list of 480 features belonging to three groups - acoustic, semantic\/ syntactic and lexical. These features include constituency-parsing based features, syntactic complexity features extracted using Lu Syntactic Complexity analyzer [12], MFCC means, variances and other higher order moments. Few of these features are listed below : \u2022 Phonation rate : Percentage of recording that is voiced. \u2022 Mean pause duration : Mean duration of pauses in seconds. \u2022 Pause word ratio : Ratio of silent segments to voiced segments. \u2022 Short pause count normalized : Normalized number of pauses less than 1 second. \u2022 Medium pause count normalized : Normalized number of pauses between 1 second and 2 seconds in length. \u2022 ZCR kurtosis : Kurtosis of Zero Crossing Rate (ZCR) of all voiced segments across frames. \u2022 MFCC means : Mean of velocity of MFCC coef\ufb01cient over all frames (this is calculated for multiple coef\ufb01cients). \u2022 MFCC kurtosis: Kurtosis of mean features. \u2022 MFCC variance: Variance of acceleration of frame energy over all frames.",
            "\u2022 MFCC means : Mean of velocity of MFCC coef\ufb01cient over all frames (this is calculated for multiple coef\ufb01cients). \u2022 MFCC kurtosis: Kurtosis of mean features. \u2022 MFCC variance: Variance of acceleration of frame energy over all frames. \u2022 Moving-average type-token ratio (MATTR): Moving average TTR (type-token ratio) over a window of 10 tokens. \u2022 Cosine cutoff : Fraction of pairs of utterances with cosine distance \u22640.001. \u2022 Pauses of type \u2018uh\u2019 : The number of \u2018uh\u2019 \ufb01llers over all tokens. \u2022 Numbers of interjections\/numerals : The number of interjections\/numerals used over all tokens. \u2022 Noun ratio: Ratio of number of nouns to number of nouns + verbs. \u2022 Temporal cohesion feature : Average number of switches in tense. 3https:\/\/dementia.talkbank.org 4During the \ufb02uency test, the experimenter asks the participant to say aloud as many names of items belonging to a certain category and as many words as possible starting with a speci\ufb01c letter in a 1 minute trial 7",
            "\u2022 Speech graph features : Features extracted from graph of spoken words in a sample including average total degree, number of edges, average shortest path, graph diameter (undirected) and graph density. \u2022 Filled pauses : Number of non-silent pauses. \u2022 Noun frequency : Average frequency norm for all nouns. \u2022 Noun imageability: Average imageability norm for all nouns. \u2022 Features from parse-tree : Number of times production rules such as number of noun phrases to determiners occurrences, occur over the total number of productions in the transcript\u2019s parse tree. \u2022 Syntactic complexity features: Ratio of clauses to T-units5, Ratio of clauses to sentences etc. [12] A.3 Hyper-parameters: Gaussian Naive Bayes with balanced priors is used. The random forest classi\ufb01er \ufb01ts 100 decision trees with other default parameters in [16]. SVM is trained with radial basis function kernel, regularization parameter C = 1 and \u03b3 = 0.001. The NN consists of one hidden layer of 10 units. The tanh activation function is used at each hidden layer.",
            "SVM is trained with radial basis function kernel, regularization parameter C = 1 and \u03b3 = 0.001. The NN consists of one hidden layer of 10 units. The tanh activation function is used at each hidden layer. The network is trained using Adam for 100 epochs with other default parameters in [16]. A.4 Effect of data from different tasks: The effect of augmenting DB with data from a different structured task (HAFP) is shown in A.4. Figure A.4: Effect of addition of data from a different structured task on F1 (micro) and F1 (macro) F1 scores (micro and macro) increase non-linearly with the addition of data. A.5 Fairness with Respect to Age: We evaluate fairness of classi\ufb01cation with respect to two groups - samples with age<60 and those with age>60. A fair classi\ufb01er would produce comparable classi\ufb01cation scores for both groups. For the best performing classi\ufb01er on DB, the F1 (micro) score for samples with age<60 is 85.9% and with age>60 is 76.4%.",
            "A fair classi\ufb01er would produce comparable classi\ufb01cation scores for both groups. For the best performing classi\ufb01er on DB, the F1 (micro) score for samples with age<60 is 85.9% and with age>60 is 76.4%. With the addition of HA, the F1 (micro) score for samples with age<60 and with age > 60 is more balanced (75.6%, 76.1% respectively) for the same set of data points from DB. Note that the average age in both datasets are similar (\u00b5age \u224868). 5T-unit: Shortest grammatically allowable sentences into which writing can be split or minimally terminable unit 8"
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-1811.12254.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 6227.000244140625,
    "avg_doclen_est": 172.97222900390625
}
