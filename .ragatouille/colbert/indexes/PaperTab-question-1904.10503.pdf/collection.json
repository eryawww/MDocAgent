[
  "Fine-Grained Named Entity Recognition using ELMo and Wikidata Cihan Dogan, Aimore Dutra, Adam Gara, Alfredo Gemma, Lei Shi, Michael Sigamani, Ella Walters Constellation AI 7 Carlisle Street London, W1D 3BW, United Kingdom michaelsigamani@constellation.ai Abstract Fine-grained Named Entity Recognition is a task whereby we detect and classify en- tity mentions to a large set of types. These types can span diverse domains such as \ufb01- nance, healthcare, and politics. We ob- serve that when the type set spans sev- eral domains the accuracy of the entity detection becomes a limitation for super- vised learning models. The primary rea- son being the lack of datasets where entity boundaries are properly annotated, whilst covering a large spectrum of entity types. Furthermore, many named entity systems suffer when considering the categorization of \ufb01ne grained entity types. Our work at- tempts to address these issues, in part, by combining state-of-the-art deep learning models (ELMo) with an expansive knowl- edge base (Wikidata).",
  "Furthermore, many named entity systems suffer when considering the categorization of \ufb01ne grained entity types. Our work at- tempts to address these issues, in part, by combining state-of-the-art deep learning models (ELMo) with an expansive knowl- edge base (Wikidata). Using our frame- work, we cross-validate our model on the 112 \ufb01ne-grained entity types based on the hierarchy given from the Wiki(GOLD) dataset. 1 Introduction Named entity recognition (NER) (Collins and Singer, 1999; Tjong Kim Sang and De Meul- der, 2003; Ratinov and Roth, 2009; Manning et al., 2014) is the process by which we iden- tify text spans which mention named entities, and to classify them into prede\ufb01ned categories such as person, location, organization etc.",
  "NER serves as the basis for a variety of natural lan- guage processing (NLP) applications such as re- lation extraction (Mintz et al., 2009), machine translation (Koehn et al., 2007), question answer- ing (Lin et al., 2012) and knowledge base con- struction (Dong et al., 2014). Although early NER systems have been successful in producing ade- quate recognition accuracy, they often require sig- ni\ufb01cant human effort in carefully designing rules or features. In recent years, deep learning methods been em- ployed in NER systems, yielding state-of-the-art performance. However, the number of types de- tected are still not suf\ufb01cient for certain domain- speci\ufb01c applications. For relation extraction, iden- tifying \ufb01ne-grained types has been shown to sig- ni\ufb01cantly increase the performance of the extrac- tor (Ling and Weld, 2012; Koch et al., 2014) since this helps in \ufb01ltering out candidate relation types which do not follow this type constraint.",
  "Furthermore, for question answering \ufb01ne-grained Named Entity Recognition (FgNER) can provide additional information helping to match questions to its potential answers thus improving perfor- mance (Dong et al., 2015). For example, Li and Roth (Li and Roth, 2002) rank questions based on their expected answer types (i.e. will the answer be food, vehicle or disease). Typically, FgNER systems use over a hundred labels, arranged in a hierarchical structure. We \ufb01nd that available training data for FgNER typ- ically contain noisy labels, and creating manu- ally annotated training data for FgNER is a time- consuming process. Furthermore, human anno- tators will have to assign a subset of correct la- bels from hundreds of possible labels making this a somewhat arduous task. Currently, FgNER sys- tems use distant supervision (Craven and Kumlien, 1999) to automatically generate training data.",
  "Furthermore, human anno- tators will have to assign a subset of correct la- bels from hundreds of possible labels making this a somewhat arduous task. Currently, FgNER sys- tems use distant supervision (Craven and Kumlien, 1999) to automatically generate training data. Dis- tant supervision is a technique which maps each entity in the corpus to knowledge bases such as Freebase (Bollacker et al., 2008), DBpedia (Auer et al., 2007), YAGO (Suchanek et al., 2007) and helps with the generation of labeled data. This method will assign the same set of labels to all mentions of a particular entity in the corpus. For 1 arXiv:1904.10503v1  [cs.IR]  23 Apr 2019",
  "example, \u201cBarack Obama\u201d is a person, politician, lawyer, and author. If a knowledge base has these four matching labels, the distant supervision tech- nique will assign all of them to every mention of \u201cBarack Obama\u201d. Therefore, the training data will also fail to distinguish between mentions of \u201cBarack Obama\u201d in all subsequent utterances. Ling et al. (2012) proposed the \ufb01rst system for FgNER, where they used 112 overlapping labels with a linear classi\ufb01er perceptron for multi-label classi\ufb01cation. Yosef et al. (2012) used multiple bi- nary SVM classi\ufb01ers to assign entities to a set of 505 types. Gillick et al. (2014) introduced context dependent FgNER and proposed a set of heuris- tics for pruning labels that might not be relevant given the local context of the entity. Yogatama et al. (2015) proposed an embedding based model where user-de\ufb01ned features and labels were em- bedded into a low dimensional feature space to fa- cilitate information sharing among labels.",
  "Yogatama et al. (2015) proposed an embedding based model where user-de\ufb01ned features and labels were em- bedded into a low dimensional feature space to fa- cilitate information sharing among labels. Shimaoka et al. (2016) proposed an attentive neural network model which used long short-term memory (LSTMs) to encode the context of the en- tity, then used an attention mechanism to allow the model to focus on relevant expressions in the en- tity mention\u2019s context. To learn entity represen- tations, we propose a scheme which is potentially more generalizable. 1.1 Datasets We evaluate our model on two publicly available datasets. The statistics for both are shown in Table 1. The details of these datasets are as follows: OntoNotes: OntoNotes 5.0 (Weischedel et al., 2013) includes texts from \ufb01ve different text gen- res: broadcast conversation (200k), broadcast news (200k), magazine (120k), newswire (625k), and web data (300k). This dataset is annotated with 18 categories.",
  "This dataset is annotated with 18 categories. Wiki(GOLD): The training data consists of Wikipedia sentences and was automatically gen- erated using a distant supervision method, map- ping hyperlinks in Wikipedia articles to Freebase, which we do not use in this study. The test data, mainly consisting of sentences from news reports, was manually annotated as described in (Ling and Weld, 2012). The class hierarchy is shown in Fig- ure 1. This dataset is annotated with 7 main cat- egories (bold text in Figure 1), which maps di- Datasets OntoNotes Wiki(GOLD) # types 18 112 # training labels 239,617 NA # evaluation labels 23,325 5,943 Table 1: Statistics of the datasets used in this work. rectly to OntoNotes. The miscellaneous category in Figure 1 does not have direct mappings, so fu- ture work may include rede\ufb01ning these categories so the mappings are more meaningful. Figure 1: The 112 tags used in Wiki(GOLD). The tags in bold are extracted in the step described in Section 2.1.",
  "Figure 1: The 112 tags used in Wiki(GOLD). The tags in bold are extracted in the step described in Section 2.1. The \ufb01ner grained tags are extracted as a \ufb01nal step described in Section 2.2. 1.2 Evaluation Metrics NER involves identifying both entity boundaries and entity types. With \u201cexact-match evaluation\u201d, a named entity is considered correctly recognized only if both the boundaries and type match the ground truth (Ling and Weld, 2012; Yogatama et al., 2015; Shimaoka et al., 2016). Precision, Re- call, and F-1 scores are computed on the num- ber of true positives (TP), false positives (FP), and false negatives (FN). Their formal de\ufb01nitions are as follows: \u2022 True Positive (TP): entities that are recog- nized by NER and match the ground truth. \u2022 False Positive (FP): entities that are recog- nized by NER but do not match the ground truth. \u2022 False Negative (FN): entities annotated in 2",
  "the ground which that are not recognized by NER. Precision measures the ability of a NER system to present only correct entities, and Recall mea- sures the ability of a NER system to recognize all entities in a corpus. Precision = TP TP + FP Recall = TP TP + FN The F-1 score is the harmonic mean of precision and recall, and the balanced F-1 score is the variant which is most commonly used. This is de\ufb01ned as: F-1 score = 2 \u00d7 Precision \u00d7 Recall Precision + Recall Since most NER systems involve multiple en- tity types, it is often required to assess the per- formance across all entity classes. Two measures are commonly used for this purpose: the macro- averaged F-1 score and the micro-averaged F-1 score. The macro-averaged F-1 score computes the F-1 score independently for each entity type, then takes the average (hence treating all entity types equally). The micro-averaged F-1 score aggregates the contributions of entities from all classes to compute the average (treating all enti- ties equally).",
  "The micro-averaged F-1 score aggregates the contributions of entities from all classes to compute the average (treating all enti- ties equally). We use the micro-averaged F-1 in our study since this accounts for label imbalances in the evaluation data and therefore a more mean- ingful statistic. 2 Method Over the few past years, the emergence of deep neural networks has fundamentally changed the design of entity detection systems. Consequently, recurrent neural networks (RNN) have found pop- ularity in the \ufb01eld since they are able to learn long term dependencies of sequential data. The re- cent success of neural network based architectures principally comes from its deep structure. Train- ing a deep neural network, however, is a dif\ufb01cult problem due to vanishing or exploding gradients. In order to solve this, LSTMs were proposed. An LSTM is an internal memory cell controlled by forget gate and input gate networks. A forget gate in an LSTM layer which determines how much prior memory should be passed into the next time increment. Similarly, an input gate scales new in- put to memory cells.",
  "An LSTM is an internal memory cell controlled by forget gate and input gate networks. A forget gate in an LSTM layer which determines how much prior memory should be passed into the next time increment. Similarly, an input gate scales new in- put to memory cells. Depending on the states of both gates, LSTM is able to capture long-term or short-term dependencies for sequential data. This is an ideal property for many NLP tasks. 2.1 NER using ELMo Recently, Peters et al. (Peters et al., 2018) pro- posed ELMo word representations. ELMo extends a traditional word embedding model with features produced bidirectionally with character convolu- tions. It has been shown that the utilization of ELMo for different NLP tasks result in improved performance compared to other types of word em- bedding models such as Word2Vec (Mikolov et al., 2013), GloVe (Ma et al., 2013), and fast- Text (Wang et al., 2013). The architecture of our proposed model is shown in Figure 2. The input is a list of tokens and the output are the predicted entity types.",
  "The architecture of our proposed model is shown in Figure 2. The input is a list of tokens and the output are the predicted entity types. The ELMo embeddings are then used with a residual LSTM to learn informative morphological repre- sentations from the character sequence of each to- ken. We then pass this to a softmax layer as a tag decoder to predict the entity types. Hyperparameter settings: The hidden-layer size of each LSTM within the model is set 512. We use a dropout with the probability of 0.2 on the output of the LSTM encoders. The embed- ding dimension from ELMo is 1024. The opti- mization method we use is Adam (Kingma and Ba, 2014). We train with a batch size of 32 for 30 epochs. The model was implemented using the TensorFlow1 framework. 2.2 Entity Linking using Wikidata Entity linking (EL) (Shen et al., 2018), also known as named entity disambiguation or normalization, is the task to determine the identity of entities mentioned in a piece of text with reference to a knowledge base.",
  "2.2 Entity Linking using Wikidata Entity linking (EL) (Shen et al., 2018), also known as named entity disambiguation or normalization, is the task to determine the identity of entities mentioned in a piece of text with reference to a knowledge base. There are a number of knowl- edge bases that provide a background repository for entity classi\ufb01cation of this type. For this study, we use Wikidata, which can be seen diagram- matically in Figure 2. Systems such as Deep- Type (Raiman et al., 2018) integrate symbolic in- formation into the reasoning process of a neural network with a type system and show state-of-the- art performances for EL. They do not, however, quote results on Wiki(GOLD) so a direct compari- son is dif\ufb01cult. While these knowledge bases provide semanti- cally rich and \ufb01ne-granular classes and relation- ship types, the task of entity classi\ufb01cation often re- quires associating coarse-grained classes with dis- covered surface forms of entities. Most existing 1http://tensorflow.org/ 3",
  "Michael Jeffrey Jordan in San Jose B-person   O   O B-loc B-FAC Bidirectional LSTM Bidirectional LSTM I-person I-person I-loc Wikidata Entity Linking Name: Michael Jordan (Q41421) Occupation: Basketball player Description: American basketball  player and businessman Also known as: Michael Jeffrey  Jordan, Mike Jordan, etc. Name: San Jose (Q3070) Instance of: Capital, City Description: Capital of Costa Rica Also known as: San Jose San Jos\u00e9, Costa Rica etc. Figure 2: The full model pipeline. The \ufb01rst level involves token embeddings from ELMo which are fed into a residual LSTM module. The \ufb01nal layer involves passing the detected entities into a knowledge base, which in our case is Wikidata. studies consider NER and entity linking as two separate tasks, whereas we try to combine the two. It has been shown that one can signi\ufb01cantly in- crease the semantic information carried by a NER system when we successfully linking entities from a deep learning method to the related entities from a knowledge base (Ji et al., 2018; Phan et al., 2018).",
  "It has been shown that one can signi\ufb01cantly in- crease the semantic information carried by a NER system when we successfully linking entities from a deep learning method to the related entities from a knowledge base (Ji et al., 2018; Phan et al., 2018). Redirection: For the Wikidata linking element, we recognize that the lookup will be constrained by the most common lookup name for each en- tity. Consider the utterance (referring to the NBA basketball player) from Figure 2 \u201cMichael Jeffrey Jordan in San Jose\u201d as an example. The lookup for this entity in Wikidata is \u201cMichael Jordan\u201d and consequently will not be picked up if we were to use an exact string match. A simple method to circumvent such a problem is the usage of a redi- rection list. Such a list is provided on an entity by entity basis in the \u201cAlso known as\u201d section in Wikidata. Using this redirection list, when we do not \ufb01nd an exact string match improves the recall of our model by 5-10%.",
  "Such a list is provided on an entity by entity basis in the \u201cAlso known as\u201d section in Wikidata. Using this redirection list, when we do not \ufb01nd an exact string match improves the recall of our model by 5-10%. Moreover, with the ex- ample of Michael Jordan (person), using our cur- rent framework, we will always refer to the retired basketball player (Q41421). We will never, for in- stance, pick up Michael Jordan (Q27069141) the American football cornerback. Or in fact any other Michael Jordan, famous or otherwise. One possi- ble method to overcome this is to add a disam- biguation layer, which seeks to use context from earlier parts of the text. This is, however, work for future improvement and we only consider the most common version of that entity. Clustering: The Wikidata taxonomy provides thousands of possible instance of, and subclass of types for our entities. Consequently, in order to perform a meaningful validation of our model, we must \ufb01nd a way to cluster these onto the 112 types provided by Wiki(GOLD). Our clustering is per- formed as follows: 1.",
  "Consequently, in order to perform a meaningful validation of our model, we must \ufb01nd a way to cluster these onto the 112 types provided by Wiki(GOLD). Our clustering is per- formed as follows: 1. If the entity type is either person, location, organization we use the NECKAr (Gei\u00df et al., 2018) tool to narrow down our list of searchable entities. 2. We then look at either the occupation for per- son, or instance of for location/organization categories to map to the available subtypes. 3. If the entity type is not person, location, or organization we search all of Wikidata. 4. The clustering we perform in part 1 or 2 is from a cosine similarity of the entity de- scription to the list of possible subtypes for that entity. For this we use Word2Vec word embeddings trained on Wikipedia. We set the minimum threshold of the average cosine similarity to be 0.1. 4",
  "As an example, consider the test sentence: \u201cThe device will be available on sale on 20th April 2011 on amazon uk Apple\u2019s iPad\u201d from Figure 3. First, we tag iPad as product using the context encoder described in Section 2.1. We then search Wikidata and return the most common variant for that entity in this case Q2796 (the most referenced variant is the one with the lowest Q-id). We then calculate a cosine similarity of the description, in this case \u201cline of tablet computers\u201d, with the possible sub- types of product. The possible subtypes, in this case, are engine, airplane, car, ship, spacecraft, train, camera, mobile phone, computer, software, game, instrument, ship, weapon. We return the highest result above 0.1, which in this case is com- puter (0.54). 3 Results The results for each class type are shown in Ta- ble 2, with some speci\ufb01c examples shown in Fig- ure 3. For the Wiki(GOLD) we quote the micro- averaged F-1 scores for the entire top level entity category.",
  "3 Results The results for each class type are shown in Ta- ble 2, with some speci\ufb01c examples shown in Fig- ure 3. For the Wiki(GOLD) we quote the micro- averaged F-1 scores for the entire top level entity category. The total F-1 score on the OntoNotes dataset is 88%, and the total F-1 cross-validation score on the 112 class Wiki(GOLD) dataset is 53%. It is worth noting that one could improve Wiki(GOLD) results by training directly using this dataset. However, the aim is not to tune our model speci\ufb01cally on this class hierarchy. We instead aim to present a framework which can be modi\ufb01ed eas- ily to any domain hierarchy and has acceptable out-of-the-box performances to any \ufb01ne-grained dataset. The results in Table 2 (OntoNotes) only show the main 7 categories in OntoNotes which map to Wiki(GOLD) for clarity.",
  "The results in Table 2 (OntoNotes) only show the main 7 categories in OntoNotes which map to Wiki(GOLD) for clarity. The other cate- gories (date, time, norp, language, ordinal, car- dinal, quantity, percent, money, law) have F-1 scores between 80-90%, with the exception of time (65%) 4 Conclusion and Future Work In this paper, we present a deep neural network model for the task of \ufb01ne-grained named en- tity classi\ufb01cation using ELMo embeddings and Wikidata. The proposed model learns represen- tations for entity mentions based on its context and incorporates the rich structure of Wikidata to augment these labels into \ufb01ner-grained subtypes. We can see comparisons of our model made on Wiki(GOLD) in Table 3. We note that the model performs similarly to existing systems without be- Figure 3: Some example outputs from the full model pipeline on the Wiki(GOLD) evaluation set. Label OntoNotes Wiki(GOLD) % F-1 % Prec. Rec.",
  "We note that the model performs similarly to existing systems without be- Figure 3: Some example outputs from the full model pipeline on the Wiki(GOLD) evaluation set. Label OntoNotes Wiki(GOLD) % F-1 % Prec. Rec. F-1 person 14 90 23 79 59 66 location 14 93 37 62 47 54 organization 24 85 26 45 16 23 event 1 70 2 81 17 28 product 1 56 2 44 4 8 building 1 65 4 81 17 11 art 2 54 0 0 0 0 Table 2: Performance of our model from the NER classi\ufb01er evaluated on OntoNotes, and the 112 subclass Wikidata linking step evaluated on Wiki(GOLD). The \ufb01rst column denotes the per- centage breakdown per class type. The precision, recall, and F-1 scores are shown for Wiki(GOLD). For OntoNotes the precision and recall are identi- cal for each category, therefore we only quote F-1.",
  "The \ufb01rst column denotes the per- centage breakdown per class type. The precision, recall, and F-1 scores are shown for Wiki(GOLD). For OntoNotes the precision and recall are identi- cal for each category, therefore we only quote F-1. All values are quoted as a percentage and rounded to the nearest whole number. Since the table only shows 7 categories, the percentages will not sum to 100. ing trained or tuned on that particular dataset. Future work may include re\ufb01ning the clustering method described in Section 2.2 to extend to types other than person, location, organization, and also to include disambiguation of entity types. References [Collins and Singer1999] Michael Collins and Yoram Singer. 1999. Unsupervised models for named en- tity classi\ufb01cation. In In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Nat- ural Language Processing and Very Large Corpora, pages 100\u2013110. [Tjong Kim Sang and De Meulder2003] Erik F. Tjong Kim Sang and Fien De Meulder. 2003.",
  "[Tjong Kim Sang and De Meulder2003] Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Intro- duction to the conll-2003 shared task: Language- independent named entity recognition. In Walter 5",
  "Datasets OntoNotes Wiki(GOLD) Our model 88.7% 52.8% Akbik et al. (2018) 89.7% NA Link et al. (2012) NA 53.2% Table 3: Comparison with existing models. Daelemans and Miles Osborne, editors, Proceed- ings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, pages 142\u2013147. [Ratinov and Roth2009] Lev Ratinov and Dan Roth. 2009. Design challenges and misconceptions in named entity recognition. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009), pages 147\u2013155, Boulder, Colorado, June. Association for Computa- tional Linguistics. [Manning et al.2014] Christopher Manning, Mihai Sur- deanu, John Bauer, Jenny Finkel, Steven Bethard, and David McClosky. 2014. The stanford corenlp natural language processing toolkit.",
  "Association for Computa- tional Linguistics. [Manning et al.2014] Christopher Manning, Mihai Sur- deanu, John Bauer, Jenny Finkel, Steven Bethard, and David McClosky. 2014. The stanford corenlp natural language processing toolkit. In Proceed- ings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 55\u201360, Baltimore, Maryland, June. Associa- tion for Computational Linguistics. [Mintz et al.2009] Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009. Distant supervi- sion for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th An- nual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 1003\u20131011, Suntec, Singapore, August. Association for Computational Linguistics.",
  "In Proceedings of the Joint Conference of the 47th An- nual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 1003\u20131011, Suntec, Singapore, August. Association for Computational Linguistics. [Koehn et al.2007] Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177\u2013180, Prague, Czech Republic, June. Association for Computational Linguistics. [Lin et al.2012] Thomas Lin, Mausam, and Oren Et- zioni. 2012. No noun phrase left behind: Detect- ing and typing unlinkable entities.",
  "Association for Computational Linguistics. [Lin et al.2012] Thomas Lin, Mausam, and Oren Et- zioni. 2012. No noun phrase left behind: Detect- ing and typing unlinkable entities. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 893\u2013903, Jeju Island, Korea, July. Association for Computational Linguistics. [Dong et al.2014] Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201914, pages 601\u2013610, New York, NY, USA. ACM. [Ling and Weld2012] Xiao Ling and Daniel S. Weld. 2012. Fine-grained entity recognition.",
  "ACM. [Ling and Weld2012] Xiao Ling and Daniel S. Weld. 2012. Fine-grained entity recognition. In Proceed- ings of the Twenty-Sixth AAAI Conference on Arti- \ufb01cial Intelligence, AAAI\u201912, pages 94\u2013100. AAAI Press. [Koch et al.2014] Mitchell Koch, John Gilmer, Stephen Soderland, and Daniel S. Weld. 2014. Type-aware distantly supervised relation extraction with linked arguments. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Pro- cessing (EMNLP), pages 1891\u20131901, Doha, Qatar, October. Association for Computational Linguistics.",
  "2014. Type-aware distantly supervised relation extraction with linked arguments. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Pro- cessing (EMNLP), pages 1891\u20131901, Doha, Qatar, October. Association for Computational Linguistics. [Mitchell et al.2015] T. Mitchell, W. Cohen, E. Hr- uschka, P. Talukdar, J. Betteridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, and J. Welling. 2015. Never- ending learning. In Proceedings of the Twenty- Ninth AAAI Conference on Arti\ufb01cial Intelligence, AAAI\u201915, pages 2302\u20132310. AAAI Press.",
  "2015. Never- ending learning. In Proceedings of the Twenty- Ninth AAAI Conference on Arti\ufb01cial Intelligence, AAAI\u201915, pages 2302\u20132310. AAAI Press. [Mitchell et al.2015] T. Mitchell, W. Cohen, E. Hr- uschka, P. Talukdar, J. Betteridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, and J. Welling. 2015. Never- ending learning. In Proceedings of the Twenty- Ninth AAAI Conference on Arti\ufb01cial Intelligence, AAAI\u201915, pages 2302\u20132310. AAAI Press.",
  "2015. Never- ending learning. In Proceedings of the Twenty- Ninth AAAI Conference on Arti\ufb01cial Intelligence, AAAI\u201915, pages 2302\u20132310. AAAI Press. [Dong et al.2015] Li Dong, Furu Wei, Hong Sun, Ming Zhou, and Ke Xu. 2015. A hybrid neural model for type classi\ufb01cation of entity mentions. In Pro- ceedings of the 24th International Conference on Arti\ufb01cial Intelligence, IJCAI\u201915, pages 1243\u20131249. AAAI Press. [Li and Roth2002] Xin Li and Dan Roth. 2002. Learn- ing question classi\ufb01ers. In Proceedings of the 19th International Conference on Computational Linguistics - Volume 1, COLING \u201902, pages 1\u20137, Stroudsburg, PA, USA. Association for Computa- tional Linguistics. [Craven and Kumlien1999] Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources.",
  "Association for Computa- tional Linguistics. [Craven and Kumlien1999] Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In Proceedings of the Seventh International Confer- ence on Intelligent Systems for Molecular Biology, pages 77\u201386. AAAI Press. [Bollacker et al.2008] Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: A collaboratively created graph 6",
  "database for structuring human knowledge. In Pro- ceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD \u201908, pages 1247\u20131250, New York, NY, USA. ACM. [Auer et al.2007] S\u00a8oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. Dbpedia: A nucleus for a web of open data. In Proceedings of the 6th International The Semantic Web and 2nd Asian Conference on Asian Semantic Web Conference, ISWC\u201907/ASWC\u201907, pages 722\u2013735, Berlin, Hei- delberg. Springer-Verlag. [Suchanek et al.2007] Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: A core of semantic knowledge. In Proceedings of the 16th International Conference on World Wide Web, WWW \u201907, pages 697\u2013706, New York, NY, USA. ACM.",
  "2007. Yago: A core of semantic knowledge. In Proceedings of the 16th International Conference on World Wide Web, WWW \u201907, pages 697\u2013706, New York, NY, USA. ACM. [Yosef et al.2012] Mohamed Amir Yosef, Sandro Bauer, Johannes Hoffart, Marc Spaniol, and Ger- hard Weikum. 2012. HYENA: Hierarchical type classi\ufb01cation for entity names. In Proceedings of COLING 2012: Posters, pages 1361\u20131370, Mumbai, India, December. The COLING 2012 Organizing Committee. [Gillick et al.2014] Dan Gillick, Nevena Lazic, Kuz- man Ganchev, Jesse Kirchner, and David Huynh. 2014. Context-dependent \ufb01ne-grained entity type tagging. arXiv preprint arXiv:1412.1820. [Yogatama et al.2015] Dani Yogatama, Daniel Gillick, and Nevena Lazic. 2015.",
  "2014. Context-dependent \ufb01ne-grained entity type tagging. arXiv preprint arXiv:1412.1820. [Yogatama et al.2015] Dani Yogatama, Daniel Gillick, and Nevena Lazic. 2015. Embedding methods for \ufb01ne grained entity type classi\ufb01cation. In Proceed- ings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Interna- tional Joint Conference on Natural Language Pro- cessing (Volume 2: Short Papers), pages 291\u2013296, Beijing, China, July. Association for Computational Linguistics. [Shimaoka et al.2016] Sonse Shimaoka, Pontus Stene- torp, Kentaro Inui, and Sebastian Riedel. 2016. An attentive neural architecture for \ufb01ne-grained entity type classi\ufb01cation. In Proceedings of the 5th Work- shop on Automated Knowledge Base Construction, pages 69\u201374, San Diego, CA, June. Association for Computational Linguistics.",
  "2016. An attentive neural architecture for \ufb01ne-grained entity type classi\ufb01cation. In Proceedings of the 5th Work- shop on Automated Knowledge Base Construction, pages 69\u201374, San Diego, CA, June. Association for Computational Linguistics. [Weischedel et al.2013] Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, et al. 2013. Ontonotes release 5.0 ldc2013t19. Linguistic Data Consortium, Philadelphia, PA. [Peters et al.2018] Mohamed Amir Yosef, Sandro Bauer, Johannes Hoffart, Marc Spaniol, and Ger- hard Weikum. 2018. Deep contextualized word representations. In Proc. NAACL-HLT, 2018, pp. 2227\u20132237. [Mikolov et al.2013] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean 2013.",
  "In Proc. NAACL-HLT, 2018, pp. 2227\u20132237. [Mikolov et al.2013] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean 2013. Dis- tributed representations of words and phrases and their compositionality In Proceedings of the 26th In- ternational Conference on Neural Information Pro- cessing Systems - Volume 2, 2013. [Ma et al.2013] X. Ma and E. Hovy 2016. End-to-end sequence labeling via bi-directional lstm-cnns-crf In Proc. ACL, pp. 1064\u20131074, 2016. [Li et al.2013] P.-H. Li, R.-P. Dong, Y.-S. Wang, J.-C. Chou, and W.-Y. Ma 2017. Leveraging linguistic structures for named entity recognition with bidirec- tional recursive neural networks In Proc. EMNLP, pp. 2664\u20132669, 2017.",
  "Wang, J.-C. Chou, and W.-Y. Ma 2017. Leveraging linguistic structures for named entity recognition with bidirec- tional recursive neural networks In Proc. EMNLP, pp. 2664\u20132669, 2017. [Wang et al.2013] C. Wang, K. Cho, and D. Kiela 2018. Code-switched named entity recognition with em- bedding attention In Proc. the Third Workshop on Computational Approaches to Linguistic Code- Switching, pp. 154\u2013158, 2018. [Kingma and Ba2014] Diederik Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti- mization. arXiv preprint arXiv:1412.6980. [Shen et al.2018] W. Shen, J. Han, J. Wang, X. Yuan, and Z. Yang 2018.",
  "Adam: A method for stochastic opti- mization. arXiv preprint arXiv:1412.6980. [Shen et al.2018] W. Shen, J. Han, J. Wang, X. Yuan, and Z. Yang 2018. Shine+: A general frame- work for domain-speci\ufb01c entity linking with hetero- geneous information networks In IEEE Transac- tions on Knowledge and Data Engineering, vol. 30, no. 2, pp. 353\u2013366, 2018. [Raiman et al.2018] Jonathan Raiman, Olivier Raiman 2018. DeepType: Multilingual Entity Linking by Neural Type System Evolution In arXiv preprint arXiv:1802.01021, 2018. [Ji et al.2018] Z. Ji, A. Sun, G. Cong, and J. Han 2018. Joint recognition and linking of \ufb01ne-grained loca- tions from tweets In Proc. WWW, 2016, pp. 1271\u2013 1281.",
  "Joint recognition and linking of \ufb01ne-grained loca- tions from tweets In Proc. WWW, 2016, pp. 1271\u2013 1281. [Phan et al.2018] M. C. Phan, A. Sun, Y. Tay, J. Han, and C. Li 2018. Pair-linking for collective entity disambiguation: Two could be better than all In arXiv preprint arXiv:1802.01074, 2018. [Gei\u00df et al.2018] Johanna Gei\u00df, Andreas Spitz, Michael Gertz, Georg Rehm, Thierry Declerck 2018. NECKAr: A Named Entity Classi\ufb01er for Wikidata In Springer International Publishing 115\u2013129, 2018. 7"
]