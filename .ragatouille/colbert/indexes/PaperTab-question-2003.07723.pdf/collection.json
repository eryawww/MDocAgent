[
  "PO-EMO: Conceptualization, Annotation, and Modeling of Aesthetic Emotions in German and English Poetry Thomas Haider1,3, Steffen Eger2, Evgeny Kim3, Roman Klinger3, Winfried Menninghaus1 1Department of Language and Literature, Max Planck Institute for Empirical Aesthetics 2NLLG, Department of Computer Science, Technische Universitat Darmstadt 3Institut f\u00fcr Maschinelle Sprachverarbeitung, University of Stuttgart {thomas.haider, w.m}@ae.mpg.de, eger@aiphes.tu-darmstadt.de {roman.klinger, evgeny.kim}@ims.uni-stuttgart.de Abstract Most approaches to emotion analysis of social media, literature, news, and other domains focus exclusively on basic emotion categories as de\ufb01ned by Ekman or Plutchik. However, art (such as literature) enables engagement in a broader range of more complex and subtle emo- tions. These have been shown to also include mixed emotional responses. We consider emotions in poetry as they are elicited in the reader, rather than what is expressed in the text or intended by the author.",
  "These have been shown to also include mixed emotional responses. We consider emotions in poetry as they are elicited in the reader, rather than what is expressed in the text or intended by the author. Thus, we conceptualize a set of aesthetic emotions that are predictive of aesthetic appreciation in the reader, and allow the annotation of multiple labels per line to capture mixed emotions within their context. We evaluate this novel setting in an annotation experiment both with carefully trained experts and via crowdsourcing. Our annotation with experts leads to an acceptable agreement of \u03ba = .70, resulting in a consistent dataset for future large scale analysis. Finally, we conduct \ufb01rst emotion classi\ufb01cation experiments based on BERT, showing that identifying aesthetic emotions is challenging in our data, with up to .52 F1-micro on the German subset. Data and resources are available at https://github.com/tnhaider/poetry-emotion. Keywords: Emotion, Aesthetic Emotions, Literature, Poetry, Annotation, Corpora, Emotion Recognition, Multi-Label 1. Introduction Emotions are central to human experience, creativity and behavior.",
  "Keywords: Emotion, Aesthetic Emotions, Literature, Poetry, Annotation, Corpora, Emotion Recognition, Multi-Label 1. Introduction Emotions are central to human experience, creativity and behavior. Models of affect and emotion, both in psychology and natural language processing, commonly operate on pre- de\ufb01ned categories, designated either by continuous scales of, e.g., Valence, Arousal and Dominance (Mohammad, 2016) or discrete emotion labels (which can also vary in intensity). Discrete sets of emotions often have been motivated by theories of basic emotions, as proposed by Ekman (1992)\u2014 Anger, Fear, Joy, Disgust, Surprise, Sadness\u2014and Plutchik (1991), who added Trust and Anticipation. These categories are likely to have evolved as they motivate behavior that is directly relevant for survival. However, art reception typi- cally presupposes a situation of safety and therefore offers special opportunities to engage in a broader range of more complex and subtle emotions. These differences between real-life and art contexts have not been considered in natural language processing work so far.",
  "However, art reception typi- cally presupposes a situation of safety and therefore offers special opportunities to engage in a broader range of more complex and subtle emotions. These differences between real-life and art contexts have not been considered in natural language processing work so far. To emotionally move readers is considered a prime goal of literature since Latin antiquity (Johnson-Laird and Oatley, 2016; Menninghaus et al., 2019; Menninghaus et al., 2015). Deeply moved readers shed tears or get chills and goose- bumps even in lab settings (Wassiliwizky et al., 2017). In cases like these, the emotional response actually implies an aesthetic evaluation: narratives that have the capacity to move readers are evaluated as good and powerful texts for this very reason. Similarly, feelings of suspense experienced in narratives not only respond to the trajectory of the plot\u2019s content, but are also directly predictive of aesthetic liking (or disliking). Emotions that exhibit this dual capacity have been de\ufb01ned as \u201caesthetic emotions\u201d (Menninghaus et al., 2019).",
  "Emotions that exhibit this dual capacity have been de\ufb01ned as \u201caesthetic emotions\u201d (Menninghaus et al., 2019). Contrary to the negativity bias of classical emotion catalogues, emotion terms used for aesthetic evaluation pur- poses include far more positive than negative emotions. At the same time, many overall positive aesthetic emotions encompass negative or mixed emotional ingredients (Men- ninghaus et al., 2019), e.g., feelings of suspense include both hopeful and fearful anticipations. For these reasons, we argue that the analysis of literature (with a focus on poetry) should rely on speci\ufb01cally selected emotion items rather than on the narrow range of basic emotions only. Our selection is based on previous research on this issue in psychological studies on art reception and, speci\ufb01cally, on poetry. For instance, Knoop et al. (2016) found that Beauty is a major factor in poetry reception. We primarily adopt and adapt emotion terms that Schindler et al. (2017) have identi\ufb01ed as aesthetic emotions in their study on how to measure and categorize such particular af- fective states.",
  "(2016) found that Beauty is a major factor in poetry reception. We primarily adopt and adapt emotion terms that Schindler et al. (2017) have identi\ufb01ed as aesthetic emotions in their study on how to measure and categorize such particular af- fective states. Further, we consider the aspect that, when selecting speci\ufb01c emotion labels, the perspective of anno- tators plays a major role. Whether emotions are elicited in the reader, expressed in the text, or intended by the au- thor largely changes the permissible labels. For example, feelings of Disgust or Love might be intended or expressed in the text, but the text might still fail to elicit correspond- ing feelings as these concepts presume a strong reaction in the reader. Our focus here was on the actual emotional experience of the readers rather than on hypothetical inten- tions of authors.",
  "Our focus here was on the actual emotional experience of the readers rather than on hypothetical inten- tions of authors. We opted for this reader perspective based on previous research in NLP (Buechel and Hahn, 2017a; Buechel and Hahn, 2017b) and work in empirical aesthetics (Menninghaus et al., 2017), that speci\ufb01cally measured the re- ception of poetry. Our \ufb01nal set of emotion labels consists of Beauty/Joy, Sadness, Uneasiness, Vitality/Energy, Suspense, Awe/Sublime, Humor, Annoyance, and Nostalgia.1 1The concepts Beauty and Awe/Sublime primarily de\ufb01ne object- based aesthetic virtues. Kant (2001) emphasized that such virtues are typically intuitively felt rather than rationally computed. Such arXiv:2003.07723v3  [cs.CL]  23 Jun 2021",
  "In addition to selecting an adapted set of emotions, the anno- tation of poetry brings further challenges, one of which is the choice of the appropriate unit of annotation. Previous work considers words2 (Mohammad and Turney, 2013; Strappar- ava and Valitutti, 2004), sentences (Alm et al., 2005; Aman and Szpakowicz, 2007), utterances (Cevher et al., 2019), sen- tence triples (Kim and Klinger, 2018), or paragraphs (Liu et al., 2019) as the units of annotation. For poetry, reasonable units follow the logical document structure of poems, i.e., verse (line), stanza, and, owing to its relative shortness, the complete text. The more coarse-grained the unit, the more dif\ufb01cult the annotation is likely to be, but the more it may also enable the annotation of emotions in context.",
  "The more coarse-grained the unit, the more dif\ufb01cult the annotation is likely to be, but the more it may also enable the annotation of emotions in context. We \ufb01nd that annotating \ufb01ne-grained units (lines) that are hierarchi- cally ordered within a larger context (stanza, poem) caters to the speci\ufb01c structure of poems, where emotions are regularly mixed and are more interpretable within the whole poem. Consequently, we allow the mixing of emotions already at line level through multi-label annotation. The remainder of this paper includes (1) a report of the annotation process that takes these challenges into consid- eration, (2) a description of our annotated corpora, and (3) an implementation of baseline models for the novel task of aesthetic emotion annotation in poetry. In a \ufb01rst study, the annotators work on the annotations in a closely supervised fashion, carefully reading each verse, stanza, and poem. In a second study, the annotations are performed via crowd- sourcing within relatively short time periods with annotators not seeing the entire poem while reading the stanza.",
  "In a \ufb01rst study, the annotators work on the annotations in a closely supervised fashion, carefully reading each verse, stanza, and poem. In a second study, the annotations are performed via crowd- sourcing within relatively short time periods with annotators not seeing the entire poem while reading the stanza. Using these two settings, we aim at obtaining a better understand- ing of the advantages and disadvantages of an expert vs. crowdsourcing setting in this novel annotation task. Par- ticularly, we are interested in estimating the potential of a crowdsourcing environment for the task of self-perceived emotion annotation in poetry, given time and cost overhead associated with in-house annotation process (that usually involve training and close supervision of the annotators). We provide the \ufb01nal datasets of German and En- glish language poems annotated with reader emotions on verse level at https://github.com/tnhaider/ poetry-emotion. 2. Related Work 2.1.",
  "We provide the \ufb01nal datasets of German and En- glish language poems annotated with reader emotions on verse level at https://github.com/tnhaider/ poetry-emotion. 2. Related Work 2.1. Poetry in Natural Language Processing Natural language understanding research on poetry has in- vestigated stylistic variation (Kaplan and Blei, 2007; Kao and Jurafsky, 2015; Voigt and Jurafsky, 2013), with a focus on broadly accepted formal features such as meter (Greene et al., 2010; Agirrezabal et al., 2016; Estes and Hench, 2016) and rhyme (Reddy and Knight, 2011; Haider and Kuhn, 2018), as well as enjambement (Ruiz et al., 2017; Baumann et al., 2018) and metaphor (Kesarwani et al., 2017; Reinig and Rehbein, 2019).",
  "Recent work has also explored the relationship of poetry and prose, mainly on a syntactic level feelings of Beauty and Sublime have therefore come to be subsumed under the rubrique of aesthetic emotions in recent psychological research (Menninghaus et al., 2019). For this reason, we refer to the whole set of category labels as emotions throughout this paper. 2to create emotion dictionaries (Krishna et al., 2019; Gopidi and Alam, 2019). Further- more, poetry also lends itself well to semantic (change) analysis (Haider, 2019; Haider and Eger, 2019), as linguistic invention (Underwood and Sellers, 2012; Herbelot, 2014) and succinctness (Roberts, 2000) are at the core of poetic production. Corpus-based analysis of emotions in poetry has been con- sidered, but there is no work on German, and little on English. Kao and Jurafsky (2015) analyze English po- ems with word associations from the Harvard Inquirer and LIWC, within the categories positive/negative outlook, pos- itive/negative emotion and phys./psych.",
  "Kao and Jurafsky (2015) analyze English po- ems with word associations from the Harvard Inquirer and LIWC, within the categories positive/negative outlook, pos- itive/negative emotion and phys./psych. well-being. Hou and Frank (2015) examine the binary sentiment polarity of Chinese poems with a weighted personalized PageRank al- gorithm. Barros et al. (2013) followed a tagging approach with a thesaurus to annotate words that are similar to the words \u2018Joy\u2019, \u2018Anger\u2019, \u2018Fear\u2019 and \u2018Sadness\u2019 (moreover trans- lating these from English to Spanish). With these word lists, they distinguish the categories \u2018Love\u2019, \u2018Songs to Lisi\u2019, \u2018Satire\u2019 and \u2018Philosophical-Moral-Religious\u2019 in Quevedo\u2019s poetry. Similarly, Alsharif et al. (2013) classify unique Arabic \u2018emotional text forms\u2019 based on word unigrams. Mohanty et al.",
  "Similarly, Alsharif et al. (2013) classify unique Arabic \u2018emotional text forms\u2019 based on word unigrams. Mohanty et al. (2018) create a corpus of 788 poems in the Indian Odia language, annotate it on text (poem) level with binary negative and positive sentiment, and are able to distin- guish these with moderate success. Sreeja and Mahalakshmi (2019) construct a corpus of 736 Indian language poems and annotate the texts on Ekman\u2019s six categories + Love + Courage. They achieve a Fleiss Kappa of .48. In contrast to our work, these studies focus on basic emo- tions and binary sentiment polarity only, rather than ad- dressing aesthetic emotions. Moreover, they annotate on the level of complete poems (instead of \ufb01ne-grained verse and stanza-level). 2.2. Emotion Annotation Emotion corpora have been created for different tasks and with different annotation strategies, with different units of analysis and different foci of emotion perspective (reader, writer, text).",
  "2.2. Emotion Annotation Emotion corpora have been created for different tasks and with different annotation strategies, with different units of analysis and different foci of emotion perspective (reader, writer, text). Examples include the ISEAR dataset (Scherer and Wallbott, 1994) (document-level); emotion annotation in children stories (Alm et al., 2005) and news headlines (Strapparava and Mihalcea, 2007) (sentence-level); and \ufb01ne- grained emotion annotation in literature by Kim and Klinger (2018) (phrase- and word-level). We refer the interested reader to an overview paper on existing corpora (Bostan and Klinger, 2018). We are only aware of a limited number of publications which look in more depth into the emotion perspective. Buechel and Hahn (2017a) report on an annotation study that focuses both on writer\u2019s and reader\u2019s emotions associated with En- glish sentences. The results show that the reader perspective yields better inter-annotator agreement. Yang et al.",
  "Buechel and Hahn (2017a) report on an annotation study that focuses both on writer\u2019s and reader\u2019s emotions associated with En- glish sentences. The results show that the reader perspective yields better inter-annotator agreement. Yang et al. (2009) also study the difference between writer and reader emo- tions, but not with a modeling perspective. The authors \ufb01nd that positive reader emotions tend to be linked to positive writer emotions in online blogs.",
  "\u0001\u0001 \u0001\u0001\u0002\u0001\u0001\u0003 \u0001\u0001\u0002\u0001\u0001\u0004 \u0001\u0001\u0002\u0001\u0001\u0005 \u0001\u0001\u0002\u0001\u0001\u0006 \u0001\u0001\u0002\u0001\u0001\u0007 \u0001\u0001\u0002\u0001\u0001\b \u0001\u0001\u0002\u0001\u0001\t \u0001\u0003\u0007\u0007\u0001\u0001\u0003\b\u0001\u0001\u0001\u0003\b\u0007\u0001\u0001\u0003\t\u0001\u0001\u0001\u0003\t\u0007\u0001\u0001\u0003 \u0001\u0001\u0001\u0003 \u0007\u0001\u0001\u0003\u000b\u0001\u0001\u0001\u0003\u000b\u0007\u0001 \u0001\u0002\u0003\u0004\u0005\u0006\u0007 \f \u000e\u000f\u0010\u0011\u0012\u0013\u0010\u0014\u0015\u0001\u0016\u0017\u0012\u0018\u0001\u0019\u001a\u0017\u001b\u001c\u0001\u001d \u0013\u001e\u0014\u0018\u0001\u0016\u0017\u0012\u0018\u0001\u0014\u001f\u0001 \u0010\u0018\u0013\u001e\u0001\u0019\u0017\u0015\u001b !\u0017\u0018\"\u0012\u0015 #\u0015$\u000f\u0010%\u001e Figure 1: Temporal distribution of poetry corpora (Kernel Density Plots with bandwidth = 0.2). German English # tokens 20403 8082 # lines 3650 1240 # stanzas 731 174 # poems 158 64 # authors 51 22 Table 1: Statistics on our poetry corpora PO-EMO. Tokens without punctuation. 2.3.",
  "German English # tokens 20403 8082 # lines 3650 1240 # stanzas 731 174 # poems 158 64 # authors 51 22 Table 1: Statistics on our poetry corpora PO-EMO. Tokens without punctuation. 2.3. Emotion Classi\ufb01cation The task of emotion classi\ufb01cation has been tackled before using rule-based and machine learning approaches. Rule- based emotion classi\ufb01cation typically relies on lexical re- sources of emotionally charged words (Strapparava and Val- itutti, 2004; Esuli and Sebastiani, 2006; Mohammad and Turney, 2013) and offers a straightforward and transparent way to detect emotions in text. In contrast to rule-based approaches, current models for emotion classi\ufb01cation are often based on neural networks and commonly use word embeddings as features. Schuff et al. (2017) applied models from the classes of CNN, Bi- LSTM, and LSTM and compare them to linear classi\ufb01ers (SVM and MaxEnt), where the BiLSTM shows best results with the most balanced precision and recall.",
  "Schuff et al. (2017) applied models from the classes of CNN, Bi- LSTM, and LSTM and compare them to linear classi\ufb01ers (SVM and MaxEnt), where the BiLSTM shows best results with the most balanced precision and recall. Abdul-Mageed and Ungar (2017) claim the highest F1 with gated recurrent unit networks (Chung et al., 2015) for Plutchik\u2019s emotion model. More recently, shared tasks on emotion analysis (Mohammad et al., 2018; Klinger et al., 2018) triggered a set of more advanced deep learning approaches, includ- ing BERT (Devlin et al., 2019) and other transfer learning methods (Dankers et al., 2019). 3. Data Collection For our annotation and modeling studies, we build on top of two poetry corpora (in English and German), which we refer to as PO-EMO. This collection represents important contributions to the literary canon over the last 400 years. We make this resource available in TEI P5 XML3 and an easy-to-use tab separated format.",
  "This collection represents important contributions to the literary canon over the last 400 years. We make this resource available in TEI P5 XML3 and an easy-to-use tab separated format. Table 1 shows a size overview of these data sets. Figure 1 shows the distribution of our data over time via density plots. Note that both corpora show a relative underrepresentation before the onset of the romantic period (around 1750). 3https://tei-c.org/guidelines/p5/ 3.1. German The German corpus contains poems available from the web- site lyrik.antikoerperchen.de (ANTI-K), which provides a platform for students to upload essays about po- ems. The data was available in the Hypertext Markup Lan- guage, with clean line and stanza segmentation, which we transformed into TEI P5. ANTI-K also has extensive meta- data, including author names, years of publication, numbers of sentences, poetic genres, and literary periods, that enable us to gauge the distribution of poems according to periods.",
  "ANTI-K also has extensive meta- data, including author names, years of publication, numbers of sentences, poetic genres, and literary periods, that enable us to gauge the distribution of poems according to periods. The 158 poems we consider (731 stanzas) are dispersed over 51 authors and the New High German timeline (1575\u20131936 A.D.). This data has been annotated, besides emotions, for meter, rhythm, and rhyme in other studies (Haider and Kuhn, 2018; Haider et al., 2020). 3.2. English The English corpus contains 64 poems of popular English writers. It was partly collected from Project Gutenberg with the GutenTag tool,4 and, in addition, includes a number of hand selected poems from the modern period and represents a cross section of popular English poets. We took care to include a number of female authors, who would have been underrepresented in a uniform sample. Time stamps in the corpus are organized by the birth year of the author, as assigned in Project Gutenberg. 4.",
  "We took care to include a number of female authors, who would have been underrepresented in a uniform sample. Time stamps in the corpus are organized by the birth year of the author, as assigned in Project Gutenberg. 4. Expert Annotation In the following, we will explain how we compiled and an- notated three data subsets, namely, (1) 48 German poems with gold annotation. These were originally annotated by three annotators. The labels were then aggregated with ma- jority voting and based on discussions among the annotators. Finally, they were curated to only include one gold annota- tion. (2) The remaining 110 German poems that are used to compute the agreement in table 3 and (3) 64 English poems contain the raw annotation from two annotators. We report the genesis of our annotation guidelines including the emotion classes. With the intention to provide a lan- guage resource for the computational analysis of emotion in poetry, we aimed at maximizing the consistency of our annotation, while doing justice to the diversity of poetry.",
  "We report the genesis of our annotation guidelines including the emotion classes. With the intention to provide a lan- guage resource for the computational analysis of emotion in poetry, we aimed at maximizing the consistency of our annotation, while doing justice to the diversity of poetry. We iteratively improved the guidelines and the annotation work\ufb02ow by annotating in batches, cleaning the class set, and the compilation of a gold standard. The \ufb01nal overall cost of producing this expert annotated dataset amounts to approximately AC3,500. 4.1. Work\ufb02ow The annotation process was initially conducted by three female university students majoring in linguistics and/or literary studies, which we refer to as our \u201cexpert annotators\u201d. We used the INCePTION platform for annotation5 (Klie et al., 2018). Starting with the German poems, we annotated in batches of about 16 (and later in some cases 32) poems. 4https://gutentag.sdsu.edu/ 5https://www.informatik.tu-darmstadt.de/ ukp/research_6/current_projects/inception/ index.en.jsp",
  "Factor Items Negative emotions anger/distasteful Prototypical Aesthetic Emotions beauty/sublime/being moved Epistemic Emotions interest/insight Animation motivation/inspiration Nostalgia / Relaxation nostalgic/calmed Sadness sad/melancholic Amusement funny/cheerful Table 2: Aesthetic Emotion Factors (Schindler et al., 2017). After each batch, we computed agreement statistics includ- ing heatmaps, and provided this feedback to the annotators. For the \ufb01rst three batches, the three annotators produced a gold standard using a majority vote for each line. Where this was inconclusive, they developed an adjudicated annota- tion based on discussion. Where necessary, we encouraged the annotators to aim for more consistency, as most of the frequent switching of emotions within a stanza could not be reconstructed or justi\ufb01ed. In poems, emotions are regularly mixed (already on line level) and are more interpretable within the whole poem. We therefore annotate lines hierarchically within the larger context of stanzas and the whole poem.",
  "In poems, emotions are regularly mixed (already on line level) and are more interpretable within the whole poem. We therefore annotate lines hierarchically within the larger context of stanzas and the whole poem. Hence, we instruct the annotators to read a complete stanza or full poem, and then annotate each line in the context of its stanza. To re\ufb02ect on the emotional complexity of poetry, we allow a maximum of two labels per line while avoiding heavy label \ufb02uctuations by encouraging annotators to re\ufb02ect on their feelings to avoid \u2018empty\u2019 annotations. Rather, they were advised to use fewer labels and more consistent annotation. This additional constraint is necessary to avoid \u201cwild\u201d, non- reconstructable or non-justi\ufb01ed annotations. All subsequent batches (all except the \ufb01rst three) were only annotated by two out of the three initial annotators, coinci- dentally those two who had the lowest initial agreement with each other. We asked these two experts to use the generated gold standard (48 poems; majority votes of 3 annotators plus manual curation) as a reference (\u201cif in doubt, annotate according to the gold standard\u201d).",
  "We asked these two experts to use the generated gold standard (48 poems; majority votes of 3 annotators plus manual curation) as a reference (\u201cif in doubt, annotate according to the gold standard\u201d). This eliminated some sys- tematic differences between them6 and markedly improved the agreement levels, roughly from 0.3\u20130.5 Cohen\u2019s \u03ba in the \ufb01rst three batches to around 0.6\u20130.8 \u03ba for all subsequent batches. This annotation procedure relaxes the reader per- spective, as we encourage annotators (if in doubt) to annotate how they think the other annotators would annotate. How- ever, we found that this formulation improves the usability of the data and leads to a more consistent annotation. 4.2. Emotion Labels We opt for measuring the reader perspective rather than the text surface or author\u2019s intent. To closer de\ufb01ne and support conceptualizing our labels, we use particular \u2018items\u2019, as they are used in psychological self-evaluations. These items consist of adjectives, verbs or short phrases.",
  "To closer de\ufb01ne and support conceptualizing our labels, we use particular \u2018items\u2019, as they are used in psychological self-evaluations. These items consist of adjectives, verbs or short phrases. We build on top 6One person labeled lines with more negative emotions such as Uneasiness and Annoyance and the person labeled more positive emotions such as Vitality/Energy and Beauty/Joy. \u03ba Ann. 1 % Ann.",
  "We build on top 6One person labeled lines with more negative emotions such as Uneasiness and Annoyance and the person labeled more positive emotions such as Vitality/Energy and Beauty/Joy. \u03ba Ann. 1 % Ann. 2 % en de en de en de Beauty / Joy .77 .74 .31 .30 .26 .30 Sadness .72 .77 .21 .20 .20 .18 Uneasiness .84 .77 .15 .19 .15 .18 Vitality / Energy .50 .63 .12 .11 .18 .13 Awe / Sublime .71 .61 .07 .06 .07 .06 Suspense .58 .65 .04 .07 .07 .08 Humor .81 .68 .04 .05 .04 .05 Nostalgia .81 \u2014 .03 \u2014 .03 \u2014 Annoyance .62 .65 .03 .04 .02 .02 Table 3: Cohen\u2019s kappa agreement levels and normalized line-level emotion frequencies for expert annotators (Nostal- gia is not available in the German data). English German avg.",
  "English German avg. \u03ba 0.707 0.688 F1 0.775 0.774 F1 Majority 0.323 0.323 F1 Random 0.108 0.119 Table 4: Top: averaged kappa scores and micro-F1 agree- ment scores, taking one annotator as gold. Bottom: Base- lines. of Schindler et al. (2017) who proposed 43 items that were then grouped by a factor analysis based on self-evaluations of participants. The resulting factors are shown in Table 2. We attempt to cover all identi\ufb01ed factors and supplement with basic emotions (Ekman, 1992; Plutchik, 1991), where possible. We started with a larger set of labels to then delete and substitute (tone down) labels during the initial annotation process to avoid infrequent classes and inconsistencies. Fur- ther, we con\ufb02ate labels if they show considerable confusion with each other. These iterative improvements particularly affected Confusion, Boredom and Other that were very in- frequently annotated and had little agreement among anno- tators (\u03ba < .2).",
  "Fur- ther, we con\ufb02ate labels if they show considerable confusion with each other. These iterative improvements particularly affected Confusion, Boredom and Other that were very in- frequently annotated and had little agreement among anno- tators (\u03ba < .2). For German, we also removed Nostalgia (\u03ba = .218) after gold standard creation, but after considera- tion, added it back for English, then achieving agreement. Nostalgia is still available in the gold standard (then with a second label Beauty/Joy or Sadness to keep consistency). However, Confusion, Boredom and Other are not available in any sub-corpus. Our \ufb01nal set consists of nine classes, i.e., (in order of fre- quency) Beauty/Joy, Sadness, Uneasiness, Vitality/Energy, Suspense, Awe/Sublime, Humor, Annoyance, and Nostalgia. In the following, we describe the labels and give further details on the aggregation process.",
  "In the following, we describe the labels and give further details on the aggregation process. Annoyance (annoys me/angers me/felt frustrated): Annoy- ance implies feeling annoyed, frustrated or even angry while reading the line/stanza. We include the class Anger here, as this was found to be too strong in intensity. Awe/Sublime (found it overwhelming/sense of greatness): Awe/Sublime implies being overwhelmed by the line/stanza, i.e., if one gets the impression of facing something sublime",
  "Annoyance Awe/Sublime Beauty/Joy Humor Nostalgia Sadness Suspense Uneasiness Vitality Annoyance Awe/Sublime Beauty/Joy Humor Nostalgia Sadness Suspense Uneasiness Vitality German, Expert 60 0 4 0 0 2 2 47 22 0 117 48 0 0 5 12 0 28 0 20 720 21 0 101 14 15 44 0 0 26 102 0 9 12 2 10 0 0 0 0 0 0 0 0 0 8 45 50 4 0 446 15 29 39 0 0 30 11 0 8 144 13 8 11 8 35 17 0 27 50 437 15 2 2 73 20 0 7 10 3 239 Annoyance Awe/Sublime Beauty/Joy Humor Nostalgia Sadness Suspense Uneasiness Vitality English,",
  "Expert 24 0 0 0 0 3 0 10 15 0 86 28 0 0 23 0 0 22 0 17 411 13 8 28 18 2 80 0 7 0 56 0 0 27 3 8 0 0 6 0 41 4 0 0 0 6 8 14 4 4 269 4 31 32 0 0 9 5 0 2 60 9 0 0 0 0 0 0 33 19 219 34 0 0 28 0 0 10 8 12 146 Annoyance Awe/Sublime Beauty/Joy Humor Nostalgia Sadness Suspense Uneasiness Vitality English,",
  "Crowdsourcing 44 31 49 27 20 82 46 45 25 31 80 82 22 26 73 99 71 38 49 82 230 25 68 105 77 56 64 27 22 25 60 25 67 40 32 26 20 26 68 25 24 62 49 25 43 82 73 105 67 62 536 113 143 61 46 99 77 40 49 113 158 115 50 45 71 56 32 25 143 115 98 27 25 38 64 26 43 61 50 27 62  0  50  100  150  200  250 Weight Figure 2: Emotion cooccurrence matrices for the German and English expert annotation experiments and the English crowdsourcing experiment. or if the line/stanza inspires one with awe (or that the expres- sion itself is sublime). Such emotions are often associated with subjects like god, death, life, truth, etc.",
  "or if the line/stanza inspires one with awe (or that the expres- sion itself is sublime). Such emotions are often associated with subjects like god, death, life, truth, etc. The term Sub- lime originated with Kant (2001) as one of the \ufb01rst aesthetic emotion terms. Awe is a more common English term. Beauty/Joy (found it beautiful/pleasing/makes me happy/joyful): Kant (2001) already spoke of a \u201cfeeling of beauty\u201d, and it should be noted that it is not a \u2018merely pleasing emotion\u2019. Therefore, in our pilot annotations, Beauty and Joy were separate labels. However, Schindler et al. (2017) found that items for Beauty and Joy load into the same factors. Furthermore, our pilot annotations revealed, while Beauty is the more dominant and frequent feeling, both labels regularly accompany each other, and they often get confused across annotators. Therefore, we add Joy to form an inclusive label Beauty/Joy that increases consistency. Humor (found it funny/amusing): Implies feeling amused by the line/stanza or if it makes one laugh.",
  "Therefore, we add Joy to form an inclusive label Beauty/Joy that increases consistency. Humor (found it funny/amusing): Implies feeling amused by the line/stanza or if it makes one laugh. Nostalgia (makes me nostalgic): Nostalgia is de\ufb01ned as a sentimental longing for things, persons or situations in the past. It often carries both positive and negative feel- ings. However, since this label is quite infrequent, and not available in all subsets of the data, we annotated it with an additional Beauty/Joy or Sadness label to ensure annotation consistency. Sadness (makes me sad/touches me): If the line/stanza makes one feel sad. It also includes a more general \u2018be- ing touched / moved\u2019. Suspense (found it gripping/sparked my interest): Choose Suspense if the line/stanza keeps one in suspense (if it excites one or triggers one\u2019s curiosity). We removed Anticipation from the earlier Suspense/Anticipation label, as Anticipation appeared to us as being a more cognitive prediction whereas Suspense is a far more straightforward emotion item.",
  "We removed Anticipation from the earlier Suspense/Anticipation label, as Anticipation appeared to us as being a more cognitive prediction whereas Suspense is a far more straightforward emotion item. Uneasiness (found it ugly/unsettling/disturbing / frighten- ing/distasteful): This label covers situations when one feels discomfort, when the line/stanza feels distasteful/ugly, un- settling/disturbing or frightens one. The labels Ugliness and Disgust were con\ufb02ated into Uneasiness, as both are seldom felt in poetry (being inadequate/too strong/high in arousal), and typically lead to Uneasiness. Vitality/Energy (found it invigorating/spurs me on/inspires me): This label is meant for a line/stanza that has an inciting, encouraging effect (if it conveys a feeling of movement, energy and vitality which animates to action). Other terms: Animated, Inspiration, Stimulation and Activation.7 4.3. Agreement Table 3 shows the Cohen\u2019s \u03ba agreement scores among our two expert annotators for each emotion category e as follows.",
  "Other terms: Animated, Inspiration, Stimulation and Activation.7 4.3. Agreement Table 3 shows the Cohen\u2019s \u03ba agreement scores among our two expert annotators for each emotion category e as follows. We assign each instance (a line in a poem) a binary label indicating whether or not the annotator has annotated the emotion category e in question. From this, we obtain vectors ve i , for annotators i = 0, 1, where each entry of ve i holds the binary value for the corresponding line. We then apply the \u03ba statistics to the two binary vectors ve i . Additionally to averaged \u03ba, we report micro-F1 values in Table 4 between the multi-label annotations of both expert annotators as well as the micro-F1 score of a random baseline as well as of the majority emotion baseline (which labels each line as Beauty/Joy). We \ufb01nd that Cohen \u03ba agreement ranges from .84 for Un- easiness in the English data, .81 for Humor and Nostalgia, down to German Suspense (.65), Awe/Sublime (.61) and Vi- tality/Energy for both languages (.50 English, .63 German).",
  "Both annotators have a similar emotion frequency pro\ufb01le, where the ranking is almost identical, especially for Ger- man. However, for English, Annotator 2 annotates more Vitality/Energy than Uneasiness. Figure 2 shows the con- fusion matrices of labels between annotators as heatmaps. Notably, Beauty/Joy and Sadness are confused across anno- tators more often than other labels. This is topical for poetry, and therefore not surprising: One might argue that the beauty of beings and situations is only beautiful because it is not enduring and therefore not to divorce from the sadness of the vanishing of beauty (Benjamin, 2016). We also \ufb01nd considerable confusion of Sadness with Awe/Sublime and 7Activation appears stable across cultures (Jackson et al., 2019)",
  "Figure 3: Distribution of number of distinct emotion labels per logical document level in the expert-based annotation. No whole poem has more than 6 emotions. No stanza has more than 4 emotions. Vitality/Energy, while the latter is also regularly confused with Beauty/Joy. Furthermore, as shown in Figure 3, we \ufb01nd that no single poem aggregates to more than six emotion labels, while no stanza aggregates to more than four emotion labels. How- ever, most lines and stanzas prefer one or two labels. Ger- man poems seem more emotionally diverse where more poems have three labels than two labels, while the majority of English poems have only two labels. This is however attributable to the generally shorter English texts. 5. Crowdsourcing Annotation After concluding the expert annotation, we performed a fo- cused crowdsourcing experiment, based on the \ufb01nal label set and items as they are listed in Table 5 and Section 4.2. With this experiment, we aim to understand whether it is possible to collect reliable judgements for aesthetic percep- tion of poetry from a crowdsourcing platform.",
  "With this experiment, we aim to understand whether it is possible to collect reliable judgements for aesthetic percep- tion of poetry from a crowdsourcing platform. A second goal is to see whether we can replicate the expensive expert annotations with less costly crowd annotations. We opted for a maximally simple annotation environment, where we asked participants to annotate English 4-line stan- zas with self-perceived reader emotions. We choose English due to the higher availability of English language annota- tors on crowdsourcing platforms. Each annotator rates each stanza independently of surrounding context. 5.1. Data and Setup For consistency and to simplify the task for the annotators, we opt for a trade-off between completeness and granularity of the annotation. Speci\ufb01cally, we subselect stanzas com- posed of four verses from the corpus of 64 hand selected English poems. The resulting selection of 59 stanzas is uploaded to Figure Eight8 for annotation. The annotators are asked to answer the following questions for each instance. Question 1 (single-choice): Read the following stanza and decide for yourself which emotions it evokes. Question 2 (multiple-choice): Which additional emotions does the stanza evoke?",
  "The annotators are asked to answer the following questions for each instance. Question 1 (single-choice): Read the following stanza and decide for yourself which emotions it evokes. Question 2 (multiple-choice): Which additional emotions does the stanza evoke? 8https://www.figure-eight.com/ The answers to both questions correspond to the emotion labels we de\ufb01ned to use in our annotation, as described in Section 4.2. We add an additional answer choice \u201cNone\u201d to Question 2 to allow annotators to say that a stanza does not evoke any additional emotions. Each instance is annotated by ten people. We restrict the task geographically to the United Kingdom and Ireland and set the parameters on Figure Eight to only have the highest quality annotators join the task. We pay AC0.09 per instance. The \ufb01nal cost of the crowdsourcing experiment is AC74. 5.2. Results In the following, we determine the best aggregation strategy regarding the 10 annotators with bootstrap resampling.",
  "We pay AC0.09 per instance. The \ufb01nal cost of the crowdsourcing experiment is AC74. 5.2. Results In the following, we determine the best aggregation strategy regarding the 10 annotators with bootstrap resampling. For instance, one could assign the label of a speci\ufb01c emotion to an instance if just one annotators picks it, or one could assign the label only if all annotators agree on this emotion. To evaluate this, we repeatedly pick two sets of 5 annotators each out of the 10 annotators for each of the 59 stanzas, 1000 times overall (i.e., 1000\u00d759 times, bootstrap resampling). For each of these repetitions, we compare the agreement of these two groups of 5 annotators. Each group gets assigned with an adjudicated emotion which is accepted if at least one annotator picks it, at least two annotators pick it, etc. up to all \ufb01ve pick it. We show the results in Table 5.",
  "Each group gets assigned with an adjudicated emotion which is accepted if at least one annotator picks it, at least two annotators pick it, etc. up to all \ufb01ve pick it. We show the results in Table 5. The \u03ba scores show the av- erage agreement between the two groups of \ufb01ve annotators, when the adjudicated class is picked based on the particular threshold of annotators with the same label choice. We see that some emotions tend to have higher agreement scores than others, namely Annoyance (.66), Sadness (up to .52), and Awe/Sublime, Beauty/Joy, Humor (all .46). The maxi- mum agreement is reached mostly with a threshold of 2 (4 times) or 3 (3 times). We further show in the same table the average numbers of labels from each strategy. Obviously, a lower threshold leads to higher numbers (corresponding to a disjunction of annotations for each emotion). The drop in label counts is comparably drastic, with on average 18 labels per class.",
  "We further show in the same table the average numbers of labels from each strategy. Obviously, a lower threshold leads to higher numbers (corresponding to a disjunction of annotations for each emotion). The drop in label counts is comparably drastic, with on average 18 labels per class. Overall, the best average \u03ba agreement (.32) is less than half of what we saw for the expert annotators (roughly .70).",
  "\u03ba Counts Threshold \u22651 \u22652 \u22653 \u22654 \u22655 \u22651 \u22652 \u22653 \u22654 \u22655 Beauty / Joy .21 .41 .46 .28 \u2013 34.58 15.98 7.51 3.23 1.43 Sadness .43 .47 .52 .02 \u2212.04 43.34 28.99 17.77 9.52 2.82 Uneasiness .18 .25 .08 \u2212.01 \u2013 36.47 16.33 5.49 1.54 1.04 Vitality .15 .26 .19 \u2013 \u2013 25.62 7.34 2.02 1.05 1.00 Awe / Sublime .31 .17 .37 .46 \u2013 29.8 11.36 3.4 1.31 1.00 Suspense .11 .29 .21 .26 \u2013 39.12 17.8 6.54 1.97 1.04 Humor .19 .46 .39 \u22480 \u2013 19.26 5.36 2.1 1.22 1.07 Nostalgia .23 .",
  "21 .26 \u2013 39.12 17.8 6.54 1.97 1.04 Humor .19 .46 .39 \u22480 \u2013 19.26 5.36 2.1 1.22 1.07 Nostalgia .23 .01 \u2212.02 \u2013 \u2013 30.52 10.16 1.95 1.00 1.00 Annoyance .01 .07 .66 0 \u2013 26.54 6.17 1.35 1.00 1.00 Average 0.20 0.27 0.32 0.14 \u22120.04 31.69 13.28 5.35 2.43 1.27 Table 5: Results obtained via boostrapping for annotation aggregation. The row Threshold shows how many people within a group of \ufb01ve annotators should agree on a particular emotion. The column labeled Counts shows the average number of times certain emotion was assigned to a stanza given the threshold. Cells with \u2018\u2013\u2019 mean that neither of two groups satis\ufb01ed the threshold.",
  "The column labeled Counts shows the average number of times certain emotion was assigned to a stanza given the threshold. Cells with \u2018\u2013\u2019 mean that neither of two groups satis\ufb01ed the threshold. Crowds especially disagree on many more intricate emotion labels (Uneasiness, Vitality/Energy, Nostalgia, Suspense). We visualize how often two emotions are used to label an instance in a confusion table in Figure 2. Sadness is used most often to annotate a stanza, and it is often confused with Suspense, Uneasiness, and Nostalgia. Further, Beauty/Joy partially overlaps with Awe/Sublime, Nostalgia, and Sad- ness. On average, each crowd annotator uses two emotion labels per stanza (56% of cases); only in 36% of the cases the an- notators use one label, and in 6% and 1% of the cases three and four labels, respectively. This contrasts with the expert annotators, who use one label in about 70% of the cases and two labels in 30% of the cases for the same 59 four-liners.",
  "This contrasts with the expert annotators, who use one label in about 70% of the cases and two labels in 30% of the cases for the same 59 four-liners. Concerning frequency distribution for emotion labels, both experts and crowds name Sadness and Beauty/Joy as the most frequent emotions (for the \u2018best\u2019 threshold of 3) and Nostalgia as one of the least frequent emotions. The Spear- man rank correlation between experts and crowds is about 0.55 with respect to the label frequency distribution, indicat- ing that crowds could replace experts to a moderate degree when it comes to extracting, e.g., emotion distributions for an author or time period. Now, we further compare crowds and experts in terms of whether crowds could replicate ex- pert annotations also on a \ufb01ner stanza level (rather than only on a distributional level). 5.3. Comparing Experts with Crowds To gauge the quality of the crowd annotations in comparison with our experts, we calculate agreement on the emotions between experts and an increasing group size from the crowd.",
  "5.3. Comparing Experts with Crowds To gauge the quality of the crowd annotations in comparison with our experts, we calculate agreement on the emotions between experts and an increasing group size from the crowd. For each stanza instance s, we pick N crowd workers, where N \u2208{4, 6, 8, 10}, then pick their majority emotion for s, and additionally pick their second ranked majority emotion if at least N 2 \u22121 workers have chosen it.9 For the experts, we aggregate their emotion labels on stanza level, then perform the same strategy for selection of emotion labels. Thus, for s, both crowds and experts have 1 or 2 emotions. For each 9For workers, we additionally require that an emotion has been chosen by at least 2 workers. Figure 4: Agreement between experts and crowds as a func- tion of the number N of crowd workers. emotion, we then compute Cohen\u2019s \u03ba as before. Note that, compared to our previous experiments in Section 5.2 with a threshold, each stanza now receives an emotion annotation (exactly one or two emotion labels), both by the experts and the crowd-workers.",
  "emotion, we then compute Cohen\u2019s \u03ba as before. Note that, compared to our previous experiments in Section 5.2 with a threshold, each stanza now receives an emotion annotation (exactly one or two emotion labels), both by the experts and the crowd-workers. In Figure 4, we plot agreement between experts and crowds on stanza level as we vary the number N of crowd work- ers involved. On average, there is roughly a steady linear increase in agreement as N grows, which may indicate that N = 20 or N = 30 would still lead to better agreement. Concerning individual emotions, Nostalgia is the emotion with the least agreement, as opposed to Sadness (in our sam- ple of 59 four-liners): the agreement for this emotion grows from .47 \u03ba with N = 4 to .65 \u03ba with N = 10. Sadness is also the most frequent emotion, both according to experts and crowds. Other emotions for which a reasonable agree- ment is achieved are Annoyance, Awe/Sublime, Beauty/Joy, Humor (\u03ba > 0.2).",
  "Sadness is also the most frequent emotion, both according to experts and crowds. Other emotions for which a reasonable agree- ment is achieved are Annoyance, Awe/Sublime, Beauty/Joy, Humor (\u03ba > 0.2). Emotions with little agreement are Vital- ity/Energy, Uneasiness, Suspense, Nostalgia (\u03ba < 0.2). By and large, we note from Figure 2 that expert annotation is more restrictive, with experts agreeing more often on particular emotion labels (seen in the darker diagonal).",
  "The results of the crowdsourcing experiment, on the other hand, are a mixed bag as evidenced by a much sparser distri- bution of emotion labels. However, we note that these differ- ences can be caused by 1) the disparate training procedure for the experts and crowds, and 2) the lack of opportunities for close supervision and on-going training of the crowds, as opposed to the in-house expert annotators. In general, however, we \ufb01nd that substituting experts with crowds is possible to a certain degree. Even though the crowds\u2019 labels look inconsistent at \ufb01rst view, there appears to be a good signal in their aggregated annotations, help- ing to approximate expert annotations to a certain degree. The average \u03ba agreement (with the experts) we get from N = 10 crowd workers (0.24) is still considerably below the agreement among the experts (0.70). 6. Modeling To estimate the dif\ufb01culty of automatic classi\ufb01cation of our data set, we perform multi-label10 document classi\ufb01cation (of stanzas) with BERT (Devlin et al., 2019).",
  "6. Modeling To estimate the dif\ufb01culty of automatic classi\ufb01cation of our data set, we perform multi-label10 document classi\ufb01cation (of stanzas) with BERT (Devlin et al., 2019). For this ex- periment we aggregate all labels for a stanza and sort them by frequency, both for the gold standard and the raw expert annotations. As can be seen in Figure 3, a stanza bears a minimum of one and a maximum of four emotions. Unfor- tunately, the label Nostalgia is only available 16 times in the German data (the gold standard) as a second label (as discussed in Section 4.2). None of our models was able to learn this label for German. Therefore we omit it, leaving us with eight proper labels. We use the code and the pre-trained BERT models of FARM,11 provided by deepset.ai.",
  "None of our models was able to learn this label for German. Therefore we omit it, leaving us with eight proper labels. We use the code and the pre-trained BERT models of FARM,11 provided by deepset.ai. We test the multilingual-uncased model (MULTILING), the german- base-cased model (BASE),12 the german-dbmdz-uncased model (DBMDZ),13 and we tune the BASE model on 80k stanzas of the German Poetry Corpus DLK (Haider and Eger, 2019) for 2 epochs, both on token (masked words) and sequence (next line) prediction (BASETUNED). We split the randomized German dataset so that each label is at least 10 times in the validation set (63 instances, 113 labels), and at least 10 times in the test set (56 instances, 108 labels) and leave the rest for training (617 instances, 946 labels).14 We train BERT for 10 epochs (with a batch size of 8), optimize with entropy loss, and report F1-micro on the test set. See Table 6 for the results.",
  "See Table 6 for the results. We \ufb01nd that the multilingual model cannot handle infre- quent categories, i.e., Awe/Sublime, Suspense and Humor. However, increasing the dataset with English data improves the results, suggesting that the classi\ufb01cation would largely bene\ufb01t from more annotated data. The best model overall is DBMDZ (.520), showing a balanced response on both validation and test set. See Table 7 for a breakdown of all emotions as predicted by the this model. Precision is mostly 10We found that single-label classi\ufb01cation had only marginally better performance, even though the task is simpler. 11https://github.com/deepset-ai/FARM 12There was no uncased model available. 13https://github.com/dbmdz a model by the Bavarian state library that was also trained on literature. 14We do the same for the English data (at least 5 labels) and add the stanzas to the respective sets. German Multiling.",
  "13https://github.com/dbmdz a model by the Bavarian state library that was also trained on literature. 14We do the same for the English data (at least 5 labels) and add the stanzas to the respective sets. German Multiling. Model dev test dev test Majority .212 .167 .176 .150 MULTILING .409 .341 .461 .384 BASE .500 .439 \u2013 \u2013 BASETUNED .477 .514 \u2013 \u2013 DBMDZ .520 .520 \u2013 \u2013 Table 6: BERT-based multi-label classi\ufb01cation on stanza- level. Label Precision Recall F1 Support Beauty/Joy 0.5000 0.5556 0.5263 18 Sadness 0.5833 0.4667 0.5185 15 Uneasiness 0.6923 0.5625 0.6207 16 Vitality/Energy 1.0000 0.5333 0.6957 15 Annoyance 1.0000 0.4000 0.5714 10 Awe/Sublime 0.5000 0.3000 0.",
  "6207 16 Vitality/Energy 1.0000 0.5333 0.6957 15 Annoyance 1.0000 0.4000 0.5714 10 Awe/Sublime 0.5000 0.3000 0.3750 10 Suspense 0.6667 0.1667 0.2667 12 Humor 1.0000 0.2500 0.4000 12 micro avg 0.6667 0.4259 0.5198 108 macro avg 0.7428 0.4043 0.4968 108 weighted avg 0.7299 0.4259 0.5100 108 samples avg 0.5804 0.4464 0.4827 108 Table 7: Recall and precision scores of the best model (db- mdz) for each emotion on the test set. \u2018Support\u2019: number of instances with this label. higher than recall. The labels Awe/Sublime, Suspense and Humor are harder to predict than the other labels.",
  "\u2018Support\u2019: number of instances with this label. higher than recall. The labels Awe/Sublime, Suspense and Humor are harder to predict than the other labels. The BASE and BASETUNED models perform slightly worse than DBMDZ. The effect of tuning of the BASE model is questionable, probably because of the restricted vocabulary (30k). We found that tuning on poetry does not show obvious improvements. Lastly, we \ufb01nd that models that were trained on lines (instead of stanzas) do not achieve the same F1 (~.42 for the German models). 7. Concluding Remarks In this paper, we presented a dataset of German and English poetry annotated with reader response to reading poetry. We argued that basic emotions as proposed by psychologists (such as Ekman and Plutchik) that are often used in emotion analysis from text are of little use for the annotation of poetry reception. We instead conceptualized aesthetic emotion labels and showed that a closely supervised annotation task results in substantial agreement\u2014in terms of \u03ba score\u2014on the \ufb01nal dataset. The task of collecting reader-perceived emotion response to poetry in a crowdsourcing setting is not straightforward.",
  "We instead conceptualized aesthetic emotion labels and showed that a closely supervised annotation task results in substantial agreement\u2014in terms of \u03ba score\u2014on the \ufb01nal dataset. The task of collecting reader-perceived emotion response to poetry in a crowdsourcing setting is not straightforward. In contrast to expert annotators, who were closely supervised and re\ufb02ected upon the task, the annotators on crowdsourc- ing platforms are dif\ufb01cult to control and may lack necessary background knowledge to perform the task at hand. How- ever, using a larger number of crowd annotators may lead to \ufb01nding an aggregation strategy with a better trade-off be- tween quality and quantity of adjudicated labels. For future work, we thus propose to repeat the experiment with larger",
  "number of crowdworkers, and develop an improved training strategy that would suit the crowdsourcing environment. The dataset presented in this paper can be of use for different application scenarios, including multi-label emotion classi- \ufb01cation, style-conditioned poetry generation, investigating the in\ufb02uence of rhythm/prosodic features on emotion, or analysis of authors, genres and diachronic variation (e.g., how emotions are represented differently in certain periods). Further, though our modeling experiments are still rudimen- tary, we propose that this data set can be used to investigate the intra-poem relations either through multi-task learning (Schulz et al., 2018) and/or with the help of hierarchical sequence classi\ufb01cation approaches. Acknowledgements A special thanks goes to Gesine Fuhrmann, who cre- ated the guidelines and tirelessly documented the an- notation progress. Also thanks to Annika Palm and Debby Trzeciak who annotated and gave lively feedback. For help with the conceptualization of labels we thank Ines Schindler. This research has been partially con- ducted within the CRETA center (http://www.creta.",
  "Also thanks to Annika Palm and Debby Trzeciak who annotated and gave lively feedback. For help with the conceptualization of labels we thank Ines Schindler. This research has been partially con- ducted within the CRETA center (http://www.creta. uni-stuttgart.de/) which is funded by the German Ministry for Education and Research (BMBF) and partially funded by the German Research Council (DFG), projects SEAT (Structured Multi-Domain Emotion Analysis from Text, KL 2869/1-1). This work has also been supported by the German Research Foundation as part of the Research Training Group Adaptive Preparation of Information from Heterogeneous Sources (AIPHES) at the Technische Uni- versit\u00e4t Darmstadt under grant No. GRK 1994/1. Appendix We illustrate two examples of our German gold standard annotation, a poem each by Friedrich H\u00f6lderlin and Georg Trakl, and an English poem by Walt Whitman. H\u00f6lder- lin\u2019s text stands out, because the mood changes starkly from the \ufb01rst stanza to the second, from Beauty/Joy to Sadness.",
  "H\u00f6lder- lin\u2019s text stands out, because the mood changes starkly from the \ufb01rst stanza to the second, from Beauty/Joy to Sadness. Trakl\u2019s text is a bit more complex with bits of Nostalgia and, most importantly, a mixture of Uneasiness with Awe/Sublime. Whitman\u2019s poem is an example of Vi- tality and its mixing with Sadness. The English annotation was uni\ufb01ed by us for space constraints. For the full anno- tation please see https://github.com/tnhaider/ poetry-emotion/ Friedrich H\u00f6lderlin: H\u00e4lfte des Lebens (1804) Mit gelben Birnen h\u00e4nget [Beauty/Joy] Und voll mit wilden Rosen [Beauty/Joy] Das Land in den See, [Beauty/Joy] Ihr holden Schw\u00e4ne, [Beauty/Joy] Und trunken von K\u00fcssen [Beauty/Joy] Tunkt ihr das Haupt [Beauty/Joy] Ins heilign\u00fcchterne Wasser.",
  "[Beauty/Joy] Weh mir, wo nehm\u2019 ich, wenn [Sadness] Es Winter ist, die Blumen, und wo [Sadness] Den Sonnenschein, [Sadness] Und Schatten der Erde? [Sadness] Die Mauern stehn [Sadness] Sprachlos und kalt, im Winde [Sadness] Klirren die Fahnen. [Sadness] Georg Trakl: In den Nachmittag ge\ufb02\u00fcstert (1912) Sonne, herbstlich d\u00fcnn und zag, [Beauty/Joy] [Nostalgia] Und das Obst f\u00e4llt von den B\u00e4umen. [Beauty/Joy] [Nostalgia] Stille wohnt in blauen R\u00e4umen [Beauty/Joy] Einen langen Nachmittag. [Beauty/Joy] Sterbekl\u00e4nge von Metall; [Sadness] [Uneasiness] Und ein wei\u00dfes Tier bricht nieder. [Sadness] [Uneasiness] Brauner M\u00e4dchen rauhe Lieder [Sadness] [Nostalgia] Sind verweht im Bl\u00e4tterfall.",
  "[Sadness] [Uneasiness] Brauner M\u00e4dchen rauhe Lieder [Sadness] [Nostalgia] Sind verweht im Bl\u00e4tterfall. [Sadness] [Nostalgia] Stirne Gottes Farben tr\u00e4umt, [Uneasiness] [Awe/Sublime] Sp\u00fcrt des Wahnsinns sanfte Fl\u00fcgel. [Uneasiness] [Awe/Sublime] Schatten drehen sich am H\u00fcgel [Uneasiness] [Awe/Sublime] Von Verwesung schwarz ums\u00e4umt. [Uneasiness] [Awe/Sublime] D\u00e4mmerung voll Ruh und Wein; [Beauty/Joy] Traurige Guitarren rinnen. [Beauty/Joy] Und zur milden Lampe drinnen [Beauty/Joy] Kehrst du wie im Traume ein. [Beauty/Joy] Walt Whitman: O Captain! My Captain! (1865) O Captain! my Captain!",
  "[Beauty/Joy] Und zur milden Lampe drinnen [Beauty/Joy] Kehrst du wie im Traume ein. [Beauty/Joy] Walt Whitman: O Captain! My Captain! (1865) O Captain! my Captain! our fearful trip is done, [Beauty/Joy] The ship has weather\u2019d every rack, the prize we sought is won, [Beauty/Joy] The port is near, the bells I hear, the people all exulting, [Beauty/Joy] While follow eyes the steady keel, the vessel grim and daring; [Beauty/Joy] But O heart! heart! heart! [Sadness] O the bleeding drops of red, [Sadness] Where on the deck my Captain lies, [Sadness] Fallen cold and dead. [Sadness] O Captain! my Captain!",
  "heart! heart! [Sadness] O the bleeding drops of red, [Sadness] Where on the deck my Captain lies, [Sadness] Fallen cold and dead. [Sadness] O Captain! my Captain! rise up and hear the bells; [Vitality] Rise up \u2013 for you the \ufb02ag is \ufb02ung \u2013 for you the bugle trills, [Vitality] For you bouquets and ribbon\u2019d wreaths \u2013 for you the shores a-crowding, [Vitality] For you they call, the swaying mass, their eager faces turning; [Vitality] Here Captain! dear father! [Vitality] This arm beneath your head! [Vitality] It is some dream that on the deck, [Sadness] You\u2019ve fallen cold and dead. [Sadness] My Captain does not answer, his lips are pale and still, [Sadness] My father does not feel my arm, he has no pulse nor will, [Sadness] The ship is anchor\u2019d safe and sound, its voyage closed and done, [Vitality] [Sadn.]",
  "From fearful trip the victor ship comes in with object won; [Vitality] [Sadn.] Exult O shores, and ring O bells! [Vitality] [Sadn.] But I with mournful tread, [Sadness] Walk the deck my Captain lies, [Sadness] Fallen cold and dead. [Sadness] 8. Bibliographical References Abdul-Mageed, M. and Ungar, L. (2017). EmoNet: Fine- grained emotion detection with gated recurrent neural networks. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 718\u2013728, Vancouver, Canada, July. Association for Computational Linguistics. Agirrezabal, M., Alegria, I., and Hulden, M. (2016). Ma- chine learning for metrical analysis of English poetry. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Pa- pers, pages 772\u2013781, Osaka, Japan, December. The COL- ING 2016 Organizing Committee.",
  "In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Pa- pers, pages 772\u2013781, Osaka, Japan, December. The COL- ING 2016 Organizing Committee. Alm, C. O., Roth, D., and Sproat, R. (2005). Emotions from text: Machine learning for text-based emotion prediction. In Proceedings of Human Language Technology Confer- ence and Conference on Empirical Methods in Natural Language Processing, pages 579\u2013586, Vancouver, British Columbia, Canada, October. Association for Computa- tional Linguistics. Alsharif, O., Alshamaa, D., and Ghneim, N. (2013). Emo- tion classi\ufb01cation in arabic poetry using machine learning. International Journal of Computer Applications, 65(16).",
  "Aman, S. and Szpakowicz, S. (2007). Identifying expres- sions of emotion in text. In V\u00e1clav Matou\u0161ek et al., edi- tors, Text, Speech and Dialogue, pages 196\u2013205, Berlin, Heidelberg. Springer Berlin Heidelberg. Barros, L., Rodriguez, P., and Ortigosa, A. (2013). Auto- matic classi\ufb01cation of literature pieces by emotion de- tection: A study on quevedo\u2019s poetry. In 2013 Humaine Association Conference on Affective Computing and In- telligent Interaction, pages 141\u2013146. IEEE. Baumann, T., Hussein, H., and Meyer-Sickendiek, B. (2018). Style detection for free verse poetry from text and speech. In Proceedings of the 27th International Con- ference on Computational Linguistics, pages 1929\u20131940. Benjamin, W. (2016). Goethes Wahlverwandtschaften. BoD\u2013Books on Demand. Bostan, L.-A.-M.",
  "Benjamin, W. (2016). Goethes Wahlverwandtschaften. BoD\u2013Books on Demand. Bostan, L.-A.-M. and Klinger, R. (2018). An analysis of annotated corpora for emotion classi\ufb01cation in text. In Proceedings of the 27th International Conference on Com- putational Linguistics, pages 2104\u20132119, Santa Fe, New Mexico, USA, aug. Association for Computational Lin- guistics. Buechel, S. and Hahn, U. (2017a). EmoBank: Studying the impact of annotation perspective and representation format on dimensional emotion analysis. In Proceedings of the 15th Conference of the European Chapter of the As- sociation for Computational Linguistics: Volume 2, Short Papers, pages 578\u2013585, Valencia, Spain, April. Associa- tion for Computational Linguistics. Buechel, S. and Hahn, U. (2017b). Readers vs. writers vs. texts: Coping with different perspectives of text un- derstanding in emotion annotation.",
  "Associa- tion for Computational Linguistics. Buechel, S. and Hahn, U. (2017b). Readers vs. writers vs. texts: Coping with different perspectives of text un- derstanding in emotion annotation. In Proceedings of the 11th Linguistic Annotation Workshop, pages 1\u201312, Valencia, Spain, April. Association for Computational Linguistics. Cevher, D., Zepf, S., and Klinger, R. (2019). Towards multimodal emotion recognition in german speech events in cars using transfer learning. In Conference on Natural Language Processing (KONVENS). Chung, J., Gulcehre, C., Cho, K., and Bengio, Y. (2015). Gated feedback recurrent neural networks. In Proceed- ings of the 32Nd International Conference on Interna- tional Conference on Machine Learning - Volume 37, ICML\u201915, pages 2067\u20132075. JMLR.org. Dankers, V., Rei, M., Lewis, M., and Shutova, E. (2019).",
  "JMLR.org. Dankers, V., Rei, M., Lewis, M., and Shutova, E. (2019). Modelling the interplay of metaphor and emotion through multitask learning. In Proceedings of the 2019 Confer- ence on Empirical Methods in Natural Language Pro- cessing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2218\u20132229, Hong Kong, China, November. Association for Computational Linguistics. Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). BERT: Pre-training of deep bidirectional trans- formers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Pa- pers), pages 4171\u20134186, Minneapolis, Minnesota, June. Association for Computational Linguistics. Ekman, P. (1992). An argument for basic emotions. Cogni- tion & emotion, 6(3-4):169\u2013200.",
  "Association for Computational Linguistics. Ekman, P. (1992). An argument for basic emotions. Cogni- tion & emotion, 6(3-4):169\u2013200. Estes, A. and Hench, C. (2016). Supervised machine learn- ing for hybrid meter. In Proceedings of the Fifth Work- shop on Computational Linguistics for Literature, pages 1\u20138. Esuli, A. and Sebastiani, F. (2006). Sentiwordnet: A pub- licly available lexical resource for opinion mining. In Pro- ceedings of the 5th Conference on Language Resources and Evaluation (LREC\u201906, pages 417\u2013422. Gopidi, A. and Alam, A. (2019). Computational analysis of the historical changes in poetry and prose. In Proceedings of the 1st International Workshop on Computational Ap- proaches to Historical Language Change, pages 14\u201322. Greene, E., Bodrumlu, T., and Knight, K. (2010). Auto- matic analysis of rhythmic poetry with applications to generation and translation.",
  "Greene, E., Bodrumlu, T., and Knight, K. (2010). Auto- matic analysis of rhythmic poetry with applications to generation and translation. In Proceedings of the 2010 conference on empirical methods in natural language processing, pages 524\u2013533. Haider, T. and Eger, S. (2019). Semantic change and emerg- ing tropes in a large corpus of new high german poetry. In Proceedings of the 1st International Workshop on Com- putational Approaches to Historical Language Change, pages 216\u2013222. Haider, T. and Kuhn, J. (2018). Supervised rhyme detec- tion with siamese recurrent networks. In Proceedings of the Second Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Hu- manities and Literature at COLING 2018, Santa Fe New Mexico, pages 81\u201386. Haider, T., Trzeciak, D., and Kentner, G. (2020). Speech rhythm and syntax in poetry and prose.",
  "Haider, T., Trzeciak, D., and Kentner, G. (2020). Speech rhythm and syntax in poetry and prose. In In Proceed- ings of the International Digital Humanities Conference DH2020, Ottawa. accepted. Haider, T. (2019). Diachronic topics in new high german poetry. In In Proceedings of the International Digital Humanities Conference DH2019, Utrecht. Herbelot, A. (2014). The semantics of poetry: a distribu- tional reading. Digital Scholarship in the Humanities, 30(4):516\u2013531. Hou, Y. and Frank, A. (2015). Analyzing sentiment in clas- sical Chinese poetry. In Proceedings of the 9th SIGHUM Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH), pages 15\u2013 24, Beijing, China, July. Association for Computational Linguistics.",
  "Analyzing sentiment in clas- sical Chinese poetry. In Proceedings of the 9th SIGHUM Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH), pages 15\u2013 24, Beijing, China, July. Association for Computational Linguistics. Jackson, J. C., Watts, J., Henry, T. R., List, J.-M., Forkel, R., Mucha, P. J., Greenhill, S. J., Gray, R. D., and Lindquist, K. A. (2019). Emotion semantics show both cultural vari- ation and universal structure. Science, 366(6472):1517\u2013 1522. Johnson-Laird, P. N. and Oatley, K., (2016). Handbook of emotions, chapter Emotions in Music, Literature, and Film, pages 82\u201397. Guilford Publications. Kant, I. (2001). Critique of the Power of Judgment. (P.Guyer & E. Matthews, Trans.). Cambridge, England: Cambridge University Press (Original work published 1790).",
  "Guilford Publications. Kant, I. (2001). Critique of the Power of Judgment. (P.Guyer & E. Matthews, Trans.). Cambridge, England: Cambridge University Press (Original work published 1790). Kao, J. T. and Jurafsky, D. (2015). A computational analy-",
  "sis of poetic style. LiLT (Linguistic Issues in Language Technology), 12. Kaplan, D. M. and Blei, D. M. (2007). A computational approach to style in american poetry. In Seventh IEEE International Conference on Data Mining (ICDM 2007), pages 553\u2013558. IEEE. Kesarwani, V., Inkpen, D., Szpakowicz, S., and Tanasescu, C. (2017). Metaphor detection in a poetry corpus. In Proceedings of the Joint SIGHUM Workshop on Compu- tational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, pages 1\u20139. Kim, E. and Klinger, R. (2018). Who feels what and why? annotation of a literature corpus with semantic roles of emotions. In Proceedings of the 27th International Con- ference on Computational Linguistics, pages 1345\u20131359, Santa Fe, New Mexico, USA, August. Association for Computational Linguistics.",
  "Who feels what and why? annotation of a literature corpus with semantic roles of emotions. In Proceedings of the 27th International Con- ference on Computational Linguistics, pages 1345\u20131359, Santa Fe, New Mexico, USA, August. Association for Computational Linguistics. Klie, J.-C., Bugert, M., Boullosa, B., de Castilho, R. E., and Gurevych, I. (2018). The INCEpTION platform: Machine-assisted and knowledge-oriented interactive an- notation. In Proceedings of the 27th International Confer- ence on Computational Linguistics: System Demonstra- tions, pages 5\u20139. Klinger, R., De Clercq, O., Mohammad, S., and Balahur, A. (2018). IEST: WASSA-2018 implicit emotions shared task. In Proceedings of the 9th Workshop on Computa- tional Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 31\u201342, Brussels, Belgium, October. Association for Computational Linguistics.",
  "IEST: WASSA-2018 implicit emotions shared task. In Proceedings of the 9th Workshop on Computa- tional Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 31\u201342, Brussels, Belgium, October. Association for Computational Linguistics. Knoop, C. A., Wagner, V., Jacobsen, T., and Menninghaus, W. (2016). Mapping the aesthetic space of literature \u201cfrom below\u201d. Poetics, 56:35\u201349. Krishna, A., Sharma, V. D., Santra, B., Chakraborty, A., Sat- uluri, P., and Goyal, P. (2019). Poetry to prose conversion in sanskrit as a linearisation task: A case for low-resource languages. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1160\u20131166. Liu, C., Osama, M., and De Andrade, A. (2019). DENS: A dataset for multi-class emotion analysis.",
  "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1160\u20131166. Liu, C., Osama, M., and De Andrade, A. (2019). DENS: A dataset for multi-class emotion analysis. In Proceedings of the 2019 Conference on Empirical Methods in Natu- ral Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP- IJCNLP), pages 6294\u20136299, Hong Kong, China, Novem- ber. Association for Computational Linguistics. Menninghaus, W., Wagner, V., Hanich, J., Wassiliwizky, E., Kuehnast, M., and Jacobsen, T. (2015). Towards a psychological construct of being moved. PloS one, 10(6):e0128451. Menninghaus, W., Wagner, V., Wassiliwizky, E., Jacobsen, T., and Knoop, C. A. (2017). The emotional and aesthetic powers of parallelistic diction. Poetics, 63:47\u201359.",
  "Menninghaus, W., Wagner, V., Wassiliwizky, E., Jacobsen, T., and Knoop, C. A. (2017). The emotional and aesthetic powers of parallelistic diction. Poetics, 63:47\u201359. Menninghaus, W., Wagner, V., Wassiliwizky, E., Schindler, I., Hanich, J., Jacobsen, T., and Koelsch, S. (2019). What are aesthetic emotions? Psychological review, 126(2):171. Mohammad, S. M. and Turney, P. D. (2013). Crowdsourc- ing a word\u2013emotion association lexicon. Computational Intelligence, 29(3):436\u2013465. Mohammad, S., Bravo-Marquez, F., Salameh, M., and Kir- itchenko, S. (2018). SemEval-2018 task 1: Affect in tweets. In Proceedings of The 12th International Work- shop on Semantic Evaluation, pages 1\u201317, New Orleans, Louisiana, June.",
  "(2018). SemEval-2018 task 1: Affect in tweets. In Proceedings of The 12th International Work- shop on Semantic Evaluation, pages 1\u201317, New Orleans, Louisiana, June. Association for Computational Linguis- tics. Mohammad, S. M. (2016). Sentiment analysis: Detecting valence, emotions, and other affectual states from text. In Emotion measurement, pages 201\u2013237. Elsevier. Mohanty, G., Mishra, P., and Mamidi, R. (2018). Kabithaa: An annotated corpus of odia poems with sentiment po- larity information. In Girish Nath Jha, et al., editors, Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Paris, France, may. European Language Resources Association (ELRA). Plutchik, R. (1991). The Emotions. University Press of America. Reddy, S. and Knight, K. (2011). Unsupervised discovery of rhyme schemes.",
  "European Language Resources Association (ELRA). Plutchik, R. (1991). The Emotions. University Press of America. Reddy, S. and Knight, K. (2011). Unsupervised discovery of rhyme schemes. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 77\u201382. Reinig, I. and Rehbein, I. (2019). Metaphor detection for german poetry. Proceedings of the 15th Conference on Natural Language Processing (KONVENS 2019). Roberts, P. (2000). How Poetry Works. Penguin UK. Ruiz, P., Cant\u00f3n, C. M., Poibeau, T., and Gonz\u00e1lez-Blanco, E. (2017). Enjambment detection in a large diachronic corpus of spanish sonnets. In Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Liter- ature, pages 27\u201332.",
  "(2017). Enjambment detection in a large diachronic corpus of spanish sonnets. In Proceedings of the Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Liter- ature, pages 27\u201332. Scherer, K. R. and Wallbott, H. G. (1994). Evidence for universality and cultural variation of differential emotion response patterning. Journal of personality and social psychology, 66(2):310. Schindler, I., Hosoya, G., Menninghaus, W., Beermann, U., Wagner, V., Eid, M., and Scherer, K. R. (2017). Measur- ing aesthetic emotions: A review of the literature and a new assessment tool. PloS one, 12(6):e0178899. Schuff, H., Barnes, J., Mohme, J., Pad\u00f3, S., and Klinger, R. (2017). Annotation, modelling and analysis of \ufb01ne- grained emotions on a stance and sentiment detection corpus.",
  "Schuff, H., Barnes, J., Mohme, J., Pad\u00f3, S., and Klinger, R. (2017). Annotation, modelling and analysis of \ufb01ne- grained emotions on a stance and sentiment detection corpus. In Proceedings of the 8th Workshop on Computa- tional Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 13\u201323, Copenhagen, Denmark, September. Association for Computational Linguistics. Schulz, C., Eger, S., Daxenberger, J., Kahse, T., and Gurevych, I. (2018). Multi-task learning for argumenta- tion mining in low-resource settings. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 35\u201341, New Orleans, Louisiana, June. Association for Computational Linguistics. Sreeja, S. P. and Mahalakshmi, G. S. (2019). Perc-an emo- tion recognition corpus for cognitive poems.",
  "Association for Computational Linguistics. Sreeja, S. P. and Mahalakshmi, G. S. (2019). Perc-an emo- tion recognition corpus for cognitive poems. In 2019 International Conference on Communication and Signal Processing (ICCSP), pages 0200\u20130207, April.",
  "Strapparava, C. and Mihalcea, R. (2007). Semeval-2007 task 14: Affective text. In Proceedings of the Fourth In- ternational Workshop on Semantic Evaluations (SemEval- 2007), pages 70\u201374. Association for Computational Lin- guistics. Strapparava, C. and Valitutti, A. (2004). WordNet affect: an affective extension of WordNet. In Proceedings of the Fourth International Conference on Language Re- sources and Evaluation (LREC\u201904). European Language Resources Association (ELRA). Underwood, T. and Sellers, J. (2012). The emergence of literary diction. The Journal of Digital Humanities, 1(2), pages http://journalofdigitalhumanities.org/1\u2013 2/theemergence\u2013of\u2013literary\u2013diction\u2013by\u2013ted\u2013 underwoodand\u2013jordan\u2013sellers/. Voigt, R. and Jurafsky, D. (2013). Tradition and modernity in 20th century chinese poetry.",
  "Voigt, R. and Jurafsky, D. (2013). Tradition and modernity in 20th century chinese poetry. In Proceedings of the Workshop on Computational Linguistics for Literature, pages 17\u201322. Wassiliwizky, E., Jacobsen, T., Heinrich, J., Schneiderbauer, M., and Menninghaus, W. (2017). Tears falling on goose- bumps: Co-occurrence of emotional lacrimation and emo- tional piloerection indicates a psychophysiological climax in emotional arousal. Frontiers in Psychology, 8:41. Yang, C., Lin, K. H., and Chen, H. (2009). Writer meets reader: Emotion analysis of social media from both the writer\u2019s and reader\u2019s perspectives. In 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology, volume 1, pages 287\u2013290, Sep."
]