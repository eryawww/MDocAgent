{
    "config": {
        "query_token_id": "[unused0]",
        "doc_token_id": "[unused1]",
        "query_token": "[Q]",
        "doc_token": "[D]",
        "ncells": null,
        "centroid_score_threshold": null,
        "ndocs": null,
        "load_index_with_mmap": false,
        "index_path": null,
        "index_bsize": 32,
        "nbits": 4,
        "kmeans_niters": 20,
        "resume": false,
        "pool_factor": 1,
        "clustering_mode": "hierarchical",
        "protected_tokens": 0,
        "similarity": "cosine",
        "bsize": 64,
        "accumsteps": 1,
        "lr": 1e-5,
        "maxsteps": 400000,
        "save_every": null,
        "warmup": 20000,
        "warmup_bert": null,
        "relu": false,
        "nway": 64,
        "use_ib_negatives": true,
        "reranker": false,
        "distillation_alpha": 1.0,
        "ignore_scores": false,
        "model_name": null,
        "query_maxlen": 32,
        "attend_to_mask_tokens": false,
        "interaction": "colbert",
        "dim": 128,
        "doc_maxlen": 256,
        "mask_punctuation": true,
        "checkpoint": "colbert-ir\/colbertv2.0",
        "triples": "\/future\/u\/okhattab\/root\/unit\/experiments\/2021.10\/downstream.distillation.round2.2_score\/round2.nway6.cosine.ib\/examples.64.json",
        "collection": [
            "A Computational Approach to Automatic Prediction of Drunk-Texting Aditya Joshi1,2,3 Abhijit Mishra1 Balamurali AR4 Pushpak Bhattacharyya1 Mark James Carman2 1IIT Bombay, India, 2Monash University, Australia 3IITB-Monash Research Academy, India 4Aix-Marseille University, France {adityaj, abhijitmishra, pb}@cse.iitb.ac.in balamurali.ar@lif.univ-mrs.fr,mark.carman@monash.edu Abstract Alcohol abuse may lead to unsociable behavior such as crime, drunk driving, or privacy leaks. We introduce auto- matic drunk-texting prediction as the task of identifying whether a text was writ- ten when under the in\ufb02uence of alcohol. We experiment with tweets labeled using hashtags as distant supervision. Our clas- si\ufb01ers use a set of N-gram and stylistic fea- tures to detect drunk tweets. Our observa- tions present the \ufb01rst quantitative evidence that text contains signals that can be ex- ploited to detect drunk-texting.",
            "Our clas- si\ufb01ers use a set of N-gram and stylistic fea- tures to detect drunk tweets. Our observa- tions present the \ufb01rst quantitative evidence that text contains signals that can be ex- ploited to detect drunk-texting. 1 Introduction The ubiquity of communication devices has made social media highly accessible. The content on these media re\ufb02ects a user\u2019s day-to-day activities. This includes content created under the in\ufb02uence of alcohol. In popular culture, this has been re- ferred to as \u2018drunk-texting\u20191. In this paper, we in- troduce automatic \u2018drunk-texting prediction\u2019 as a computational task. Given a tweet, the goal is to automatically identify if it was written by a drunk user. We refer to tweets written under the in\ufb02u- ence of alcohol as \u2018drunk tweets\u2019, and the opposite as \u2018sober tweets\u2019. A key challenge is to obtain an annotated dataset. We use hashtag-based supervision so that the authors of the tweets mention if they were drunk at the time of posting a tweet.",
            "A key challenge is to obtain an annotated dataset. We use hashtag-based supervision so that the authors of the tweets mention if they were drunk at the time of posting a tweet. We create three datasets by using different strategies that are related to the use of hashtags. We then present SVM-based classi\ufb01ers that use N-gram and stylis- tic features such as capitalisation, spelling errors, etc. Through our experiments, we make subtle points related to: (a) the performance of our fea- tures, (b) how our approach compares against 1Source: http:\/\/www.urbandictionary.com human ability to detect drunk-texting, (c) most discriminative stylistic features, and (d) an error analysis that points to future work. To the best of our knowledge, this is a \ufb01rst study that shows the feasibility of text-based analysis for drunk-texting prediction.",
            "To the best of our knowledge, this is a \ufb01rst study that shows the feasibility of text-based analysis for drunk-texting prediction. 2 Motivation Past studies show the relation between alcohol abuse and unsociable behaviour such as aggres- sion (Bushman and Cooper, 1990), crime (Carpen- ter, 2007), suicide attempts (Merrill et al., 1992), drunk driving (Loomis and West, 1958), and risky sexual behaviour (Bryan et al., 2005). Merrill et al. (1992) state that \u201cthose responsible for assess- ing cases of attempted suicide should be adept at detecting alcohol misuse\u201d. Thus, a drunk-texting prediction system can be used to identify individ- uals susceptible to these behaviours, or for inves- tigative purposes after an incident. Drunk-texting may also cause regret. Mail Goggles2 prompts a user to solve math questions before sending an email on weekend evenings. Some Android applications3 avoid drunk-texting by blocking outgoing texts at the click of a button. However, to the best of our knowledge, these tools require a user command to begin blocking.",
            "Mail Goggles2 prompts a user to solve math questions before sending an email on weekend evenings. Some Android applications3 avoid drunk-texting by blocking outgoing texts at the click of a button. However, to the best of our knowledge, these tools require a user command to begin blocking. An on- going text-based analysis will be more helpful, es- pecially since it offers a more natural setting by monitoring stream of social media text and not ex- plicitly seeking user input. Thus, automatic drunk- texting prediction will improve systems aimed to avoid regrettable drunk-texting. To the best of our knowledge, ours is the \ufb01rst study that does a quantitative analysis, in terms of prediction of the drunk state by using textual clues. Several studies have studied linguistic traits associated with emotion expression and mental 2http:\/\/gmailblog.blogspot.in\/2008\/10\/new-in-labs-stop- sending-mail-you-later.html 3https:\/\/play.google.com\/store\/apps\/details?id=com.oopsapp arXiv:1610.00879v1  [cs.CL]  4 Oct 2016",
            "health issues, suicidal nature, criminal status, etc. (Pennebaker, 1993; Pennebaker, 1997). NLP tech- niques have been used in the past to address so- cial safety and mental health issues (Resnik et al., 2013). 3 De\ufb01nition and Challenges Drunk-texting prediction is the task of classifying a text as drunk or sober. For example, a tweet \u2018Feeling buzzed. Can\u2019t remember how the evening went\u2019 must be predicted as \u2018drunk\u2019, whereas, \u2018Re- turned from work late today, the traf\ufb01c was bad\u2019 must be predicted as \u2018sober\u2019. The challenges are: 1. More than topic categorisation: Drunk- texting prediction is similar to topic cate- gorisation (that is, classi\ufb01cation of docu- ments into a set of categories such as \u2018news\u2019, \u2018sports\u2019, etc.). However, Borrill et al. (1987) show that alcohol abusers have more pro- nounced emotions, speci\ufb01cally, anger.",
            "However, Borrill et al. (1987) show that alcohol abusers have more pro- nounced emotions, speci\ufb01cally, anger. In this respect, drunk-texting prediction lies at the con\ufb02uence of topic categorisation and emo- tion classi\ufb01cation. 2. Identi\ufb01cation of labeled examples: It is dif- \ufb01cult to obtain a set of sober tweets. The ideal label can be possibly given only by the author. For example, whether a tweet such as \u2018I am feeling lonely tonight\u2019 is a drunk tweet is ambiguous. This is similar to sar- casm expressed as an exaggeration (for ex- ample, \u2018This is the best \ufb01lm ever!), where the context beyond the text needs to be consid- ered. 3. Precision\/Recall trade-off: The goal that a drunk-texting prediction system must chase depends on the application. An application that identi\ufb01es potential crimes must work with high precision, since the target popula- tion to be monitored will be large.",
            "3. Precision\/Recall trade-off: The goal that a drunk-texting prediction system must chase depends on the application. An application that identi\ufb01es potential crimes must work with high precision, since the target popula- tion to be monitored will be large. On the other hand, when being used to avoid regret- table drunk-texting, a prediction system must produce high recall in order to ensure that a drunk message does not pass through. 4 Dataset Creation We use hashtag-based supervision to create our datasets, similar to tasks like emotion classi\ufb01ca- tion (Purver and Battersby, 2012). The tweets are downloaded using Twitter API (https:\/\/dev. twitter.com\/). We remove non-Unicode characters, and eliminate tweets that contain hy- perlinks4 and also tweets that are shorter than 6 words in length. Finally, hashtags used to indi- cate drunk or sober tweets are removed so that they provide labels, but do not act as features. The dataset is available on request.",
            "Finally, hashtags used to indi- cate drunk or sober tweets are removed so that they provide labels, but do not act as features. The dataset is available on request. As a result, we cre- ate three datasets, each using a different strategy for sober tweets, as follows: Figure 1: Word cloud for drunk tweets 1. Dataset 1 (2435 drunk, 762 sober): We col- lect tweets that are marked as drunk and sober, using hashtags. Tweets containing hashtags #drunk, #drank and #imdrunk are considered to be drunk tweets, while those with #notdrunk, #imnotdrunk and #sober are considered to be sober tweets. 2. Dataset 2 (2435 drunk, 5644 sober): The drunk tweets are downloaded using drunk hashtags, as above. The list of users who cre- ated these tweets is extracted. For the nega- tive class, we download tweets by these users, which do not contain the hashtags that corre- spond to drunk tweets. 3.",
            "The list of users who cre- ated these tweets is extracted. For the nega- tive class, we download tweets by these users, which do not contain the hashtags that corre- spond to drunk tweets. 3. Dataset H (193 drunk, 317 sober): A sepa- rate dataset is created where drunk tweets are downloaded using drunk hashtags, as above. The set of sober tweets is collected using both the approaches above. The resultant is the held-out test set Dataset-H that contains no tweets in common with Datasets 1 and 2. The drunk tweets for Datasets 1 and 2 are the same. Figure 1 shows a word-cloud for these drunk tweets (with stop words and forms of the word \u2018drunk\u2019 removed), created using 4This is a rigid criterion, but we observe that tweets with hyperlinks are likely to be promotional in nature.",
            "Feature Description N-gram Features Unigram & Bigram (Presence) Boolean features indicating unigrams and bigrams Unigram & Bigram (Count) Real-valued features indicating unigrams and bigrams Stylistic Features LDA unigrams (Presence\/Count) Boolean & real-valued features indicating unigrams from LDA POS Ratio Ratios of nouns, adjectives, adverbs in the tweet #Named Entity Mentions Number of named entity mentions #Discourse Connectors Number of discourse connectors Spelling errors Boolean feature indicating presence of spelling mistakes Repeated characters Boolean feature indicating whether a character is repeated three times consecutively Capitalisation Number of capital letters in the tweet Length Number of words Emoticon (Presence\/Count) Boolean & real-valued features indicating unigrams Sentiment Ratio Positive and negative word ratios Table 1: Our Feature Set for Drunk-texting Prediction WordItOut5. The size of a word indicates its fre- quency. In addition to topical words such as \u2018bar\u2019, \u2018bottle\u2019 and \u2018wine\u2019, the word-cloud shows senti- ment words such as \u2018love\u2019 or \u2018damn\u2019, along with profane words. Heuristics other than these hashtags could have been used for dataset creation.",
            "In addition to topical words such as \u2018bar\u2019, \u2018bottle\u2019 and \u2018wine\u2019, the word-cloud shows senti- ment words such as \u2018love\u2019 or \u2018damn\u2019, along with profane words. Heuristics other than these hashtags could have been used for dataset creation. For example, timestamps were a good option to account for time at which a tweet was posted. However, this could not be used because user\u2019s local times was not available, since very few users had geolocation en- abled. 5 Feature Design The complete set of features is shown in Table 1. There are two sets of features: (a) N-gram fea- tures, and (b) Stylistic features. We use unigrams and bigrams as N-gram features- considering both presence and count. Table 1 shows the complete set of stylistic fea- tures of our prediction system. POS ratios are a set of features that record the proportion of each POS tag in the dataset (for example, the proportion of nouns\/adjectives, etc.). The POS tags and named entity mentions are obtained from NLTK (Bird, 2006).",
            "POS ratios are a set of features that record the proportion of each POS tag in the dataset (for example, the proportion of nouns\/adjectives, etc.). The POS tags and named entity mentions are obtained from NLTK (Bird, 2006). Discourse connectors are identi\ufb01ed based on a manually created list. Spelling errors are identi\ufb01ed using a spell checker by Aby (2014). The repeated characters feature captures a situ- ation in which a word contains a letter that is repeated three or more times, as in the case of 5www.worditout.com happpy. Since drunk-texting is often associated with emotional expression, we also incorporate a set of sentiment-based features. These features in- clude: count\/presence of emoticons and sentiment ratio. Sentiment ratio is the proportion of posi- tive and negative words in the tweet. To deter- mine positive and negative words, we use the sen- timent lexicon in Wilson et al. (2005).",
            "Sentiment ratio is the proportion of posi- tive and negative words in the tweet. To deter- mine positive and negative words, we use the sen- timent lexicon in Wilson et al. (2005). To identify a more re\ufb01ned set of words that correspond to the two classes, we also estimated 20 topics for the dataset by estimating an LDA model (Blei et al., 2003). We then consider top 10 words per topic, for both classes. This results in 400 LDA-speci\ufb01c unigrams that are then used as features.",
            "We then consider top 10 words per topic, for both classes. This results in 400 LDA-speci\ufb01c unigrams that are then used as features. A (%) NP (%) PP (%) NR (%) PR (%) Dataset 1 N-gram 85.5 72.8 88.8 63.4 92.5 Stylistic 75.6 32.5 76.2 3.2 98.6 All 85.4 71.9 89.1 64.6 91.9 Dataset 2 N-gram 77.9 82.3 65.5 87.2 56.5 Stylistic 70.3 70.8 56.7 97.9 6.01 All 78.1 82.6 65.3 86.9 57.5 Table 2: Performance of our features on Datasets 1 and 2",
            "6 Evaluation Using the two sets of features, we train SVM clas- si\ufb01ers (Chang and Lin, 2011)6. We show the \ufb01ve-fold cross-validation performance of our fea- tures on Datasets 1 and 2, in Section 6.1, and on Dataset H in Section 6.2. Section 6.3 presents an error analysis. Accuracy, positive\/negative preci- sion and positive\/negative recall are shown as A, PP\/NP and PR\/NR respectively. \u2018Drunk\u2019 forms the positive class, while \u2018Sober\u2019 forms the nega- tive class.",
            "Accuracy, positive\/negative preci- sion and positive\/negative recall are shown as A, PP\/NP and PR\/NR respectively. \u2018Drunk\u2019 forms the positive class, while \u2018Sober\u2019 forms the nega- tive class. Top features # Dataset 1 Dataset 2 1 POS NOUN Spelling error 2 Capitalization LDA drinking 3 Spelling error POS NOUN 4 POS PREPOSITION Length 5 Length LDA tonight 6 LDA Llife Sentiment Ratio 7 POS VERB Char repeat 8 LDA today LDA today 9 POS ADV LDA drunken 10 Sentiment Ratio LDA lmao Table 3: Top stylistic features for Datasets 1 and 2 obtained using Chi-squared test-based ranking 6.1 Performance for Datasets 1 and 2 Table 2 shows the performance for \ufb01ve-fold cross- validation for Datasets 1 and 2. In case of Dataset 1, we observe that N-gram features achieve an ac- curacy of 85.5%.",
            "In case of Dataset 1, we observe that N-gram features achieve an ac- curacy of 85.5%. We see that our stylistic features alone exhibit degraded performance, with an ac- curacy of 75.6%, in the case of Dataset 1. Ta- ble 3 shows top stylistic features, when trained on the two datasets. Spelling errors, POS ratios for nouns (POS NOUN)7, length and sentiment ratios appear in both lists, in addition to LDA- based unigrams. However, negative recall reduces to a mere 3.2%. This degradation implies that our features capture a subset of drunk tweets and that there are properties of drunk tweets that may be more subtle. When both N-gram and stylis- tic features are used, there is negligible improve- ment. The accuracy for Dataset 2 increases from 6We also repeated all experiments for Na\u00a8\u0131ve Bayes. They do not perform as well as SVM, and have poor recall.",
            "When both N-gram and stylis- tic features are used, there is negligible improve- ment. The accuracy for Dataset 2 increases from 6We also repeated all experiments for Na\u00a8\u0131ve Bayes. They do not perform as well as SVM, and have poor recall. 7POS ratios for nouns, adjectives and adverbs were nearly similar in drunk and sober tweets - with the maximum differ- ence being 0.03% 77.9% to 78.1%. Precision\/Recall metrics do not change signi\ufb01cantly either. The best accuracy of our classi\ufb01er is 78.1% for all features, and 75.6% for stylistic features. This shows that text-based clues can indeed be used for drunk-texting predic- tion.",
            "The best accuracy of our classi\ufb01er is 78.1% for all features, and 75.6% for stylistic features. This shows that text-based clues can indeed be used for drunk-texting predic- tion. A1 A2 A3 A1 - 0.42 0.36 A2 0.42 - 0.30 A3 0.36 0.30 - Table 4: Cohen\u2019s Kappa for three annotators (A1- A3) A (%) NP (%) PP (%) NR (%) PR (%) Annotators 68.8 71.7 61.7 83.9 43.5 Training Dataset Our classi\ufb01ers Dataset 1 47.3 70 40 26 81 Dataset 2 64 70 53 72 50 Table 5: Performance of human evaluators and our classi\ufb01ers (trained on all features), for Dataset-H as the test set 6.2 Performance for Held-out Dataset H Using held-out dataset H, we evaluate how our system performs in comparison to humans.",
            "Three annotators, A1-A3, mark each tweet in the Dataset H as drunk or sober. Table 4 shows a moderate agreement between our annotators (for example, it is 0.42 for A1 and A2). Table 5 compares our classi\ufb01er with humans. Our human annotators per- form the task with an average accuracy of 68.8%, while our classi\ufb01er (with all features) trained on Dataset 2 reaches 64%. The classi\ufb01er trained on Dataset 2 is better than which is trained on Dataset 1. 6.3 Error Analysis Some categories of errors that occur are: 1. Incorrect hashtag supervision: The tweet \u2018Can\u2019t believe I lost my bag last night, lit- erally had everything in! Thanks god the bar man found it\u2019 was marked with\u2018#Drunk\u2019. However, this tweet is not likely to be a drunk tweet, but describes a drunk episode in retro- spective. Our classi\ufb01er predicts it as sober.",
            "2. Seemingly sober tweets: Human annotators as well as our classi\ufb01er could not identify whether \u2018Will you take her on a date? But really she does like you\u2019 was drunk, although the author of the tweet had marked it so. This example also highlights the dif\ufb01culty of drunk-texting prediction. 3. Pragmatic dif\ufb01culty: The tweet \u2018National dress of Ireland is one\u2019s one vomit.. my fam- ily is lovely\u2019 was correctly identi\ufb01ed by our human annotators as a drunk tweet. This tweet contains an element of humour and topic change, but our classi\ufb01er could not cap- ture it. 7 Conclusion & Future Work In this paper, we introduce automatic drunk- texting prediction as the task of predicting a tweet as drunk or sober. First, we justify the need for drunk-texting prediction as means of identifying risky social behavior arising out of alcohol abuse, and the need to build tools that avoid privacy leaks due to drunk-texting. We then highlight the chal- lenges of drunk-texting prediction: one of the challenges is selection of negative examples (sober tweets).",
            "We then highlight the chal- lenges of drunk-texting prediction: one of the challenges is selection of negative examples (sober tweets). Using hashtag-based supervision, we cre- ate three datasets annotated with drunk or sober labels. We then present SVM-based classi\ufb01ers which use two sets of features: N-gram and stylis- tic features. Our drunk prediction system obtains a best accuracy of 78.1%. We observe that our stylistic features add negligible value to N-gram features. We use our heldout dataset to compare how our system performs against human annota- tors. While human annotators achieve an accuracy of 68.8%, our system reaches reasonably close and performs with a best accuracy of 64%. Our analysis of the task and experimental \ufb01nd- ings make a case for drunk-texting prediction as a useful and feasible NLP application. References [Aby2014] Aby. 2014. Aby word processing website, January. [Bird2006] Steven Bird. 2006. Nltk: the natural lan- guage toolkit.",
            "References [Aby2014] Aby. 2014. Aby word processing website, January. [Bird2006] Steven Bird. 2006. Nltk: the natural lan- guage toolkit. In Proceedings of the COLING\/ACL on Interactive presentation sessions, pages 69\u201372. Association for Computational Linguistics. [Blei et al.2003] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3:993\u2013 1022. [Borrill et al.1987] Josephine A Borrill, Bernard K Rosen, and Angela B Summer\ufb01eld. 1987. The in- \ufb02uence of alcohol on judgement of facial expres- sions of emotion. British Journal of Medical Psy- chology. [Bryan et al.2005] Angela Bryan, Courtney A Roche- leau, Reuben N Robbins, and Kent E Hutchinson. 2005.",
            "British Journal of Medical Psy- chology. [Bryan et al.2005] Angela Bryan, Courtney A Roche- leau, Reuben N Robbins, and Kent E Hutchinson. 2005. Condom use among high-risk adolescents: testing the in\ufb02uence of alcohol use on the relation- ship of cognitive correlates of behavior. Health Psy- chology, 24(2):133. [Bushman and Cooper1990] Brad J Bushman and Har- ris M Cooper. 1990. Effects of alcohol on human aggression: An intergrative research review. Psy- chological bulletin, 107(3):341. [Carpenter2007] Christopher Carpenter. 2007. Heavy alcohol use and crime: Evidence from underage drunk-driving laws. Journal of Law and Economics, 50(3):539\u2013557. [Chang and Lin2011] Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27.",
            "[Chang and Lin2011] Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27. [Loomis and West1958] Ted A Loomis and TC West. 1958. The in\ufb02uence of alcohol on automobile driv- ing ability: An experimental study for the evaluation of certain medicological aspects. Quarterly journal of studies on alcohol, 19(1):30\u201346. [Merrill et al.1992] John Merrill, GABRIELLE MILKER, John Owens, and Allister Vale. 1992. Alcohol and attempted suicide. British journal of addiction, 87(1):83\u201389. [Pennebaker1993] James W Pennebaker. 1993. Putting stress into words: Health, linguistic, and therapeu- tic implications. Behaviour research and therapy, 31(6):539\u2013548. [Pennebaker1997] James W Pennebaker. 1997.",
            "1993. Putting stress into words: Health, linguistic, and therapeu- tic implications. Behaviour research and therapy, 31(6):539\u2013548. [Pennebaker1997] James W Pennebaker. 1997. Writ- ing about emotional experiences as a therapeutic process. Psychological science, 8(3):162\u2013166. [Purver and Battersby2012] Matthew Purver and Stuart Battersby. 2012. Experimenting with distant su- pervision for emotion classi\ufb01cation. In Proceed- ings of the 13th Conference of the European Chap- ter of the Association for Computational Linguistics, pages 482\u2013491. Association for Computational Lin- guistics. [Resnik et al.2013] Philip Resnik, Anderson Garron, and Rebecca Resnik. 2013. Using topic modeling to improve prediction of neuroticism and depression. In Proceedings of the 2013 Conference on Empirical Methods in Natural, pages 1348\u20131353. Association for Computational Linguistics.",
            "[Wilson et al.2005] Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual po- larity in phrase-level sentiment analysis. In Pro- ceedings of the conference on human language tech- nology and empirical methods in natural language processing, pages 347\u2013354. Association for Compu- tational Linguistics."
        ],
        "queries": "\/future\/u\/okhattab\/data\/MSMARCO\/queries.train.tsv",
        "index_name": "PaperTab-question-1610.00879.pdf",
        "overwrite": false,
        "root": ".ragatouille\/",
        "experiment": "colbert",
        "index_root": null,
        "name": "2025-05\/17\/10.22.50",
        "rank": 0,
        "nranks": 1,
        "amp": true,
        "gpus": 1,
        "avoid_fork_if_possible": false
    },
    "num_chunks": 1,
    "num_partitions": 1024,
    "num_embeddings_est": 5020.000183105469,
    "avg_doclen_est": 179.2857208251953
}
