[
    {
        "doc_id": "1912.01214.pdf",
        "q_uid": "5eda469a8a77f028d0c5f1acd296111085614537",
        "question": "what language pairs are explored?",
        "answer": "De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-En, En-Ru",
        "answer_2": "French-English-Spanish (Fr-En-Es), German-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De), Arabic (Ar), Spanish (Es), and Russian (Ru), and mutual translation between themselves constitutes six zero-shot translation",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            4,
            1,
            2,
            5,
            3,
            6,
            7
        ],
        "image-top-10-question_score": [
            11.882766723632812,
            11.859766006469727,
            11.714985847473145,
            11.706747055053711,
            11.29313850402832,
            11.293096542358398,
            11.189079284667969,
            10.693439483642578
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.01214.pdf",
        "text-top-10-question": [
            2,
            1,
            2,
            0,
            3,
            2,
            1,
            6,
            0,
            0
        ],
        "text-top-10-question_score": [
            20.59375,
            16.875,
            16.59375,
            16.3125,
            16.0625,
            15.640625,
            15.328125,
            14.984375,
            14.9453125,
            14.734375
        ]
    },
    {
        "doc_id": "1801.05147.pdf",
        "q_uid": "ef4dba073d24042f24886580ae77add5326f2130",
        "question": "What accuracy does the proposed system achieve?",
        "answer": "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data ",
        "answer_2": "F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            6,
            5,
            2,
            0,
            4,
            7,
            3,
            8
        ],
        "image-top-10-question_score": [
            12.881686210632324,
            12.536737442016602,
            12.360159873962402,
            11.973154067993164,
            11.89864730834961,
            11.825187683105469,
            11.577610969543457,
            11.151148796081543,
            11.074540138244629
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1801.05147.pdf",
        "text-top-10-question": [
            5,
            5,
            6,
            1,
            0,
            5,
            5,
            6,
            1,
            0
        ],
        "text-top-10-question_score": [
            16.328125,
            15.7734375,
            15.53125,
            15.3046875,
            15.015625,
            15.0078125,
            14.9453125,
            14.4140625,
            14.3984375,
            13.4375
        ]
    },
    {
        "doc_id": "1704.06194.pdf",
        "q_uid": "9ee07edc371e014df686ced4fb0c3a7b9ce3d5dc",
        "question": "On which benchmarks they achieve the state of the art?",
        "answer": "SimpleQuestions, WebQSP",
        "answer_2": "WebQSP, SimpleQuestions",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            7,
            6,
            11,
            0,
            1,
            2,
            9,
            10,
            5
        ],
        "image-top-10-question_score": [
            15.138031959533691,
            14.659759521484375,
            14.378725051879883,
            13.979938507080078,
            13.976005554199219,
            13.848716735839844,
            13.747800827026367,
            13.499780654907227,
            13.449071884155273,
            13.280149459838867
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1704.06194.pdf",
        "text-top-10-question": [
            0,
            8,
            8,
            6,
            6,
            8,
            1,
            8,
            6,
            1
        ],
        "text-top-10-question_score": [
            14.90625,
            14.765625,
            13.6484375,
            13.625,
            13.3203125,
            13.28125,
            12.9140625,
            12.25,
            8.703125,
            7.7890625
        ]
    },
    {
        "doc_id": "1909.00512.pdf",
        "q_uid": "891c2001d6baaaf0da4e65b647402acac621a7d2",
        "question": "How do they calculate a static embedding for each word?",
        "answer": "They use the first principal component of a word's contextualized representation in a given layer as its static embedding.",
        "answer_2": " by taking the first principal component (PC) of its contextualized representations in a given layer",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            1,
            7,
            0,
            4,
            3,
            8,
            2,
            5,
            9
        ],
        "image-top-10-question_score": [
            17.295757293701172,
            17.14215087890625,
            16.737295150756836,
            16.689231872558594,
            16.445899963378906,
            16.431848526000977,
            16.133556365966797,
            15.233200073242188,
            14.955803871154785,
            13.685507774353027
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00512.pdf",
        "text-top-10-question": [
            7,
            6,
            7,
            3,
            1,
            1,
            0,
            8,
            7,
            3
        ],
        "text-top-10-question_score": [
            24.015625,
            22.359375,
            22.078125,
            22.015625,
            21.984375,
            21.703125,
            20.90625,
            20.609375,
            20.515625,
            20.296875
        ]
    },
    {
        "doc_id": "2003.03106.pdf",
        "q_uid": "66c96c297c2cffdf5013bab5e95b59101cb38655",
        "question": "What is the performance of BERT on the task?",
        "answer": "F1 scores are:\nHUBES-PHI: Detection(0.965), Classification relaxed (0.95), Classification strict (0.937)\nMedoccan: Detection(0.972), Classification (0.967)",
        "answer_2": "BERT remains only 0.3 F1-score points behind, and would have achieved the second position among all the MEDDOCAN shared task competitors. Taking into account that only 3% of the gold labels remain incorrectly annotated,  Table ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            6,
            0,
            7,
            1,
            4,
            5,
            2,
            8
        ],
        "image-top-10-question_score": [
            16.313854217529297,
            16.140317916870117,
            16.004661560058594,
            15.992659568786621,
            15.928020477294922,
            15.807117462158203,
            15.057018280029297,
            14.821084976196289,
            14.101493835449219
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.03106.pdf",
        "text-top-10-question": [
            3,
            0,
            7,
            3,
            0,
            5,
            6,
            3,
            7,
            1
        ],
        "text-top-10-question_score": [
            24.015625,
            23.9375,
            22.984375,
            22.1875,
            21.890625,
            21.515625,
            21.5,
            21.015625,
            20.859375,
            20.65625
        ]
    },
    {
        "doc_id": "1909.11687.pdf",
        "q_uid": "efe9bad55107a6be7704ed97ecce948a8ca7b1d2",
        "question": "What state-of-the-art compression techniques were used in the comparison?",
        "answer": "baseline without knowledge distillation (termed NoKD), Patient Knowledge Distillation (PKD)",
        "answer_2": "NoKD, PKD, BERTBASE teacher model",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            2,
            4,
            6,
            3,
            1
        ],
        "image-top-10-question_score": [
            18.732927322387695,
            18.692768096923828,
            17.59136199951172,
            17.516307830810547,
            17.508262634277344,
            17.395368576049805,
            17.30988311767578
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.11687.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            0,
            4,
            5,
            4,
            0,
            2,
            6
        ],
        "text-top-10-question_score": [
            19.953125,
            18.546875,
            16.90625,
            16.4375,
            14.0,
            13.1953125,
            12.15625,
            11.765625,
            11.1171875,
            10.78125
        ]
    },
    {
        "doc_id": "1804.05918.pdf",
        "q_uid": "f17ca24b135f9fe6bb25dc5084b13e1637ec7744",
        "question": "What discourse relations does it work best/worst for?",
        "answer": "explicit discourse relations",
        "answer_2": "Best: Expansion (Exp). Worst: Comparison (Comp).",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            4,
            5,
            10,
            3,
            6,
            9,
            8,
            2
        ],
        "image-top-10-question_score": [
            16.585325241088867,
            16.312759399414062,
            16.153568267822266,
            15.950780868530273,
            15.933507919311523,
            15.930068016052246,
            15.885042190551758,
            15.860729217529297,
            15.857206344604492,
            15.667632102966309
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1804.05918.pdf",
        "text-top-10-question": [
            5,
            7,
            8,
            7,
            0,
            6,
            5,
            8,
            1,
            0
        ],
        "text-top-10-question_score": [
            19.46875,
            19.34375,
            18.96875,
            18.046875,
            17.4375,
            17.28125,
            17.0,
            16.78125,
            16.578125,
            16.5
        ]
    },
    {
        "doc_id": "2002.01664.pdf",
        "q_uid": "75df70ce7aa714ec4c6456d0c51f82a16227f2cb",
        "question": "Which 7 Indian languages do they experiment with?",
        "answer": "Hindi, English, Kannada, Telugu, Assamese, Bengali and Malayalam",
        "answer_2": "Kannada, Hindi, Telugu, Malayalam, Bengali,  English and Assamese (in table, missing in text)",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            2,
            3,
            4,
            1
        ],
        "image-top-10-question_score": [
            15.47580337524414,
            15.055339813232422,
            12.85190486907959,
            11.447528839111328,
            11.243755340576172
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.01664.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            3,
            2,
            0,
            2,
            3,
            2,
            4
        ],
        "text-top-10-question_score": [
            22.1875,
            20.453125,
            19.046875,
            18.203125,
            16.03125,
            15.6796875,
            13.8125,
            13.6015625,
            12.109375,
            11.484375
        ]
    },
    {
        "doc_id": "1809.00540.pdf",
        "q_uid": "a99fdd34422f4231442c220c97eafc26c76508dd",
        "question": "Do they use graphical models?",
        "answer": "No",
        "answer_2": "No",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            9,
            1,
            6,
            7,
            5,
            4,
            0,
            3,
            2
        ],
        "image-top-10-question_score": [
            11.18918514251709,
            11.184396743774414,
            10.53566837310791,
            10.00113296508789,
            9.933804512023926,
            9.821905136108398,
            9.796416282653809,
            9.773019790649414,
            9.50322151184082,
            9.402619361877441
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.00540.pdf",
        "text-top-10-question": [
            8,
            7,
            8,
            4,
            7,
            5,
            4,
            6,
            6,
            3
        ],
        "text-top-10-question_score": [
            13.375,
            13.1796875,
            12.25,
            11.8515625,
            11.71875,
            11.703125,
            11.6171875,
            10.2265625,
            10.1953125,
            10.125
        ]
    },
    {
        "doc_id": "1809.00540.pdf",
        "q_uid": "d604f5fb114169f75f9a38fab18c1e866c5ac28b",
        "question": "What metric is used for evaluation?",
        "answer": "F1, precision, recall, accuracy",
        "answer_2": "Precision, recall, F1, accuracy",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            3,
            2,
            6,
            8,
            7,
            9,
            0,
            1
        ],
        "image-top-10-question_score": [
            12.341267585754395,
            10.349916458129883,
            9.978758811950684,
            9.696354866027832,
            9.271356582641602,
            9.162073135375977,
            8.804387092590332,
            8.572491645812988,
            8.485301971435547,
            8.115890502929688
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.00540.pdf",
        "text-top-10-question": [
            5,
            5,
            3,
            4,
            3,
            2,
            4,
            7,
            5,
            7
        ],
        "text-top-10-question_score": [
            15.6875,
            14.671875,
            14.3203125,
            13.6953125,
            13.640625,
            12.8828125,
            12.6328125,
            12.390625,
            11.9609375,
            11.7890625
        ]
    },
    {
        "doc_id": "2004.03354.pdf",
        "q_uid": "1d3e914d0890fc09311a70de0b20974bf7f0c9fe",
        "question": "Which eight NER tasks did they evaluate on?",
        "answer": "BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800",
        "answer_2": "BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            0,
            2,
            5,
            3,
            1,
            4,
            6
        ],
        "image-top-10-question_score": [
            14.586748123168945,
            13.583581924438477,
            13.467226028442383,
            13.387158393859863,
            13.378339767456055,
            11.350608825683594,
            11.286724090576172,
            10.835750579833984
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2004.03354.pdf",
        "text-top-10-question": [
            0,
            0,
            3,
            7,
            3,
            0,
            2,
            0,
            7,
            7
        ],
        "text-top-10-question_score": [
            22.265625,
            20.65625,
            19.90625,
            19.703125,
            19.09375,
            18.21875,
            17.296875,
            17.125,
            16.96875,
            16.859375
        ]
    },
    {
        "doc_id": "1611.04798.pdf",
        "q_uid": "897ba53ef44f658c128125edd26abf605060fb13",
        "question": "Do they test their framework performance on commonly used language pairs, such as English-to-German?",
        "answer": "Yes",
        "answer_2": "Yes",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            7,
            6,
            8,
            4,
            3,
            2,
            0,
            1,
            9
        ],
        "image-top-10-question_score": [
            23.07705307006836,
            22.938655853271484,
            22.7220458984375,
            22.343353271484375,
            21.595508575439453,
            21.321590423583984,
            20.789318084716797,
            20.682477951049805,
            20.25292205810547,
            19.64862823486328
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1611.04798.pdf",
        "text-top-10-question": [
            5,
            4,
            5,
            0,
            0,
            4,
            3,
            7,
            7,
            7
        ],
        "text-top-10-question_score": [
            18.59375,
            15.9921875,
            15.7578125,
            15.484375,
            15.2578125,
            15.015625,
            14.8828125,
            14.71875,
            14.671875,
            14.53125
        ]
    },
    {
        "doc_id": "1809.01541.pdf",
        "q_uid": "c32adef59efcb9d1a5b10e1d7c999a825c9e6d9a",
        "question": "What languages are evaluated?",
        "answer": "German, English, Spanish, Finnish, French, Russian,  Swedish.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            2,
            5,
            0,
            1
        ],
        "image-top-10-question_score": [
            11.212301254272461,
            11.061952590942383,
            10.826942443847656,
            10.59985637664795,
            10.085859298706055,
            9.261557579040527
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.01541.pdf",
        "text-top-10-question": [
            0,
            3,
            3,
            1,
            2,
            3,
            5,
            2,
            4,
            3
        ],
        "text-top-10-question_score": [
            15.53125,
            14.21875,
            13.09375,
            12.6953125,
            12.6875,
            12.4375,
            12.1953125,
            12.1796875,
            12.0390625,
            11.8671875
        ]
    },
    {
        "doc_id": "1809.01541.pdf",
        "q_uid": "32a3c248b928d4066ce00bbb0053534ee62596e7",
        "question": "What is MSD prediction?",
        "answer": "The task of predicting MSD tags: V, PST, V.PCTP, PASS.",
        "answer_2": "morphosyntactic descriptions (MSD)",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            5,
            0,
            2,
            1
        ],
        "image-top-10-question_score": [
            12.286491394042969,
            11.829146385192871,
            11.694489479064941,
            11.6721773147583,
            11.509178161621094,
            11.311002731323242
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.01541.pdf",
        "text-top-10-question": [
            4,
            2,
            3,
            4,
            1,
            1,
            0,
            0,
            2,
            5
        ],
        "text-top-10-question_score": [
            21.828125,
            21.703125,
            21.375,
            21.1875,
            19.875,
            18.640625,
            18.484375,
            17.359375,
            16.296875,
            16.1875
        ]
    },
    {
        "doc_id": "1809.09194.pdf",
        "q_uid": "d3dbb5c22ef204d85707d2d24284cc77fa816b6c",
        "question": "What other models do they compare to?",
        "answer": "SAN Baseline, BNA, DocQA, R.M-Reader, R.M-Reader+Verifier and DocQA+ELMo",
        "answer_2": "BNA, DocQA, R.M-Reader, R.M-Reader + Verifier, DocQA + ELMo, R.M-Reader+Verifier+ELMo",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            1,
            0,
            3,
            2,
            5
        ],
        "image-top-10-question_score": [
            13.853155136108398,
            13.034723281860352,
            12.846981048583984,
            12.743529319763184,
            11.92613410949707,
            11.504175186157227
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.09194.pdf",
        "text-top-10-question": [
            4,
            3,
            0,
            0,
            3,
            3,
            1,
            1,
            0,
            3
        ],
        "text-top-10-question_score": [
            18.84375,
            15.78125,
            15.765625,
            14.265625,
            13.1875,
            12.34375,
            12.328125,
            12.1171875,
            11.890625,
            11.8046875
        ]
    },
    {
        "doc_id": "1802.06024.pdf",
        "q_uid": "286078813136943dfafb5155ee15d2429e7601d9",
        "question": "How much better than the baseline is LiLi?",
        "answer": "In case of Freebase knowledge base, LiLi model had better F1 score than the single model by 0.20 , 0.01, 0.159 for kwn, unk, and all test Rel type.  The values for WordNet are 0.25, 0.1, 0.2. \n",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            7,
            4,
            5,
            6,
            2,
            3,
            9,
            0,
            1
        ],
        "image-top-10-question_score": [
            15.45988941192627,
            15.4116792678833,
            14.947250366210938,
            14.895513534545898,
            14.887662887573242,
            14.868703842163086,
            14.864678382873535,
            14.153024673461914,
            14.075691223144531,
            13.761528015136719
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1802.06024.pdf",
        "text-top-10-question": [
            8,
            8,
            8,
            7,
            8,
            8,
            8,
            7,
            5,
            5
        ],
        "text-top-10-question_score": [
            20.234375,
            19.8125,
            19.5625,
            19.421875,
            19.265625,
            18.6875,
            17.6875,
            17.125,
            16.625,
            16.609375
        ]
    },
    {
        "doc_id": "1809.00530.pdf",
        "q_uid": "6aa2a1e2e3666f2b2a1f282d4cbdd1ca325eb9de",
        "question": "How many labels do the datasets have?",
        "answer": "719313",
        "answer_2": "Book, Electronics, Beauty and Music each have 6000, IMDB 84919, Yelp 231163, Cell Phone 194792 and Baby 160792 labeled data.",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            6,
            5,
            10,
            2,
            1,
            7,
            11,
            3,
            13
        ],
        "image-top-10-question_score": [
            14.598295211791992,
            13.720138549804688,
            13.427511215209961,
            13.356595993041992,
            13.286845207214355,
            13.050687789916992,
            12.887413024902344,
            12.797225952148438,
            12.688188552856445,
            12.251368522644043
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.00530.pdf",
        "text-top-10-question": [
            4,
            10,
            4,
            4,
            5,
            5,
            10,
            4,
            6,
            7
        ],
        "text-top-10-question_score": [
            22.75,
            19.1875,
            18.21875,
            18.140625,
            17.15625,
            16.5625,
            15.4296875,
            15.265625,
            15.1640625,
            15.046875
        ]
    },
    {
        "doc_id": "1809.00530.pdf",
        "q_uid": "9176d2ba1c638cdec334971c4c7f1bb959495a8e",
        "question": "What are the source and target domains?",
        "answer": "Book, electronics, beauty, music, IMDB, Yelp, cell phone, baby, DVDs, kitchen",
        "answer_2": "we use set 1 of the source domain as the only source with sentiment label information during training, and we evaluate the trained model on set 1 of the target domain, Book (BK), Electronics (E), Beauty (BT), and Music (M)",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            10,
            2,
            8,
            0,
            5,
            1,
            9,
            13,
            12
        ],
        "image-top-10-question_score": [
            13.566386222839355,
            13.514955520629883,
            13.227553367614746,
            13.222655296325684,
            12.983709335327148,
            12.931913375854492,
            12.195316314697266,
            12.186145782470703,
            11.983837127685547,
            11.952972412109375
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.00530.pdf",
        "text-top-10-question": [
            0,
            8,
            0,
            5,
            10,
            4,
            5,
            1,
            4,
            2
        ],
        "text-top-10-question_score": [
            20.328125,
            19.875,
            19.71875,
            19.546875,
            19.4375,
            19.234375,
            18.953125,
            18.546875,
            18.3125,
            18.15625
        ]
    },
    {
        "doc_id": "1912.08960.pdf",
        "q_uid": "b1bc9ae9d40e7065343c12f860a461c7c730a612",
        "question": "Which datasets are used?",
        "answer": "Existential (OneShape, MultiShapes), Spacial (TwoShapes, Multishapes), Quantification (Count, Ratio) datasets are generated from ShapeWorldICE",
        "answer_2": "ShapeWorldICE datasets: OneShape, MultiShapes, TwoShapes, MultiShapes, Count, and Ratio",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            5,
            1,
            4,
            2,
            7,
            6,
            0
        ],
        "image-top-10-question_score": [
            12.374192237854004,
            11.837966918945312,
            11.558751106262207,
            11.478139877319336,
            11.175454139709473,
            10.940695762634277,
            10.51688003540039,
            10.253929138183594
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.08960.pdf",
        "text-top-10-question": [
            3,
            1,
            3,
            4,
            6,
            0,
            1,
            1,
            5,
            5
        ],
        "text-top-10-question_score": [
            18.328125,
            17.703125,
            15.8203125,
            15.6796875,
            15.1171875,
            14.9140625,
            14.6171875,
            13.84375,
            13.7109375,
            13.640625
        ]
    },
    {
        "doc_id": "2002.11910.pdf",
        "q_uid": "9da1e124d28b488b0d94998d32aa2fa8a5ebec51",
        "question": "What are previous state of the art results?",
        "answer": "Overall F1 score:\n- He and Sun (2017) 58.23\n- Peng and Dredze (2017) 58.99\n- Xu et al. (2018) 59.11",
        "answer_2": "For Named entity the maximum precision was 66.67%, and the average 62.58%, same values for Recall was 55.97% and 50.33%, and for F1 57.14% and 55.64%. Where for Nominal Mention had maximum recall of 74.48% and average of 73.67%, Recall had values of 54.55% and 53.7%,  and F1 had values of  62.97% and 62.12%. Finally the Overall F1 score had maximum value of 59.11% and average of 58.77%",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            2,
            0,
            1
        ],
        "image-top-10-question_score": [
            13.993696212768555,
            13.546826362609863,
            12.730252265930176,
            12.641046524047852,
            12.548213958740234
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.11910.pdf",
        "text-top-10-question": [
            3,
            1,
            0,
            3,
            0,
            4,
            2,
            3,
            2,
            4
        ],
        "text-top-10-question_score": [
            16.8125,
            16.546875,
            16.25,
            11.3046875,
            10.0703125,
            9.671875,
            9.234375,
            8.671875,
            8.375,
            8.28125
        ]
    },
    {
        "doc_id": "1909.09587.pdf",
        "q_uid": "37be0d479480211291e068d0d3823ad0c13321d3",
        "question": "What is the model performance on target language reading comprehension?",
        "answer": "Table TABREF6, Table TABREF8",
        "answer_2": "when testing on English, the F1 score of the model training on Chinese (Zh) is 53.8,  F1 score is only 44.1 for the model training on Zh-En",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            4,
            5,
            1,
            2,
            6,
            3,
            7
        ],
        "image-top-10-question_score": [
            15.906238555908203,
            15.823455810546875,
            15.418315887451172,
            14.761707305908203,
            14.725411415100098,
            14.430017471313477,
            14.037647247314453,
            11.507057189941406
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.09587.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            5,
            0,
            4,
            4,
            5,
            0,
            4
        ],
        "text-top-10-question_score": [
            23.21875,
            21.671875,
            19.1875,
            17.828125,
            17.09375,
            16.75,
            16.171875,
            15.9453125,
            15.671875,
            15.6328125
        ]
    },
    {
        "doc_id": "1909.09587.pdf",
        "q_uid": "a3d9b101765048f4b61cbd3eaa2439582ebb5c77",
        "question": "What source-target language pairs were used in this work? ",
        "answer": "En-Fr, En-Zh, En-Jp, En-Kr, Zh-En, Zh-Fr, Zh-Jp, Zh-Kr to English, Chinese or Korean",
        "answer_2": "English , Chinese",
        "answer_3": "English, Chinese, Korean, we translated the English and Chinese datasets into more languages, with Google Translate",
        "image-top-10-question": [
            0,
            6,
            3,
            1,
            2,
            5,
            4,
            7
        ],
        "image-top-10-question_score": [
            17.756040573120117,
            17.56623077392578,
            16.951623916625977,
            16.81839370727539,
            16.78850746154785,
            16.318368911743164,
            16.102230072021484,
            13.934926986694336
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.09587.pdf",
        "text-top-10-question": [
            0,
            6,
            6,
            0,
            6,
            0,
            0,
            6,
            2,
            2
        ],
        "text-top-10-question_score": [
            20.625,
            20.625,
            19.4375,
            16.6875,
            16.125,
            15.4921875,
            14.75,
            14.3671875,
            14.09375,
            13.90625
        ]
    },
    {
        "doc_id": "1809.02286.pdf",
        "q_uid": "0ad4359e3e7e5e5f261c2668fe84c12bc762b3b8",
        "question": "Which baselines did they compare against?",
        "answer": "Various tree structured neural networks including variants of Tree-LSTM, Tree-based CNN, RNTN, and non-tree models including variants of LSTMs, CNNs, residual, and self-attention based networks",
        "answer_2": "Sentence classification baselines: RNTN (Socher et al. 2013), AdaMC-RNTN (Dong et al. 2014), TE-RNTN (Qian et al. 2015), TBCNN (Mou et al. 2015), Tree-LSTM (Tai, Socher, and Manning 2015), AdaHT-LSTM-CM (Liu, Qiu, and Huang 2017), DC-TreeLSTM (Liu, Qiu, and Huang 2017), TE-LSTM (Huang, Qian, and Zhu 2017), BiConTree (Teng and Zhang 2017), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), TreeNet (Cheng et al. 2018), CNN (Kim 2014), AdaSent (Zhao, Lu, and Poupart 2015), LSTM-CNN (Zhou et al. 2016), byte-mLSTM (Radford, Jozefowicz, and Sutskever 2017), BCN + Char + CoVe (McCann et al. 2017), BCN + Char + ELMo (Peters et al. 2018). \nStanford Natural Language Inference baselines: Latent Syntax Tree-LSTM (Yogatama et al. 2017), Tree-based CNN (Mou et al. 2016), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), NSE (Munkhdalai and Yu 2017), Reinforced Self- Attention Network (Shen et al. 2018), Residual stacked encoders: (Nie and Bansal 2017), BiLSTM with generalized pooling (Chen, Ling, and Zhu 2018).",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            1,
            7,
            8,
            6,
            0,
            2,
            3
        ],
        "image-top-10-question_score": [
            11.942843437194824,
            11.833974838256836,
            11.534717559814453,
            11.200584411621094,
            11.185552597045898,
            10.843860626220703,
            10.730035781860352,
            10.44790267944336,
            10.272099494934082
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.02286.pdf",
        "text-top-10-question": [
            4,
            4,
            5,
            5,
            1,
            5,
            6,
            4,
            0,
            4
        ],
        "text-top-10-question_score": [
            14.2109375,
            13.78125,
            11.015625,
            11.015625,
            10.484375,
            10.2109375,
            9.84375,
            8.765625,
            8.7578125,
            8.7421875
        ]
    },
    {
        "doc_id": "1809.01202.pdf",
        "q_uid": "4cbe5a36b492b99f9f9fea8081fe4ba10a7a0e94",
        "question": "What baselines did they consider?",
        "answer": "state-of-the-art PDTB taggers",
        "answer_2": "Linear SVM, RBF SVM, and Random Forest",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            3,
            7,
            2,
            0,
            6,
            9,
            8,
            1
        ],
        "image-top-10-question_score": [
            11.187989234924316,
            10.701062202453613,
            10.590492248535156,
            10.534756660461426,
            10.449426651000977,
            10.317575454711914,
            10.258484840393066,
            10.165133476257324,
            10.076102256774902,
            10.067070960998535
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.01202.pdf",
        "text-top-10-question": [
            5,
            2,
            0,
            2,
            6,
            1,
            0,
            1,
            6,
            2
        ],
        "text-top-10-question_score": [
            14.0,
            12.2890625,
            10.53125,
            9.2890625,
            8.4921875,
            8.375,
            8.25,
            7.80078125,
            7.703125,
            7.41796875
        ]
    },
    {
        "doc_id": "1906.01081.pdf",
        "q_uid": "ffa7f91d6406da11ddf415ef094aaf28f3c3872d",
        "question": "By how much more does PARENT correlate with human judgements in comparison to other text generation metrics?",
        "answer": "Best proposed metric has average correlation with human judgement of 0.913 and 0.846 compared to best compared metrics result of 0.758 and 0.829 on WikiBio and WebNLG challenge.",
        "answer_2": "Their average correlation tops the best other model by 0.155 on WikiBio.",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            8,
            0,
            6,
            5,
            1,
            3,
            2,
            4,
            9
        ],
        "image-top-10-question_score": [
            22.49062728881836,
            22.374467849731445,
            22.22359275817871,
            21.75103187561035,
            21.704605102539062,
            21.657852172851562,
            20.804033279418945,
            19.5737247467041,
            19.514673233032227,
            19.074705123901367
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1906.01081.pdf",
        "text-top-10-question": [
            0,
            7,
            7,
            6,
            7,
            5,
            7,
            8,
            6,
            7
        ],
        "text-top-10-question_score": [
            22.375,
            21.875,
            21.65625,
            20.875,
            20.4375,
            19.78125,
            19.578125,
            19.484375,
            18.59375,
            18.5
        ]
    },
    {
        "doc_id": "1812.10479.pdf",
        "q_uid": "b634ff1607ce5756655e61b9a6f18bc736f84c83",
        "question": "Which stock market sector achieved the best performance?",
        "answer": "Energy with accuracy of 0.538",
        "answer_2": "Energy",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            28,
            5,
            38,
            27,
            7,
            1,
            31,
            19,
            35
        ],
        "image-top-10-question_score": [
            14.117057800292969,
            13.853128433227539,
            13.618795394897461,
            13.498849868774414,
            13.176471710205078,
            12.939702033996582,
            12.891998291015625,
            12.870195388793945,
            12.81416130065918,
            12.716873168945312
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1812.10479.pdf",
        "text-top-10-question": [
            0,
            0,
            27,
            38,
            38,
            26,
            5,
            35,
            5,
            28
        ],
        "text-top-10-question_score": [
            21.515625,
            21.140625,
            19.5,
            17.5625,
            17.3125,
            15.9375,
            15.7578125,
            15.3359375,
            14.7109375,
            14.296875
        ]
    },
    {
        "doc_id": "1909.08089.pdf",
        "q_uid": "de5b6c25e35b3a6c5e40e350fc5e52c160b33490",
        "question": "How much does their model outperform existing models?",
        "answer": "Best proposed model result vs best previous result:\nArxiv dataset: Rouge 1 (43.62 vs 42.81), Rouge L (29.30 vs 31.80), Meteor (21.78 vs 21.35)\nPubmed dataset: Rouge 1 (44.85 vs 44.29), Rouge L (31.48 vs 35.21), Meteor (20.83 vs 20.56)",
        "answer_2": "On arXiv dataset, the proposed model outperforms baselie model by (ROUGE-1,2,L)  0.67 0.72 0.77 respectively and by Meteor 0.31.\n",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            5,
            7,
            8,
            4,
            1,
            3,
            2,
            0,
            9
        ],
        "image-top-10-question_score": [
            14.610809326171875,
            14.55491828918457,
            14.434478759765625,
            14.273327827453613,
            13.851763725280762,
            13.744775772094727,
            13.713380813598633,
            13.557703018188477,
            13.538139343261719,
            12.85949993133545
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.08089.pdf",
        "text-top-10-question": [
            6,
            1,
            5,
            1,
            0,
            6,
            7,
            8,
            8,
            8
        ],
        "text-top-10-question_score": [
            17.4375,
            16.5625,
            15.8359375,
            15.6640625,
            14.5078125,
            14.40625,
            13.5078125,
            13.3671875,
            13.2890625,
            13.0234375
        ]
    },
    {
        "doc_id": "1609.00559.pdf",
        "q_uid": "8b3d3953454c88bde88181897a7a2c0c8dd87e23",
        "question": "What embedding techniques are explored in the paper?",
        "answer": "Skip\u2013gram, CBOW",
        "answer_2": "integrated vector-res, vector-faith, Skip\u2013gram, CBOW",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            7,
            8,
            3,
            4,
            1,
            5,
            6,
            9,
            2
        ],
        "image-top-10-question_score": [
            14.611109733581543,
            13.732198715209961,
            12.708915710449219,
            12.479225158691406,
            12.096595764160156,
            11.806442260742188,
            11.784900665283203,
            11.773309707641602,
            11.621994018554688,
            11.595849990844727
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1609.00559.pdf",
        "text-top-10-question": [
            7,
            6,
            0,
            7,
            6,
            8,
            0,
            8,
            1,
            7
        ],
        "text-top-10-question_score": [
            19.546875,
            18.78125,
            17.78125,
            16.3125,
            15.9140625,
            15.09375,
            14.4765625,
            13.7265625,
            13.0,
            11.3203125
        ]
    },
    {
        "doc_id": "1904.10503.pdf",
        "q_uid": "5a65ad10ff954d0f27bb3ccd9027e3d8f7f6bb76",
        "question": "Which other approaches do they compare their model with?",
        "answer": "Akbik et al. (2018), Link et al. (2012)",
        "answer_2": "They compare to Akbik et al. (2018) and Link et al. (2012).",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            5,
            0,
            2,
            3,
            6
        ],
        "image-top-10-question_score": [
            15.199092864990234,
            14.771928787231445,
            14.719453811645508,
            14.272993087768555,
            14.079383850097656,
            13.576873779296875,
            12.2647123336792
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1904.10503.pdf",
        "text-top-10-question": [
            3,
            4,
            5,
            1,
            3,
            3,
            4,
            2,
            0,
            1
        ],
        "text-top-10-question_score": [
            15.578125,
            15.515625,
            15.3125,
            14.921875,
            14.5546875,
            14.2265625,
            14.09375,
            14.0390625,
            13.3671875,
            12.71875
        ]
    },
    {
        "doc_id": "1912.01772.pdf",
        "q_uid": "f9bf6bef946012dd42835bf0c547c0de9c1d229f",
        "question": "How is non-standard pronunciation identified?",
        "answer": "Original transcription was labeled with additional labels in [] brackets with nonstandard pronunciation.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            1,
            0,
            4,
            5
        ],
        "image-top-10-question_score": [
            13.029766082763672,
            12.544486045837402,
            12.28920841217041,
            11.791516304016113,
            11.5756254196167,
            10.721482276916504
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.01772.pdf",
        "text-top-10-question": [
            2,
            0,
            0,
            2,
            2,
            1,
            3,
            2,
            3,
            3
        ],
        "text-top-10-question_score": [
            19.40625,
            17.375,
            15.421875,
            15.171875,
            14.6640625,
            14.328125,
            13.03125,
            12.6015625,
            12.5859375,
            12.53125
        ]
    },
    {
        "doc_id": "1909.04002.pdf",
        "q_uid": "4d28c99750095763c81bcd5544491a0ba51d9070",
        "question": "What kind of celebrities do they obtain tweets from?",
        "answer": "Amitabh Bachchan, Ariana Grande, Barack Obama, Bill Gates, Donald Trump,\nEllen DeGeneres, J K Rowling, Jimmy Fallon, Justin Bieber, Kevin Durant, Kim Kardashian, Lady Gaga, LeBron James,Narendra Modi, Oprah Winfrey",
        "answer_2": "Celebrities from varioius domains - Acting, Music, Politics, Business, TV, Author, Sports, Modeling. ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            0,
            1,
            8,
            7,
            5,
            6,
            4,
            3,
            9
        ],
        "image-top-10-question_score": [
            16.21254539489746,
            15.983469009399414,
            15.974321365356445,
            15.946188926696777,
            15.45506763458252,
            14.952394485473633,
            14.771650314331055,
            14.371105194091797,
            14.3587646484375,
            13.798513412475586
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.04002.pdf",
        "text-top-10-question": [
            1,
            1,
            8,
            2,
            2,
            1,
            0,
            6,
            8,
            2
        ],
        "text-top-10-question_score": [
            19.328125,
            19.0,
            18.65625,
            18.546875,
            17.9375,
            17.90625,
            17.65625,
            17.53125,
            17.4375,
            17.25
        ]
    },
    {
        "doc_id": "1712.00991.pdf",
        "q_uid": "443d2448136364235389039cbead07e80922ec5c",
        "question": "What summarization algorithms did the authors experiment with?",
        "answer": "LSA, TextRank, LexRank and ILP-based summary.",
        "answer_2": "LSA, TextRank, LexRank",
        "answer_3": " ",
        "image-top-10-question": [
            11,
            9,
            12,
            13,
            2,
            6,
            4,
            0,
            1,
            7
        ],
        "image-top-10-question_score": [
            15.332297325134277,
            14.832559585571289,
            13.495640754699707,
            13.471363067626953,
            13.429728507995605,
            13.361120223999023,
            13.14250373840332,
            13.089883804321289,
            13.047967910766602,
            13.00971794128418
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1712.00991.pdf",
        "text-top-10-question": [
            11,
            12,
            11,
            12,
            9,
            11,
            2,
            5,
            9,
            13
        ],
        "text-top-10-question_score": [
            17.59375,
            16.703125,
            16.3125,
            16.3125,
            16.125,
            14.9453125,
            13.7109375,
            13.6640625,
            13.328125,
            13.1796875
        ]
    },
    {
        "doc_id": "1712.00991.pdf",
        "q_uid": "fb3d30d59ed49e87f63d3735b876d45c4c6b8939",
        "question": "What evaluation metrics are looked at for classification tasks?",
        "answer": "Precision, Recall, F-measure, accuracy",
        "answer_2": "Precision, Recall and F-measure",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            4,
            11,
            2,
            12,
            13,
            6,
            1,
            8,
            0
        ],
        "image-top-10-question_score": [
            14.225810050964355,
            13.63485336303711,
            13.002819061279297,
            12.917318344116211,
            12.157082557678223,
            12.149391174316406,
            12.114930152893066,
            12.001472473144531,
            11.650691986083984,
            11.522080421447754
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1712.00991.pdf",
        "text-top-10-question": [
            2,
            1,
            6,
            2,
            13,
            2,
            11,
            9,
            4,
            4
        ],
        "text-top-10-question_score": [
            14.3359375,
            13.1875,
            12.2109375,
            12.0078125,
            11.96875,
            11.8515625,
            11.8046875,
            11.765625,
            11.6484375,
            11.5703125
        ]
    },
    {
        "doc_id": "1712.00991.pdf",
        "q_uid": "197b276d0610ebfacd57ab46b0b29f3033c96a40",
        "question": "What methods were used for sentence classification?",
        "answer": "Logistic Regression, Multinomial Naive Bayes, Random Forest, AdaBoost, Linear SVM, SVM with ADWSK and Pattern-based",
        "answer_2": "Logistic Regression, Multinomial Naive Bayes, Random Forest, AdaBoost, Linear SVM, SVM with ADWSK, Pattern-based approach",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            4,
            1,
            12,
            6,
            5,
            11,
            3,
            9,
            8
        ],
        "image-top-10-question_score": [
            14.18365478515625,
            14.11340045928955,
            14.048551559448242,
            13.985133171081543,
            12.82691764831543,
            12.707908630371094,
            12.48154067993164,
            11.996034622192383,
            11.093716621398926,
            10.994626998901367
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1712.00991.pdf",
        "text-top-10-question": [
            2,
            12,
            1,
            2,
            12,
            11,
            12,
            4,
            12,
            3
        ],
        "text-top-10-question_score": [
            20.859375,
            20.78125,
            19.953125,
            19.328125,
            18.671875,
            18.328125,
            18.203125,
            16.953125,
            16.578125,
            16.3125
        ]
    },
    {
        "doc_id": "2003.04642.pdf",
        "q_uid": "9ecde59ffab3c57ec54591c3c7826a9188b2b270",
        "question": "What modern MRC gold standards are analyzed?",
        "answer": "fit our problem definition and were published in the years 2016 to 2019, have at least $(2019 - publication\\ year) \\times 20$ citations",
        "answer_2": "MSMARCO,  HOTPOTQA, RECORD,  MULTIRC, NEWSQA, and DROP.",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            3,
            0,
            7,
            18,
            4,
            16,
            17,
            5,
            6
        ],
        "image-top-10-question_score": [
            13.808794975280762,
            13.647052764892578,
            13.034643173217773,
            12.050302505493164,
            12.003446578979492,
            11.368749618530273,
            10.95273208618164,
            10.844400405883789,
            10.813350677490234,
            10.518363952636719
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.04642.pdf",
        "text-top-10-question": [
            7,
            0,
            1,
            0,
            3,
            1,
            7,
            18,
            7,
            1
        ],
        "text-top-10-question_score": [
            20.71875,
            20.015625,
            19.921875,
            19.890625,
            19.640625,
            19.15625,
            19.140625,
            19.046875,
            18.296875,
            17.515625
        ]
    },
    {
        "doc_id": "1904.07904.pdf",
        "q_uid": "38f58f13c7f23442d5952c8caf126073a477bac0",
        "question": "What was the score of the proposed model?",
        "answer": "Best results authors obtain is EM 51.10 and F1 63.11",
        "answer_2": "EM Score of 51.10",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            1,
            0,
            4,
            5
        ],
        "image-top-10-question_score": [
            13.30470085144043,
            12.3991060256958,
            12.33083724975586,
            12.086297035217285,
            10.723862648010254,
            10.167142868041992
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1904.07904.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            3,
            0,
            0,
            2,
            1,
            2,
            1
        ],
        "text-top-10-question_score": [
            23.5625,
            23.0,
            22.84375,
            21.953125,
            20.953125,
            19.28125,
            17.078125,
            16.90625,
            15.6015625,
            15.34375
        ]
    },
    {
        "doc_id": "2003.11645.pdf",
        "q_uid": "27275fe9f6a9004639f9ac33c3a5767fea388a98",
        "question": "What hyperparameters are explored?",
        "answer": "Dimension size, window size, architecture, algorithm, epochs, hidden dimension size, learning rate, loss function, optimizer algorithm.",
        "answer_2": "Hyperparameters explored were: dimension size, window size, architecture, algorithm and epochs.",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            0,
            5,
            3,
            4,
            6,
            7
        ],
        "image-top-10-question_score": [
            12.560375213623047,
            12.182531356811523,
            12.145401000976562,
            11.842562675476074,
            9.838663101196289,
            9.598752975463867,
            9.46342945098877,
            9.252023696899414
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.11645.pdf",
        "text-top-10-question": [
            2,
            2,
            5,
            0,
            2,
            0,
            0,
            0,
            1,
            1
        ],
        "text-top-10-question_score": [
            18.03125,
            17.15625,
            15.4140625,
            13.84375,
            12.6953125,
            12.203125,
            11.71875,
            11.5234375,
            10.984375,
            10.421875
        ]
    },
    {
        "doc_id": "2003.11645.pdf",
        "q_uid": "c2d1387e08cf25cb6b1f482178cca58030e85b70",
        "question": "Do they test both skipgram and c-bow?",
        "answer": "Yes",
        "answer_2": "Yes",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            2,
            3,
            5,
            4,
            6,
            7
        ],
        "image-top-10-question_score": [
            14.58266830444336,
            13.549695014953613,
            13.503026008605957,
            13.371211051940918,
            12.811548233032227,
            12.794902801513672,
            12.772481918334961,
            11.863542556762695
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.11645.pdf",
        "text-top-10-question": [
            3,
            3,
            0,
            0,
            1,
            0,
            3,
            0,
            2,
            4
        ],
        "text-top-10-question_score": [
            15.1796875,
            14.5234375,
            14.5,
            14.0078125,
            13.2578125,
            13.1640625,
            13.09375,
            12.03125,
            11.9609375,
            10.4921875
        ]
    },
    {
        "doc_id": "1608.06757.pdf",
        "q_uid": "c2b8ee872b99f698b3d2082d57f9408a91e1b4c1",
        "question": "what is the state of the art?",
        "answer": "Babelfy, DBpedia Spotlight, Entityclassifier.eu, FOX, LingPipe MUC-7, NERD-ML, Stanford NER, TagMe 2",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            8,
            9,
            2,
            6,
            7,
            5,
            0,
            3
        ],
        "image-top-10-question_score": [
            13.312345504760742,
            12.981990814208984,
            12.445456504821777,
            12.178764343261719,
            12.131072044372559,
            11.832448959350586,
            11.724273681640625,
            11.547954559326172,
            11.451674461364746,
            11.260103225708008
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1608.06757.pdf",
        "text-top-10-question": [
            1,
            5,
            4,
            4,
            1,
            5,
            1,
            4,
            4,
            3
        ],
        "text-top-10-question_score": [
            20.640625,
            15.390625,
            14.2109375,
            14.203125,
            13.5234375,
            13.453125,
            12.5703125,
            11.7578125,
            11.5390625,
            9.7734375
        ]
    },
    {
        "doc_id": "1806.04330.pdf",
        "q_uid": "8bf7f1f93d0a2816234d36395ab40c481be9a0e0",
        "question": "Do the authors also analyze transformer-based architectures?",
        "answer": "No",
        "answer_2": "No",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            3,
            2,
            12,
            10,
            6,
            9,
            11,
            4
        ],
        "image-top-10-question_score": [
            14.413077354431152,
            14.214293479919434,
            14.151445388793945,
            14.053544044494629,
            13.894914627075195,
            13.842618942260742,
            13.734216690063477,
            13.589737892150879,
            13.540253639221191,
            13.457293510437012
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1806.04330.pdf",
        "text-top-10-question": [
            1,
            0,
            0,
            2,
            8,
            3,
            9,
            9,
            4,
            12
        ],
        "text-top-10-question_score": [
            12.1640625,
            11.15625,
            11.1171875,
            10.8125,
            10.5078125,
            9.984375,
            9.8515625,
            9.8125,
            9.71875,
            9.5703125
        ]
    },
    {
        "doc_id": "1904.03288.pdf",
        "q_uid": "2ddb51b03163d309434ee403fef42d6b9aecc458",
        "question": "what were the baselines?",
        "answer": "LF-MMI Attention\nSeq2Seq \nRNN-T \nChar E2E LF-MMI \nPhone E2E LF-MMI \nCTC + Gram-CTC",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            2,
            0,
            1
        ],
        "image-top-10-question_score": [
            9.842575073242188,
            9.629645347595215,
            9.376362800598145,
            9.325814247131348,
            9.00590705871582
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1904.03288.pdf",
        "text-top-10-question": [
            3,
            0,
            1,
            3,
            1,
            1,
            0,
            2,
            1,
            0
        ],
        "text-top-10-question_score": [
            12.4921875,
            6.96484375,
            6.515625,
            6.26953125,
            6.19921875,
            6.13671875,
            5.85546875,
            5.76171875,
            5.75,
            5.69921875
        ]
    },
    {
        "doc_id": "1904.03288.pdf",
        "q_uid": "e587559f5ab6e42f7d981372ee34aebdc92b646e",
        "question": "what competitive results did they obtain?",
        "answer": "In case of read speech datasets,  their best model got the highest nov93 score of 16.1 and the highest nov92 score of 13.3.\nIn case of Conversational Speech, their best model got the highest SWB of 8.3 and the highest CHM of 19.3. ",
        "answer_2": "On WSJ datasets author's best approach achieves 9.3 and 6.9 WER compared to best results of 7.5 and 4.1 on nov93 and nov92 subsets.\nOn Hub5'00 datasets author's best approach achieves WER of 7.8 and 16.2 compared to best result of 7.3 and 14.2 on Switchboard (SWB) and Callhome (CHM) subsets.",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            1,
            2,
            4
        ],
        "image-top-10-question_score": [
            10.1019287109375,
            9.463520050048828,
            8.436829566955566,
            8.207962036132812,
            7.962806224822998
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1904.03288.pdf",
        "text-top-10-question": [
            0,
            3,
            0,
            3,
            2,
            3,
            3,
            3,
            3,
            1
        ],
        "text-top-10-question_score": [
            15.90625,
            12.6875,
            12.6484375,
            12.5390625,
            11.6484375,
            10.2890625,
            10.125,
            9.6953125,
            9.21875,
            8.78125
        ]
    },
    {
        "doc_id": "1909.13714.pdf",
        "q_uid": "f68508adef6f4bcdc0cc0a3ce9afc9a2b6333cc5",
        "question": "By how much is performance improved with multimodality?",
        "answer": "by 2.3-6.8 points in f1 score for intent recognition and 0.8-3.5 for slot filling",
        "answer_2": "F1 score increased from 0.89 to 0.92",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            2
        ],
        "image-top-10-question_score": [
            14.079451560974121,
            13.824573516845703,
            12.215873718261719
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.13714.pdf",
        "text-top-10-question": [
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            0,
            1
        ],
        "text-top-10-question_score": [
            20.046875,
            19.125,
            16.03125,
            15.0703125,
            14.5234375,
            14.25,
            13.5546875,
            13.09375,
            13.078125,
            12.5078125
        ]
    },
    {
        "doc_id": "1909.03405.pdf",
        "q_uid": "bdc91d1283a82226aeeb7a2f79dbbc57d3e84a1a",
        "question": "How much is performance improved on NLI?",
        "answer": " improvement on the RTE dataset is significant, i.e., 4% absolute gain over the BERTBase",
        "answer_2": "The average score improved by 1.4 points over the previous best result.",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            1,
            5,
            0,
            6,
            7,
            4,
            2
        ],
        "image-top-10-question_score": [
            13.260736465454102,
            12.605544090270996,
            12.595858573913574,
            12.471351623535156,
            12.008330345153809,
            11.635997772216797,
            11.486324310302734,
            10.51628303527832
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.03405.pdf",
        "text-top-10-question": [
            3,
            5,
            3,
            1,
            0,
            0,
            3,
            3,
            1,
            0
        ],
        "text-top-10-question_score": [
            21.625,
            21.125,
            20.875,
            20.40625,
            20.359375,
            19.09375,
            18.21875,
            18.046875,
            18.015625,
            17.84375
        ]
    },
    {
        "doc_id": "1907.03060.pdf",
        "q_uid": "761de1610e934189850e8fda707dc5239dd58092",
        "question": "what was the baseline?",
        "answer": "pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17",
        "answer_2": "M2M Transformer",
        "answer_3": " ",
        "image-top-10-question": [
            9,
            4,
            5,
            8,
            11,
            1,
            3,
            0,
            6,
            10
        ],
        "image-top-10-question_score": [
            10.578044891357422,
            9.770378112792969,
            9.657281875610352,
            9.47338581085205,
            8.87787914276123,
            8.67829704284668,
            8.655445098876953,
            8.508194923400879,
            8.408686637878418,
            8.393982887268066
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1907.03060.pdf",
        "text-top-10-question": [
            8,
            8,
            8,
            4,
            4,
            5,
            8,
            9,
            0,
            4
        ],
        "text-top-10-question_score": [
            13.0078125,
            12.7734375,
            12.203125,
            12.0,
            11.09375,
            10.890625,
            10.8125,
            9.9765625,
            7.796875,
            5.7890625
        ]
    },
    {
        "doc_id": "1911.10049.pdf",
        "q_uid": "603fee7314fa65261812157ddfc2c544277fcf90",
        "question": "How larger are the training sets of these versions of ELMo compared to the previous ones?",
        "answer": "By 14 times.",
        "answer_2": "up to 1.95 times larger",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            1,
            0,
            5,
            2,
            4,
            6,
            7
        ],
        "image-top-10-question_score": [
            21.719623565673828,
            21.61734390258789,
            21.503957748413086,
            21.422761917114258,
            21.04375457763672,
            20.852842330932617,
            18.51691436767578,
            15.676996231079102
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.10049.pdf",
        "text-top-10-question": [
            3,
            5,
            5,
            1,
            3,
            5,
            1,
            1,
            4,
            5
        ],
        "text-top-10-question_score": [
            20.328125,
            19.75,
            19.015625,
            19.0,
            18.40625,
            18.375,
            18.15625,
            17.96875,
            17.96875,
            17.875
        ]
    },
    {
        "doc_id": "1911.10049.pdf",
        "q_uid": "09a1173e971e0fcdbf2fbecb1b077158ab08f497",
        "question": "What is the improvement in performance for Estonian in the NER task?",
        "answer": "5 percent points.",
        "answer_2": "0.05 F1",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            3,
            0,
            6,
            1,
            2,
            7
        ],
        "image-top-10-question_score": [
            16.614303588867188,
            15.023908615112305,
            14.684245109558105,
            14.47507095336914,
            14.352389335632324,
            14.20059585571289,
            13.928842544555664,
            11.470817565917969
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.10049.pdf",
        "text-top-10-question": [
            5,
            5,
            4,
            0,
            5,
            5,
            5,
            3,
            4,
            4
        ],
        "text-top-10-question_score": [
            19.984375,
            19.21875,
            18.96875,
            18.0,
            17.203125,
            16.234375,
            16.21875,
            15.2109375,
            15.0546875,
            14.90625
        ]
    },
    {
        "doc_id": "1812.06864.pdf",
        "q_uid": "70e9210fe64f8d71334e5107732d764332a81cb1",
        "question": "what is the state of the art on WSJ?",
        "answer": "CNN-DNN-BLSTM-HMM",
        "answer_2": "HMM-based system",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            2,
            1,
            4,
            3
        ],
        "image-top-10-question_score": [
            16.1093807220459,
            15.625739097595215,
            14.337039947509766,
            14.264776229858398,
            13.592826843261719
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1812.06864.pdf",
        "text-top-10-question": [
            0,
            0,
            2,
            2,
            2,
            1,
            2,
            0,
            3,
            1
        ],
        "text-top-10-question_score": [
            20.71875,
            16.828125,
            16.828125,
            15.5,
            14.4609375,
            14.3359375,
            13.296875,
            13.2265625,
            13.140625,
            12.9765625
        ]
    },
    {
        "doc_id": "1811.12254.pdf",
        "q_uid": "57f23dfc264feb62f45d9a9e24c60bd73d7fe563",
        "question": "what is the size of the augmented dataset?",
        "answer": "609",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            3,
            7,
            0,
            2,
            6,
            5,
            4
        ],
        "image-top-10-question_score": [
            14.385171890258789,
            13.890416145324707,
            13.32594108581543,
            13.084518432617188,
            12.860702514648438,
            12.330562591552734,
            12.225147247314453,
            12.02260684967041
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1811.12254.pdf",
        "text-top-10-question": [
            2,
            2,
            6,
            2,
            3,
            6,
            1,
            2,
            3,
            2
        ],
        "text-top-10-question_score": [
            15.0703125,
            15.046875,
            14.6796875,
            14.2265625,
            13.9375,
            12.921875,
            12.296875,
            12.109375,
            11.515625,
            11.0703125
        ]
    },
    {
        "doc_id": "1908.05828.pdf",
        "q_uid": "d51dc36fbf6518226b8e45d4c817e07e8f642003",
        "question": "How many sentences does the dataset contain?",
        "answer": "3606",
        "answer_2": "6946",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            0,
            7,
            1,
            6,
            5,
            8,
            2,
            9
        ],
        "image-top-10-question_score": [
            14.551396369934082,
            14.48349380493164,
            13.656776428222656,
            13.036516189575195,
            12.727947235107422,
            12.41954231262207,
            12.232793807983398,
            11.779285430908203,
            11.628752708435059,
            11.41777229309082
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.05828.pdf",
        "text-top-10-question": [
            3,
            3,
            4,
            4,
            2,
            3,
            0,
            5,
            3,
            3
        ],
        "text-top-10-question_score": [
            21.8125,
            18.484375,
            17.9375,
            16.171875,
            16.078125,
            16.015625,
            14.5546875,
            13.734375,
            13.40625,
            13.265625
        ]
    },
    {
        "doc_id": "1908.05828.pdf",
        "q_uid": "cb77d6a74065cb05318faf57e7ceca05e126a80d",
        "question": "What is the baseline?",
        "answer": "CNN modelBIBREF0, Stanford CRF modelBIBREF21",
        "answer_2": "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            9,
            3,
            7,
            0,
            6,
            4,
            2,
            8,
            1
        ],
        "image-top-10-question_score": [
            9.073845863342285,
            9.001420974731445,
            8.872133255004883,
            8.863329887390137,
            8.67174243927002,
            8.67116928100586,
            8.499101638793945,
            8.336027145385742,
            8.312938690185547,
            8.295082092285156
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.05828.pdf",
        "text-top-10-question": [
            5,
            5,
            8,
            0,
            0,
            2,
            2,
            3,
            7,
            0
        ],
        "text-top-10-question_score": [
            8.2265625,
            7.97265625,
            5.91015625,
            5.18359375,
            4.58203125,
            4.1796875,
            3.921875,
            3.921875,
            3.751953125,
            3.54296875
        ]
    },
    {
        "doc_id": "1908.05828.pdf",
        "q_uid": "a1b3e2107302c5a993baafbe177684ae88d6f505",
        "question": "What is the size of the dataset?",
        "answer": "Dataset contains 3606 total sentences and 79087 total entities.",
        "answer_2": "ILPRL contains 548 sentences, OurNepali contains 3606 sentences",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            0,
            7,
            1,
            8,
            5,
            9,
            6,
            2
        ],
        "image-top-10-question_score": [
            14.86099624633789,
            14.66071605682373,
            14.570701599121094,
            14.152734756469727,
            13.442058563232422,
            13.171424865722656,
            13.137678146362305,
            13.085441589355469,
            13.080642700195312,
            12.950794219970703
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.05828.pdf",
        "text-top-10-question": [
            4,
            5,
            5,
            3,
            3,
            0,
            3,
            6,
            3,
            4
        ],
        "text-top-10-question_score": [
            19.6875,
            18.515625,
            17.59375,
            16.515625,
            16.265625,
            16.140625,
            15.28125,
            14.8203125,
            14.5703125,
            14.40625
        ]
    },
    {
        "doc_id": "1908.05828.pdf",
        "q_uid": "1462eb312944926469e7cee067dfc7f1267a2a8c",
        "question": "How many different types of entities exist in the dataset?",
        "answer": "OurNepali contains 3 different types of entities, ILPRL contains 4 different types of entities",
        "answer_2": "three",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            7,
            1,
            0,
            3,
            6,
            9,
            8,
            2,
            5
        ],
        "image-top-10-question_score": [
            16.227752685546875,
            16.04023551940918,
            15.129178047180176,
            15.109214782714844,
            14.809118270874023,
            14.631322860717773,
            14.091245651245117,
            14.025773048400879,
            13.955520629882812,
            13.694564819335938
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.05828.pdf",
        "text-top-10-question": [
            4,
            3,
            1,
            0,
            7,
            6,
            7,
            3,
            3,
            6
        ],
        "text-top-10-question_score": [
            17.125,
            15.7890625,
            14.984375,
            14.4921875,
            14.375,
            14.3359375,
            14.3125,
            13.578125,
            13.578125,
            13.140625
        ]
    },
    {
        "doc_id": "1908.05828.pdf",
        "q_uid": "f59f1f5b528a2eec5cfb1e49c87699e0c536cc45",
        "question": "How big is the new Nepali NER dataset?",
        "answer": "3606 sentences",
        "answer_2": "Dataset contains 3606 total sentences and 79087 total entities.",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            0,
            6,
            1,
            7,
            4,
            5,
            8,
            2,
            9
        ],
        "image-top-10-question_score": [
            14.767420768737793,
            14.624638557434082,
            14.611075401306152,
            14.042608261108398,
            13.796566009521484,
            13.425247192382812,
            13.100610733032227,
            13.085838317871094,
            12.950884819030762,
            12.34033203125
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.05828.pdf",
        "text-top-10-question": [
            6,
            0,
            3,
            7,
            1,
            3,
            3,
            0,
            0,
            3
        ],
        "text-top-10-question_score": [
            20.765625,
            20.203125,
            19.515625,
            19.40625,
            18.734375,
            18.4375,
            17.21875,
            17.0,
            16.6875,
            16.46875
        ]
    },
    {
        "doc_id": "1908.05828.pdf",
        "q_uid": "9bd080bb2a089410fd7ace82e91711136116af6c",
        "question": "What is the performance improvement of the grapheme-level representation model over the character-level model?",
        "answer": "On OurNepali test dataset Grapheme-level representation model achieves average 0.16% improvement, on ILPRL test dataset it achieves maximum 1.62% improvement",
        "answer_2": "BiLSTM+CNN(grapheme-level) which turns out to be performing on par with BiLSTM+CNN(character-level) under the same configuration",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            1,
            3,
            2,
            0,
            8,
            5,
            7,
            4,
            9
        ],
        "image-top-10-question_score": [
            24.118553161621094,
            23.29666519165039,
            22.64893913269043,
            22.21614646911621,
            22.163150787353516,
            21.455080032348633,
            20.88494300842285,
            20.813316345214844,
            20.69751739501953,
            18.73085594177246
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.05828.pdf",
        "text-top-10-question": [
            6,
            6,
            3,
            2,
            1,
            6,
            3,
            1,
            0,
            7
        ],
        "text-top-10-question_score": [
            19.4375,
            19.3125,
            18.671875,
            17.796875,
            17.65625,
            16.25,
            16.203125,
            15.890625,
            15.0078125,
            14.703125
        ]
    },
    {
        "doc_id": "2002.02070.pdf",
        "q_uid": "d53299fac8c94bd0179968eb868506124af407d1",
        "question": "What is the performance of classifiers?",
        "answer": "Table TABREF10,  The KNN classifier seem to perform the best across all four metrics. This is probably due to the multi-class nature of the data set,  While these classifiers did not perform particularly well, they provide a good starting point for future work on this subject",
        "answer_2": "Using F1 Micro measure, the KNN classifier perform 0.6762, the RF 0.6687, SVM 0.6712 and MLP 0.6778.",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            0
        ],
        "image-top-10-question_score": [
            13.13532543182373,
            11.954215049743652,
            9.870716094970703
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.02070.pdf",
        "text-top-10-question": [
            2,
            2,
            2,
            1,
            2,
            0,
            1,
            0,
            0,
            1
        ],
        "text-top-10-question_score": [
            18.65625,
            17.90625,
            17.25,
            14.5859375,
            14.3515625,
            11.1953125,
            8.078125,
            7.546875,
            7.43359375,
            6.99609375
        ]
    },
    {
        "doc_id": "2002.02070.pdf",
        "q_uid": "29f2954098f055fb19d9502572f085862d75bf61",
        "question": "What classifiers have been trained?",
        "answer": "KNN\nRF\nSVM\nMLP",
        "answer_2": " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            0
        ],
        "image-top-10-question_score": [
            12.785385131835938,
            11.798951148986816,
            9.526759147644043
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.02070.pdf",
        "text-top-10-question": [
            2,
            2,
            2,
            1,
            2,
            0,
            1,
            0,
            2,
            2
        ],
        "text-top-10-question_score": [
            19.625,
            18.9375,
            17.46875,
            16.640625,
            16.09375,
            11.125,
            10.765625,
            10.578125,
            10.265625,
            8.6171875
        ]
    },
    {
        "doc_id": "1908.10084.pdf",
        "q_uid": "e2db361ae9ad9dbaa9a85736c5593eb3a471983d",
        "question": "What other sentence embeddings methods are evaluated?",
        "answer": "GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent",
        "answer_2": "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder.",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            3,
            1,
            7,
            6,
            0,
            2,
            4,
            9,
            8
        ],
        "image-top-10-question_score": [
            14.859077453613281,
            14.801068305969238,
            14.794572830200195,
            14.678272247314453,
            14.483820915222168,
            14.259130477905273,
            14.25273323059082,
            13.7607421875,
            13.043659210205078,
            12.52307415008545
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.10084.pdf",
        "text-top-10-question": [
            1,
            1,
            6,
            1,
            5,
            4,
            1,
            5,
            3,
            6
        ],
        "text-top-10-question_score": [
            23.890625,
            23.6875,
            23.375,
            23.28125,
            21.875,
            21.78125,
            21.65625,
            21.421875,
            21.390625,
            21.296875
        ]
    },
    {
        "doc_id": "1806.04511.pdf",
        "q_uid": "e79a5b6b6680bd2f63e9f4adbaae1d7795d81e38",
        "question": "which non-english language had the best performance?",
        "answer": "Russian",
        "answer_2": "Russsian",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            1,
            0,
            4,
            2
        ],
        "image-top-10-question_score": [
            14.828275680541992,
            13.974445343017578,
            13.910680770874023,
            13.326791763305664,
            13.222827911376953
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1806.04511.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            0,
            3,
            0,
            0,
            1,
            1,
            3
        ],
        "text-top-10-question_score": [
            18.28125,
            17.5625,
            14.8125,
            13.3359375,
            12.8828125,
            12.1484375,
            10.6875,
            10.375,
            10.3203125,
            10.2734375
        ]
    },
    {
        "doc_id": "1910.06592.pdf",
        "q_uid": "3e1829e96c968cbd8ad8e9ce850e3a92a76b26e4",
        "question": "How big is the dataset used in this work?",
        "answer": "Total dataset size: 171 account (522967 tweets)",
        "answer_2": "212 accounts",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            5,
            0,
            4,
            1,
            6,
            7,
            2
        ],
        "image-top-10-question_score": [
            15.166478157043457,
            14.70120620727539,
            14.635056495666504,
            14.591289520263672,
            14.560954093933105,
            14.360383987426758,
            14.243959426879883,
            14.222281455993652
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.06592.pdf",
        "text-top-10-question": [
            4,
            4,
            3,
            0,
            3,
            7,
            3,
            2,
            5,
            4
        ],
        "text-top-10-question_score": [
            15.0078125,
            14.8125,
            13.328125,
            11.6015625,
            11.4609375,
            10.0625,
            8.59375,
            8.25,
            8.21875,
            8.1875
        ]
    },
    {
        "doc_id": "1902.09666.pdf",
        "q_uid": "74fb77a624ea9f1821f58935a52cca3086bb0981",
        "question": "What is the size of the new dataset?",
        "answer": "14,100 tweets",
        "answer_2": "Dataset contains total of 14100 annotations.",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            4,
            1,
            0,
            5
        ],
        "image-top-10-question_score": [
            14.127359390258789,
            13.671126365661621,
            13.586248397827148,
            13.577939987182617,
            13.534610748291016,
            12.9826078414917
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1902.09666.pdf",
        "text-top-10-question": [
            1,
            3,
            3,
            4,
            2,
            0,
            2,
            2,
            2,
            4
        ],
        "text-top-10-question_score": [
            15.7421875,
            15.0390625,
            13.875,
            13.4140625,
            13.2890625,
            12.9609375,
            12.0390625,
            11.578125,
            11.578125,
            11.546875
        ]
    },
    {
        "doc_id": "1902.09666.pdf",
        "q_uid": "1b72aa2ec3ce02131e60626639f0cf2056ec23ca",
        "question": "How long is the dataset for each step of hierarchy?",
        "answer": "Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            0,
            2,
            3,
            5
        ],
        "image-top-10-question_score": [
            14.415040969848633,
            13.82286548614502,
            12.931297302246094,
            12.53740406036377,
            12.521272659301758,
            11.238714218139648
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1902.09666.pdf",
        "text-top-10-question": [
            4,
            1,
            0,
            1,
            2,
            4,
            3,
            3,
            0,
            2
        ],
        "text-top-10-question_score": [
            14.15625,
            14.015625,
            13.3359375,
            13.046875,
            11.8984375,
            10.90625,
            10.5390625,
            9.796875,
            9.7890625,
            9.140625
        ]
    },
    {
        "doc_id": "1604.00400.pdf",
        "q_uid": "bf52c01bf82612d0c7bbf2e6a5bb2570c322936f",
        "question": "What different correlations result when using different variants of ROUGE scores?",
        "answer": "we observe that many variants of Rouge scores do not have high correlations with human pyramid scores",
        "answer_2": "Using Pearson corelation measure,  for example, ROUGE-1-P is 0.257 and ROUGE-3-F 0.878.",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            5,
            4,
            6,
            0,
            3,
            7,
            2
        ],
        "image-top-10-question_score": [
            17.572673797607422,
            17.306411743164062,
            17.112443923950195,
            16.42131805419922,
            15.975685119628906,
            15.161388397216797,
            14.83067512512207,
            14.64614200592041
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1604.00400.pdf",
        "text-top-10-question": [
            5,
            5,
            6,
            5,
            5,
            5,
            0,
            1,
            6,
            6
        ],
        "text-top-10-question_score": [
            25.765625,
            25.578125,
            25.390625,
            25.234375,
            25.171875,
            24.640625,
            24.515625,
            24.28125,
            24.046875,
            23.859375
        ]
    },
    {
        "doc_id": "1810.12196.pdf",
        "q_uid": "52f8a3e3cd5d42126b5307adc740b71510a6bdf5",
        "question": "What tasks were evaluated?",
        "answer": "ReviewQA's test set",
        "answer_2": "Detection of an aspect in a review, Prediction of the customer general satisfaction, Prediction of the global trend of an aspect in a given review, Prediction of whether the rating of a given aspect is above or under a given value, Prediction of the exact rating of an aspect in a review, Prediction of the list of all the positive/negative aspects mentioned in the review, Comparison between aspects, Prediction of the strengths and weaknesses in a review",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            7,
            6,
            1,
            2,
            5,
            0,
            9,
            8
        ],
        "image-top-10-question_score": [
            11.97671890258789,
            10.897972106933594,
            10.55109977722168,
            10.515222549438477,
            10.502229690551758,
            10.253060340881348,
            9.972537994384766,
            9.427621841430664,
            9.018030166625977,
            8.770045280456543
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.12196.pdf",
        "text-top-10-question": [
            4,
            4,
            7,
            0,
            1,
            7,
            3,
            2,
            4,
            1
        ],
        "text-top-10-question_score": [
            21.4375,
            20.0625,
            20.03125,
            19.484375,
            19.203125,
            19.1875,
            18.390625,
            17.75,
            17.03125,
            16.5625
        ]
    },
    {
        "doc_id": "1707.05236.pdf",
        "q_uid": "ab9b0bde6113ffef8eb1c39919d21e5913a05081",
        "question": "What are their results on both datasets?",
        "answer": "Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            4,
            0,
            1,
            5
        ],
        "image-top-10-question_score": [
            13.625478744506836,
            13.328460693359375,
            13.196304321289062,
            12.59726333618164,
            12.288864135742188,
            12.085744857788086
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1707.05236.pdf",
        "text-top-10-question": [
            2,
            2,
            3,
            2,
            3,
            0,
            0,
            0,
            2,
            4
        ],
        "text-top-10-question_score": [
            16.96875,
            15.953125,
            15.578125,
            15.1875,
            14.6640625,
            14.65625,
            14.0078125,
            13.046875,
            12.9375,
            12.484375
        ]
    },
    {
        "doc_id": "1908.11047.pdf",
        "q_uid": "f2155dc4aeab86bf31a838c8ff388c85440fce6e",
        "question": "Does this method help in sentiment classification task improvement?",
        "answer": "Yes",
        "answer_2": "No",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            5,
            7,
            1,
            6,
            0,
            2
        ],
        "image-top-10-question_score": [
            15.106342315673828,
            14.894655227661133,
            14.267350196838379,
            14.052413940429688,
            13.795763969421387,
            13.682103157043457,
            13.390824317932129,
            13.337262153625488
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.11047.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            4,
            7,
            4,
            2,
            4,
            0,
            2
        ],
        "text-top-10-question_score": [
            19.375,
            18.375,
            15.6796875,
            15.40625,
            14.8359375,
            13.9921875,
            12.78125,
            12.703125,
            12.6953125,
            12.3828125
        ]
    },
    {
        "doc_id": "1908.11047.pdf",
        "q_uid": "ed6a15f0f7fa4594e51d5bde21cc0c6c1bedbfdc",
        "question": "For how many probe tasks the shallow-syntax-aware contextual embedding perform better than ELMo\u2019s embedding?",
        "answer": "performance of baseline ELMo-transformer and mSynC are similar, with mSynC doing slightly worse on 7 out of 9 tasks",
        "answer_2": "3",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            6,
            0,
            1,
            4,
            5,
            7
        ],
        "image-top-10-question_score": [
            23.96639633178711,
            23.843372344970703,
            23.58871078491211,
            23.236087799072266,
            22.932849884033203,
            22.561237335205078,
            21.384483337402344,
            20.35538101196289
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.11047.pdf",
        "text-top-10-question": [
            1,
            0,
            2,
            0,
            6,
            4,
            0,
            3,
            2,
            1
        ],
        "text-top-10-question_score": [
            22.984375,
            22.046875,
            19.265625,
            18.875,
            18.21875,
            18.109375,
            17.578125,
            17.390625,
            17.28125,
            16.984375
        ]
    },
    {
        "doc_id": "1908.11047.pdf",
        "q_uid": "4d706ce5bde82caf40241f5b78338ea5ee5eb01e",
        "question": "What are the black-box probes used?",
        "answer": "CCG Supertagging CCGBank , PTB part-of-speech tagging, EWT part-of-speech tagging,\nChunking, Named Entity Recognition, Semantic Tagging, Grammar Error Detection, Preposition Supersense Role, Preposition Supersense Function, Event Factuality Detection",
        "answer_2": "Probes are linear models trained on frozen cwrs to make predictions about linguistic (syntactic and semantic) properties of words and phrases.",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            6,
            2,
            0,
            7,
            5,
            1
        ],
        "image-top-10-question_score": [
            10.971580505371094,
            10.959576606750488,
            10.412418365478516,
            10.255285263061523,
            9.553894996643066,
            9.535158157348633,
            9.314403533935547,
            9.211748123168945
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.11047.pdf",
        "text-top-10-question": [
            1,
            0,
            3,
            3,
            4,
            4,
            2,
            4,
            6,
            3
        ],
        "text-top-10-question_score": [
            18.828125,
            18.8125,
            14.90625,
            12.0234375,
            10.65625,
            9.421875,
            9.234375,
            9.2265625,
            9.0,
            8.203125
        ]
    },
    {
        "doc_id": "1908.11047.pdf",
        "q_uid": "86bf75245358f17e35fc133e46a92439ac86d472",
        "question": "What are improvements for these two approaches relative to ELMo-only baselines?",
        "answer": "only modest gains on three of the four downstream tasks",
        "answer_2": " the performance differences across all tasks are small enough ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            4,
            3,
            1,
            2,
            6,
            5,
            7
        ],
        "image-top-10-question_score": [
            18.681299209594727,
            18.677785873413086,
            18.51245880126953,
            18.19945526123047,
            18.044471740722656,
            17.82358169555664,
            16.094629287719727,
            15.39659595489502
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.11047.pdf",
        "text-top-10-question": [
            0,
            1,
            4,
            3,
            3,
            2,
            3,
            0,
            4,
            4
        ],
        "text-top-10-question_score": [
            20.03125,
            19.640625,
            18.203125,
            17.96875,
            17.546875,
            17.4375,
            17.265625,
            17.171875,
            16.5625,
            16.453125
        ]
    },
    {
        "doc_id": "1612.08205.pdf",
        "q_uid": "cd2878c5a52542ddf080b20bec005d9a74f2d916",
        "question": "What are the industry classes defined in this paper?",
        "answer": "technology, religion, fashion, publishing, sports or recreation, real estate, agriculture/environment, law, security/military, tourism, construction, museums or libraries, banking/investment banking, automotive",
        "answer_2": "Technology, Religion, Fashion, Publishing, Sports coach, Real Estate, Law, Environment, Tourism, Construction, Museums, Banking, Security, Automotive.",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            5,
            4,
            2,
            7,
            6,
            3
        ],
        "image-top-10-question_score": [
            15.404035568237305,
            15.293123245239258,
            14.972282409667969,
            13.975675582885742,
            13.857745170593262,
            13.391353607177734,
            13.374595642089844,
            13.15892219543457
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1612.08205.pdf",
        "text-top-10-question": [
            0,
            0,
            2,
            2,
            2,
            0,
            4,
            6,
            6,
            1
        ],
        "text-top-10-question_score": [
            18.3125,
            17.65625,
            16.921875,
            16.640625,
            16.578125,
            16.390625,
            16.046875,
            16.0,
            15.796875,
            15.78125
        ]
    },
    {
        "doc_id": "1907.09369.pdf",
        "q_uid": "fd2c6c26fd0ab3c10aae4f2550c5391576a77491",
        "question": "Do they report results only on English data?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            3,
            4,
            2,
            5,
            0
        ],
        "image-top-10-question_score": [
            13.237092018127441,
            12.858278274536133,
            12.573829650878906,
            12.554664611816406,
            12.428613662719727,
            12.39236068725586
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1907.09369.pdf",
        "text-top-10-question": [
            1,
            3,
            3,
            2,
            3,
            1,
            3,
            1,
            3,
            3
        ],
        "text-top-10-question_score": [
            14.46875,
            13.6328125,
            11.78125,
            11.453125,
            11.0234375,
            10.625,
            10.4375,
            10.2890625,
            9.65625,
            9.59375
        ]
    },
    {
        "doc_id": "1911.07555.pdf",
        "q_uid": "307e8ab37b67202fe22aedd9a98d9d06aaa169c5",
        "question": "Does the paper report the performance of a baseline model on South African languages LID?",
        "answer": "Yes",
        "answer_2": "Yes",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            2,
            1,
            3,
            4,
            5
        ],
        "image-top-10-question_score": [
            19.975217819213867,
            19.760784149169922,
            19.646583557128906,
            19.172122955322266,
            18.56294059753418,
            18.2705078125
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.07555.pdf",
        "text-top-10-question": [
            0,
            1,
            3,
            0,
            0,
            2,
            0,
            1,
            3,
            1
        ],
        "text-top-10-question_score": [
            19.015625,
            18.796875,
            18.46875,
            18.375,
            17.984375,
            17.46875,
            17.40625,
            16.3125,
            15.5703125,
            15.25
        ]
    },
    {
        "doc_id": "1911.07555.pdf",
        "q_uid": "e5c8e9e54e77960c8c26e8e238168a603fcdfcc6",
        "question": "Does the algorithm improve on the state-of-the-art methods?",
        "answer": "Yes",
        "answer_2": "From all reported results proposed method (NB+Lex) shows best accuracy on all 3 datasets - some models are not evaluated and not available in literature.",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            0,
            1,
            2,
            5,
            4
        ],
        "image-top-10-question_score": [
            19.897485733032227,
            19.503393173217773,
            19.061355590820312,
            18.641067504882812,
            17.405439376831055,
            16.936649322509766
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.07555.pdf",
        "text-top-10-question": [
            3,
            3,
            2,
            5,
            0,
            3,
            5,
            0,
            4,
            0
        ],
        "text-top-10-question_score": [
            16.34375,
            15.96875,
            14.171875,
            12.3125,
            11.984375,
            11.859375,
            11.328125,
            10.6640625,
            10.578125,
            10.546875
        ]
    },
    {
        "doc_id": "1804.11346.pdf",
        "q_uid": "2ceced87af4c8fdebf2dc959aa700a5c95bd518f",
        "question": "Is the dataset balanced between speakers of different L1s?",
        "answer": "No",
        "answer_2": "No",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            1,
            2,
            5,
            3
        ],
        "image-top-10-question_score": [
            16.586246490478516,
            16.215904235839844,
            15.980203628540039,
            14.914761543273926,
            14.597049713134766,
            14.042759895324707
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1804.11346.pdf",
        "text-top-10-question": [
            4,
            1,
            1,
            4,
            4,
            0,
            0,
            1,
            4,
            0
        ],
        "text-top-10-question_score": [
            21.734375,
            19.140625,
            18.21875,
            17.65625,
            17.265625,
            17.09375,
            16.546875,
            15.9296875,
            15.6171875,
            15.453125
        ]
    },
    {
        "doc_id": "1909.00175.pdf",
        "q_uid": "badc9db40adbbf2ea7bac29f2e4e3b6b9175b1f9",
        "question": "What state-of-the-art results are achieved?",
        "answer": "F1 score of 92.19 on homographic pun detection, 80.19 on homographic pun location, 89.76 on heterographic pun detection.",
        "answer_2": "for the homographic dataset F1 score of 92.19 and 80.19 on detection and location and for the heterographic dataset F1 score of 89.76 on detection",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            2,
            0,
            6,
            5,
            1
        ],
        "image-top-10-question_score": [
            16.69186782836914,
            15.820308685302734,
            15.811095237731934,
            15.757071495056152,
            15.358829498291016,
            15.107067108154297,
            15.035463333129883
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00175.pdf",
        "text-top-10-question": [
            0,
            3,
            1,
            1,
            2,
            4,
            3,
            2,
            2,
            3
        ],
        "text-top-10-question_score": [
            17.40625,
            15.6171875,
            13.921875,
            13.296875,
            12.5703125,
            12.4765625,
            11.6640625,
            11.4296875,
            10.984375,
            10.7109375
        ]
    },
    {
        "doc_id": "1909.00175.pdf",
        "q_uid": "67b66fe67a3cb2ce043070513664203e564bdcbd",
        "question": "What baselines do they compare with?",
        "answer": "They compare with the following models: by Pedersen (2017), by Pramanick and Das (2017), by Mikhalkova and Karyakin (2017),  by Vadehra (2017), Indurthi and Oota (2017), by Vechtomova (2017), by (Cai et al., 2018), and CRF.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            4,
            5,
            6,
            1,
            0
        ],
        "image-top-10-question_score": [
            13.314027786254883,
            12.372695922851562,
            11.662734985351562,
            11.354059219360352,
            11.257477760314941,
            10.762960433959961,
            10.628774642944336
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00175.pdf",
        "text-top-10-question": [
            3,
            2,
            3,
            2,
            0,
            3,
            2,
            2,
            3,
            0
        ],
        "text-top-10-question_score": [
            17.953125,
            13.03125,
            11.4453125,
            11.3046875,
            11.0625,
            10.296875,
            9.515625,
            8.875,
            8.2578125,
            7.703125
        ]
    },
    {
        "doc_id": "1910.06036.pdf",
        "q_uid": "92294820ac0d9421f086139e816354970f066d8a",
        "question": "How big are significant improvements?",
        "answer": "Metrics show better results on all metrics compared to baseline except Bleu1  on Zhou split (worse by 0.11 compared to baseline). Bleu1 score on DuSplit is 45.66 compared to best baseline 43.47, other metrics on average by 1",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            6,
            10,
            0,
            1,
            7,
            9,
            2,
            8,
            3
        ],
        "image-top-10-question_score": [
            11.078242301940918,
            9.069625854492188,
            8.763957977294922,
            8.718950271606445,
            8.676244735717773,
            8.442651748657227,
            8.315652847290039,
            8.26467514038086,
            8.154020309448242,
            7.803591728210449
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.06036.pdf",
        "text-top-10-question": [
            6,
            1,
            6,
            0,
            5,
            6,
            0,
            6,
            0,
            5
        ],
        "text-top-10-question_score": [
            14.71875,
            12.4140625,
            12.1640625,
            11.6796875,
            11.40625,
            11.0703125,
            10.4765625,
            10.2109375,
            10.0703125,
            9.9921875
        ]
    },
    {
        "doc_id": "2002.01984.pdf",
        "q_uid": "9ec1f88ceec84a10dc070ba70e90a792fba8ce71",
        "question": "What was their highest MRR score?",
        "answer": "0.5115",
        "answer_2": "0.6103",
        "answer_3": " ",
        "image-top-10-question": [
            21,
            1,
            2,
            14,
            10,
            8,
            11,
            5,
            16,
            12
        ],
        "image-top-10-question_score": [
            14.235137939453125,
            13.937017440795898,
            13.787361145019531,
            13.43953800201416,
            13.270160675048828,
            13.158987045288086,
            12.660406112670898,
            10.381816864013672,
            10.258895874023438,
            10.166187286376953
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.01984.pdf",
        "text-top-10-question": [
            14,
            2,
            0,
            0,
            1,
            10,
            21,
            11,
            1,
            10
        ],
        "text-top-10-question_score": [
            24.9375,
            23.46875,
            22.859375,
            22.421875,
            21.140625,
            20.921875,
            19.515625,
            15.5546875,
            14.2265625,
            14.0703125
        ]
    },
    {
        "doc_id": "1809.03449.pdf",
        "q_uid": "52f9cd05d8312ae3c7a43689804bac63f7cac34b",
        "question": "Do the authors hypothesize that humans' robustness to noise is due to their general knowledge?",
        "answer": "Yes",
        "answer_2": "Yes",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            7,
            6,
            8,
            4,
            1,
            2,
            9,
            3
        ],
        "image-top-10-question_score": [
            18.44832420349121,
            18.177860260009766,
            18.078027725219727,
            17.988101959228516,
            17.936691284179688,
            16.645706176757812,
            16.604061126708984,
            16.37381362915039,
            16.25690269470215,
            15.621763229370117
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.03449.pdf",
        "text-top-10-question": [
            0,
            0,
            1,
            0,
            8,
            0,
            6,
            7,
            5,
            5
        ],
        "text-top-10-question_score": [
            18.28125,
            16.859375,
            16.40625,
            16.0625,
            15.875,
            15.546875,
            14.671875,
            14.3515625,
            14.1953125,
            14.0078125
        ]
    },
    {
        "doc_id": "1903.09722.pdf",
        "q_uid": "ab0fd94dfc291cf3e54e9b7a7f78b852ddc1a797",
        "question": "What is the previous state-of-the-art in summarization?",
        "answer": "BIBREF26 ",
        "answer_2": "BIBREF26",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            2,
            3,
            5,
            0,
            7,
            6
        ],
        "image-top-10-question_score": [
            18.77475357055664,
            18.08066177368164,
            18.034320831298828,
            18.013591766357422,
            17.46450424194336,
            17.00149154663086,
            16.179550170898438,
            15.787884712219238
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1903.09722.pdf",
        "text-top-10-question": [
            3,
            0,
            0,
            3,
            3,
            4,
            1,
            4,
            4,
            1
        ],
        "text-top-10-question_score": [
            17.734375,
            16.828125,
            16.234375,
            15.9765625,
            11.453125,
            10.5859375,
            10.296875,
            9.4296875,
            9.4140625,
            9.109375
        ]
    },
    {
        "doc_id": "1806.11432.pdf",
        "q_uid": "701571680724c05ca70c11bc267fb1160ea1460a",
        "question": "Does the method achieve sota performance on this dataset?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            2,
            3,
            6,
            1,
            0
        ],
        "image-top-10-question_score": [
            13.141762733459473,
            13.09978199005127,
            12.85561466217041,
            12.562191009521484,
            11.948249816894531,
            11.756546020507812,
            11.497811317443848
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1806.11432.pdf",
        "text-top-10-question": [
            5,
            1,
            4,
            6,
            0,
            2,
            2,
            6,
            1,
            5
        ],
        "text-top-10-question_score": [
            10.3671875,
            10.234375,
            10.2265625,
            9.9609375,
            9.765625,
            9.5703125,
            9.5546875,
            9.171875,
            9.0390625,
            9.0390625
        ]
    },
    {
        "doc_id": "1806.11432.pdf",
        "q_uid": "600b097475b30480407ce1de81c28c54a0b3b2f8",
        "question": "What are the baselines used in the paper?",
        "answer": "GloVe vectors trained on Wikipedia Corpus with ensembling, and GloVe vectors trained on Airbnb Data without ensembling",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            6,
            5,
            2,
            3,
            4,
            1
        ],
        "image-top-10-question_score": [
            14.283045768737793,
            14.020624160766602,
            13.92058277130127,
            13.613641738891602,
            13.611673355102539,
            13.586882591247559,
            13.481269836425781
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1806.11432.pdf",
        "text-top-10-question": [
            6,
            0,
            3,
            0,
            4,
            6,
            1,
            5,
            1,
            5
        ],
        "text-top-10-question_score": [
            10.9921875,
            9.2890625,
            8.359375,
            8.0546875,
            8.0546875,
            7.71484375,
            7.62890625,
            7.1015625,
            7.08984375,
            6.8671875
        ]
    },
    {
        "doc_id": "1910.14537.pdf",
        "q_uid": "5fda8539a97828e188ba26aad5cda1b9dd642bc8",
        "question": "How better is performance compared to previous state-of-the-art models?",
        "answer": "F1 score of 97.5 on MSR and 95.7 on AS",
        "answer_2": "MSR: 97.7 compared to 97.5 of baseline\nAS: 95.7 compared to 95.6 of baseline",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            7,
            6,
            2,
            1,
            0,
            3,
            5,
            4,
            9
        ],
        "image-top-10-question_score": [
            20.498680114746094,
            20.07279396057129,
            19.958202362060547,
            19.94736099243164,
            19.302352905273438,
            18.915756225585938,
            18.88228988647461,
            18.458538055419922,
            18.042652130126953,
            16.79340362548828
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.14537.pdf",
        "text-top-10-question": [
            8,
            7,
            7,
            6,
            7,
            1,
            2,
            7,
            1,
            0
        ],
        "text-top-10-question_score": [
            18.84375,
            17.875,
            16.90625,
            16.84375,
            16.3125,
            16.234375,
            15.8046875,
            15.359375,
            15.2421875,
            15.1171875
        ]
    },
    {
        "doc_id": "1910.14537.pdf",
        "q_uid": "fabcd71644bb63559d34b38d78f6ef87c256d475",
        "question": "What are strong baselines model is compared to?",
        "answer": "Baseline models are:\n- Chen et al., 2015a\n- Chen et al., 2015b\n- Liu et al., 2016\n- Cai and Zhao, 2016\n- Cai et al., 2017\n- Zhou et al., 2017\n- Ma et al., 2018\n- Wang et al., 2019",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            8,
            7,
            6,
            2,
            1,
            3,
            5,
            4,
            10
        ],
        "image-top-10-question_score": [
            14.331911087036133,
            14.012730598449707,
            13.888069152832031,
            13.881002426147461,
            13.828977584838867,
            13.460476875305176,
            13.258856773376465,
            13.257020950317383,
            12.723140716552734,
            12.22559642791748
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.14537.pdf",
        "text-top-10-question": [
            0,
            7,
            6,
            2,
            7,
            7,
            2,
            6,
            1,
            1
        ],
        "text-top-10-question_score": [
            15.6171875,
            14.859375,
            13.546875,
            13.1875,
            13.078125,
            12.7734375,
            12.109375,
            11.75,
            11.734375,
            11.5390625
        ]
    },
    {
        "doc_id": "1702.03342.pdf",
        "q_uid": "2a6003a74d051d0ebbe62e8883533a5f5e55078b",
        "question": "which neural embedding model works better?",
        "answer": "the CRX model",
        "answer_2": "3C model",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            21,
            18,
            6,
            16,
            4,
            7,
            5,
            24
        ],
        "image-top-10-question_score": [
            12.171232223510742,
            12.162322998046875,
            12.05749225616455,
            11.926685333251953,
            11.922801971435547,
            11.781709671020508,
            11.528213500976562,
            11.518089294433594,
            11.201488494873047,
            11.158815383911133
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1702.03342.pdf",
        "text-top-10-question": [
            0,
            21,
            3,
            4,
            0,
            22,
            3,
            16,
            5,
            3
        ],
        "text-top-10-question_score": [
            22.125,
            20.734375,
            20.328125,
            19.6875,
            19.46875,
            19.375,
            19.3125,
            18.890625,
            18.25,
            18.1875
        ]
    },
    {
        "doc_id": "1702.03342.pdf",
        "q_uid": "1b1b0c71f1a4b37c6562d444f75c92eb2c727d9b",
        "question": "What is the degree of dimension reduction of the efficient aggregation method?",
        "answer": "The number of dimensions can be reduced by up to 212 times.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            10,
            18,
            13,
            16,
            19,
            5,
            22,
            23
        ],
        "image-top-10-question_score": [
            15.712221145629883,
            15.51016616821289,
            15.35722541809082,
            13.663260459899902,
            13.57000732421875,
            13.558606147766113,
            13.402639389038086,
            13.264707565307617,
            13.249223709106445,
            13.243505477905273
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1702.03342.pdf",
        "text-top-10-question": [
            3,
            0,
            3,
            0,
            10,
            3,
            19,
            19,
            18,
            10
        ],
        "text-top-10-question_score": [
            17.75,
            16.703125,
            16.40625,
            14.8046875,
            14.734375,
            13.9765625,
            13.0390625,
            12.734375,
            10.875,
            10.765625
        ]
    },
    {
        "doc_id": "1805.03710.pdf",
        "q_uid": "9c44df7503720709eac933a15569e5761b378046",
        "question": "For which languages do they build word embeddings for?",
        "answer": "English",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            0,
            1,
            5,
            2
        ],
        "image-top-10-question_score": [
            15.693490982055664,
            15.643580436706543,
            15.382674217224121,
            15.163482666015625,
            14.901233673095703,
            14.867274284362793
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1805.03710.pdf",
        "text-top-10-question": [
            0,
            5,
            4,
            0,
            1,
            4,
            4,
            4,
            3,
            4
        ],
        "text-top-10-question_score": [
            21.484375,
            21.109375,
            20.390625,
            19.328125,
            18.875,
            18.625,
            18.375,
            18.359375,
            17.390625,
            16.90625
        ]
    },
    {
        "doc_id": "1909.03135.pdf",
        "q_uid": "d509081673f5667060400eb325a8050fa5db7cc8",
        "question": "How big was the corpora they trained ELMo on?",
        "answer": "2174000000, 989000000",
        "answer_2": "2174 million tokens for English and 989 million tokens for Russian",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            5,
            4,
            2,
            3,
            6
        ],
        "image-top-10-question_score": [
            16.684703826904297,
            16.062660217285156,
            15.51710319519043,
            15.436511993408203,
            15.325309753417969,
            14.95456600189209,
            12.628238677978516
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.03135.pdf",
        "text-top-10-question": [
            1,
            1,
            1,
            1,
            2,
            5,
            0,
            3,
            0,
            4
        ],
        "text-top-10-question_score": [
            22.328125,
            21.40625,
            20.375,
            18.46875,
            18.328125,
            17.796875,
            17.59375,
            16.46875,
            16.40625,
            15.7734375
        ]
    },
    {
        "doc_id": "1804.07789.pdf",
        "q_uid": "6cd25c637c6b772ce29e8ee81571e8694549c5ab",
        "question": "What dataset is used?",
        "answer": "English WIKIBIO, French WIKIBIO , German WIKIBIO ",
        "answer_2": "WikiBio dataset,  introduce two new biography datasets, one in French and one in German",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            5,
            1,
            2,
            6,
            10,
            9,
            7,
            11
        ],
        "image-top-10-question_score": [
            11.31329345703125,
            11.00982666015625,
            11.003678321838379,
            10.887716293334961,
            10.828900337219238,
            10.823709487915039,
            10.806777954101562,
            10.757942199707031,
            10.745126724243164,
            10.737220764160156
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1804.07789.pdf",
        "text-top-10-question": [
            2,
            4,
            4,
            0,
            4,
            1,
            0,
            0,
            1,
            5
        ],
        "text-top-10-question_score": [
            18.765625,
            17.234375,
            16.328125,
            16.25,
            15.8046875,
            15.46875,
            15.3984375,
            15.0078125,
            14.0078125,
            13.9375
        ]
    },
    {
        "doc_id": "1810.12085.pdf",
        "q_uid": "ceb767e33fde4b927e730f893db5ece947ffb0d8",
        "question": "what topics did they label?",
        "answer": "Demographics Age, DiagnosisHistory, MedicationHistory, ProcedureHistory, Symptoms/Signs, Vitals/Labs, Procedures/Results, Meds/Treatments, Movement, Other.",
        "answer_2": "Demographics, Diagnosis History, Medication History, Procedure History, Symptoms, Labs, Procedures, Treatments, Hospital movements, and others",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            5,
            4,
            2,
            0,
            3,
            6,
            7
        ],
        "image-top-10-question_score": [
            12.556583404541016,
            11.38768482208252,
            11.221874237060547,
            10.899518966674805,
            10.627828598022461,
            10.513901710510254,
            9.562629699707031,
            9.306519508361816
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.12085.pdf",
        "text-top-10-question": [
            1,
            1,
            4,
            2,
            2,
            2,
            5,
            0,
            5,
            5
        ],
        "text-top-10-question_score": [
            19.828125,
            18.1875,
            13.984375,
            13.8828125,
            13.703125,
            13.203125,
            13.0078125,
            12.5546875,
            12.5546875,
            12.359375
        ]
    },
    {
        "doc_id": "1810.12085.pdf",
        "q_uid": "c2cb6c4500d9e02fc9a1bdffd22c3df69655189f",
        "question": "did they compare with other extractive summarization methods?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            4,
            5,
            3,
            6,
            7,
            2
        ],
        "image-top-10-question_score": [
            15.885627746582031,
            15.659012794494629,
            15.521092414855957,
            15.475418090820312,
            15.43993854522705,
            14.348491668701172,
            14.302448272705078,
            14.179667472839355
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.12085.pdf",
        "text-top-10-question": [
            4,
            1,
            5,
            1,
            0,
            5,
            0,
            6,
            0,
            1
        ],
        "text-top-10-question_score": [
            20.46875,
            19.96875,
            19.40625,
            19.125,
            18.4375,
            18.234375,
            17.796875,
            17.328125,
            17.265625,
            17.125
        ]
    },
    {
        "doc_id": "1610.07809.pdf",
        "q_uid": "06eb9f2320451df83e27362c22eb02f4a426a018",
        "question": "what levels of document preprocessing are looked at?",
        "answer": "raw text, text cleaning through document logical structure detection, removal of keyphrase sparse sections of the document",
        "answer_2": "Level 1, Level 2 and Level 3.",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            0,
            2,
            4,
            1,
            3,
            6,
            7
        ],
        "image-top-10-question_score": [
            15.740499496459961,
            15.619620323181152,
            15.475101470947266,
            15.459121704101562,
            15.445001602172852,
            15.262372016906738,
            14.242794036865234,
            11.954154968261719
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1610.07809.pdf",
        "text-top-10-question": [
            5,
            4,
            2,
            5,
            5,
            5,
            3,
            0,
            1,
            3
        ],
        "text-top-10-question_score": [
            22.34375,
            22.109375,
            21.84375,
            20.890625,
            20.765625,
            20.46875,
            20.390625,
            20.125,
            19.578125,
            19.046875
        ]
    },
    {
        "doc_id": "2003.03044.pdf",
        "q_uid": "46c9e5f335b2927db995a55a18b7c7621fd3d051",
        "question": "How many different phenotypes are present in the dataset?",
        "answer": "15 clinical patient phenotypes",
        "answer_2": "Thirteen different phenotypes are present in the dataset.",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            4,
            1,
            3,
            0,
            5
        ],
        "image-top-10-question_score": [
            15.22968578338623,
            14.789131164550781,
            14.626588821411133,
            14.452851295471191,
            13.509088516235352,
            12.454961776733398
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.03044.pdf",
        "text-top-10-question": [
            2,
            0,
            4,
            0,
            3,
            1,
            1,
            1,
            4,
            4
        ],
        "text-top-10-question_score": [
            21.125,
            20.265625,
            19.71875,
            19.703125,
            19.0625,
            19.0625,
            16.890625,
            16.46875,
            16.3125,
            15.703125
        ]
    },
    {
        "doc_id": "2003.03044.pdf",
        "q_uid": "ce0e2a8675055a5468c4c54dbb099cfd743df8a7",
        "question": "What are 10 other phenotypes that are annotated?",
        "answer": "Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            1,
            4,
            0,
            5
        ],
        "image-top-10-question_score": [
            16.020626068115234,
            15.830587387084961,
            15.439571380615234,
            15.112648010253906,
            13.978331565856934,
            11.71479606628418
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.03044.pdf",
        "text-top-10-question": [
            0,
            0,
            1,
            2,
            4,
            4,
            1,
            5,
            5,
            1
        ],
        "text-top-10-question_score": [
            23.234375,
            22.953125,
            21.359375,
            19.484375,
            19.25,
            17.875,
            16.890625,
            16.828125,
            16.71875,
            16.5625
        ]
    },
    {
        "doc_id": "1909.00015.pdf",
        "q_uid": "f8c1b17d265a61502347c9a937269b38fc3fcab1",
        "question": "HOw does the method perform compared with baselines?",
        "answer": "On the datasets DE-EN, JA-EN, RO-EN, and EN-DE, the baseline achieves 29.79, 21.57, 32.70, and 26.02  BLEU score, respectively. The 1.5-entmax achieves  29.83, 22.13, 33.10, and 25.89 BLEU score, which is a difference of +0.04, +0.56, +0.40, and -0.13 BLEU score versus the baseline. The \u03b1-entmax achieves 29.90, 21.74, 32.89, and 26.93 BLEU score, which is a difference of +0.11, +0.17, +0.19, +0.91 BLEU score versus the baseline.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            8,
            4,
            9,
            1,
            7,
            15,
            6,
            0,
            10
        ],
        "image-top-10-question_score": [
            14.610774993896484,
            14.372217178344727,
            14.331268310546875,
            14.17759895324707,
            14.103262901306152,
            14.092348098754883,
            13.993827819824219,
            13.990591049194336,
            13.947433471679688,
            13.924240112304688
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00015.pdf",
        "text-top-10-question": [
            3,
            3,
            0,
            6,
            5,
            9,
            4,
            17,
            1,
            1
        ],
        "text-top-10-question_score": [
            13.0390625,
            12.9375,
            11.8984375,
            11.5859375,
            11.546875,
            10.28125,
            10.046875,
            9.9296875,
            9.8671875,
            9.859375
        ]
    },
    {
        "doc_id": "1705.01214.pdf",
        "q_uid": "cc608df2884e1e82679f663ed9d9d67a4b6c03f3",
        "question": "What evaluation metrics did look at?",
        "answer": "precision, recall, F1 and accuracy",
        "answer_2": "Response time, resource consumption (memory, CPU, network bandwidth), precision, recall, F1, accuracy.",
        "answer_3": " ",
        "image-top-10-question": [
            31,
            32,
            0,
            34,
            39,
            33,
            38,
            28,
            21,
            35
        ],
        "image-top-10-question_score": [
            11.41553020477295,
            10.327630996704102,
            9.888053894042969,
            9.759553909301758,
            9.150697708129883,
            9.14616584777832,
            9.140485763549805,
            9.110161781311035,
            9.055082321166992,
            9.04958724975586
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1705.01214.pdf",
        "text-top-10-question": [
            31,
            34,
            31,
            32,
            31,
            11,
            21,
            0,
            29,
            34
        ],
        "text-top-10-question_score": [
            13.4453125,
            13.265625,
            12.7109375,
            12.484375,
            11.8671875,
            11.171875,
            10.421875,
            9.9921875,
            9.515625,
            9.4140625
        ]
    },
    {
        "doc_id": "1908.07195.pdf",
        "q_uid": "79f9468e011670993fd162543d1a4b3dd811ac5d",
        "question": "How much improvement is gained from Adversarial Reward Augmented Maximum Likelihood (ARAML)?",
        "answer": "ARAM has achieved improvement over all baseline methods using reverese perplexity and  slef-BLEU metric.  The maximum reverse perplexity improvement 936,16 is gained for EMNLP2017  WMT  dataset and  48,44 for COCO dataset.",
        "answer_2": "Compared to the baselines, ARAML does not do better in terms of perplexity on COCO and EMNLP 2017 WMT datasets, but it does by up to 0.27 Self-BLEU points on COCO and 0.35 Self-BLEU on EMNLP 2017 WMT. In terms of Grammaticality and Relevance, it scores better than the baselines on up to 75.5% and 73% of the cases respectively.",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            8,
            2,
            1,
            6,
            7,
            5,
            9,
            10
        ],
        "image-top-10-question_score": [
            21.211387634277344,
            20.658594131469727,
            20.089494705200195,
            19.9121150970459,
            19.85239601135254,
            19.740314483642578,
            19.330739974975586,
            19.15918731689453,
            17.722415924072266,
            17.64138412475586
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.07195.pdf",
        "text-top-10-question": [
            1,
            0,
            0,
            1,
            4,
            0,
            6,
            1,
            8,
            2
        ],
        "text-top-10-question_score": [
            18.40625,
            17.765625,
            17.765625,
            15.9140625,
            15.6875,
            15.5234375,
            15.421875,
            14.3671875,
            14.21875,
            13.0859375
        ]
    },
    {
        "doc_id": "1703.07090.pdf",
        "q_uid": "1bb7eb5c3d029d95d1abf9f2892c1ec7b6eef306",
        "question": "what was their character error rate?",
        "answer": "2.49% for  layer-wise training, 2.63% for distillation, 6.26% for transfer learning.",
        "answer_2": "Their best model achieved a 2.49% Character Error Rate.",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            5,
            6,
            2,
            3,
            0,
            7
        ],
        "image-top-10-question_score": [
            12.034146308898926,
            9.334562301635742,
            9.235843658447266,
            8.708322525024414,
            8.675788879394531,
            8.545053482055664,
            8.390047073364258,
            8.081520080566406
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1703.07090.pdf",
        "text-top-10-question": [
            4,
            1,
            0,
            2,
            3,
            3,
            2,
            3,
            2,
            2
        ],
        "text-top-10-question_score": [
            17.296875,
            15.375,
            10.671875,
            9.6328125,
            9.0234375,
            8.328125,
            7.765625,
            7.7578125,
            6.859375,
            6.859375
        ]
    },
    {
        "doc_id": "1703.07090.pdf",
        "q_uid": "c0af8b7bf52dc15e0b33704822c4a34077e09cd1",
        "question": "which lstm models did they compare with?",
        "answer": "Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            4,
            5,
            7,
            3,
            2,
            6
        ],
        "image-top-10-question_score": [
            15.258389472961426,
            14.953986167907715,
            14.87172794342041,
            14.87071704864502,
            13.281997680664062,
            13.044092178344727,
            12.732210159301758,
            12.543498992919922
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1703.07090.pdf",
        "text-top-10-question": [
            5,
            5,
            5,
            5,
            5,
            0,
            4,
            5,
            1,
            1
        ],
        "text-top-10-question_score": [
            22.0625,
            21.578125,
            21.296875,
            21.203125,
            20.78125,
            20.734375,
            19.75,
            18.9375,
            18.453125,
            18.09375
        ]
    },
    {
        "doc_id": "1707.03569.pdf",
        "q_uid": "37edc25e39515ffc2d92115d2fcd9e6ceb18898b",
        "question": "What was the baseline?",
        "answer": "SVMs, LR, BIBREF2",
        "answer_2": "SVM INLINEFORM0, SVM INLINEFORM1, LR INLINEFORM2, MaxEnt",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            1,
            0,
            2
        ],
        "image-top-10-question_score": [
            10.038189888000488,
            8.822834014892578,
            8.595848083496094,
            8.49417495727539,
            8.431230545043945
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1707.03569.pdf",
        "text-top-10-question": [
            3,
            2,
            2,
            1,
            3,
            0,
            2,
            1,
            1,
            0
        ],
        "text-top-10-question_score": [
            16.859375,
            6.2734375,
            6.1796875,
            5.10546875,
            4.80859375,
            4.21484375,
            3.892578125,
            3.85546875,
            3.7890625,
            3.73046875
        ]
    },
    {
        "doc_id": "1707.03569.pdf",
        "q_uid": "e431661f17347607c3d3d9764928385a8f3d9650",
        "question": "By how much did they improve?",
        "answer": "They decrease MAE in 0.34",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            2,
            1,
            0
        ],
        "image-top-10-question_score": [
            8.504875183105469,
            8.273833274841309,
            7.717683792114258,
            7.379714488983154,
            7.327670097351074
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1707.03569.pdf",
        "text-top-10-question": [
            4,
            3,
            1,
            3,
            0,
            3,
            3,
            0,
            0,
            2
        ],
        "text-top-10-question_score": [
            11.171875,
            9.8984375,
            9.5078125,
            9.2109375,
            8.5390625,
            6.76953125,
            6.4453125,
            6.24609375,
            6.04296875,
            5.8515625
        ]
    },
    {
        "doc_id": "1912.10011.pdf",
        "q_uid": "664db503509b8236bc4d3dc39cebb74498365750",
        "question": "What is quantitative improvement of proposed method (the best variant) w.r.t. baseline (the best variant)?",
        "answer": "Hierarchical-k",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            10,
            8,
            7,
            11,
            6,
            2,
            9,
            4,
            0,
            3
        ],
        "image-top-10-question_score": [
            25.061206817626953,
            23.22675323486328,
            22.837265014648438,
            22.35498046875,
            22.317251205444336,
            22.080686569213867,
            21.992141723632812,
            21.543197631835938,
            21.498538970947266,
            21.36979866027832
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.10011.pdf",
        "text-top-10-question": [
            11,
            10,
            2,
            11,
            9,
            12,
            12,
            2,
            11,
            2
        ],
        "text-top-10-question_score": [
            13.78125,
            12.96875,
            12.5234375,
            12.2265625,
            12.046875,
            11.96875,
            11.6328125,
            11.4296875,
            11.3671875,
            11.2578125
        ]
    },
    {
        "doc_id": "2003.11563.pdf",
        "q_uid": "b0a18628289146472aa42f992d0db85c200ec64b",
        "question": "What metrics are used in evaluation?",
        "answer": "precision, recall , F1 score",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            4,
            6,
            3,
            7,
            5,
            1,
            8,
            9,
            0
        ],
        "image-top-10-question_score": [
            10.825488090515137,
            10.31757926940918,
            9.95338249206543,
            9.850361824035645,
            9.823939323425293,
            9.550098419189453,
            9.399840354919434,
            9.336225509643555,
            8.998406410217285,
            8.605979919433594
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.11563.pdf",
        "text-top-10-question": [
            2,
            4,
            3,
            4,
            3,
            3,
            6,
            7,
            4,
            6
        ],
        "text-top-10-question_score": [
            13.953125,
            12.8046875,
            12.3671875,
            10.7734375,
            10.6328125,
            10.4453125,
            10.40625,
            10.0078125,
            10.0,
            9.7421875
        ]
    },
    {
        "doc_id": "1909.00105.pdf",
        "q_uid": "5b551ba47d582f2e6467b1b91a8d4d6a30c343ec",
        "question": "What metrics are used for evaluation?",
        "answer": "Byte-Pair Encoding perplexity  (BPE PPL),\nBLEU-1,\nBLEU-4,\nROUGE-L,\npercentage of distinct unigram (D-1),\npercentage of distinct bigrams(D-2),\nuser matching accuracy(UMA),\nMean Reciprocal Rank(MRR)\nPairwise preference over baseline(PP)",
        "answer_2": "BLEU-1/4 and ROUGE-L, likelihood of generated recipes using identical input specifications but conditioned on ten different user profiles, user matching accuracy (UMA), Mean Reciprocal Rank (MRR), neural scoring model from BIBREF33 to measure recipe-level coherence",
        "answer_3": " Distinct-1/2, UMA = User Matching Accuracy, MRR\n= Mean Reciprocal Rank, PP = Pairwise preference over baseline (evaluated for 310 recipe pairs per model)",
        "image-top-10-question": [
            3,
            4,
            0,
            7,
            2,
            5,
            11,
            8,
            6,
            1
        ],
        "image-top-10-question_score": [
            11.844952583312988,
            11.183126449584961,
            11.110225677490234,
            10.811424255371094,
            10.402423858642578,
            10.02187442779541,
            9.856243133544922,
            9.355210304260254,
            9.243053436279297,
            9.087042808532715
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00105.pdf",
        "text-top-10-question": [
            0,
            3,
            4,
            0,
            3,
            11,
            2,
            4,
            3,
            7
        ],
        "text-top-10-question_score": [
            16.546875,
            15.8359375,
            15.828125,
            15.5703125,
            15.328125,
            14.6328125,
            14.625,
            14.109375,
            13.90625,
            13.875
        ]
    },
    {
        "doc_id": "1809.06537.pdf",
        "q_uid": "e3c9e4bc7bb93461856e1f4354f33010bc7d28d5",
        "question": "what are the state-of-the-art models?",
        "answer": "SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ",
        "answer_2": "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            1,
            5,
            7,
            2,
            8,
            0,
            4,
            9,
            3
        ],
        "image-top-10-question_score": [
            16.762989044189453,
            16.437255859375,
            16.297225952148438,
            16.105695724487305,
            16.008874893188477,
            15.810867309570312,
            15.765266418457031,
            15.508744239807129,
            15.408005714416504,
            15.322301864624023
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.06537.pdf",
        "text-top-10-question": [
            0,
            7,
            1,
            5,
            8,
            5,
            6,
            4,
            5,
            7
        ],
        "text-top-10-question_score": [
            16.890625,
            16.703125,
            16.0,
            11.34375,
            10.6328125,
            10.6171875,
            10.5,
            10.3125,
            10.109375,
            10.0
        ]
    },
    {
        "doc_id": "2003.03014.pdf",
        "q_uid": "0682bf049f96fa603d50f0fdad0b79a5c55f6c97",
        "question": "Do they analyze specific derogatory words?",
        "answer": "Yes",
        "answer_2": "Yes",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            23,
            24,
            11,
            9,
            21,
            2,
            18,
            19,
            16
        ],
        "image-top-10-question_score": [
            12.380861282348633,
            12.353140830993652,
            12.26882553100586,
            12.041389465332031,
            11.990697860717773,
            11.930241584777832,
            11.911754608154297,
            11.876380920410156,
            11.819849014282227,
            11.818628311157227
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.03014.pdf",
        "text-top-10-question": [
            24,
            2,
            15,
            3,
            1,
            4,
            2,
            4,
            7,
            4
        ],
        "text-top-10-question_score": [
            13.9609375,
            13.6796875,
            13.3125,
            13.09375,
            12.8515625,
            12.8125,
            12.53125,
            12.421875,
            12.34375,
            12.3125
        ]
    },
    {
        "doc_id": "1908.08345.pdf",
        "q_uid": "c17b609b0b090d7e8f99de1445be04f8f66367d4",
        "question": "What rouge score do they achieve?",
        "answer": "Best results on unigram:\nCNN/Daily Mail: Rogue F1 43.85\nNYT: Rogue Recall 49.02\nXSum: Rogue F1 38.81",
        "answer_2": "Highest scores for ROUGE-1, ROUGE-2 and ROUGE-L on CNN/DailyMail test set are 43.85, 20.34 and 39.90 respectively; on the XSum test set 38.81, 16.50 and 31.27 and on the NYT test set 49.02, 31.02 and 45.55",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            6,
            9,
            8,
            7,
            2,
            1,
            4,
            3,
            0
        ],
        "image-top-10-question_score": [
            12.960152626037598,
            12.106878280639648,
            10.000810623168945,
            9.644303321838379,
            9.517648696899414,
            9.130118370056152,
            8.904666900634766,
            8.73197078704834,
            8.61332893371582,
            8.388738632202148
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.08345.pdf",
        "text-top-10-question": [
            5,
            5,
            6,
            5,
            6,
            6,
            7,
            2,
            9,
            2
        ],
        "text-top-10-question_score": [
            18.84375,
            18.625,
            17.8125,
            17.734375,
            16.765625,
            15.9921875,
            15.828125,
            13.3359375,
            13.3046875,
            12.796875
        ]
    },
    {
        "doc_id": "1605.07333.pdf",
        "q_uid": "6cd8bad8a031ce6d802ded90f9754088e0c8d653",
        "question": "By how much does their best model outperform the state-of-the-art?",
        "answer": "0.8% F1 better than the best state-of-the-art",
        "answer_2": "Best proposed model achieves F1 score of 84.9 compared to best previous result of 84.1.",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            3,
            2,
            1,
            5
        ],
        "image-top-10-question_score": [
            20.088451385498047,
            19.741483688354492,
            19.585756301879883,
            18.837818145751953,
            18.585439682006836,
            17.186771392822266
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1605.07333.pdf",
        "text-top-10-question": [
            4,
            0,
            4,
            0,
            0,
            4,
            4,
            3,
            3,
            2
        ],
        "text-top-10-question_score": [
            15.7265625,
            14.0,
            13.8046875,
            12.15625,
            12.0859375,
            11.5859375,
            11.4453125,
            10.921875,
            10.1484375,
            10.109375
        ]
    },
    {
        "doc_id": "2003.08385.pdf",
        "q_uid": "35b3ce3a7499070e9b280f52e2cb0c29b0745380",
        "question": "Does the paper report the performance of the model for each individual language?",
        "answer": "Yes",
        "answer_2": "Yes",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            7,
            6,
            3,
            1,
            4,
            2,
            9,
            8
        ],
        "image-top-10-question_score": [
            18.123249053955078,
            18.091522216796875,
            18.005762100219727,
            17.84728240966797,
            17.723224639892578,
            17.60959815979004,
            17.523513793945312,
            17.440767288208008,
            16.511245727539062,
            16.229007720947266
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.08385.pdf",
        "text-top-10-question": [
            0,
            5,
            6,
            6,
            7,
            4,
            6,
            7,
            6,
            3
        ],
        "text-top-10-question_score": [
            16.5625,
            16.109375,
            15.8359375,
            15.3125,
            15.265625,
            13.8046875,
            13.2421875,
            13.15625,
            12.640625,
            12.515625
        ]
    },
    {
        "doc_id": "2003.08385.pdf",
        "q_uid": "71ba1b09bb03f5977d790d91702481cc406b3767",
        "question": "What is the performance of the baseline?",
        "answer": "M-Bert had 76.6 F1 macro score.",
        "answer_2": "75.1% and 75.6% accuracy",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            6,
            7,
            0,
            3,
            1,
            11,
            2,
            10
        ],
        "image-top-10-question_score": [
            13.504672050476074,
            13.321279525756836,
            12.847360610961914,
            11.937968254089355,
            11.81110954284668,
            11.8092679977417,
            11.480609893798828,
            11.386971473693848,
            11.342447280883789,
            11.202468872070312
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.08385.pdf",
        "text-top-10-question": [
            5,
            0,
            5,
            0,
            4,
            4,
            7,
            5,
            5,
            6
        ],
        "text-top-10-question_score": [
            20.109375,
            18.0,
            17.703125,
            17.21875,
            16.765625,
            15.515625,
            15.296875,
            15.0546875,
            14.25,
            13.3125
        ]
    },
    {
        "doc_id": "2003.08385.pdf",
        "q_uid": "bd40f33452da7711b65faaa248aca359b27fddb6",
        "question": "What was the performance of multilingual BERT?",
        "answer": "BERT had 76.6 F1 macro score on x-stance dataset.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            5,
            6,
            0,
            1,
            3,
            4,
            8,
            9,
            2
        ],
        "image-top-10-question_score": [
            14.475874900817871,
            14.430091857910156,
            14.227646827697754,
            13.639671325683594,
            12.37969970703125,
            12.090778350830078,
            11.546624183654785,
            10.9607515335083,
            10.866918563842773,
            10.827380180358887
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.08385.pdf",
        "text-top-10-question": [
            7,
            0,
            9,
            0,
            5,
            7,
            5,
            5,
            0,
            4
        ],
        "text-top-10-question_score": [
            22.09375,
            22.078125,
            21.6875,
            20.265625,
            20.25,
            19.96875,
            19.671875,
            19.015625,
            18.578125,
            18.578125
        ]
    },
    {
        "doc_id": "1908.07245.pdf",
        "q_uid": "e82fa03f1638a8c59ceb62bb9a6b41b498950e1f",
        "question": "What is the state of the art system mentioned?",
        "answer": "Two knowledge-based systems,\ntwo traditional word expert supervised systems, six recent neural-based systems, and one BERT feature-based system.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            3,
            1,
            5,
            2
        ],
        "image-top-10-question_score": [
            14.455184936523438,
            14.004465103149414,
            13.834571838378906,
            13.665325164794922,
            13.256543159484863,
            12.919891357421875
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.07245.pdf",
        "text-top-10-question": [
            4,
            1,
            0,
            2,
            2,
            1,
            3,
            3,
            3,
            3
        ],
        "text-top-10-question_score": [
            15.6953125,
            15.390625,
            14.328125,
            8.9609375,
            8.8125,
            7.9453125,
            7.32421875,
            7.265625,
            7.03125,
            7.00390625
        ]
    },
    {
        "doc_id": "1901.01010.pdf",
        "q_uid": "1097768b89f8bd28d6ef6443c94feb04c1a1318e",
        "question": "Do the methods that work best on academic papers also work best on Wikipedia?",
        "answer": "Yes",
        "answer_2": "No",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            3,
            7,
            2,
            6,
            5,
            8,
            4
        ],
        "image-top-10-question_score": [
            19.079261779785156,
            19.01743507385254,
            18.8248291015625,
            18.556015014648438,
            18.509601593017578,
            18.355894088745117,
            18.18046760559082,
            17.755695343017578,
            17.538616180419922
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.01010.pdf",
        "text-top-10-question": [
            1,
            1,
            6,
            4,
            5,
            6,
            0,
            0,
            1,
            1
        ],
        "text-top-10-question_score": [
            17.21875,
            16.171875,
            15.8984375,
            15.2734375,
            14.4375,
            14.3984375,
            14.203125,
            14.1875,
            13.59375,
            13.4921875
        ]
    },
    {
        "doc_id": "1901.01010.pdf",
        "q_uid": "fc1679c714eab822431bbe96f0e9cf4079cd8b8d",
        "question": "What is their system's absolute accuracy?",
        "answer": "59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            6,
            0,
            8,
            5,
            1,
            7,
            2,
            3
        ],
        "image-top-10-question_score": [
            11.380918502807617,
            10.97726821899414,
            10.87476921081543,
            10.873165130615234,
            10.784191131591797,
            10.503484725952148,
            10.48971176147461,
            10.035843849182129,
            9.562456130981445
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.01010.pdf",
        "text-top-10-question": [
            4,
            4,
            4,
            6,
            6,
            1,
            0,
            4,
            5,
            0
        ],
        "text-top-10-question_score": [
            15.4765625,
            14.6484375,
            12.9453125,
            11.6640625,
            11.6484375,
            11.5546875,
            10.9140625,
            10.84375,
            9.453125,
            9.4296875
        ]
    },
    {
        "doc_id": "1809.02279.pdf",
        "q_uid": "c35806cf68220b2b9bb082b62f493393b9bdff86",
        "question": "What were their best results on the benchmark datasets?",
        "answer": "In SNLI, our best model achieves the new state-of-the-art accuracy of 87.0%,  we can see that our models outperform other models by large margin, achieving the new state of the art., Our models achieve the new state-of-the-art accuracy on SST-2 and competitive accuracy on SST-5",
        "answer_2": "accuracy of 87.0%",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            6,
            11,
            7,
            8,
            1,
            9,
            10,
            2,
            12
        ],
        "image-top-10-question_score": [
            14.55386734008789,
            14.427218437194824,
            14.393919944763184,
            14.332703590393066,
            13.918009757995605,
            13.895052909851074,
            13.591483116149902,
            13.495098114013672,
            13.270288467407227,
            13.111137390136719
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.02279.pdf",
        "text-top-10-question": [
            0,
            11,
            7,
            1,
            8,
            10,
            7,
            7,
            8,
            6
        ],
        "text-top-10-question_score": [
            16.34375,
            16.28125,
            15.3984375,
            14.796875,
            14.65625,
            14.5859375,
            13.7578125,
            13.515625,
            13.1484375,
            13.03125
        ]
    },
    {
        "doc_id": "2002.01207.pdf",
        "q_uid": "76ed74788e3eb3321e646c48ae8bf6cdfe46dca1",
        "question": "what linguistics features are used?",
        "answer": "POS, gender/number and stem POS",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            13,
            0,
            1,
            16,
            15,
            12,
            3,
            8,
            14
        ],
        "image-top-10-question_score": [
            12.009857177734375,
            11.93946647644043,
            11.873640060424805,
            11.817289352416992,
            11.65884780883789,
            11.55557632446289,
            11.265605926513672,
            11.15501880645752,
            11.126029968261719,
            11.07638168334961
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.01207.pdf",
        "text-top-10-question": [
            16,
            0,
            16,
            0,
            4,
            13,
            4,
            7,
            12,
            11
        ],
        "text-top-10-question_score": [
            19.515625,
            18.046875,
            17.359375,
            17.265625,
            16.9375,
            16.578125,
            16.03125,
            15.953125,
            15.0859375,
            14.6796875
        ]
    },
    {
        "doc_id": "1909.06162.pdf",
        "q_uid": "c9305e5794b65b33399c22ac8e4e024f6b757a30",
        "question": "What is best performing model among author's submissions, what performance it had?",
        "answer": "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively).",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            4,
            3,
            5,
            2,
            1
        ],
        "image-top-10-question_score": [
            18.499513626098633,
            18.159839630126953,
            17.787067413330078,
            16.704769134521484,
            15.259367942810059,
            14.625990867614746
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.06162.pdf",
        "text-top-10-question": [
            4,
            3,
            1,
            0,
            1,
            4,
            0,
            3,
            4,
            3
        ],
        "text-top-10-question_score": [
            13.375,
            12.3515625,
            11.53125,
            11.4296875,
            10.953125,
            10.0078125,
            9.8984375,
            9.6328125,
            9.390625,
            9.2421875
        ]
    },
    {
        "doc_id": "1909.06162.pdf",
        "q_uid": "56b7319be68197727baa7d498fa38af0a8440fe4",
        "question": "What extracted features were most influencial on performance?",
        "answer": "Linguistic",
        "answer_2": "BERT",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            3,
            2,
            4,
            5
        ],
        "image-top-10-question_score": [
            12.929874420166016,
            12.873034477233887,
            12.687738418579102,
            12.079324722290039,
            11.988187789916992,
            11.345726013183594
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.06162.pdf",
        "text-top-10-question": [
            1,
            4,
            3,
            1,
            1,
            3,
            0,
            4,
            0,
            1
        ],
        "text-top-10-question_score": [
            14.90625,
            13.2421875,
            12.015625,
            11.921875,
            11.25,
            11.1875,
            11.0234375,
            10.9921875,
            10.78125,
            10.328125
        ]
    },
    {
        "doc_id": "1909.06162.pdf",
        "q_uid": "2268c9044e868ba0a16e92d2063ada87f68b5d03",
        "question": "Did ensemble schemes help in boosting peformance, by how much?",
        "answer": "The best ensemble topped the best single model by 0.029 in F1 score on dev (external).",
        "answer_2": "They increased F1 Score by 0.029 in Sentence Level Classification, and by 0.044 in Fragment-Level classification",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            4,
            1,
            0,
            5
        ],
        "image-top-10-question_score": [
            14.505770683288574,
            13.983604431152344,
            13.668688774108887,
            13.217500686645508,
            12.644001007080078,
            11.825530052185059
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.06162.pdf",
        "text-top-10-question": [
            0,
            4,
            1,
            1,
            3,
            3,
            3,
            2,
            1,
            3
        ],
        "text-top-10-question_score": [
            18.59375,
            15.921875,
            15.65625,
            14.5234375,
            13.8984375,
            12.4921875,
            12.296875,
            11.859375,
            11.7109375,
            11.3203125
        ]
    },
    {
        "doc_id": "1909.06162.pdf",
        "q_uid": "6b7354d7d715bad83183296ce2f3ddf2357cb449",
        "question": "Which basic neural architecture perform best by itself?",
        "answer": "BERT",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            2,
            4,
            1,
            5
        ],
        "image-top-10-question_score": [
            12.904869079589844,
            12.52800178527832,
            12.148675918579102,
            12.136362075805664,
            11.214459419250488,
            9.983207702636719
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.06162.pdf",
        "text-top-10-question": [
            3,
            0,
            0,
            4,
            4,
            4,
            4,
            4,
            0,
            5
        ],
        "text-top-10-question_score": [
            16.09375,
            15.1015625,
            13.578125,
            12.8515625,
            12.7109375,
            10.5,
            10.3046875,
            9.796875,
            9.5078125,
            9.4609375
        ]
    },
    {
        "doc_id": "1909.06162.pdf",
        "q_uid": "e949b28f6d1f20e18e82742e04d68158415dc61e",
        "question": "What participating systems had better results than ones authors submitted?",
        "answer": "For SLC task : Ituorp, ProperGander and YMJA  teams had better results.\nFor FLC task: newspeak and Antiganda teams had better results.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            5,
            2,
            3,
            1
        ],
        "image-top-10-question_score": [
            14.547161102294922,
            13.983304023742676,
            13.665138244628906,
            12.819403648376465,
            12.535446166992188,
            11.03499984741211
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.06162.pdf",
        "text-top-10-question": [
            4,
            0,
            3,
            3,
            0,
            0,
            2,
            0,
            2,
            4
        ],
        "text-top-10-question_score": [
            13.5703125,
            13.015625,
            11.3515625,
            10.6875,
            10.296875,
            10.0546875,
            9.7421875,
            9.0234375,
            8.921875,
            8.7578125
        ]
    },
    {
        "doc_id": "1810.05241.pdf",
        "q_uid": "a3efe43a72b76b8f5e5111b54393d00e6a5c97ab",
        "question": "What is the size of the StackExchange dataset?",
        "answer": "around 332k questions",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            14,
            6,
            11,
            12,
            10,
            0,
            1,
            5,
            13,
            2
        ],
        "image-top-10-question_score": [
            15.201891899108887,
            14.961996078491211,
            14.903678894042969,
            14.482617378234863,
            13.689233779907227,
            13.230815887451172,
            12.981854438781738,
            12.907524108886719,
            12.806051254272461,
            12.790196418762207
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.05241.pdf",
        "text-top-10-question": [
            6,
            10,
            11,
            11,
            11,
            14,
            6,
            6,
            11,
            6
        ],
        "text-top-10-question_score": [
            18.671875,
            18.125,
            17.796875,
            17.234375,
            16.484375,
            15.90625,
            15.8671875,
            15.2109375,
            14.5859375,
            14.2109375
        ]
    },
    {
        "doc_id": "1810.05241.pdf",
        "q_uid": "f1e90a553a4185a4b0299bd179f4f156df798bce",
        "question": "What were the baselines?",
        "answer": "CopyRNN (Meng et al., 2017), Multi-Task (Ye and Wang, 2018), and TG-Net (Chen et al., 2018b)",
        "answer_2": "CopyRNN BIBREF0, KEA BIBREF4 and Maui BIBREF8, CopyRNN*",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            6,
            11,
            14,
            13,
            5,
            12,
            7,
            9,
            10
        ],
        "image-top-10-question_score": [
            10.818948745727539,
            10.2456693649292,
            10.167546272277832,
            9.841500282287598,
            9.739595413208008,
            9.726609230041504,
            9.568930625915527,
            9.504049301147461,
            9.491907119750977,
            9.483100891113281
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.05241.pdf",
        "text-top-10-question": [
            5,
            0,
            6,
            6,
            6,
            1,
            9,
            1,
            2,
            11
        ],
        "text-top-10-question_score": [
            11.7421875,
            10.4140625,
            10.0078125,
            7.08203125,
            6.79296875,
            6.6640625,
            6.3828125,
            6.3125,
            5.97265625,
            5.88671875
        ]
    },
    {
        "doc_id": "1909.01383.pdf",
        "q_uid": "b68f72aed961d5ba152e9dc50345e1e832196a76",
        "question": "by how much did the BLEU score improve?",
        "answer": "On average 0.64 ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            6,
            5,
            8,
            1,
            4,
            0,
            2,
            7,
            9
        ],
        "image-top-10-question_score": [
            17.060009002685547,
            16.83222007751465,
            16.386638641357422,
            15.762351989746094,
            14.611799240112305,
            13.332818984985352,
            12.436210632324219,
            12.121162414550781,
            11.748677253723145,
            11.73681926727295
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.01383.pdf",
        "text-top-10-question": [
            6,
            3,
            3,
            6,
            5,
            3,
            3,
            0,
            6,
            3
        ],
        "text-top-10-question_score": [
            22.109375,
            21.875,
            20.5625,
            20.171875,
            18.015625,
            17.8125,
            17.6875,
            16.46875,
            16.375,
            16.125
        ]
    },
    {
        "doc_id": "2001.08868.pdf",
        "q_uid": "df0257ab04686ddf1c6c4d9b0529a7632330b98e",
        "question": "How better does new approach behave than existing solutions?",
        "answer": " On the other hand, phase 1 of Go-Explore finds an optimal trajectory with approximately half the interactions with the environment, Moreover, the trajectory length found by Go-Explore is always optimal (i.e. 30 steps) whereas both DQN++ and DRQN++ have an average length of 38 and 42 respectively., Especially interesting is that the performance of DRRN is substantially lower than that of the Go-Explore Seq2Seq model",
        "answer_2": "On Coin Collector, proposed model finds shorter path in fewer number of interactions with enironment.\nOn Cooking World, proposed model uses smallest amount of steps and on average has bigger score and number of wins by significant margin.",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            1,
            9,
            0,
            7,
            5,
            3,
            11,
            2,
            4
        ],
        "image-top-10-question_score": [
            13.680755615234375,
            13.28885269165039,
            13.174388885498047,
            12.769970893859863,
            12.741679191589355,
            12.493605613708496,
            12.405959129333496,
            11.951351165771484,
            11.75067138671875,
            11.670034408569336
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.08868.pdf",
        "text-top-10-question": [
            0,
            1,
            8,
            0,
            1,
            1,
            9,
            7,
            8,
            7
        ],
        "text-top-10-question_score": [
            18.53125,
            17.3125,
            17.078125,
            15.359375,
            14.7265625,
            12.84375,
            12.3671875,
            12.1640625,
            11.8671875,
            11.765625
        ]
    },
    {
        "doc_id": "1910.12795.pdf",
        "q_uid": "3415762847ed13acc3c90de60e3ef42612bc49af",
        "question": "How much is classification performance improved in experiments for low data regime and class-imbalance problems?",
        "answer": "Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            7,
            6,
            8,
            1,
            4,
            2,
            9,
            10
        ],
        "image-top-10-question_score": [
            22.67957305908203,
            21.56427001953125,
            21.044448852539062,
            20.811555862426758,
            20.153045654296875,
            19.743549346923828,
            19.461502075195312,
            18.199058532714844,
            17.922691345214844,
            17.883258819580078
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.12795.pdf",
        "text-top-10-question": [
            0,
            6,
            7,
            8,
            6,
            5,
            4,
            4,
            8,
            1
        ],
        "text-top-10-question_score": [
            19.46875,
            19.265625,
            19.21875,
            18.25,
            17.703125,
            17.625,
            17.421875,
            17.125,
            17.125,
            16.734375
        ]
    },
    {
        "doc_id": "2003.04866.pdf",
        "q_uid": "a616a3f0d244368ec588f04dfbc37d77fda01b4c",
        "question": "What are the 12 languages covered?",
        "answer": "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese",
        "answer_2": "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese",
        "answer_3": " ",
        "image-top-10-question": [
            10,
            31,
            25,
            11,
            22,
            15,
            24,
            26,
            12,
            14
        ],
        "image-top-10-question_score": [
            15.199991226196289,
            14.95749282836914,
            14.819432258605957,
            14.693612098693848,
            14.663564682006836,
            14.638755798339844,
            14.63155746459961,
            14.62208366394043,
            14.493040084838867,
            14.491862297058105
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.04866.pdf",
        "text-top-10-question": [
            0,
            28,
            9,
            19,
            35,
            27,
            24,
            10,
            2,
            2
        ],
        "text-top-10-question_score": [
            17.40625,
            16.6875,
            16.53125,
            16.390625,
            15.9609375,
            15.578125,
            15.2265625,
            15.171875,
            14.9375,
            14.9375
        ]
    },
    {
        "doc_id": "1901.08079.pdf",
        "q_uid": "5fa36dc8f7c4e65acb962fc484989d20b8fdaeec",
        "question": "Do they report results only on English data?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            5,
            11,
            0,
            3,
            7,
            1,
            12,
            16,
            9
        ],
        "image-top-10-question_score": [
            13.261163711547852,
            13.229175567626953,
            12.86649227142334,
            12.81733512878418,
            12.738783836364746,
            12.659175872802734,
            12.616878509521484,
            12.482048034667969,
            12.476752281188965,
            12.4065523147583
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.08079.pdf",
        "text-top-10-question": [
            5,
            6,
            2,
            5,
            6,
            6,
            4,
            1,
            3,
            0
        ],
        "text-top-10-question_score": [
            12.3984375,
            12.2734375,
            12.1953125,
            11.7578125,
            11.59375,
            10.40625,
            10.2734375,
            10.234375,
            10.1796875,
            9.7421875
        ]
    },
    {
        "doc_id": "1705.01265.pdf",
        "q_uid": "12159f04e0427fe33fa05af6ba8c950f1a5ce5ea",
        "question": "Which hyperparameters were varied in the experiments on the four tasks?",
        "answer": "number of clusters, seed value in clustering, selection of word vectors, window size and dimension of embedding",
        "answer_2": "different number of clusters, different embeddings",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            2,
            3,
            4,
            5,
            6
        ],
        "image-top-10-question_score": [
            16.167509078979492,
            16.008121490478516,
            15.798537254333496,
            15.438462257385254,
            15.097082138061523,
            14.806539535522461,
            14.109506607055664
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1705.01265.pdf",
        "text-top-10-question": [
            1,
            4,
            1,
            2,
            1,
            0,
            3,
            1,
            0,
            2
        ],
        "text-top-10-question_score": [
            16.484375,
            14.203125,
            14.140625,
            14.0546875,
            13.171875,
            12.7265625,
            12.671875,
            12.65625,
            12.53125,
            12.375
        ]
    },
    {
        "doc_id": "1906.10225.pdf",
        "q_uid": "01f4a0a19467947a8f3bdd7ec9fac75b5222d710",
        "question": "what were the evaluation metrics?",
        "answer": "INLINEFORM0 scores",
        "answer_2": "Unlabeled sentence-level F1, perplexity, grammatically judgment performance",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            13,
            14,
            4,
            6,
            17,
            0,
            8,
            11,
            7
        ],
        "image-top-10-question_score": [
            11.165590286254883,
            10.916810989379883,
            10.820822715759277,
            10.276803016662598,
            9.443217277526855,
            9.355623245239258,
            9.209012985229492,
            9.136177062988281,
            9.093687057495117,
            9.040674209594727
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1906.10225.pdf",
        "text-top-10-question": [
            4,
            5,
            14,
            14,
            11,
            5,
            6,
            13,
            4,
            7
        ],
        "text-top-10-question_score": [
            14.4765625,
            13.59375,
            13.0234375,
            12.90625,
            12.6796875,
            12.5234375,
            12.4609375,
            12.2421875,
            11.5703125,
            11.125
        ]
    },
    {
        "doc_id": "1712.05999.pdf",
        "q_uid": "907b3af3cfaf68fe188de9467ed1260e52ec6cf1",
        "question": "What were their distribution results?",
        "answer": "Distributions of Followers, Friends and URLs are significantly different between the set of tweets containing fake news and those non containing them, but for Favourites, Mentions, Media, Retweets and Hashtags they are not significantly different",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            5,
            3,
            4,
            0,
            2,
            1,
            8,
            7
        ],
        "image-top-10-question_score": [
            11.204680442810059,
            11.14340591430664,
            10.902286529541016,
            10.821060180664062,
            10.678598403930664,
            10.522417068481445,
            9.20565414428711,
            8.989089965820312,
            8.15517807006836
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1712.05999.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            4,
            5,
            3,
            5,
            4,
            3,
            0
        ],
        "text-top-10-question_score": [
            17.921875,
            17.125,
            17.078125,
            15.609375,
            15.390625,
            15.125,
            14.1328125,
            13.9140625,
            13.75,
            12.8828125
        ]
    },
    {
        "doc_id": "1808.09029.pdf",
        "q_uid": "6aaf12505add25dd133c7b0dafe8f4fe966d1f1d",
        "question": "what previous RNN models do they compare with?",
        "answer": "Variational LSTM, CharCNN, Pointer Sentinel-LSTM, RHN, NAS Cell, SRU, QRNN, RAN, 4-layer skip-connection LSTM, AWD-LSTM, Quantized LSTM",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            1,
            4,
            0,
            5,
            7,
            10,
            6,
            8
        ],
        "image-top-10-question_score": [
            13.994800567626953,
            13.586335182189941,
            13.431344985961914,
            13.414234161376953,
            13.197656631469727,
            12.899828910827637,
            12.38370132446289,
            12.338820457458496,
            12.196615219116211,
            11.945423126220703
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1808.09029.pdf",
        "text-top-10-question": [
            2,
            1,
            0,
            1,
            9,
            2,
            10,
            9,
            3,
            2
        ],
        "text-top-10-question_score": [
            17.984375,
            17.109375,
            17.015625,
            16.953125,
            15.7578125,
            15.609375,
            15.53125,
            15.0390625,
            14.71875,
            14.65625
        ]
    },
    {
        "doc_id": "2004.04721.pdf",
        "q_uid": "5bc1dc6ebcb88fd0310b21d2a74939e35a4c1a11",
        "question": "What are the languages they use in their experiment?",
        "answer": "English\nFrench\nSpanish\nGerman\nGreek\nBulgarian\nRussian\nTurkish\nArabic\nVietnamese\nThai\nChinese\nHindi\nSwahili\nUrdu\nFinnish",
        "answer_2": "English, Spanish, Finnish",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            5,
            3,
            1,
            4,
            6,
            0,
            9,
            8,
            10
        ],
        "image-top-10-question_score": [
            14.685264587402344,
            14.24591064453125,
            13.88602352142334,
            13.564291000366211,
            13.236137390136719,
            12.554031372070312,
            12.338846206665039,
            12.301628112792969,
            12.252878189086914,
            12.05864143371582
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2004.04721.pdf",
        "text-top-10-question": [
            2,
            1,
            2,
            5,
            4,
            6,
            2,
            3,
            1,
            2
        ],
        "text-top-10-question_score": [
            19.703125,
            19.4375,
            18.78125,
            18.421875,
            16.171875,
            16.03125,
            15.8359375,
            15.5546875,
            15.4765625,
            15.3203125
        ]
    },
    {
        "doc_id": "2002.04181.pdf",
        "q_uid": "cd06d775f491b4a17c9d616a8729fd45aa2e79bf",
        "question": "Which sentiment class is the most accurately predicted by ELS systems?",
        "answer": "neutral sentiment",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            0,
            4,
            3
        ],
        "image-top-10-question_score": [
            18.901268005371094,
            17.188570022583008,
            17.09696388244629,
            16.486865997314453,
            15.559926986694336
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.04181.pdf",
        "text-top-10-question": [
            0,
            2,
            2,
            1,
            2,
            1,
            1,
            0,
            0,
            0
        ],
        "text-top-10-question_score": [
            21.109375,
            19.390625,
            18.921875,
            18.390625,
            18.265625,
            16.65625,
            16.421875,
            16.40625,
            16.21875,
            15.359375
        ]
    },
    {
        "doc_id": "1908.06264.pdf",
        "q_uid": "0af16b164db20d8569df4ce688d5a62c861ace0b",
        "question": "what were the baselines?",
        "answer": "BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN",
        "answer_2": "bag-of-words (BOW), term frequency\u2013inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            2,
            5,
            0,
            3,
            1
        ],
        "image-top-10-question_score": [
            11.338565826416016,
            9.919198989868164,
            9.784224510192871,
            9.602224349975586,
            9.556255340576172,
            9.339666366577148
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.06264.pdf",
        "text-top-10-question": [
            4,
            4,
            4,
            5,
            2,
            2,
            4,
            3,
            1,
            5
        ],
        "text-top-10-question_score": [
            15.9765625,
            15.4453125,
            11.3203125,
            6.9609375,
            6.828125,
            6.4296875,
            5.59765625,
            5.359375,
            5.328125,
            5.22265625
        ]
    },
    {
        "doc_id": "1908.06264.pdf",
        "q_uid": "6a14379fee26a39631aebd0e14511ce3756e42ad",
        "question": "What BERT models are used?",
        "answer": "BERT-base, BERT-large, BERT-uncased, BERT-cased",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            3,
            5,
            0,
            2,
            4
        ],
        "image-top-10-question_score": [
            12.934846878051758,
            12.809076309204102,
            12.765953063964844,
            12.529741287231445,
            12.034408569335938,
            11.728544235229492
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.06264.pdf",
        "text-top-10-question": [
            1,
            0,
            1,
            2,
            1,
            1,
            4,
            5,
            5,
            4
        ],
        "text-top-10-question_score": [
            22.671875,
            22.203125,
            21.703125,
            20.21875,
            19.96875,
            19.671875,
            19.4375,
            19.3125,
            19.0625,
            18.875
        ]
    },
    {
        "doc_id": "1709.10367.pdf",
        "q_uid": "40c0f97c3547232d6aa039fcb330f142668dea4b",
        "question": "Do they evaluate on English only datasets?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            5,
            6,
            9,
            0,
            10,
            1,
            8,
            11,
            4
        ],
        "image-top-10-question_score": [
            12.015389442443848,
            11.917789459228516,
            11.880681991577148,
            11.443780899047852,
            11.426437377929688,
            11.381704330444336,
            11.209127426147461,
            11.127079010009766,
            10.947664260864258,
            10.871162414550781
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1709.10367.pdf",
        "text-top-10-question": [
            5,
            5,
            5,
            2,
            5,
            6,
            6,
            0,
            2,
            1
        ],
        "text-top-10-question_score": [
            14.0625,
            12.453125,
            12.4453125,
            12.2265625,
            12.1953125,
            12.0859375,
            11.9765625,
            11.4609375,
            11.390625,
            11.2109375
        ]
    },
    {
        "doc_id": "1908.06267.pdf",
        "q_uid": "2858620e0498db2f2224bfbed5263432f0570832",
        "question": "Which component is the least impactful?",
        "answer": "Based on table results provided changing directed to undirected edges had least impact - max abs difference of 0.33 points on all three datasets.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            4,
            6,
            7,
            2,
            5,
            1,
            3,
            8
        ],
        "image-top-10-question_score": [
            9.325333595275879,
            9.208602905273438,
            9.102022171020508,
            9.025612831115723,
            8.746346473693848,
            8.609651565551758,
            8.574361801147461,
            8.528667449951172,
            8.43510913848877
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.06267.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            4,
            0,
            1,
            0,
            4,
            4,
            2
        ],
        "text-top-10-question_score": [
            12.2578125,
            9.7890625,
            8.8515625,
            8.25,
            7.99609375,
            7.3125,
            6.92578125,
            6.8671875,
            6.86328125,
            6.83203125
        ]
    },
    {
        "doc_id": "1908.06267.pdf",
        "q_uid": "545e92833b0ad4ba32eac5997edecf97a366a244",
        "question": "Which component has the greatest impact on performance?",
        "answer": "Increasing number of message passing iterations showed consistent improvement in performance - around 1 point improvement compared between 1 and 4 iterations",
        "answer_2": "Removing the master node deteriorates performance across all datasets",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            4,
            5,
            1,
            6,
            2,
            3,
            8,
            7
        ],
        "image-top-10-question_score": [
            12.294485092163086,
            11.79894733428955,
            11.573022842407227,
            11.552375793457031,
            10.313909530639648,
            10.168134689331055,
            9.7859525680542,
            9.745800018310547,
            9.719423294067383
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.06267.pdf",
        "text-top-10-question": [
            0,
            0,
            4,
            5,
            5,
            4,
            4,
            5,
            4,
            4
        ],
        "text-top-10-question_score": [
            20.546875,
            18.0,
            14.7734375,
            13.109375,
            12.609375,
            12.5,
            12.46875,
            12.125,
            11.7734375,
            11.28125
        ]
    },
    {
        "doc_id": "1701.05574.pdf",
        "q_uid": "bbb77f2d6685c9257763ca38afaaef29044b4018",
        "question": "What is the best reported system?",
        "answer": "Gaze Sarcasm using Multi Instance Logistic Regression.",
        "answer_2": "the MILR classifier",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            0,
            1,
            5,
            6,
            10,
            2,
            3,
            9,
            7
        ],
        "image-top-10-question_score": [
            11.142362594604492,
            11.097574234008789,
            10.652254104614258,
            10.609429359436035,
            10.41113567352295,
            10.257769584655762,
            10.229802131652832,
            10.107673645019531,
            10.089859008789062,
            9.961822509765625
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1701.05574.pdf",
        "text-top-10-question": [
            6,
            6,
            0,
            8,
            6,
            6,
            0,
            8,
            1,
            6
        ],
        "text-top-10-question_score": [
            15.75,
            14.359375,
            11.6640625,
            9.71875,
            9.4375,
            9.1328125,
            9.078125,
            8.609375,
            8.6015625,
            8.5
        ]
    },
    {
        "doc_id": "1701.05574.pdf",
        "q_uid": "74b338d5352fe1a6fd592e38269a4c81fe79b866",
        "question": "What cognitive features are used?",
        "answer": "Readability (RED),  Number of Words (LEN), Avg. Fixation Duration (FDUR), Avg. Fixation Count (FC), Avg. Saccade Length (SL), Regression Count (REG), Skip count (SKIP), Count of regressions from second half\nto first half of the sentence (RSF), Largest Regression Position (LREG),  Edge density of the saliency gaze\ngraph (ED),  Fixation Duration at Left/Source\n(F1H, F1S),  Fixation Duration at Right/Target\n(F2H, F2S),  Forward Saccade Word Count of\nSource (PSH, PSS),  Forward SaccadeWord Count of Destination\n(PSDH, PSDS), Regressive Saccade Word Count of\nSource (RSH, RSS),  Regressive Saccade Word Count of\nDestination (RSDH, RSDS)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            7,
            1,
            8,
            3,
            2,
            4,
            5,
            9,
            10
        ],
        "image-top-10-question_score": [
            12.924631118774414,
            12.634538650512695,
            12.358522415161133,
            10.98486328125,
            10.287688255310059,
            10.144279479980469,
            10.101997375488281,
            9.928583145141602,
            9.617986679077148,
            9.244742393493652
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1701.05574.pdf",
        "text-top-10-question": [
            1,
            7,
            6,
            4,
            8,
            0,
            4,
            2,
            5,
            0
        ],
        "text-top-10-question_score": [
            23.796875,
            21.546875,
            19.96875,
            19.703125,
            19.53125,
            19.28125,
            18.359375,
            18.234375,
            18.15625,
            17.828125
        ]
    },
    {
        "doc_id": "1909.00694.pdf",
        "q_uid": "9d578ddccc27dd849244d632dd0f6bf27348ad81",
        "question": "What are the results?",
        "answer": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            6,
            0,
            7,
            5,
            1,
            2
        ],
        "image-top-10-question_score": [
            11.432888984680176,
            10.53974437713623,
            9.718853950500488,
            9.538061141967773,
            9.248541831970215,
            9.248178482055664,
            8.847504615783691,
            8.837884902954102
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00694.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            0,
            4,
            4,
            4,
            0,
            3,
            2
        ],
        "text-top-10-question_score": [
            15.21875,
            12.359375,
            10.6796875,
            10.5546875,
            10.203125,
            10.0625,
            8.875,
            8.109375,
            7.49609375,
            7.3203125
        ]
    },
    {
        "doc_id": "1909.00694.pdf",
        "q_uid": "44c4bd6decc86f1091b5fc0728873d9324cdde4e",
        "question": "How big is the Japanese data?",
        "answer": "7000000 pairs of events were extracted from the Japanese Web corpus, 529850 pairs of events were extracted from the ACP corpus",
        "answer_2": "The ACP corpus has around 700k events split into positive and negative polarity ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            7,
            3,
            1,
            5,
            6,
            2,
            4
        ],
        "image-top-10-question_score": [
            12.327842712402344,
            12.022930145263672,
            11.476341247558594,
            10.735013961791992,
            10.619956970214844,
            10.547718048095703,
            10.538418769836426,
            10.315061569213867
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00694.pdf",
        "text-top-10-question": [
            7,
            2,
            7,
            0,
            0,
            0,
            3,
            4,
            5,
            4
        ],
        "text-top-10-question_score": [
            17.53125,
            17.109375,
            16.8125,
            16.21875,
            15.5546875,
            15.265625,
            15.0234375,
            13.625,
            13.328125,
            13.015625
        ]
    },
    {
        "doc_id": "1909.00694.pdf",
        "q_uid": "c029deb7f99756d2669abad0a349d917428e9c12",
        "question": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?",
        "answer": "3%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            3,
            1,
            2,
            7,
            5,
            6
        ],
        "image-top-10-question_score": [
            25.58673858642578,
            24.77499008178711,
            24.260543823242188,
            22.809417724609375,
            22.527769088745117,
            22.50212860107422,
            21.360782623291016,
            20.849197387695312
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00694.pdf",
        "text-top-10-question": [
            4,
            0,
            4,
            0,
            0,
            0,
            4,
            0,
            3,
            1
        ],
        "text-top-10-question_score": [
            13.9921875,
            13.9609375,
            13.9296875,
            13.6484375,
            13.4140625,
            12.5859375,
            12.3203125,
            12.3046875,
            11.9375,
            11.4140625
        ]
    },
    {
        "doc_id": "2003.07723.pdf",
        "q_uid": "3a9d391d25cde8af3334ac62d478b36b30079d74",
        "question": "Does the paper report macro F1?",
        "answer": "Yes",
        "answer_2": "Yes",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            3,
            8,
            2,
            10,
            9,
            4,
            1,
            0,
            6
        ],
        "image-top-10-question_score": [
            12.50991439819336,
            12.2203369140625,
            11.54135799407959,
            11.339455604553223,
            11.282060623168945,
            11.186805725097656,
            11.169994354248047,
            11.103381156921387,
            11.094551086425781,
            10.978799819946289
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.07723.pdf",
        "text-top-10-question": [
            3,
            4,
            7,
            7,
            2,
            7,
            7,
            1,
            8,
            1
        ],
        "text-top-10-question_score": [
            13.75,
            12.8125,
            12.578125,
            12.0078125,
            11.8359375,
            10.921875,
            10.890625,
            9.6796875,
            9.6640625,
            9.1484375
        ]
    },
    {
        "doc_id": "1910.14497.pdf",
        "q_uid": "8958465d1eaf81c8b781ba4d764a4f5329f026aa",
        "question": "What are the three measures of bias which are reduced in experiments?",
        "answer": "RIPA, Neighborhood Metric, WEAT",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            0,
            1,
            4,
            5,
            6
        ],
        "image-top-10-question_score": [
            16.3955078125,
            16.101287841796875,
            15.885223388671875,
            15.570995330810547,
            14.726900100708008,
            14.241830825805664,
            11.968587875366211
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.14497.pdf",
        "text-top-10-question": [
            0,
            0,
            1,
            0,
            2,
            3,
            1,
            2,
            1,
            1
        ],
        "text-top-10-question_score": [
            20.046875,
            18.390625,
            16.96875,
            16.640625,
            15.796875,
            15.75,
            15.1328125,
            15.0859375,
            14.6484375,
            14.546875
        ]
    },
    {
        "doc_id": "2003.12218.pdf",
        "q_uid": "4f243056e63a74d1349488983dc1238228ca76a7",
        "question": "Do they list all the named entity types present?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            2,
            1,
            3,
            4
        ],
        "image-top-10-question_score": [
            14.5692138671875,
            14.310712814331055,
            13.721675872802734,
            13.093961715698242,
            11.846301078796387
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.12218.pdf",
        "text-top-10-question": [
            1,
            1,
            0,
            2,
            0,
            2,
            1,
            0,
            1,
            2
        ],
        "text-top-10-question_score": [
            22.25,
            20.40625,
            19.984375,
            19.90625,
            19.265625,
            18.734375,
            17.5,
            17.3125,
            16.515625,
            16.3125
        ]
    },
    {
        "doc_id": "1904.09678.pdf",
        "q_uid": "8f87215f4709ee1eb9ddcc7900c6c054c970160b",
        "question": "how is quality measured?",
        "answer": "Accuracy and the macro-F1 (averaged F1 over positive and negative classes) are used as a measure of quality.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            5,
            0,
            6,
            4,
            7,
            2,
            8,
            3
        ],
        "image-top-10-question_score": [
            9.962526321411133,
            9.500941276550293,
            9.412384986877441,
            9.066728591918945,
            8.396317481994629,
            8.220282554626465,
            8.063422203063965,
            7.8092827796936035,
            7.30192756652832
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1904.09678.pdf",
        "text-top-10-question": [
            3,
            6,
            0,
            5,
            2,
            0,
            6,
            3,
            1,
            5
        ],
        "text-top-10-question_score": [
            13.65625,
            13.515625,
            13.34375,
            13.28125,
            12.2734375,
            11.9375,
            11.6015625,
            9.8515625,
            9.1484375,
            9.078125
        ]
    },
    {
        "doc_id": "1910.04269.pdf",
        "q_uid": "dc1fe3359faa2d7daa891c1df33df85558bc461b",
        "question": "Does the model use both spectrogram images and raw waveforms as features?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            1,
            11,
            2,
            13,
            10,
            0,
            12,
            9,
            8
        ],
        "image-top-10-question_score": [
            18.19780731201172,
            17.504459381103516,
            17.06485366821289,
            16.919818878173828,
            16.682098388671875,
            16.64883804321289,
            16.06366729736328,
            15.59981918334961,
            15.376174926757812,
            15.314874649047852
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.04269.pdf",
        "text-top-10-question": [
            1,
            1,
            0,
            4,
            4,
            10,
            2,
            10,
            2,
            11
        ],
        "text-top-10-question_score": [
            24.015625,
            21.65625,
            19.5625,
            19.484375,
            18.859375,
            18.234375,
            17.109375,
            17.0625,
            16.953125,
            16.640625
        ]
    },
    {
        "doc_id": "2001.00137.pdf",
        "q_uid": "3b745f086fb5849e7ce7ce2c02ccbde7cfdedda5",
        "question": "By how much do they outperform other models in the sentiment in intent classification tasks?",
        "answer": "In the sentiment classification task by 6% to 8% and in the intent classification task by 0.94% on average",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            18,
            11,
            15,
            3,
            4,
            16,
            23,
            21,
            17,
            5
        ],
        "image-top-10-question_score": [
            20.45578384399414,
            20.279006958007812,
            19.823631286621094,
            19.74274444580078,
            19.681133270263672,
            19.62342643737793,
            19.49224090576172,
            19.433549880981445,
            19.35733985900879,
            19.04288673400879
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.00137.pdf",
        "text-top-10-question": [
            23,
            18,
            3,
            16,
            21,
            11,
            21,
            2,
            20,
            3
        ],
        "text-top-10-question_score": [
            21.640625,
            21.09375,
            20.6875,
            19.296875,
            18.5625,
            18.03125,
            17.9375,
            17.921875,
            17.265625,
            17.0625
        ]
    },
    {
        "doc_id": "2002.06644.pdf",
        "q_uid": "680dc3e56d1dc4af46512284b9996a1056f89ded",
        "question": "What is the baseline for the experiments?",
        "answer": "FastText, BiLSTM, BERT",
        "answer_2": "FastText, BERT , two-layer BiLSTM architecture with GloVe word embeddings",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0
        ],
        "image-top-10-question_score": [
            13.318199157714844,
            11.760172843933105
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.06644.pdf",
        "text-top-10-question": [
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            0
        ],
        "text-top-10-question_score": [
            20.34375,
            19.1875,
            18.859375,
            16.75,
            13.9296875,
            12.546875,
            12.1953125,
            11.8046875,
            11.5390625,
            8.6875
        ]
    },
    {
        "doc_id": "1809.04960.pdf",
        "q_uid": "8cc56fc44136498471754186cfa04056017b4e54",
        "question": "By how much does their system outperform the lexicon-based models?",
        "answer": "Under the retrieval evaluation setting, their proposed model + IR2 had better MRR than NVDM by 0.3769, better MR by 4.6, and better Recall@10 by  20 . \nUnder the generative evaluation setting the proposed model + IR2 had better BLEU by 0.044 , better CIDEr by 0.033, better ROUGE by 0.032, and better METEOR by 0.029",
        "answer_2": "Proposed model is better than both lexical based models by significan margin in all metrics: BLEU 0.261 vs 0.250, ROUGLE 0.162 vs 0.155 etc.",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            0,
            3,
            5,
            4,
            2,
            7,
            1,
            8
        ],
        "image-top-10-question_score": [
            16.444015502929688,
            16.16733741760254,
            16.011953353881836,
            15.471986770629883,
            15.435378074645996,
            15.065892219543457,
            14.985739707946777,
            14.98089599609375,
            13.645990371704102
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.04960.pdf",
        "text-top-10-question": [
            6,
            0,
            1,
            6,
            5,
            6,
            5,
            5,
            3,
            3
        ],
        "text-top-10-question_score": [
            19.203125,
            18.453125,
            18.0,
            16.59375,
            16.359375,
            16.046875,
            16.0,
            15.5703125,
            15.078125,
            13.7421875
        ]
    },
    {
        "doc_id": "1909.08859.pdf",
        "q_uid": "171ebfdc9b3a98e4cdee8f8715003285caeb2f39",
        "question": "How better is accuracy of new model compared to previously reported models?",
        "answer": "Average accuracy of proposed model vs best prevous result:\nSingle-task Training: 57.57 vs 55.06\nMulti-task Training: 50.17 vs 50.59",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            5,
            0,
            6,
            2,
            7,
            3,
            1,
            4,
            9
        ],
        "image-top-10-question_score": [
            16.707162857055664,
            16.521249771118164,
            16.45484161376953,
            15.809106826782227,
            15.420074462890625,
            15.318222045898438,
            14.455892562866211,
            14.206279754638672,
            14.129471778869629,
            13.780926704406738
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.08859.pdf",
        "text-top-10-question": [
            0,
            8,
            5,
            5,
            0,
            6,
            6,
            0,
            7,
            7
        ],
        "text-top-10-question_score": [
            19.71875,
            14.9921875,
            14.8046875,
            14.5546875,
            14.3984375,
            13.46875,
            12.3125,
            11.828125,
            11.7265625,
            11.4453125
        ]
    },
    {
        "doc_id": "1905.00563.pdf",
        "q_uid": "bc9c31b3ce8126d1d148b1025c66f270581fde10",
        "question": "What datasets are used to evaluate this approach?",
        "answer": " Kinship and Nations knowledge graphs, YAGO3-10 and WN18KGs knowledge graphs ",
        "answer_2": "WN18 and YAGO3-10",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            8,
            1,
            6,
            0,
            5,
            3,
            7,
            11,
            2
        ],
        "image-top-10-question_score": [
            14.936301231384277,
            14.078298568725586,
            14.044004440307617,
            13.83996295928955,
            13.767386436462402,
            13.707775115966797,
            13.617776870727539,
            13.492036819458008,
            13.411198616027832,
            13.185288429260254
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1905.00563.pdf",
        "text-top-10-question": [
            4,
            3,
            4,
            0,
            8,
            0,
            1,
            8,
            1,
            7
        ],
        "text-top-10-question_score": [
            21.484375,
            20.25,
            18.234375,
            16.140625,
            16.03125,
            15.25,
            14.6953125,
            14.4921875,
            14.234375,
            14.1328125
        ]
    },
    {
        "doc_id": "1902.00330.pdf",
        "q_uid": "b0376a7f67f1568a7926eff8ff557a93f434a253",
        "question": "How big is the performance difference between this method and the baseline?",
        "answer": "Comparing with the highest performing baseline: 1.3 points on ACE2004 dataset, 0.6 points on CWEB dataset, and 0.86 points in the average of all scores.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            5,
            1,
            4,
            7,
            8,
            0,
            3,
            2,
            9
        ],
        "image-top-10-question_score": [
            17.187908172607422,
            16.41407012939453,
            15.343451499938965,
            15.334206581115723,
            15.300559997558594,
            14.527493476867676,
            14.416853904724121,
            14.387349128723145,
            14.33140754699707,
            13.624177932739258
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1902.00330.pdf",
        "text-top-10-question": [
            6,
            5,
            4,
            5,
            6,
            6,
            4,
            6,
            8,
            5
        ],
        "text-top-10-question_score": [
            13.5703125,
            11.7421875,
            11.2578125,
            10.90625,
            10.8203125,
            9.671875,
            9.609375,
            9.140625,
            9.09375,
            8.9609375
        ]
    },
    {
        "doc_id": "1810.06743.pdf",
        "q_uid": "564dcaf8d0bcc274ab64c784e4c0f50d7a2c17ee",
        "question": "Which languages do they validate on?",
        "answer": "Ar, Bg, Ca, Cs, Da, De, En, Es, Eu, Fa, Fi, Fr, Ga, He, Hi, Hu, It, La, Lt, Lv, Nb, Nl, Nn, PL, Pt, Ro, Ru, Sl, Sv, Tr, Uk, Ur",
        "answer_2": "We apply this conversion to the 31 languages, Arabic, Hindi, Lithuanian, Persian, and Russian. , Dutch, Spanish",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            7,
            0,
            1,
            6,
            3,
            10,
            5,
            2,
            4
        ],
        "image-top-10-question_score": [
            11.253133773803711,
            10.905130386352539,
            10.680126190185547,
            10.673763275146484,
            10.601041793823242,
            10.50119400024414,
            10.40539264678955,
            10.356498718261719,
            9.97541618347168,
            9.96701431274414
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.06743.pdf",
        "text-top-10-question": [
            0,
            0,
            1,
            6,
            7,
            8,
            6,
            10,
            4,
            10
        ],
        "text-top-10-question_score": [
            17.046875,
            12.921875,
            12.890625,
            11.9921875,
            11.6015625,
            11.28125,
            10.921875,
            10.8203125,
            10.703125,
            10.671875
        ]
    },
    {
        "doc_id": "1905.11901.pdf",
        "q_uid": "4547818a3bbb727c4bb4a76554b5a5a7b5c5fedb",
        "question": "what amounts of size were used on german-english?",
        "answer": "Training data with 159000, 80000, 40000, 20000, 10000 and 5000 sentences, and 7584 sentences for development",
        "answer_2": "ultra-low data condition (100k words of training data) and the full IWSLT 14 training corpus (3.2M words)",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            4,
            10,
            8,
            0,
            5,
            6,
            1,
            7
        ],
        "image-top-10-question_score": [
            15.361345291137695,
            15.207696914672852,
            14.907737731933594,
            14.783365249633789,
            13.971017837524414,
            13.365140914916992,
            13.207308769226074,
            12.806363105773926,
            12.598823547363281,
            12.54829216003418
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1905.11901.pdf",
        "text-top-10-question": [
            3,
            3,
            2,
            0,
            2,
            3,
            1,
            8,
            1,
            3
        ],
        "text-top-10-question_score": [
            19.71875,
            17.6875,
            17.59375,
            14.78125,
            14.203125,
            13.3671875,
            13.0390625,
            12.90625,
            12.4296875,
            12.0
        ]
    },
    {
        "doc_id": "1912.13109.pdf",
        "q_uid": "5908d7fb6c48f975c5dfc5b19bb0765581df2b25",
        "question": "How big is the dataset?",
        "answer": "3189 rows of text messages",
        "answer_2": "Resulting dataset was 7934 messages for train and 700 messages for test.",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            3,
            2,
            0,
            4,
            5
        ],
        "image-top-10-question_score": [
            12.758594512939453,
            12.404730796813965,
            12.232646942138672,
            11.848092079162598,
            11.515911102294922,
            11.267131805419922
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.13109.pdf",
        "text-top-10-question": [
            1,
            1,
            1,
            4,
            4,
            1,
            2,
            0,
            2,
            5
        ],
        "text-top-10-question_score": [
            16.875,
            16.609375,
            16.4375,
            13.9453125,
            13.546875,
            12.9296875,
            12.4375,
            12.234375,
            12.0078125,
            11.84375
        ]
    },
    {
        "doc_id": "1911.03310.pdf",
        "q_uid": "66125cfdf11d3bf8e59728428e02021177142c3a",
        "question": "How they demonstrate that language-neutral component is sufficiently general in terms of modeling semantics to allow high-accuracy word-alignment?",
        "answer": "Table TABREF15 shows that word-alignment based on mBERT representations surpasses the outputs of the standard FastAlign tool even if it was provided large parallel corpus. This suggests that word-level semantics are well captured by mBERT contextual embeddings. For this task, learning an explicit projection had a negligible effect on the performance.",
        "answer_2": "explicit projection had a negligible effect on the performance",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            3,
            4,
            5,
            2
        ],
        "image-top-10-question_score": [
            27.981544494628906,
            27.58920669555664,
            27.155935287475586,
            26.264705657958984,
            25.614696502685547,
            25.470430374145508
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.03310.pdf",
        "text-top-10-question": [
            0,
            3,
            0,
            0,
            1,
            3,
            4,
            1,
            4,
            2
        ],
        "text-top-10-question_score": [
            21.890625,
            19.78125,
            19.578125,
            18.140625,
            16.984375,
            16.234375,
            16.0625,
            15.84375,
            15.796875,
            15.7890625
        ]
    },
    {
        "doc_id": "1909.00578.pdf",
        "q_uid": "ff28d34d1aaa57e7ad553dba09fc924dc21dd728",
        "question": "What are their correlation results?",
        "answer": "High correlation results range from 0.472 to 0.936",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            4,
            0,
            1,
            5,
            6
        ],
        "image-top-10-question_score": [
            12.60243034362793,
            11.983235359191895,
            11.36638069152832,
            11.11784839630127,
            11.068366050720215,
            9.672090530395508,
            9.314026832580566
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00578.pdf",
        "text-top-10-question": [
            3,
            3,
            4,
            4,
            2,
            0,
            4,
            2,
            0,
            5
        ],
        "text-top-10-question_score": [
            16.765625,
            16.25,
            14.796875,
            14.4375,
            14.28125,
            13.5390625,
            12.4140625,
            12.0703125,
            10.40625,
            9.7890625
        ]
    },
    {
        "doc_id": "1904.05584.pdf",
        "q_uid": "323e100a6c92d3fe503f7a93b96d821408f92109",
        "question": "Which downstream sentence-level tasks do they evaluate on?",
        "answer": "BIBREF13 , BIBREF18",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            3,
            6,
            5,
            8,
            0,
            14,
            12,
            1,
            9
        ],
        "image-top-10-question_score": [
            16.698196411132812,
            16.042579650878906,
            15.814994812011719,
            15.605057716369629,
            15.143805503845215,
            14.631671905517578,
            14.617820739746094,
            14.593988418579102,
            14.371166229248047,
            14.357667922973633
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1904.05584.pdf",
        "text-top-10-question": [
            3,
            7,
            6,
            7,
            1,
            3,
            11,
            0,
            11,
            0
        ],
        "text-top-10-question_score": [
            24.53125,
            23.8125,
            23.640625,
            23.640625,
            21.640625,
            21.015625,
            20.859375,
            20.765625,
            20.109375,
            18.859375
        ]
    },
    {
        "doc_id": "1910.03891.pdf",
        "q_uid": "52f7e42fe8f27d800d1189251dfec7446f0e1d3b",
        "question": "How much better is performance of proposed method than state-of-the-art methods in experiments?",
        "answer": "Accuracy of best proposed method KANE (LSTM+Concatenation) are 0.8011, 0.8592, 0.8605 compared to best state-of-the art method R-GCN + LR 0.7721, 0.8193, 0.8229 on three datasets respectively.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            5,
            1,
            6,
            2,
            0,
            3,
            7
        ],
        "image-top-10-question_score": [
            22.830015182495117,
            22.57103729248047,
            21.713022232055664,
            20.750125885009766,
            20.67467498779297,
            20.04360580444336,
            19.96731185913086,
            19.160663604736328
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.03891.pdf",
        "text-top-10-question": [
            1,
            1,
            5,
            4,
            0,
            4,
            1,
            6,
            1,
            5
        ],
        "text-top-10-question_score": [
            17.4375,
            16.234375,
            15.96875,
            14.859375,
            14.390625,
            14.2734375,
            13.1796875,
            13.1640625,
            13.1171875,
            12.8046875
        ]
    },
    {
        "doc_id": "1610.00879.pdf",
        "q_uid": "6412e97373e8e9ae3aa20aa17abef8326dc05450",
        "question": "What baseline model is used?",
        "answer": "Human evaluators",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            2,
            1,
            5,
            0
        ],
        "image-top-10-question_score": [
            11.023904800415039,
            10.755511283874512,
            10.385046005249023,
            10.377914428710938,
            9.998987197875977,
            9.880172729492188
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1610.00879.pdf",
        "text-top-10-question": [
            2,
            3,
            0,
            3,
            0,
            1,
            2,
            4,
            2,
            1
        ],
        "text-top-10-question_score": [
            11.234375,
            10.1171875,
            8.9296875,
            8.828125,
            8.6875,
            8.546875,
            8.3203125,
            8.0078125,
            7.9609375,
            7.890625
        ]
    },
    {
        "doc_id": "1610.00879.pdf",
        "q_uid": "957bda6b421ef7d2839c3cec083404ac77721f14",
        "question": "What stylistic features are used to detect drunk texts?",
        "answer": "LDA unigrams (Presence/Count), POS Ratio, #Named Entity Mentions, #Discourse Connectors,  Spelling errors, Repeated characters, Capitalisation, Length,  Emoticon (Presence/Count ) \n and Sentiment Ratio",
        "answer_2": "LDA unigrams (Presence/Count), POS Ratio, #Named Entity Mentions, #Discourse Connectors, Spelling errors, Repeated characters, Capitalization, Length, Emoticon (Presence/Count), Sentiment Ratio.",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            2,
            1,
            3,
            4,
            5
        ],
        "image-top-10-question_score": [
            15.660455703735352,
            15.51469898223877,
            15.37404727935791,
            15.32426929473877,
            14.54926586151123,
            12.52724552154541
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1610.00879.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            3,
            4,
            2,
            3,
            0,
            3,
            3
        ],
        "text-top-10-question_score": [
            23.3125,
            22.671875,
            22.609375,
            21.453125,
            21.375,
            20.421875,
            20.21875,
            19.3125,
            19.0625,
            17.9375
        ]
    },
    {
        "doc_id": "1704.05572.pdf",
        "q_uid": "eb95af36347ed0e0808e19963fe4d058e2ce3c9f",
        "question": "What is the accuracy of the proposed technique?",
        "answer": "51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            1,
            2,
            4,
            5,
            6
        ],
        "image-top-10-question_score": [
            12.179290771484375,
            11.999639511108398,
            11.513189315795898,
            11.468741416931152,
            11.426692962646484,
            11.301813125610352,
            10.933839797973633
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1704.05572.pdf",
        "text-top-10-question": [
            1,
            0,
            4,
            4,
            5,
            4,
            3,
            0,
            4,
            0
        ],
        "text-top-10-question_score": [
            16.40625,
            13.25,
            11.4765625,
            10.4453125,
            9.734375,
            9.640625,
            9.3984375,
            9.375,
            9.2734375,
            8.984375
        ]
    },
    {
        "doc_id": "1911.07228.pdf",
        "q_uid": "71d59c36225b5ee80af11d3568bdad7425f17b0c",
        "question": "How much better was the BLSTM-CNN-CRF than the BLSTM-CRF?",
        "answer": "Best BLSTM-CNN-CRF had F1 score 86.87 vs 86.69 of best BLSTM-CRF ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            2,
            1,
            0,
            3,
            5,
            10,
            8,
            4,
            7
        ],
        "image-top-10-question_score": [
            21.6668701171875,
            20.93618392944336,
            20.49925422668457,
            19.523605346679688,
            19.35913848876953,
            18.337005615234375,
            17.261547088623047,
            16.923131942749023,
            16.835186004638672,
            15.636180877685547
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.07228.pdf",
        "text-top-10-question": [
            5,
            1,
            0,
            5,
            0,
            2,
            1,
            10,
            10,
            6
        ],
        "text-top-10-question_score": [
            19.578125,
            19.375,
            19.28125,
            18.8125,
            18.71875,
            18.421875,
            17.09375,
            16.5,
            15.765625,
            15.15625
        ]
    },
    {
        "doc_id": "1603.07044.pdf",
        "q_uid": "08333e4dd1da7d6b5e9b645d40ec9d502823f5d7",
        "question": "How much performance gap between their approach and the strong handcrafted method?",
        "answer": "0.007 MAP on Task A, 0.032 MAP on Task B, 0.055 MAP on Task C",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            1,
            7,
            3,
            6,
            8,
            2,
            4
        ],
        "image-top-10-question_score": [
            15.489168167114258,
            14.263825416564941,
            14.175418853759766,
            14.078102111816406,
            14.07744312286377,
            13.764281272888184,
            13.464648246765137,
            13.34007740020752,
            13.223703384399414
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1603.07044.pdf",
        "text-top-10-question": [
            0,
            0,
            3,
            5,
            5,
            7,
            3,
            6,
            0,
            5
        ],
        "text-top-10-question_score": [
            14.1171875,
            12.8515625,
            12.3515625,
            11.0625,
            10.9609375,
            10.9453125,
            9.8203125,
            9.2734375,
            9.21875,
            9.1953125
        ]
    },
    {
        "doc_id": "1902.09314.pdf",
        "q_uid": "8434974090491a3c00eed4f22a878f0b70970713",
        "question": "How big is their model?",
        "answer": "Proposed model has 1.16 million parameters and 11.04 MB.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            1,
            0,
            2,
            3,
            6
        ],
        "image-top-10-question_score": [
            11.41120719909668,
            10.997553825378418,
            10.935941696166992,
            10.462684631347656,
            10.342412948608398,
            10.30674934387207,
            9.285608291625977
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1902.09314.pdf",
        "text-top-10-question": [
            5,
            3,
            5,
            5,
            5,
            1,
            1,
            1,
            1,
            0
        ],
        "text-top-10-question_score": [
            19.765625,
            16.6875,
            16.390625,
            14.453125,
            13.9609375,
            12.71875,
            11.71875,
            11.6796875,
            10.609375,
            10.5703125
        ]
    },
    {
        "doc_id": "1910.11769.pdf",
        "q_uid": "a4e66e842be1438e5cd8d7cb2a2c589f494aee27",
        "question": "Which tested technique was the worst performer?",
        "answer": "Depeche + SVM",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            2,
            1,
            4,
            3,
            6,
            5
        ],
        "image-top-10-question_score": [
            12.661893844604492,
            11.964816093444824,
            11.559028625488281,
            11.488038063049316,
            11.408525466918945,
            11.30544376373291,
            10.863195419311523
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.11769.pdf",
        "text-top-10-question": [
            2,
            4,
            2,
            4,
            0,
            4,
            4,
            2,
            0,
            0
        ],
        "text-top-10-question_score": [
            15.5234375,
            14.46875,
            13.5703125,
            12.65625,
            11.5546875,
            10.109375,
            9.0703125,
            8.828125,
            8.765625,
            7.953125
        ]
    },
    {
        "doc_id": "1909.13375.pdf",
        "q_uid": "579941de2838502027716bae88e33e79e69997a6",
        "question": "What is difference in peformance between proposed model and state-of-the art on other question types?",
        "answer": "For single-span questions, the proposed LARGE-SQUAD improve performance of the MTMSNlarge baseline for 2.1 EM and 1.55 F1.\nFor number type question,  MTMSNlarge baseline  have improvement over LARGE-SQUAD for 3,11  EM and  2,98 F1. \nFor date question,  LARGE-SQUAD have improvements in 2,02 EM but MTMSNlarge have improvement of 4,39 F1.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            0,
            2,
            1,
            5,
            6,
            4
        ],
        "image-top-10-question_score": [
            23.538921356201172,
            22.68763542175293,
            22.40256690979004,
            22.201570510864258,
            21.25929069519043,
            20.583404541015625,
            19.735897064208984
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.13375.pdf",
        "text-top-10-question": [
            3,
            0,
            0,
            0,
            0,
            2,
            2,
            3,
            2,
            3
        ],
        "text-top-10-question_score": [
            13.78125,
            13.546875,
            13.203125,
            13.0859375,
            12.9296875,
            11.875,
            11.765625,
            11.65625,
            11.5,
            11.390625
        ]
    },
    {
        "doc_id": "1909.13375.pdf",
        "q_uid": "9a65cfff4d99e4f9546c72dece2520cae6231810",
        "question": "What is the performance of proposed model on entire DROP dataset?",
        "answer": "The proposed model achieves  EM 77,63 and F1 80,73  on the test and EM  76,95 and  F1 80,25 on the dev",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            0,
            2,
            5,
            1,
            6,
            4
        ],
        "image-top-10-question_score": [
            17.19992446899414,
            16.639575958251953,
            16.357070922851562,
            16.27205467224121,
            15.836544036865234,
            15.697250366210938,
            15.571592330932617
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.13375.pdf",
        "text-top-10-question": [
            0,
            3,
            1,
            2,
            3,
            2,
            3,
            2,
            5,
            3
        ],
        "text-top-10-question_score": [
            20.453125,
            20.390625,
            19.71875,
            17.984375,
            17.875,
            17.546875,
            17.328125,
            17.015625,
            16.546875,
            16.28125
        ]
    },
    {
        "doc_id": "1909.00430.pdf",
        "q_uid": "47a30eb4d0d6f5f2ff4cdf6487265a25c1b18fd8",
        "question": "Does the system trained only using XR loss outperform the fully supervised neural system?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            6,
            7,
            3,
            0,
            8,
            4,
            5,
            2,
            9
        ],
        "image-top-10-question_score": [
            18.52065086364746,
            18.25806427001953,
            18.2103271484375,
            18.053009033203125,
            17.89620590209961,
            17.853130340576172,
            17.589624404907227,
            17.13382339477539,
            16.609649658203125,
            15.173784255981445
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00430.pdf",
        "text-top-10-question": [
            1,
            3,
            0,
            6,
            5,
            6,
            1,
            7,
            8,
            5
        ],
        "text-top-10-question_score": [
            19.625,
            18.546875,
            18.53125,
            18.109375,
            17.203125,
            17.015625,
            16.921875,
            16.65625,
            16.4375,
            16.046875
        ]
    },
    {
        "doc_id": "1909.00430.pdf",
        "q_uid": "e42fbf6c183abf1c6c2321957359c7683122b48e",
        "question": "How accurate is the aspect based sentiment classifier trained only using the XR loss?",
        "answer": "BiLSTM-XR-Dev Estimation accuracy is 83.31 for SemEval-15 and 87.68 for SemEval-16.\nBiLSTM-XR accuracy is 83.31 for SemEval-15 and 88.12 for SemEval-16.\n",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            1,
            3,
            6,
            7,
            0,
            5,
            2,
            4,
            9
        ],
        "image-top-10-question_score": [
            19.20035171508789,
            19.056812286376953,
            19.05652618408203,
            18.943954467773438,
            18.686504364013672,
            18.366539001464844,
            18.155725479125977,
            17.971874237060547,
            17.810989379882812,
            16.73138999938965
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00430.pdf",
        "text-top-10-question": [
            1,
            3,
            3,
            6,
            5,
            1,
            2,
            8,
            7,
            5
        ],
        "text-top-10-question_score": [
            23.703125,
            22.46875,
            21.15625,
            20.546875,
            20.5,
            20.015625,
            20.015625,
            19.703125,
            19.296875,
            19.015625
        ]
    },
    {
        "doc_id": "1910.00912.pdf",
        "q_uid": "7c794fa0b2818d354ca666969107818a2ffdda0c",
        "question": "What metrics other than entity tagging are compared?",
        "answer": "We also report the metrics in BIBREF7 for consistency, we report the span F1,  Exact Match (EM) accuracy of the entire sequence of labels, metric that combines intent and entities",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            6,
            1,
            7,
            3,
            4,
            2,
            9,
            8,
            0
        ],
        "image-top-10-question_score": [
            14.358949661254883,
            13.619586944580078,
            13.128080368041992,
            13.08918571472168,
            12.633624076843262,
            12.440483093261719,
            12.382429122924805,
            11.573076248168945,
            11.04135513305664,
            10.779141426086426
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.00912.pdf",
        "text-top-10-question": [
            5,
            5,
            5,
            5,
            5,
            6,
            5,
            5,
            6,
            6
        ],
        "text-top-10-question_score": [
            21.328125,
            20.09375,
            17.46875,
            16.78125,
            16.6875,
            15.9453125,
            15.546875,
            14.75,
            14.2890625,
            14.09375
        ]
    },
    {
        "doc_id": "1910.03814.pdf",
        "q_uid": "4e9684fd68a242cb354fa6961b0e3b5c35aae4b6",
        "question": "What is the results of multimodal compared to unimodal models?",
        "answer": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            6,
            0,
            7,
            3,
            2,
            1,
            5
        ],
        "image-top-10-question_score": [
            16.360929489135742,
            15.532547950744629,
            15.432621002197266,
            15.149850845336914,
            14.952390670776367,
            14.569969177246094,
            14.223227500915527,
            13.464723587036133
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.03814.pdf",
        "text-top-10-question": [
            0,
            0,
            4,
            6,
            4,
            0,
            6,
            7,
            2,
            2
        ],
        "text-top-10-question_score": [
            21.15625,
            21.109375,
            21.0,
            20.953125,
            19.25,
            18.6875,
            18.5625,
            18.359375,
            18.0625,
            17.765625
        ]
    },
    {
        "doc_id": "1701.00185.pdf",
        "q_uid": "9e04730907ad728d62049f49ac828acb4e0a1a2a",
        "question": "What were their performance results?",
        "answer": "On SearchSnippets dataset ACC 77.01%, NMI 62.94%, on StackOverflow dataset ACC 51.14%, NMI 49.08%, on Biomedical dataset ACC 43.00%, NMI 38.18%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            18,
            24,
            2,
            22,
            16,
            21,
            20,
            6,
            26,
            1
        ],
        "image-top-10-question_score": [
            11.463472366333008,
            11.170282363891602,
            10.96543025970459,
            10.717809677124023,
            10.57676887512207,
            10.439749717712402,
            10.367527961730957,
            10.090204238891602,
            10.027983665466309,
            9.82368278503418
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1701.00185.pdf",
        "text-top-10-question": [
            21,
            16,
            18,
            24,
            22,
            2,
            20,
            24,
            16,
            16
        ],
        "text-top-10-question_score": [
            18.28125,
            17.90625,
            17.078125,
            16.796875,
            16.390625,
            15.96875,
            15.2578125,
            15.0625,
            14.6484375,
            14.1953125
        ]
    },
    {
        "doc_id": "1701.00185.pdf",
        "q_uid": "5a0841cc0628e872fe473874694f4ab9411a1d10",
        "question": "By how much did they outperform the other methods?",
        "answer": "on SearchSnippets dataset by 6.72% in ACC, by 6.94% in NMI; on Biomedical dataset by 5.77% in ACC, 3.91% in NMI",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            21,
            18,
            19,
            20,
            16,
            1,
            24,
            31,
            10,
            32
        ],
        "image-top-10-question_score": [
            14.791318893432617,
            14.62016773223877,
            14.540691375732422,
            14.439691543579102,
            13.868070602416992,
            13.769774436950684,
            13.726834297180176,
            13.607223510742188,
            13.486541748046875,
            13.48281192779541
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1701.00185.pdf",
        "text-top-10-question": [
            21,
            0,
            20,
            6,
            15,
            20,
            18,
            14,
            21,
            14
        ],
        "text-top-10-question_score": [
            16.46875,
            15.515625,
            15.015625,
            14.1015625,
            12.4140625,
            12.390625,
            12.21875,
            11.9140625,
            11.6796875,
            11.640625
        ]
    },
    {
        "doc_id": "1912.01673.pdf",
        "q_uid": "2d536961c6e1aec9f8491e41e383dc0aac700e0a",
        "question": "What are all 15 types of modifications ilustrated in the dataset?",
        "answer": "- paraphrase 1\n- paraphrase 2\n- different meaning\n- opposite meaning\n- nonsense\n- minimal change\n- generalization\n- gossip\n- formal sentence\n- non-standard sentence\n- simple sentence\n- possibility\n- ban\n- future\n- past",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            0,
            3,
            4,
            1,
            5,
            6
        ],
        "image-top-10-question_score": [
            17.94026756286621,
            16.80107879638672,
            16.498977661132812,
            16.293689727783203,
            16.038864135742188,
            15.885589599609375,
            15.797602653503418
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.01673.pdf",
        "text-top-10-question": [
            2,
            2,
            0,
            2,
            3,
            2,
            1,
            1,
            0,
            0
        ],
        "text-top-10-question_score": [
            15.0703125,
            14.8125,
            13.8125,
            13.140625,
            12.8515625,
            12.0546875,
            11.7734375,
            11.640625,
            11.3984375,
            11.0546875
        ]
    },
    {
        "doc_id": "1706.08032.pdf",
        "q_uid": "efb3a87845460655c53bd7365bcb8393c99358ec",
        "question": "What were their results on the three datasets?",
        "answer": "accuracy of 86.63 on STS, 85.14 on Sanders and 80.9 on HCR",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            5,
            1,
            0,
            2,
            3
        ],
        "image-top-10-question_score": [
            14.760486602783203,
            13.935860633850098,
            13.807068824768066,
            13.57064437866211,
            13.14120864868164,
            12.436962127685547
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1706.08032.pdf",
        "text-top-10-question": [
            4,
            4,
            0,
            4,
            0,
            4,
            1,
            5,
            1,
            0
        ],
        "text-top-10-question_score": [
            18.015625,
            14.9453125,
            14.8828125,
            14.859375,
            14.0390625,
            13.6171875,
            13.1953125,
            12.4296875,
            11.8203125,
            11.75
        ]
    },
    {
        "doc_id": "1706.08032.pdf",
        "q_uid": "d60a3887a0d434abc0861637bbcd9ad0c596caf4",
        "question": "What semantic rules are proposed?",
        "answer": "rules that compute polarity of words after POS tagging or parsing steps",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            4,
            5,
            0,
            3
        ],
        "image-top-10-question_score": [
            13.030202865600586,
            12.333358764648438,
            11.19509506225586,
            11.055968284606934,
            10.66901683807373,
            9.905801773071289
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1706.08032.pdf",
        "text-top-10-question": [
            2,
            2,
            1,
            2,
            4,
            1,
            0,
            0,
            4,
            2
        ],
        "text-top-10-question_score": [
            24.765625,
            21.546875,
            21.171875,
            19.59375,
            18.15625,
            17.859375,
            16.453125,
            15.75,
            14.1796875,
            11.9375
        ]
    },
    {
        "doc_id": "1911.01799.pdf",
        "q_uid": "8c0a0747a970f6ea607ff9b18cfeb738502d9a95",
        "question": "What was the performance of both approaches on their dataset?",
        "answer": "ERR of 19.05 with i-vectors and 15.52 with x-vectors",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            1,
            0,
            4,
            5
        ],
        "image-top-10-question_score": [
            15.26038932800293,
            14.49921989440918,
            14.26910400390625,
            14.25406265258789,
            13.506771087646484,
            13.445524215698242
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.01799.pdf",
        "text-top-10-question": [
            3,
            3,
            0,
            0,
            3,
            3,
            3,
            3,
            0,
            0
        ],
        "text-top-10-question_score": [
            18.6875,
            18.640625,
            17.5,
            16.921875,
            16.6875,
            15.1953125,
            14.1484375,
            13.953125,
            13.828125,
            13.6171875
        ]
    },
    {
        "doc_id": "1911.01799.pdf",
        "q_uid": "a2be2bd84e5ae85de2ab9968147b3d49c84dfb7f",
        "question": "What genres are covered?",
        "answer": "genre, entertainment, interview, singing, play, movie, vlog, live broadcast, speech, drama, recitation and advertisement",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            2,
            0,
            4,
            5,
            3
        ],
        "image-top-10-question_score": [
            11.699433326721191,
            11.225151062011719,
            10.094293594360352,
            8.739901542663574,
            8.211225509643555,
            8.093795776367188
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.01799.pdf",
        "text-top-10-question": [
            0,
            1,
            2,
            1,
            0,
            1,
            2,
            0,
            1,
            2
        ],
        "text-top-10-question_score": [
            21.71875,
            20.265625,
            17.890625,
            17.234375,
            17.078125,
            13.734375,
            12.6484375,
            12.640625,
            12.5,
            10.109375
        ]
    },
    {
        "doc_id": "1911.01799.pdf",
        "q_uid": "944d5dbe0cfc64bf41ea36c11b1d378c408d40b8",
        "question": "Which of the two speech recognition models works better overall on CN-Celeb?",
        "answer": "x-vector",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            3,
            2,
            4,
            5
        ],
        "image-top-10-question_score": [
            19.79633140563965,
            19.527843475341797,
            19.222625732421875,
            18.533706665039062,
            16.814550399780273,
            15.782173156738281
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.01799.pdf",
        "text-top-10-question": [
            3,
            0,
            3,
            0,
            2,
            3,
            1,
            3,
            0,
            3
        ],
        "text-top-10-question_score": [
            21.046875,
            19.53125,
            19.453125,
            18.59375,
            18.484375,
            18.484375,
            18.46875,
            18.046875,
            17.84375,
            17.78125
        ]
    },
    {
        "doc_id": "1911.01799.pdf",
        "q_uid": "327e6c6609fbd4c6ae76284ca639951f03eb4a4c",
        "question": "By how much is performance on CN-Celeb inferior to performance on VoxCeleb?",
        "answer": "For i-vector system, performances are 11.75% inferior to voxceleb. For x-vector system, performances are 10.74% inferior to voxceleb",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            0,
            1,
            2,
            4,
            5
        ],
        "image-top-10-question_score": [
            20.749282836914062,
            19.941577911376953,
            19.73684310913086,
            18.784923553466797,
            16.95431137084961,
            14.404760360717773
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.01799.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            0,
            3,
            3,
            3,
            1,
            0,
            0
        ],
        "text-top-10-question_score": [
            23.1875,
            22.0,
            21.984375,
            21.09375,
            20.90625,
            20.8125,
            20.59375,
            19.859375,
            19.796875,
            19.578125
        ]
    },
    {
        "doc_id": "1812.06705.pdf",
        "q_uid": "df8cc1f395486a12db98df805248eb37c087458b",
        "question": "On what datasets is the new model evaluated on?",
        "answer": "SST (Stanford Sentiment Treebank), Subj (Subjectivity dataset), MPQA Opinion Corpus, RT is another movie review sentiment dataset, TREC is a dataset for classification of the six question types",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            5,
            3,
            6,
            1,
            7,
            2,
            0,
            8
        ],
        "image-top-10-question_score": [
            14.76117992401123,
            14.435271263122559,
            14.174243927001953,
            14.135318756103516,
            13.794569969177246,
            13.559274673461914,
            13.254347801208496,
            13.076160430908203,
            13.061986923217773
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1812.06705.pdf",
        "text-top-10-question": [
            4,
            3,
            3,
            4,
            6,
            6,
            3,
            5,
            6,
            5
        ],
        "text-top-10-question_score": [
            19.515625,
            17.171875,
            16.71875,
            16.15625,
            16.046875,
            15.734375,
            15.5,
            14.8515625,
            14.5546875,
            14.3984375
        ]
    },
    {
        "doc_id": "1812.06705.pdf",
        "q_uid": "6e97c06f998f09256be752fa75c24ba853b0db24",
        "question": "How do the authors measure performance?",
        "answer": "Accuracy across six datasets",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            6,
            4,
            1,
            0,
            8,
            7,
            2,
            3
        ],
        "image-top-10-question_score": [
            10.826745986938477,
            10.66507339477539,
            10.598237991333008,
            10.13637924194336,
            10.035655975341797,
            9.70673942565918,
            9.606412887573242,
            9.364850997924805,
            8.939111709594727
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1812.06705.pdf",
        "text-top-10-question": [
            5,
            5,
            5,
            8,
            8,
            4,
            5,
            6,
            6,
            7
        ],
        "text-top-10-question_score": [
            13.40625,
            13.1875,
            12.1953125,
            11.609375,
            11.5546875,
            11.0625,
            10.1953125,
            9.4609375,
            9.3671875,
            9.046875
        ]
    },
    {
        "doc_id": "1812.06705.pdf",
        "q_uid": "63bb39fd098786a510147f8ebc02408de350cb7c",
        "question": "Are other pretrained language models also evaluated for contextual augmentation? ",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            1,
            5,
            2,
            6,
            4,
            7,
            8
        ],
        "image-top-10-question_score": [
            17.38249969482422,
            17.099409103393555,
            17.094921112060547,
            16.91877555847168,
            16.764114379882812,
            16.58516502380371,
            16.521455764770508,
            16.454029083251953,
            13.256771087646484
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1812.06705.pdf",
        "text-top-10-question": [
            1,
            1,
            4,
            5,
            0,
            0,
            7,
            1,
            3,
            4
        ],
        "text-top-10-question_score": [
            21.765625,
            21.546875,
            21.21875,
            20.109375,
            19.578125,
            19.46875,
            19.21875,
            19.125,
            19.109375,
            18.96875
        ]
    },
    {
        "doc_id": "1905.08949.pdf",
        "q_uid": "999b20dc14cb3d389d9e3ba5466bc3869d2d6190",
        "question": "What is the latest paper covered by this survey?",
        "answer": "Kim et al. (2019)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            7,
            9,
            2,
            10,
            11,
            3,
            8,
            1,
            4
        ],
        "image-top-10-question_score": [
            14.685534477233887,
            14.624920845031738,
            12.489798545837402,
            12.43128776550293,
            12.345980644226074,
            12.299622535705566,
            11.932821273803711,
            11.903141021728516,
            11.234033584594727,
            11.172555923461914
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1905.08949.pdf",
        "text-top-10-question": [
            0,
            2,
            7,
            0,
            3,
            9,
            11,
            8,
            9,
            2
        ],
        "text-top-10-question_score": [
            13.046875,
            12.5,
            11.53125,
            11.484375,
            9.6328125,
            9.59375,
            9.5546875,
            9.5234375,
            9.4375,
            9.2890625
        ]
    },
    {
        "doc_id": "2001.06286.pdf",
        "q_uid": "6e962f1f23061f738f651177346b38fd440ff480",
        "question": "What is the state of the art?",
        "answer": "BERTje BIBREF8, an ULMFiT model (Universal Language Model Fine-tuning for Text Classification model) BIBREF19., mBERT",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            9,
            0,
            7,
            1,
            4,
            8,
            2,
            5,
            10
        ],
        "image-top-10-question_score": [
            13.579906463623047,
            12.27963638305664,
            12.237985610961914,
            12.213874816894531,
            12.002723693847656,
            11.956247329711914,
            11.901765823364258,
            11.813863754272461,
            11.77009391784668,
            11.55461597442627
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.06286.pdf",
        "text-top-10-question": [
            10,
            10,
            1,
            0,
            3,
            0,
            8,
            3,
            8,
            5
        ],
        "text-top-10-question_score": [
            18.34375,
            17.21875,
            15.8046875,
            15.5390625,
            15.109375,
            14.796875,
            12.640625,
            9.8828125,
            5.6953125,
            5.58203125
        ]
    },
    {
        "doc_id": "1902.00672.pdf",
        "q_uid": "babe72f0491e65beff0e5889380e8e32d7a81f78",
        "question": "How does the model compare with the MMR baseline?",
        "answer": " Moreover, our TL-TranSum method also outperforms other approaches such as MaxCover ( $5\\%$ ) and MRMR ( $7\\%$ )",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            19,
            20,
            6,
            21,
            23,
            18,
            2,
            17,
            24,
            3
        ],
        "image-top-10-question_score": [
            13.401409149169922,
            13.327125549316406,
            13.021038055419922,
            12.803779602050781,
            12.715898513793945,
            12.558140754699707,
            12.481216430664062,
            12.477645874023438,
            12.306072235107422,
            12.204654693603516
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1902.00672.pdf",
        "text-top-10-question": [
            20,
            19,
            18,
            21,
            9,
            7,
            2,
            20,
            8,
            21
        ],
        "text-top-10-question_score": [
            14.453125,
            13.9765625,
            13.6015625,
            13.5390625,
            13.2734375,
            12.8359375,
            12.7421875,
            12.625,
            12.5625,
            12.3828125
        ]
    },
    {
        "doc_id": "2001.10161.pdf",
        "q_uid": "c180f44667505ec03214d44f4970c0db487a8bae",
        "question": "How well did the system do?",
        "answer": "the neural approach is generally preferred by a greater percentage of participants than the rules or random, human-made game outperforms them all",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            5,
            4,
            2,
            3,
            6
        ],
        "image-top-10-question_score": [
            11.4269380569458,
            11.381271362304688,
            11.174152374267578,
            11.054574012756348,
            11.01474380493164,
            10.922149658203125,
            10.763185501098633
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.10161.pdf",
        "text-top-10-question": [
            1,
            1,
            5,
            1,
            4,
            0,
            3,
            5,
            0,
            2
        ],
        "text-top-10-question_score": [
            10.4921875,
            10.390625,
            10.1328125,
            9.6328125,
            9.1171875,
            9.0390625,
            8.7109375,
            6.83984375,
            6.38671875,
            6.09765625
        ]
    },
    {
        "doc_id": "1909.00279.pdf",
        "q_uid": "d484a71e23d128f146182dccc30001df35cdf93f",
        "question": "How much is proposed model better in perplexity and BLEU score than typical UMT models?",
        "answer": "Perplexity of the best model is 65.58 compared to best baseline 105.79.\nBleu of the best model is 6.57 compared to best baseline 5.50.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            6,
            5,
            0,
            2,
            7,
            4,
            3,
            1,
            9
        ],
        "image-top-10-question_score": [
            22.57964324951172,
            21.705076217651367,
            21.18538475036621,
            20.452316284179688,
            20.377960205078125,
            19.319387435913086,
            19.31370735168457,
            19.08344268798828,
            19.04146957397461,
            18.113187789916992
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00279.pdf",
        "text-top-10-question": [
            8,
            0,
            6,
            5,
            6,
            2,
            3,
            2,
            2,
            4
        ],
        "text-top-10-question_score": [
            19.625,
            17.140625,
            16.84375,
            16.046875,
            15.7265625,
            15.6171875,
            15.5625,
            15.3828125,
            14.234375,
            13.9453125
        ]
    },
    {
        "doc_id": "1701.02877.pdf",
        "q_uid": "94e0cf44345800ef46a8c7d52902f074a1139e1a",
        "question": "What web and user-generated NER datasets are used for the analysis?",
        "answer": "MUC, CoNLL, ACE, OntoNotes, MSM, Ritter, UMBC",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            30,
            3,
            0,
            27,
            1,
            22,
            5,
            2,
            18,
            29
        ],
        "image-top-10-question_score": [
            18.04324722290039,
            18.010889053344727,
            17.948524475097656,
            17.855804443359375,
            17.741539001464844,
            17.699010848999023,
            17.668113708496094,
            17.521848678588867,
            17.514970779418945,
            17.48664093017578
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1701.02877.pdf",
        "text-top-10-question": [
            26,
            0,
            29,
            10,
            4,
            34,
            4,
            22,
            3,
            5
        ],
        "text-top-10-question_score": [
            18.96875,
            18.921875,
            18.875,
            17.703125,
            17.640625,
            17.578125,
            17.515625,
            17.421875,
            17.375,
            16.90625
        ]
    },
    {
        "doc_id": "1911.00069.pdf",
        "q_uid": "5c90e1ed208911dbcae7e760a553e912f8c237a5",
        "question": "How big are the datasets?",
        "answer": "In-house dataset consists of  3716 documents \nACE05 dataset consists of  1635 documents",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            8,
            10,
            9,
            6,
            7,
            1,
            3,
            4,
            0
        ],
        "image-top-10-question_score": [
            12.682608604431152,
            11.764293670654297,
            11.539182662963867,
            11.48525619506836,
            11.432793617248535,
            10.78267765045166,
            10.465174674987793,
            10.397201538085938,
            10.375085830688477,
            10.30577278137207
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.00069.pdf",
        "text-top-10-question": [
            5,
            5,
            5,
            5,
            6,
            6,
            7,
            0,
            8,
            1
        ],
        "text-top-10-question_score": [
            15.515625,
            14.15625,
            13.046875,
            12.9609375,
            12.3359375,
            11.8203125,
            11.8125,
            11.75,
            10.859375,
            10.328125
        ]
    },
    {
        "doc_id": "1810.00663.pdf",
        "q_uid": "3aee5c856e0ee608a7664289ffdd11455d153234",
        "question": "What was the performance of their model?",
        "answer": "For test-repeated set, EM score of 61.17, F1 of 93.54, ED of 0.75 and GM of 61.36. For test-new set, EM score of 41.71, F1 of 91.02, ED of 1.22 and GM of 41.81",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            8,
            6,
            4,
            3,
            0,
            5,
            1,
            2,
            9
        ],
        "image-top-10-question_score": [
            14.353902816772461,
            13.983987808227539,
            13.380656242370605,
            12.887346267700195,
            12.637575149536133,
            12.556924819946289,
            12.461759567260742,
            11.677083969116211,
            10.40207290649414,
            10.212240219116211
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.00663.pdf",
        "text-top-10-question": [
            6,
            7,
            6,
            8,
            6,
            8,
            7,
            5,
            4,
            7
        ],
        "text-top-10-question_score": [
            21.375,
            19.8125,
            19.296875,
            18.8125,
            18.015625,
            17.21875,
            15.5078125,
            15.4921875,
            14.9140625,
            14.234375
        ]
    },
    {
        "doc_id": "1809.05752.pdf",
        "q_uid": "fbee81a9d90ff23603ee4f5986f9e8c0eb035b52",
        "question": "What are their initial results on this task?",
        "answer": "Achieved the highest per-domain scores on Substance (F1 \u2248 0.8) and the lowest scores on Interpersonal and Mood (F1 \u2248 0.5), and show consistency in per-domain performance rankings between MLP and RBF models.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            5,
            0,
            1,
            7,
            6,
            3,
            4,
            8,
            9
        ],
        "image-top-10-question_score": [
            11.556265830993652,
            11.277786254882812,
            11.27562427520752,
            11.177103996276855,
            10.620735168457031,
            10.528071403503418,
            10.249786376953125,
            9.874284744262695,
            9.167394638061523,
            9.014036178588867
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.05752.pdf",
        "text-top-10-question": [
            5,
            3,
            2,
            1,
            0,
            3,
            4,
            7,
            3,
            7
        ],
        "text-top-10-question_score": [
            13.640625,
            13.078125,
            12.34375,
            12.0703125,
            11.8125,
            10.8125,
            10.609375,
            10.609375,
            10.53125,
            10.4921875
        ]
    },
    {
        "doc_id": "1910.05154.pdf",
        "q_uid": "85abd60094c92eb16f39f861c6de8c2064807d02",
        "question": "What are the different bilingual models employed?",
        "answer": " Neural Machine Translation (NMT) models are trained between language pairs, using as source language the translation (word-level) and as target",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            0,
            1,
            4
        ],
        "image-top-10-question_score": [
            14.659016609191895,
            14.435769081115723,
            14.26531982421875,
            14.023218154907227,
            12.389424324035645
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.05154.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            2,
            0,
            0,
            2,
            1,
            1,
            1
        ],
        "text-top-10-question_score": [
            22.46875,
            21.3125,
            21.171875,
            20.15625,
            19.796875,
            19.046875,
            17.046875,
            16.921875,
            15.421875,
            14.0
        ]
    },
    {
        "doc_id": "1909.00754.pdf",
        "q_uid": "ed7a3e7fc1672f85a768613e7d1b419475950ab4",
        "question": "Does this approach perform better in the multi-domain or single-domain setting?",
        "answer": "single-domain setting",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            9,
            1,
            5,
            0,
            2,
            4,
            6,
            8,
            7,
            3
        ],
        "image-top-10-question_score": [
            19.491657257080078,
            19.465560913085938,
            19.184207916259766,
            19.00822639465332,
            17.920989990234375,
            17.885358810424805,
            17.6740779876709,
            17.532615661621094,
            17.360877990722656,
            17.112932205200195
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00754.pdf",
        "text-top-10-question": [
            0,
            5,
            8,
            6,
            0,
            7,
            7,
            9,
            9,
            6
        ],
        "text-top-10-question_score": [
            17.671875,
            15.6640625,
            15.5546875,
            15.515625,
            15.1484375,
            15.1171875,
            14.53125,
            14.4375,
            14.34375,
            14.0859375
        ]
    },
    {
        "doc_id": "2002.11402.pdf",
        "q_uid": "1771a55236823ed44d3ee537de2e85465bf03eaf",
        "question": "What is the difference in recall score between the systems?",
        "answer": "Between the model and Stanford, Spacy and Flair the differences are 42.91, 25.03, 69.8 with Traditional NERs as reference and  49.88, 43.36, 62.43 with Wikipedia titles as reference.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            0,
            3,
            1,
            5,
            4
        ],
        "image-top-10-question_score": [
            15.815048217773438,
            15.224224090576172,
            13.223316192626953,
            13.218015670776367,
            12.903839111328125,
            12.564414978027344
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.11402.pdf",
        "text-top-10-question": [
            2,
            2,
            0,
            2,
            2,
            0,
            0,
            1,
            1,
            3
        ],
        "text-top-10-question_score": [
            17.890625,
            15.6171875,
            15.375,
            14.09375,
            13.875,
            12.7734375,
            11.5,
            10.8984375,
            9.1015625,
            7.9375
        ]
    },
    {
        "doc_id": "2002.11402.pdf",
        "q_uid": "1d74fd1d38a5532d20ffae4abbadaeda225b6932",
        "question": "What is their f1 score and recall?",
        "answer": "F1 score and Recall are 68.66, 80.08 with Traditional NERs as reference and 59.56, 69.76 with Wikipedia titles as reference.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            0,
            5,
            1,
            3,
            4
        ],
        "image-top-10-question_score": [
            12.71961498260498,
            11.95960521697998,
            11.15636157989502,
            11.065287590026855,
            10.946090698242188,
            10.64179801940918
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.11402.pdf",
        "text-top-10-question": [
            0,
            2,
            2,
            2,
            0,
            1,
            2,
            0,
            1,
            1
        ],
        "text-top-10-question_score": [
            22.890625,
            20.890625,
            19.953125,
            18.6875,
            18.078125,
            16.875,
            16.765625,
            16.046875,
            8.296875,
            7.98828125
        ]
    },
    {
        "doc_id": "2002.00652.pdf",
        "q_uid": "cc9f0ac8ead575a9b485a51ddc06b9ecb2e2a44d",
        "question": "How big is improvement in performances of proposed model over state of the art?",
        "answer": "Compared with the previous SOTA without BERT on SParC, our model improves Ques.Match and Int.Match by $10.6$ and $5.4$ points, respectively.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            1,
            5,
            0,
            2,
            6,
            7
        ],
        "image-top-10-question_score": [
            18.267377853393555,
            17.679218292236328,
            17.428699493408203,
            16.89881134033203,
            16.437252044677734,
            15.5816650390625,
            15.569801330566406,
            14.251691818237305
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.00652.pdf",
        "text-top-10-question": [
            0,
            1,
            3,
            4,
            4,
            2,
            4,
            1,
            0,
            1
        ],
        "text-top-10-question_score": [
            15.828125,
            15.40625,
            14.5625,
            13.53125,
            13.1875,
            12.0078125,
            11.96875,
            11.90625,
            11.7265625,
            11.6640625
        ]
    },
    {
        "doc_id": "1905.06566.pdf",
        "q_uid": "fc8bc6a3c837a9d1c869b7ee90cf4e3c39bcd102",
        "question": "Is the baseline a non-heirarchical model like BERT?",
        "answer": "There were hierarchical and non-hierarchical baselines; BERT was one of those baselines",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            7,
            3,
            8,
            0,
            2,
            4,
            1,
            5,
            10
        ],
        "image-top-10-question_score": [
            16.16011619567871,
            16.154447555541992,
            15.538358688354492,
            15.342023849487305,
            14.935070037841797,
            14.776275634765625,
            14.627856254577637,
            14.517651557922363,
            14.120736122131348,
            12.540773391723633
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1905.06566.pdf",
        "text-top-10-question": [
            6,
            6,
            6,
            7,
            7,
            6,
            6,
            7,
            1,
            3
        ],
        "text-top-10-question_score": [
            18.28125,
            18.28125,
            17.90625,
            16.59375,
            13.1640625,
            12.84375,
            12.75,
            12.0703125,
            11.9765625,
            11.578125
        ]
    },
    {
        "doc_id": "1901.04899.pdf",
        "q_uid": "40e3639b79e2051bf6bce300d06548e7793daee0",
        "question": "Did they compare against other systems?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            2
        ],
        "image-top-10-question_score": [
            11.543716430664062,
            11.437664031982422,
            11.031431198120117
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.04899.pdf",
        "text-top-10-question": [
            0,
            0,
            2,
            0,
            1,
            2,
            0,
            1,
            2,
            2
        ],
        "text-top-10-question_score": [
            10.1640625,
            8.71875,
            7.2734375,
            6.39453125,
            6.390625,
            6.12890625,
            5.6640625,
            5.47265625,
            5.30859375,
            4.39453125
        ]
    },
    {
        "doc_id": "1606.05320.pdf",
        "q_uid": "6ea63327ffbab2fc734dd5c2414e59d3acc56ea5",
        "question": "How large is the gap in performance between the HMMs and the LSTMs?",
        "answer": "With similar number of parameters, the log likelihood is about 0.1 lower for LSTMs across datasets. When the number of parameters in LSTMs is increased, their log likelihood is up to 0.7 lower.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            0,
            3,
            4
        ],
        "image-top-10-question_score": [
            20.315494537353516,
            19.871246337890625,
            19.728477478027344,
            19.35240936279297,
            19.075380325317383
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1606.05320.pdf",
        "text-top-10-question": [
            1,
            4,
            2,
            4,
            1,
            0,
            4,
            2,
            2,
            3
        ],
        "text-top-10-question_score": [
            20.0625,
            18.765625,
            18.734375,
            18.453125,
            18.40625,
            18.0,
            17.953125,
            17.171875,
            17.09375,
            16.890625
        ]
    },
    {
        "doc_id": "1809.10644.pdf",
        "q_uid": "a3f108f60143d13fe38d911b1cc3b17bdffde3bd",
        "question": "what was their system's f1 performance?",
        "answer": "Proposed model achieves 0.86, 0.924, 0.71 F1 score on SR, HATE, HAR datasets respectively.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            6,
            7,
            1,
            0,
            4,
            3,
            5,
            8
        ],
        "image-top-10-question_score": [
            14.664545059204102,
            14.254247665405273,
            14.089969635009766,
            13.56783390045166,
            12.468238830566406,
            12.102344512939453,
            12.099827766418457,
            12.085210800170898,
            11.950641632080078
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.10644.pdf",
        "text-top-10-question": [
            0,
            2,
            0,
            2,
            7,
            6,
            2,
            7,
            6,
            0
        ],
        "text-top-10-question_score": [
            19.75,
            18.171875,
            18.078125,
            16.09375,
            15.7109375,
            14.3203125,
            14.1796875,
            13.859375,
            13.4921875,
            10.34375
        ]
    },
    {
        "doc_id": "1910.03467.pdf",
        "q_uid": "84737d871bde8058d8033e496179f7daec31c2d3",
        "question": "Is the supervised morphological learner tested on Japanese?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            1,
            3,
            2,
            4,
            0,
            6,
            7
        ],
        "image-top-10-question_score": [
            13.229326248168945,
            13.228212356567383,
            13.223920822143555,
            13.162660598754883,
            12.859134674072266,
            12.850096702575684,
            12.496420860290527,
            12.385168075561523
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.03467.pdf",
        "text-top-10-question": [
            0,
            7,
            2,
            0,
            3,
            5,
            1,
            2,
            4,
            6
        ],
        "text-top-10-question_score": [
            17.875,
            16.75,
            16.125,
            15.359375,
            15.359375,
            15.046875,
            14.84375,
            13.8359375,
            13.4765625,
            13.2265625
        ]
    },
    {
        "doc_id": "1908.07816.pdf",
        "q_uid": "c034f38a570d40360c3551a6469486044585c63c",
        "question": "How better is proposed method than baselines perpexity wise?",
        "answer": "Perplexity of proposed MEED model is 19.795 vs 19.913 of next best result on test set.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            6,
            3,
            2,
            4,
            9,
            8,
            7,
            1,
            0
        ],
        "image-top-10-question_score": [
            15.477407455444336,
            15.399961471557617,
            14.851909637451172,
            14.696308135986328,
            14.552597999572754,
            14.50755786895752,
            14.46796703338623,
            14.322953224182129,
            14.230610847473145,
            14.090740203857422
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.07816.pdf",
        "text-top-10-question": [
            0,
            0,
            5,
            8,
            5,
            7,
            5,
            9,
            2,
            5
        ],
        "text-top-10-question_score": [
            14.1953125,
            14.171875,
            13.4140625,
            11.6484375,
            11.34375,
            10.453125,
            10.3125,
            10.3046875,
            10.078125,
            9.6640625
        ]
    },
    {
        "doc_id": "1810.09774.pdf",
        "q_uid": "a48c6d968707bd79469527493a72bfb4ef217007",
        "question": "Which training dataset allowed for the best generalization to benchmark sets?",
        "answer": "MultiNLI",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            2,
            5,
            1,
            4,
            6,
            3,
            7,
            9,
            8
        ],
        "image-top-10-question_score": [
            16.838539123535156,
            15.946281433105469,
            15.859161376953125,
            15.572993278503418,
            15.00831413269043,
            14.954510688781738,
            14.263357162475586,
            13.904685974121094,
            13.697266578674316,
            13.678399085998535
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.09774.pdf",
        "text-top-10-question": [
            0,
            0,
            1,
            2,
            6,
            1,
            0,
            0,
            6,
            1
        ],
        "text-top-10-question_score": [
            20.453125,
            19.953125,
            18.984375,
            18.0,
            17.34375,
            17.0625,
            15.8984375,
            15.890625,
            15.7265625,
            15.6875
        ]
    },
    {
        "doc_id": "2004.03744.pdf",
        "q_uid": "5dfa59c116e0ceb428efd99bab19731aa3df4bbd",
        "question": "How many natural language explanations are human-written?",
        "answer": "Totally 6980 validation and test image-sentence pairs have been corrected.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            6,
            4,
            5,
            1,
            7,
            8,
            2
        ],
        "image-top-10-question_score": [
            15.636116027832031,
            14.419300079345703,
            14.09344482421875,
            13.886541366577148,
            13.400120735168457,
            12.630590438842773,
            12.482170104980469,
            10.828472137451172,
            10.740272521972656
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2004.03744.pdf",
        "text-top-10-question": [
            3,
            3,
            4,
            4,
            6,
            0,
            0,
            4,
            0,
            4
        ],
        "text-top-10-question_score": [
            20.265625,
            17.484375,
            17.265625,
            16.75,
            16.46875,
            16.265625,
            16.1875,
            15.0078125,
            14.59375,
            13.6796875
        ]
    },
    {
        "doc_id": "2001.06888.pdf",
        "q_uid": "8a871b136ccef78391922377f89491c923a77730",
        "question": "What are the baseline state of the art models?",
        "answer": "Stanford NER, BiLSTM+CRF, LSTM+CNN+CRF, T-NER and BiLSTM+CNN+Co-Attention",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            11,
            2,
            5,
            9,
            8,
            10,
            13,
            6,
            0,
            7
        ],
        "image-top-10-question_score": [
            15.64493465423584,
            14.784965515136719,
            14.722768783569336,
            14.691934585571289,
            14.591897010803223,
            14.582158088684082,
            14.463399887084961,
            14.345207214355469,
            14.316675186157227,
            14.015792846679688
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.06888.pdf",
        "text-top-10-question": [
            11,
            11,
            11,
            3,
            5,
            8,
            9,
            3,
            3,
            11
        ],
        "text-top-10-question_score": [
            17.484375,
            15.53125,
            15.3515625,
            14.5703125,
            14.046875,
            11.96875,
            10.7578125,
            10.375,
            10.2734375,
            10.015625
        ]
    },
    {
        "doc_id": "1709.10217.pdf",
        "q_uid": "96c09ece36a992762860cde4c110f1653c110d96",
        "question": "What was the result of the highest performing system?",
        "answer": "For task 1 best F1 score was 0.9391 on closed and 0.9414 on open test.\nFor task2 best result had: Ratio 0.3175 , Satisfaction 64.53, Fluency 0, Turns -1 and Guide 2",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            2,
            3,
            0,
            1
        ],
        "image-top-10-question_score": [
            13.65530014038086,
            13.595172882080078,
            13.377118110656738,
            13.037261009216309,
            13.032415390014648
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1709.10217.pdf",
        "text-top-10-question": [
            2,
            3,
            1,
            3,
            2,
            0,
            2,
            1,
            1,
            2
        ],
        "text-top-10-question_score": [
            14.3515625,
            13.9375,
            12.5625,
            11.8515625,
            11.3671875,
            10.796875,
            10.5,
            10.3515625,
            10.2421875,
            10.140625
        ]
    },
    {
        "doc_id": "1901.02262.pdf",
        "q_uid": "2d274c93901c193cf7ad227ab28b1436c5f410af",
        "question": "What are the baselines that Masque is compared against?",
        "answer": "BiDAF, Deep Cascade QA, S-Net+CES2S, BERT+Multi-PGNet, Selector+CCG, VNET, DECAPROP, MHPGM+NOIC, ConZNet, RMR+A2D",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            12,
            13,
            1,
            14,
            4,
            5,
            7,
            11,
            8
        ],
        "image-top-10-question_score": [
            15.175400733947754,
            15.140260696411133,
            15.015115737915039,
            14.891756057739258,
            14.808198928833008,
            14.462985038757324,
            14.202195167541504,
            14.032081604003906,
            13.879115104675293,
            13.85896110534668
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.02262.pdf",
        "text-top-10-question": [
            5,
            0,
            0,
            8,
            7,
            5,
            1,
            1,
            14,
            6
        ],
        "text-top-10-question_score": [
            18.65625,
            16.359375,
            15.59375,
            14.6328125,
            14.5078125,
            14.328125,
            13.984375,
            13.9609375,
            13.8359375,
            13.65625
        ]
    },
    {
        "doc_id": "1901.02262.pdf",
        "q_uid": "e63bde5c7b154fbe990c3185e2626d13a1bad171",
        "question": "What is the performance achieved on NarrativeQA?",
        "answer": "Bleu-1: 54.11, Bleu-4: 30.43, METEOR: 26.13, ROUGE-L: 59.87",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            7,
            12,
            8,
            14,
            5,
            0,
            9,
            4,
            11
        ],
        "image-top-10-question_score": [
            15.120672225952148,
            14.656050682067871,
            14.645544052124023,
            14.627420425415039,
            14.262116432189941,
            13.3846435546875,
            13.173256874084473,
            13.14293098449707,
            13.044893264770508,
            12.664897918701172
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.02262.pdf",
        "text-top-10-question": [
            0,
            7,
            8,
            6,
            7,
            12,
            7,
            14,
            9,
            6
        ],
        "text-top-10-question_score": [
            22.265625,
            21.703125,
            20.03125,
            19.46875,
            18.953125,
            18.0,
            17.78125,
            17.546875,
            17.515625,
            17.46875
        ]
    },
    {
        "doc_id": "1911.12579.pdf",
        "q_uid": "a1064307a19cd7add32163a70b6623278a557946",
        "question": "How many uniue words are in the dataset?",
        "answer": "908456 unique words are available in collected corpus.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            4,
            7,
            18,
            1,
            15,
            12,
            13,
            3,
            5
        ],
        "image-top-10-question_score": [
            13.73965835571289,
            13.678014755249023,
            13.571189880371094,
            13.526676177978516,
            13.277280807495117,
            13.260936737060547,
            13.212593078613281,
            13.153814315795898,
            13.117260932922363,
            13.028995513916016
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.12579.pdf",
        "text-top-10-question": [
            14,
            1,
            11,
            7,
            6,
            17,
            11,
            5,
            15,
            18
        ],
        "text-top-10-question_score": [
            16.453125,
            14.125,
            13.59375,
            13.234375,
            12.8984375,
            12.796875,
            12.7421875,
            12.734375,
            12.6796875,
            12.5546875
        ]
    },
    {
        "doc_id": "1707.00110.pdf",
        "q_uid": "6e8c587b6562fafb43a7823637b84cd01487059a",
        "question": "How much is the BLEU score?",
        "answer": "Ranges from 44.22 to 100.00 depending on K and the sequence length.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            5,
            7,
            0,
            8,
            6,
            1,
            2
        ],
        "image-top-10-question_score": [
            15.429237365722656,
            13.641006469726562,
            12.264022827148438,
            10.54153060913086,
            10.322229385375977,
            9.986383438110352,
            9.970592498779297,
            9.87119197845459,
            9.48512077331543
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1707.00110.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            5,
            4,
            3,
            1,
            0,
            4,
            5
        ],
        "text-top-10-question_score": [
            21.421875,
            21.3125,
            21.1875,
            18.0,
            17.703125,
            17.1875,
            10.3984375,
            9.796875,
            9.515625,
            9.4453125
        ]
    },
    {
        "doc_id": "1909.01013.pdf",
        "q_uid": "d0c79f4a5d5c45fe673d9fcb3cd0b7dd65df7636",
        "question": "What are new best results on standard benchmark?",
        "answer": "New best results of accuracy (P@1) on Vecmap:\nOurs-GeoMMsemi: EN-IT 50.00 IT-EN 42.67 EN-DE 51.60 DE-EN 47.22 FI-EN 39.62 EN-ES 39.47 ES-EN 36.43",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            3,
            2,
            5,
            6,
            1
        ],
        "image-top-10-question_score": [
            14.126691818237305,
            13.455663681030273,
            12.478758811950684,
            12.420344352722168,
            11.047025680541992,
            10.95085334777832,
            10.889768600463867
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.01013.pdf",
        "text-top-10-question": [
            4,
            0,
            0,
            0,
            2,
            3,
            0,
            3,
            2,
            3
        ],
        "text-top-10-question_score": [
            18.609375,
            18.421875,
            16.03125,
            14.390625,
            11.6796875,
            11.359375,
            10.8515625,
            10.3671875,
            9.875,
            9.703125
        ]
    },
    {
        "doc_id": "1909.01013.pdf",
        "q_uid": "54c7fc08598b8b91a8c0399f6ab018c45e259f79",
        "question": "How better is performance compared to competitive baselines?",
        "answer": "Proposed method vs best baseline result on Vecmap (Accuracy P@1):\nEN-IT: 50 vs 50\nIT-EN: 42.67 vs 42.67\nEN-DE: 51.6 vs 51.47\nDE-EN: 47.22 vs 46.96\nEN-FI: 35.88 vs 36.24\nFI-EN: 39.62 vs 39.57\nEN-ES: 39.47 vs 39.30\nES-EN: 36.43 vs 36.06",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            4,
            2,
            6,
            5,
            1
        ],
        "image-top-10-question_score": [
            14.61026382446289,
            14.3043212890625,
            13.395645141601562,
            12.951383590698242,
            12.252992630004883,
            12.15747356414795,
            11.930221557617188
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.01013.pdf",
        "text-top-10-question": [
            4,
            0,
            0,
            0,
            3,
            3,
            3,
            2,
            3,
            2
        ],
        "text-top-10-question_score": [
            16.640625,
            16.34375,
            14.8046875,
            14.5078125,
            14.3828125,
            13.671875,
            12.2421875,
            11.6875,
            11.359375,
            11.0703125
        ]
    },
    {
        "doc_id": "1909.01013.pdf",
        "q_uid": "03ce42ff53aa3f1775bc57e50012f6eb1998c480",
        "question": "What 6 language pairs is experimented on?",
        "answer": "EN<->ES\nEN<->DE\nEN<->IT\nEN<->EO\nEN<->MS\nEN<->FI",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            4,
            0,
            5,
            6,
            1
        ],
        "image-top-10-question_score": [
            13.58810806274414,
            13.275485038757324,
            12.718463897705078,
            12.676643371582031,
            11.939939498901367,
            11.66575813293457,
            11.227374076843262
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.01013.pdf",
        "text-top-10-question": [
            0,
            3,
            3,
            3,
            0,
            0,
            4,
            0,
            5,
            2
        ],
        "text-top-10-question_score": [
            21.3125,
            17.421875,
            16.3125,
            14.9921875,
            14.984375,
            14.9375,
            13.7890625,
            13.578125,
            12.8515625,
            12.7734375
        ]
    },
    {
        "doc_id": "1605.08675.pdf",
        "q_uid": "63496705fff20c55d4b3d8cdf4786f93e742dd3d",
        "question": "Do they compare DeepER against other approaches?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            19,
            21,
            9,
            0,
            8,
            18,
            16,
            7,
            17,
            20
        ],
        "image-top-10-question_score": [
            14.950031280517578,
            14.393010139465332,
            14.351861953735352,
            14.288330078125,
            13.90477180480957,
            13.826685905456543,
            13.675716400146484,
            13.630390167236328,
            13.374951362609863,
            13.273774147033691
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1605.08675.pdf",
        "text-top-10-question": [
            7,
            19,
            0,
            20,
            1,
            1,
            0,
            15,
            7,
            16
        ],
        "text-top-10-question_score": [
            18.8125,
            16.828125,
            16.640625,
            15.734375,
            15.6953125,
            15.1328125,
            14.625,
            14.4765625,
            14.1796875,
            14.046875
        ]
    },
    {
        "doc_id": "1911.04952.pdf",
        "q_uid": "447eb98e602616c01187960c9c3011c62afd7c27",
        "question": "What are lyrical topics present in the metal genre?",
        "answer": "Table TABREF10 displays the twenty resulting topics",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            6,
            4,
            2,
            3,
            1
        ],
        "image-top-10-question_score": [
            16.451082229614258,
            15.81302261352539,
            15.778369903564453,
            15.623734474182129,
            14.690674781799316,
            14.677453994750977,
            14.276914596557617
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.04952.pdf",
        "text-top-10-question": [
            2,
            0,
            4,
            1,
            0,
            2,
            6,
            0,
            5,
            0
        ],
        "text-top-10-question_score": [
            25.375,
            24.984375,
            22.875,
            22.703125,
            22.46875,
            22.375,
            21.6875,
            21.453125,
            21.40625,
            21.1875
        ]
    },
    {
        "doc_id": "1910.00825.pdf",
        "q_uid": "f398587b9a0008628278a5ea858e01d3f5559f65",
        "question": "By how much does SPNet outperforms state-of-the-art abstractive summarization methods on evaluation metrics?",
        "answer": "SPNet vs best baseline:\nROUGE-1: 90.97 vs 90.68\nCIC: 70.45 vs 70.25",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            1,
            7,
            0,
            6,
            3,
            8,
            9,
            4,
            12
        ],
        "image-top-10-question_score": [
            26.658737182617188,
            26.467239379882812,
            25.709388732910156,
            24.85720443725586,
            24.76776123046875,
            23.872711181640625,
            23.379024505615234,
            23.290771484375,
            23.252344131469727,
            22.547584533691406
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.00825.pdf",
        "text-top-10-question": [
            0,
            1,
            5,
            6,
            7,
            6,
            5,
            7,
            0,
            5
        ],
        "text-top-10-question_score": [
            22.078125,
            20.953125,
            19.28125,
            19.09375,
            18.515625,
            18.46875,
            18.25,
            17.828125,
            17.53125,
            17.484375
        ]
    },
    {
        "doc_id": "1910.00458.pdf",
        "q_uid": "9fe4a2a5b9e5cf29310ab428922cc8e7b2fc1d11",
        "question": "What are state of the art methods MMM is compared to?",
        "answer": "FTLM++, BERT-large, XLNet",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            6,
            7,
            3,
            1,
            4,
            5,
            8,
            9,
            2
        ],
        "image-top-10-question_score": [
            16.585573196411133,
            16.439998626708984,
            16.152299880981445,
            16.132862091064453,
            15.737873077392578,
            15.423133850097656,
            14.921285629272461,
            14.244758605957031,
            14.20692253112793,
            14.031758308410645
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.00458.pdf",
        "text-top-10-question": [
            0,
            3,
            6,
            0,
            6,
            1,
            7,
            6,
            3,
            6
        ],
        "text-top-10-question_score": [
            21.1875,
            19.65625,
            18.875,
            18.25,
            17.875,
            17.203125,
            17.109375,
            16.4375,
            16.328125,
            14.171875
        ]
    },
    {
        "doc_id": "1909.08824.pdf",
        "q_uid": "8e2b125426d1220691cceaeaf1875f76a6049cbd",
        "question": "By how much do they improve the accuracy of inferences over state-of-the-art methods?",
        "answer": "ON Event2Mind, the accuracy of proposed method is improved by  absolute BLUE  2.9,  10.87, 1.79 for xIntent, xReact and oReact respectively.\nOn Atomic dataset, the accuracy of proposed method is improved by  absolute BLUE 3.95.   4.11, 4.49 for xIntent, xReact and oReact.respectively.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            0,
            7,
            1,
            6,
            2,
            8,
            4,
            9,
            3
        ],
        "image-top-10-question_score": [
            22.068845748901367,
            22.00506591796875,
            21.883636474609375,
            21.836078643798828,
            21.65032196044922,
            20.04680824279785,
            19.49285888671875,
            19.445812225341797,
            19.13357925415039,
            18.940710067749023
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.08824.pdf",
        "text-top-10-question": [
            0,
            1,
            1,
            5,
            5,
            6,
            8,
            6,
            5,
            0
        ],
        "text-top-10-question_score": [
            20.296875,
            15.6953125,
            15.21875,
            14.5703125,
            14.484375,
            14.4765625,
            14.25,
            14.1796875,
            13.96875,
            13.7265625
        ]
    },
    {
        "doc_id": "1909.08824.pdf",
        "q_uid": "42bc4e0cd0f3e238a4891142f1b84ebcd6594bf1",
        "question": "Which models do they use as baselines on the Atomic dataset?",
        "answer": "RNN-based Seq2Seq, Variational Seq2Seq, VRNMT , CWVAE-Unpretrained",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            6,
            0,
            5,
            2,
            7,
            4,
            3,
            8,
            9
        ],
        "image-top-10-question_score": [
            17.395095825195312,
            17.108753204345703,
            16.8287353515625,
            15.920170783996582,
            15.684734344482422,
            15.022032737731934,
            14.369154930114746,
            14.111699104309082,
            13.899035453796387,
            13.818426132202148
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.08824.pdf",
        "text-top-10-question": [
            1,
            1,
            5,
            5,
            6,
            0,
            0,
            5,
            4,
            5
        ],
        "text-top-10-question_score": [
            21.734375,
            20.890625,
            20.65625,
            20.34375,
            18.53125,
            16.875,
            16.71875,
            16.671875,
            16.1875,
            16.125
        ]
    },
    {
        "doc_id": "1701.03214.pdf",
        "q_uid": "a978a1ee73547ff3a80c66e6db3e6c3d3b6512f4",
        "question": "How much improvement does their method get over the fine tuning baseline?",
        "answer": "0.08 points on the 2011 test set, 0.44 points on the 2012 test set, 0.42 points on the 2013 test set for IWSLT-CE.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            1,
            4,
            0,
            2,
            5
        ],
        "image-top-10-question_score": [
            15.728666305541992,
            15.685722351074219,
            15.432456970214844,
            15.092635154724121,
            14.038568496704102,
            12.022765159606934
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1701.03214.pdf",
        "text-top-10-question": [
            3,
            1,
            0,
            3,
            1,
            1,
            0,
            3,
            3,
            3
        ],
        "text-top-10-question_score": [
            18.4375,
            17.765625,
            17.265625,
            16.875,
            16.5625,
            15.84375,
            15.3515625,
            13.8359375,
            13.7109375,
            12.8671875
        ]
    },
    {
        "doc_id": "1611.02550.pdf",
        "q_uid": "b6b5f92a1d9fa623b25c70c1ac67d59d84d9eec8",
        "question": "By how much do they outpeform previous results on the word discrimination task?",
        "answer": "Their best average precision tops previous best result by 0.202",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            2,
            5,
            3,
            0,
            4,
            7,
            6
        ],
        "image-top-10-question_score": [
            17.275592803955078,
            17.145671844482422,
            17.026830673217773,
            16.878673553466797,
            16.526538848876953,
            16.48817253112793,
            15.762741088867188,
            15.62486457824707
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1611.02550.pdf",
        "text-top-10-question": [
            2,
            5,
            1,
            0,
            1,
            2,
            0,
            1,
            4,
            4
        ],
        "text-top-10-question_score": [
            19.203125,
            17.3125,
            17.28125,
            16.59375,
            16.421875,
            16.0625,
            14.546875,
            14.53125,
            13.65625,
            11.75
        ]
    },
    {
        "doc_id": "1908.05434.pdf",
        "q_uid": "2d4d0735c50749aa8087d1502ab7499faa2f0dd8",
        "question": "By how much do they outperform previous state-of-the-art models?",
        "answer": "Proposed ORNN has 0.769, 1.238, 0.818, 0.772 compared to 0.778, 1.244, 0.813, 0.781 of best state of the art result on Mean Absolute Error (MAE), macro-averaged Mean Absolute Error (MAEM ), binary classification accuracy (Acc.) and weighted binary classification accuracy (Wt. Acc.)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            3,
            1,
            4,
            6,
            0,
            8,
            2,
            7
        ],
        "image-top-10-question_score": [
            19.209985733032227,
            19.16884422302246,
            18.708667755126953,
            18.4739990234375,
            18.18020248413086,
            18.024765014648438,
            17.859771728515625,
            17.756391525268555,
            17.696971893310547
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.05434.pdf",
        "text-top-10-question": [
            1,
            6,
            3,
            3,
            0,
            4,
            4,
            0,
            4,
            3
        ],
        "text-top-10-question_score": [
            17.4375,
            16.15625,
            15.9140625,
            15.203125,
            12.6640625,
            12.2109375,
            11.9375,
            11.9140625,
            11.7734375,
            11.5390625
        ]
    },
    {
        "doc_id": "1909.02480.pdf",
        "q_uid": "ba6422e22297c7eb0baa381225a2f146b9621791",
        "question": "What is the performance difference between proposed method and state-of-the-arts on these datasets?",
        "answer": "Difference is around 1 BLEU score lower on average than state of the art methods.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            7,
            1,
            12,
            8,
            4,
            0,
            5,
            3,
            2
        ],
        "image-top-10-question_score": [
            22.326541900634766,
            21.894508361816406,
            21.742507934570312,
            21.534229278564453,
            21.514820098876953,
            21.341135025024414,
            21.169384002685547,
            21.08513069152832,
            20.968454360961914,
            20.568078994750977
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.02480.pdf",
        "text-top-10-question": [
            0,
            1,
            1,
            7,
            5,
            5,
            7,
            5,
            6,
            6
        ],
        "text-top-10-question_score": [
            13.9140625,
            13.34375,
            13.2734375,
            12.984375,
            11.7890625,
            11.6328125,
            11.5078125,
            10.6015625,
            10.6015625,
            10.34375
        ]
    },
    {
        "doc_id": "2004.01694.pdf",
        "q_uid": "cc5d8e12f6aecf6a5f305e2f8b3a0c67f49801a9",
        "question": "What percentage fewer errors did professional translations make?",
        "answer": "36%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            9,
            12,
            11,
            3,
            10,
            17,
            15,
            6,
            13,
            0
        ],
        "image-top-10-question_score": [
            14.449538230895996,
            14.38767147064209,
            14.283334732055664,
            14.206729888916016,
            14.191274642944336,
            13.845708847045898,
            13.840414047241211,
            13.718841552734375,
            13.695133209228516,
            13.307872772216797
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2004.01694.pdf",
        "text-top-10-question": [
            0,
            9,
            17,
            11,
            15,
            15,
            9,
            10,
            8,
            9
        ],
        "text-top-10-question_score": [
            22.75,
            21.625,
            21.421875,
            21.078125,
            21.078125,
            20.828125,
            20.359375,
            20.03125,
            19.984375,
            19.890625
        ]
    },
    {
        "doc_id": "1904.10500.pdf",
        "q_uid": "e659ceb184777015c12db2da5ae396635192f0b0",
        "question": "Are the intent labels imbalanced in the dataset?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            11,
            4,
            10,
            7,
            13,
            9,
            5,
            12,
            1,
            6
        ],
        "image-top-10-question_score": [
            14.444507598876953,
            14.30571174621582,
            14.09524154663086,
            13.860652923583984,
            13.703184127807617,
            13.605810165405273,
            13.584521293640137,
            13.51376724243164,
            13.487159729003906,
            13.427536010742188
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1904.10500.pdf",
        "text-top-10-question": [
            2,
            4,
            11,
            4,
            6,
            10,
            8,
            2,
            13,
            11
        ],
        "text-top-10-question_score": [
            15.6875,
            15.5703125,
            15.140625,
            15.1015625,
            14.609375,
            14.5625,
            14.4609375,
            13.90625,
            13.671875,
            13.640625
        ]
    },
    {
        "doc_id": "1711.11221.pdf",
        "q_uid": "c1c611409b5659a1fd4a870b6cc41f042e2e9889",
        "question": "What evaluations did the authors use on their system?",
        "answer": "BLEU scores, exact matches of words in both translations and topic cache, and cosine similarities of adjacent sentences for coherence.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            6,
            0,
            8,
            7,
            4,
            2,
            9,
            10,
            3
        ],
        "image-top-10-question_score": [
            13.424449920654297,
            12.706840515136719,
            12.668891906738281,
            12.598795890808105,
            12.410364151000977,
            12.254656791687012,
            12.049764633178711,
            11.968732833862305,
            11.526443481445312,
            11.231075286865234
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1711.11221.pdf",
        "text-top-10-question": [
            9,
            4,
            5,
            4,
            2,
            0,
            6,
            9,
            9,
            5
        ],
        "text-top-10-question_score": [
            13.28125,
            12.203125,
            11.6953125,
            10.7890625,
            10.21875,
            9.8828125,
            9.28125,
            9.2421875,
            9.1953125,
            9.1328125
        ]
    },
    {
        "doc_id": "1809.09795.pdf",
        "q_uid": "46570c8faaeefecc8232cfc2faab0005faaba35f",
        "question": "What are the 7 different datasets?",
        "answer": "SemEval 2018 Task 3, BIBREF20, BIBREF4, SARC 2.0, SARC 2.0 pol, Sarcasm Corpus V1 (SC-V1), Sarcasm Corpus V2 (SC-V2)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            1,
            0,
            5,
            4
        ],
        "image-top-10-question_score": [
            14.526870727539062,
            14.074536323547363,
            13.27182674407959,
            13.225249290466309,
            13.057384490966797,
            12.662413597106934
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.09795.pdf",
        "text-top-10-question": [
            0,
            1,
            2,
            3,
            2,
            0,
            2,
            0,
            2,
            3
        ],
        "text-top-10-question_score": [
            19.78125,
            18.390625,
            16.421875,
            16.390625,
            15.640625,
            15.40625,
            14.921875,
            14.578125,
            14.2890625,
            14.2109375
        ]
    },
    {
        "doc_id": "2003.01769.pdf",
        "q_uid": "e1b36927114969f3b759cba056cfb3756de474e4",
        "question": "By how much does using phonetic feedback improve state-of-the-art systems?",
        "answer": "Improved AECNN-T by 2.1 and AECNN-T-SM BY 0.9",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            0,
            1,
            4,
            2
        ],
        "image-top-10-question_score": [
            20.998445510864258,
            20.997600555419922,
            17.151090621948242,
            17.030010223388672,
            16.851985931396484
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.01769.pdf",
        "text-top-10-question": [
            0,
            0,
            3,
            3,
            0,
            0,
            0,
            2,
            2,
            3
        ],
        "text-top-10-question_score": [
            23.46875,
            22.125,
            20.484375,
            18.1875,
            16.953125,
            16.15625,
            14.96875,
            13.9453125,
            13.2109375,
            13.1640625
        ]
    },
    {
        "doc_id": "1806.09103.pdf",
        "q_uid": "f513e27db363c28d19a29e01f758437d7477eb24",
        "question": "what are the baselines?",
        "answer": "AS Reader, GA Reader, CAS Reader",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            3,
            12,
            6,
            10,
            9,
            7,
            11,
            8
        ],
        "image-top-10-question_score": [
            10.781323432922363,
            10.361247062683105,
            9.934538841247559,
            9.779739379882812,
            9.77730941772461,
            9.737396240234375,
            9.733207702636719,
            9.715235710144043,
            9.703044891357422,
            9.670495986938477
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1806.09103.pdf",
        "text-top-10-question": [
            0,
            5,
            8,
            2,
            2,
            4,
            6,
            10,
            4,
            1
        ],
        "text-top-10-question_score": [
            10.2734375,
            9.5390625,
            7.5703125,
            5.8671875,
            5.4453125,
            5.328125,
            5.29296875,
            5.12890625,
            5.05078125,
            4.78125
        ]
    },
    {
        "doc_id": "1711.02013.pdf",
        "q_uid": "3070d6d6a52aa070f0c0a7b4de8abddd3da4f056",
        "question": "How do they measure performance of language model tasks?",
        "answer": "BPC, Perplexity",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            7,
            9,
            0,
            8,
            11,
            1,
            10,
            12,
            2
        ],
        "image-top-10-question_score": [
            15.011518478393555,
            14.771774291992188,
            14.75324821472168,
            14.479753494262695,
            14.307640075683594,
            14.263607025146484,
            14.10140609741211,
            13.900157928466797,
            13.75009536743164,
            13.352519989013672
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1711.02013.pdf",
        "text-top-10-question": [
            6,
            6,
            8,
            7,
            6,
            9,
            9,
            0,
            0,
            9
        ],
        "text-top-10-question_score": [
            19.921875,
            18.1875,
            17.984375,
            17.96875,
            17.84375,
            17.8125,
            17.78125,
            17.578125,
            17.1875,
            17.15625
        ]
    },
    {
        "doc_id": "1707.03764.pdf",
        "q_uid": "157b9f6f8fb5d370fa23df31de24ae7efb75d6f3",
        "question": "How do their results compare against other competitors in the PAN 2017 shared task on Author Profiling?",
        "answer": "They achieved best result in the PAN 2017 shared task with accuracy for Variety prediction task 0.0013 more than the 2nd best baseline, accuracy for Gender prediction task 0.0029 more than 2nd best baseline and accuracy for Joint prediction task 0.0101 more than the 2nd best baseline",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            9,
            3,
            6,
            8,
            7,
            4,
            2,
            5
        ],
        "image-top-10-question_score": [
            24.15989112854004,
            22.876911163330078,
            22.841999053955078,
            22.72953224182129,
            21.909364700317383,
            21.134971618652344,
            20.792831420898438,
            20.555885314941406,
            20.005107879638672,
            19.422178268432617
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1707.03764.pdf",
        "text-top-10-question": [
            1,
            1,
            0,
            3,
            9,
            0,
            9,
            9,
            3,
            0
        ],
        "text-top-10-question_score": [
            19.234375,
            18.9375,
            18.015625,
            17.671875,
            16.921875,
            15.7578125,
            15.578125,
            14.4609375,
            14.1640625,
            13.7265625
        ]
    },
    {
        "doc_id": "1701.06538.pdf",
        "q_uid": "e8fcfb1412c3b30da6cbc0766152b6e11e17196c",
        "question": "What improvement does the MOE model make over the SOTA on language modelling?",
        "answer": "Perpexity is improved from 34.7 to 28.0.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            15,
            5,
            6,
            2,
            16,
            14,
            7,
            8,
            1,
            13
        ],
        "image-top-10-question_score": [
            18.65829086303711,
            18.642576217651367,
            18.575891494750977,
            18.473997116088867,
            18.453311920166016,
            18.353912353515625,
            18.248300552368164,
            18.117856979370117,
            17.960708618164062,
            17.934436798095703
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1701.06538.pdf",
        "text-top-10-question": [
            8,
            6,
            2,
            6,
            0,
            8,
            4,
            16,
            16,
            1
        ],
        "text-top-10-question_score": [
            19.75,
            19.65625,
            19.46875,
            19.46875,
            19.453125,
            19.296875,
            18.96875,
            18.78125,
            18.78125,
            18.71875
        ]
    },
    {
        "doc_id": "1905.10810.pdf",
        "q_uid": "44104668796a6ca10e2ea3ecf706541da1cec2cf",
        "question": "What is the difference in performance between the interpretable system (e.g. vectors and cosine distance) and LSTM with ELMo system?",
        "answer": "Accuracy of best interpretible system was 0.3945 while accuracy of LSTM-ELMo net was 0.6818.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            2,
            0,
            3,
            4
        ],
        "image-top-10-question_score": [
            27.475616455078125,
            27.369083404541016,
            26.043790817260742,
            24.04926300048828,
            18.753070831298828
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1905.10810.pdf",
        "text-top-10-question": [
            0,
            0,
            3,
            1,
            1,
            2,
            2,
            1,
            2,
            2
        ],
        "text-top-10-question_score": [
            19.84375,
            17.015625,
            16.125,
            15.9296875,
            15.5,
            15.109375,
            14.828125,
            14.2734375,
            13.4921875,
            13.375
        ]
    },
    {
        "doc_id": "1910.07481.pdf",
        "q_uid": "c1f4d632da78714308dc502fe4e7b16ea6f76f81",
        "question": "Which language-pair had the better performance?",
        "answer": "French-English",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            1,
            4,
            6,
            5,
            0
        ],
        "image-top-10-question_score": [
            14.129064559936523,
            13.909658432006836,
            13.759546279907227,
            12.306270599365234,
            12.175350189208984,
            12.130023956298828,
            12.09660816192627
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.07481.pdf",
        "text-top-10-question": [
            2,
            2,
            0,
            0,
            4,
            2,
            0,
            1,
            0,
            3
        ],
        "text-top-10-question_score": [
            17.765625,
            14.796875,
            14.5390625,
            14.296875,
            13.5625,
            13.3984375,
            13.3203125,
            12.6640625,
            12.5625,
            12.453125
        ]
    },
    {
        "doc_id": "2001.05493.pdf",
        "q_uid": "e829f008d62312357e0354a9ed3b0827c91c9401",
        "question": "Which psycholinguistic and basic linguistic features are used?",
        "answer": "Emotion Sensor Feature, Part of Speech, Punctuation, Sentiment Analysis, Empath, TF-IDF Emoticon features",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            2,
            0,
            9,
            8,
            4,
            3,
            6,
            7,
            5
        ],
        "image-top-10-question_score": [
            17.115371704101562,
            16.712047576904297,
            16.674297332763672,
            16.1278076171875,
            15.223335266113281,
            14.788370132446289,
            14.59769058227539,
            13.918033599853516,
            13.805013656616211,
            12.939277648925781
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.05493.pdf",
        "text-top-10-question": [
            1,
            0,
            2,
            0,
            2,
            1,
            1,
            8,
            2,
            0
        ],
        "text-top-10-question_score": [
            19.46875,
            17.703125,
            17.59375,
            17.375,
            13.7890625,
            12.9921875,
            12.6328125,
            12.4765625,
            12.3359375,
            12.2578125
        ]
    },
    {
        "doc_id": "1901.02257.pdf",
        "q_uid": "3aa7173612995223a904cc0f8eef4ff203cbb860",
        "question": "What baseline models do they compare against?",
        "answer": "SLQA, Rusalka, HMA Model (single), TriAN (single), jiangnan (ensemble), MITRE (ensemble), TriAN (ensemble), HMA Model (ensemble)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            7,
            2,
            9,
            1,
            3,
            5,
            10,
            11,
            8
        ],
        "image-top-10-question_score": [
            13.75487232208252,
            13.202896118164062,
            12.860185623168945,
            12.82255744934082,
            12.066967964172363,
            11.875614166259766,
            11.797955513000488,
            11.698799133300781,
            11.69288158416748,
            11.52830696105957
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.02257.pdf",
        "text-top-10-question": [
            7,
            7,
            6,
            8,
            2,
            1,
            9,
            10,
            6,
            6
        ],
        "text-top-10-question_score": [
            14.046875,
            13.9375,
            12.90625,
            12.4921875,
            11.75,
            11.6796875,
            11.5234375,
            11.0703125,
            10.765625,
            10.359375
        ]
    },
    {
        "doc_id": "2002.02492.pdf",
        "q_uid": "6f2f304ef292d8bcd521936f93afeec917cbe28a",
        "question": "How much improvement is gained from the proposed approaches?",
        "answer": "It eliminates non-termination in some models fixing for some models up to 6% of non-termination ratio.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            8,
            10,
            6,
            9,
            1,
            0,
            2,
            14,
            13
        ],
        "image-top-10-question_score": [
            13.273110389709473,
            12.804229736328125,
            12.48947811126709,
            12.20199966430664,
            11.905061721801758,
            11.892171859741211,
            11.859320640563965,
            11.81671142578125,
            11.292400360107422,
            11.14542293548584
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.02492.pdf",
        "text-top-10-question": [
            5,
            8,
            6,
            0,
            8,
            2,
            2,
            1,
            4,
            6
        ],
        "text-top-10-question_score": [
            13.6640625,
            13.2578125,
            13.09375,
            11.03125,
            9.859375,
            9.6796875,
            9.5078125,
            9.4921875,
            9.1171875,
            9.1171875
        ]
    },
    {
        "doc_id": "1910.08210.pdf",
        "q_uid": "37e8f5851133a748c4e3e0beeef0d83883117a98",
        "question": "How better is performance of proposed model compared to baselines?",
        "answer": "Proposed model achive 66+-22 win rate, baseline CNN 13+-1  and baseline FiLM 32+-3 .",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            15,
            12,
            7,
            4,
            14,
            5,
            3,
            0,
            8
        ],
        "image-top-10-question_score": [
            15.889297485351562,
            15.837239265441895,
            15.59980297088623,
            15.43066120147705,
            15.401433944702148,
            15.383275032043457,
            15.180845260620117,
            15.064849853515625,
            14.80096435546875,
            14.70386791229248
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.08210.pdf",
        "text-top-10-question": [
            6,
            6,
            8,
            6,
            0,
            15,
            7,
            7,
            13,
            15
        ],
        "text-top-10-question_score": [
            20.046875,
            18.65625,
            17.546875,
            16.71875,
            15.328125,
            15.0,
            14.9921875,
            14.7421875,
            14.5390625,
            14.09375
        ]
    },
    {
        "doc_id": "1911.02711.pdf",
        "q_uid": "68e3f3908687505cb63b538e521756390c321a1c",
        "question": "What is the performance difference of using a generated summary vs. a user-written one?",
        "answer": "2.7 accuracy points",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            7,
            0,
            9,
            1,
            5,
            8,
            2,
            3,
            4
        ],
        "image-top-10-question_score": [
            21.46500015258789,
            21.34486961364746,
            21.26459503173828,
            21.14440155029297,
            20.81157684326172,
            20.730440139770508,
            20.390060424804688,
            19.80307388305664,
            19.476818084716797,
            19.3563175201416
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.02711.pdf",
        "text-top-10-question": [
            7,
            6,
            7,
            2,
            1,
            0,
            6,
            0,
            1,
            1
        ],
        "text-top-10-question_score": [
            21.140625,
            21.046875,
            17.15625,
            16.828125,
            16.734375,
            16.4375,
            16.0625,
            15.328125,
            15.09375,
            13.953125
        ]
    },
    {
        "doc_id": "1912.06670.pdf",
        "q_uid": "5fa464a158dc8abf7cef8ca7d42a7080670c1edd",
        "question": "Is audio data per language balanced in dataset?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            2,
            0,
            3,
            4
        ],
        "image-top-10-question_score": [
            13.529363632202148,
            13.516904830932617,
            13.081918716430664,
            12.948015213012695,
            12.763069152832031
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.06670.pdf",
        "text-top-10-question": [
            2,
            0,
            1,
            1,
            2,
            3,
            1,
            1,
            0,
            0
        ],
        "text-top-10-question_score": [
            20.484375,
            18.75,
            17.78125,
            17.75,
            17.46875,
            17.171875,
            16.953125,
            16.46875,
            15.71875,
            15.6875
        ]
    },
    {
        "doc_id": "1906.03538.pdf",
        "q_uid": "281cd4e78b27a62713ec43249df5000812522a89",
        "question": "What is the average length of the claims?",
        "answer": "Average claim length is 8.9 tokens.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            5,
            0,
            14,
            13,
            3,
            15,
            2,
            1,
            10
        ],
        "image-top-10-question_score": [
            14.882329940795898,
            14.651935577392578,
            14.441476821899414,
            14.405948638916016,
            14.209606170654297,
            13.959806442260742,
            13.936117172241211,
            13.926385879516602,
            13.284845352172852,
            13.2234468460083
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1906.03538.pdf",
        "text-top-10-question": [
            4,
            4,
            1,
            5,
            7,
            5,
            15,
            0,
            1,
            6
        ],
        "text-top-10-question_score": [
            23.53125,
            20.828125,
            14.9375,
            14.9140625,
            14.5546875,
            14.125,
            13.8359375,
            13.53125,
            13.4140625,
            13.2421875
        ]
    },
    {
        "doc_id": "1803.09230.pdf",
        "q_uid": "9776156fc93daa36f4613df591e2b49827d25ad2",
        "question": "By how much, the proposed method improves BiDAF and DCN on SQuAD dataset?",
        "answer": "In terms of F1 score, the Hybrid approach improved by 23.47% and 1.39% on BiDAF and DCN respectively. The DCA approach improved by 23.2% and 1.12% on BiDAF and DCN respectively.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            2,
            4,
            7,
            3,
            5,
            6
        ],
        "image-top-10-question_score": [
            21.060880661010742,
            20.844955444335938,
            20.792770385742188,
            20.32621192932129,
            20.208724975585938,
            19.80881118774414,
            19.66791534423828,
            17.94111442565918
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1803.09230.pdf",
        "text-top-10-question": [
            0,
            1,
            2,
            2,
            2,
            4,
            1,
            6,
            4,
            4
        ],
        "text-top-10-question_score": [
            21.15625,
            19.0625,
            18.28125,
            17.796875,
            17.25,
            17.171875,
            17.03125,
            16.8125,
            16.71875,
            16.28125
        ]
    },
    {
        "doc_id": "2003.05377.pdf",
        "q_uid": "6b91fe29175be8cd8f22abf27fb3460e43b9889a",
        "question": "what genres do they songs fall under?",
        "answer": "Gospel, Sertanejo, MPB, Forr\u00f3, Pagode, Rock, Samba, Pop, Ax\u00e9, Funk-carioca, Infantil, Velha-guarda, Bossa-nova and Jovem-guarda",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            5,
            1,
            0,
            6,
            4,
            3
        ],
        "image-top-10-question_score": [
            14.530887603759766,
            14.511547088623047,
            14.244831085205078,
            13.965188980102539,
            13.694107055664062,
            13.238709449768066,
            12.348286628723145
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.05377.pdf",
        "text-top-10-question": [
            1,
            2,
            2,
            5,
            1,
            0,
            4,
            6,
            6,
            0
        ],
        "text-top-10-question_score": [
            19.765625,
            17.625,
            17.015625,
            16.609375,
            16.5625,
            16.078125,
            16.0625,
            15.5859375,
            15.5703125,
            15.4453125
        ]
    },
    {
        "doc_id": "2001.05467.pdf",
        "q_uid": "4b8a0e99bf3f2f6c80c57c0e474c47a5ee842b2c",
        "question": "To what other competitive baselines is this approach compared?",
        "answer": "LSTMs with and without attention, HRED, VHRED with and without attention, MMI and Reranking-RL",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            2,
            0,
            5,
            1,
            7,
            3,
            6
        ],
        "image-top-10-question_score": [
            14.300094604492188,
            14.077376365661621,
            13.92441177368164,
            13.599562644958496,
            13.563835144042969,
            13.542141914367676,
            13.509244918823242,
            13.393424987792969
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.05467.pdf",
        "text-top-10-question": [
            0,
            4,
            1,
            0,
            3,
            3,
            4,
            4,
            4,
            2
        ],
        "text-top-10-question_score": [
            17.96875,
            15.1484375,
            13.375,
            13.2578125,
            13.0,
            12.28125,
            11.9609375,
            11.8828125,
            11.8671875,
            11.3828125
        ]
    },
    {
        "doc_id": "2001.05467.pdf",
        "q_uid": "5e9732ff8595b31f81740082333b241d0a5f7c9a",
        "question": "How much better were results of the proposed models than base LSTM-RNN model?",
        "answer": "on diversity 6.87 and on relevance 4.6 points higher",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            1,
            4,
            3,
            0,
            2,
            7,
            6
        ],
        "image-top-10-question_score": [
            19.465656280517578,
            19.453840255737305,
            19.15915298461914,
            18.219999313354492,
            17.652536392211914,
            17.160240173339844,
            16.14676284790039,
            16.077747344970703
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.05467.pdf",
        "text-top-10-question": [
            0,
            1,
            6,
            1,
            5,
            5,
            5,
            5,
            4,
            1
        ],
        "text-top-10-question_score": [
            20.75,
            20.6875,
            17.53125,
            16.796875,
            16.71875,
            16.046875,
            15.8125,
            15.4921875,
            15.296875,
            15.140625
        ]
    },
    {
        "doc_id": "1909.09484.pdf",
        "q_uid": "c165ea43256d7ee1b1fb6f5c0c8af5f7b585e60d",
        "question": "How much is proposed model better than baselines in performed experiments?",
        "answer": "most of the models have similar performance on BPRA: DSTC2 (+0.0015), Maluuba (+0.0729)\nGDP achieves the best performance in APRA: DSTC2 (+0.2893), Maluuba (+0.2896)\nGDP significantly outperforms the baselines on BLEU: DSTC2 (+0.0791), Maluuba (+0.0492)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            1,
            6,
            5,
            4,
            8,
            2,
            0,
            3,
            9
        ],
        "image-top-10-question_score": [
            17.625370025634766,
            17.542240142822266,
            17.517013549804688,
            17.340957641601562,
            15.902209281921387,
            15.020000457763672,
            14.728021621704102,
            14.64705753326416,
            14.074625015258789,
            13.915942192077637
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.09484.pdf",
        "text-top-10-question": [
            6,
            7,
            7,
            7,
            5,
            6,
            6,
            6,
            7,
            1
        ],
        "text-top-10-question_score": [
            20.1875,
            20.171875,
            19.75,
            17.34375,
            17.265625,
            17.125,
            16.71875,
            16.25,
            15.3671875,
            14.5703125
        ]
    },
    {
        "doc_id": "1807.07961.pdf",
        "q_uid": "4a8bceb3b6d45f14c4749115d6aa83912f0b0a6e",
        "question": "Do they evaluate only on English datasets?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            5,
            4,
            8,
            7,
            2,
            3,
            0,
            6
        ],
        "image-top-10-question_score": [
            12.428911209106445,
            12.352752685546875,
            12.304553031921387,
            12.139741897583008,
            11.793811798095703,
            11.770491600036621,
            11.757827758789062,
            11.642509460449219,
            11.422011375427246
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1807.07961.pdf",
        "text-top-10-question": [
            5,
            8,
            5,
            4,
            5,
            2,
            5,
            2,
            4,
            4
        ],
        "text-top-10-question_score": [
            13.7109375,
            12.5078125,
            11.9140625,
            11.828125,
            11.7109375,
            11.484375,
            11.40625,
            11.0703125,
            10.921875,
            10.8515625
        ]
    },
    {
        "doc_id": "1709.05413.pdf",
        "q_uid": "b8cee4782e05afaeb9647efdb8858554490feba5",
        "question": "Do they evaluate only on English datasets?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            2,
            5,
            4,
            11,
            3,
            6,
            1,
            7,
            12
        ],
        "image-top-10-question_score": [
            12.274263381958008,
            11.911502838134766,
            11.86604118347168,
            11.749312400817871,
            11.681252479553223,
            11.61607551574707,
            11.448175430297852,
            11.413009643554688,
            11.29769515991211,
            11.26093864440918
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1709.05413.pdf",
        "text-top-10-question": [
            8,
            1,
            8,
            7,
            7,
            2,
            5,
            6,
            2,
            6
        ],
        "text-top-10-question_score": [
            13.1328125,
            11.828125,
            11.8125,
            11.5703125,
            11.1328125,
            10.9453125,
            10.65625,
            10.59375,
            10.1953125,
            10.1953125
        ]
    },
    {
        "doc_id": "1804.00079.pdf",
        "q_uid": "e2f269997f5a01949733c2ec8169f126dabd7571",
        "question": "Which data sources do they use?",
        "answer": "- En-Fr (WMT14)\n- En-De (WMT15)\n- Skipthought (BookCorpus)\n- AllNLI (SNLI + MultiNLI)\n- Parsing (PTB + 1-billion word)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            13,
            5,
            3,
            14,
            9,
            10,
            15,
            7,
            8
        ],
        "image-top-10-question_score": [
            11.822049140930176,
            11.798604011535645,
            11.600617408752441,
            11.385358810424805,
            11.073152542114258,
            10.887696266174316,
            10.826435089111328,
            10.719690322875977,
            10.623031616210938,
            10.472954750061035
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1804.00079.pdf",
        "text-top-10-question": [
            13,
            4,
            6,
            4,
            13,
            13,
            4,
            0,
            13,
            5
        ],
        "text-top-10-question_score": [
            14.09375,
            12.6328125,
            12.6171875,
            11.3125,
            10.9609375,
            10.0859375,
            9.8125,
            9.765625,
            9.6875,
            9.5
        ]
    },
    {
        "doc_id": "2003.12738.pdf",
        "q_uid": "c69f4df4943a2ca4c10933683a02b179a5e76f64",
        "question": "What approach performs better in experiments global latent or sequence of fine-grained latent variables?",
        "answer": "PPL: SVT\nDiversity: GVT\nEmbeddings Similarity: SVT\nHuman Evaluation: SVT",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            0,
            1,
            4,
            2,
            3,
            7,
            5,
            8,
            9
        ],
        "image-top-10-question_score": [
            19.705535888671875,
            19.21251678466797,
            19.115337371826172,
            19.01164436340332,
            18.973133087158203,
            18.911855697631836,
            18.74077606201172,
            18.62063217163086,
            18.53215217590332,
            16.764774322509766
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.12738.pdf",
        "text-top-10-question": [
            0,
            6,
            1,
            7,
            0,
            1,
            0,
            0,
            1,
            2
        ],
        "text-top-10-question_score": [
            18.921875,
            17.46875,
            16.984375,
            16.375,
            16.25,
            15.9921875,
            15.8515625,
            15.7421875,
            15.6171875,
            15.4921875
        ]
    },
    {
        "doc_id": "1909.03544.pdf",
        "q_uid": "7772cb23b7609f1d4cfd6511ac3fcdc20f8481ba",
        "question": "What previous approaches did this method outperform?",
        "answer": "Table TABREF44, Table TABREF44, Table TABREF47, Table TABREF47",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            1,
            0,
            8,
            5,
            6,
            9,
            10,
            4,
            2
        ],
        "image-top-10-question_score": [
            12.557570457458496,
            12.416791915893555,
            12.352682113647461,
            12.18989372253418,
            11.994672775268555,
            11.983514785766602,
            11.949285507202148,
            11.463518142700195,
            11.454492568969727,
            11.206671714782715
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.03544.pdf",
        "text-top-10-question": [
            9,
            7,
            9,
            5,
            9,
            7,
            7,
            0,
            10,
            5
        ],
        "text-top-10-question_score": [
            14.0390625,
            13.484375,
            12.8984375,
            12.4921875,
            12.4453125,
            12.3046875,
            12.171875,
            12.09375,
            12.0,
            11.9375
        ]
    },
    {
        "doc_id": "1811.01088.pdf",
        "q_uid": "6992f8e5a33f0af0f2206769484c72fecc14700b",
        "question": "Is the new model evaluated on the tasks that BERT and ELMo are evaluated on?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            5,
            3,
            1,
            2,
            7,
            6,
            11,
            0,
            8
        ],
        "image-top-10-question_score": [
            21.29528045654297,
            21.282135009765625,
            21.14749526977539,
            21.092082977294922,
            21.079002380371094,
            20.747644424438477,
            20.693199157714844,
            20.625587463378906,
            19.54881477355957,
            18.517885208129883
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1811.01088.pdf",
        "text-top-10-question": [
            2,
            2,
            2,
            0,
            5,
            5,
            6,
            2,
            1,
            7
        ],
        "text-top-10-question_score": [
            22.40625,
            21.390625,
            21.3125,
            20.9375,
            20.46875,
            19.984375,
            19.953125,
            19.53125,
            18.953125,
            18.8125
        ]
    },
    {
        "doc_id": "1902.10525.pdf",
        "q_uid": "097ab15f58cb1fce5b5ffb5082b8d7bbee720659",
        "question": "Which language has the lowest error rate reduction?",
        "answer": "thai",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            9,
            0,
            11,
            5,
            7,
            8,
            10,
            12,
            2
        ],
        "image-top-10-question_score": [
            13.635193824768066,
            13.48066234588623,
            13.40011978149414,
            13.00597095489502,
            12.784688949584961,
            12.419815063476562,
            11.793338775634766,
            11.577130317687988,
            11.274396896362305,
            10.857141494750977
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1902.10525.pdf",
        "text-top-10-question": [
            0,
            6,
            5,
            11,
            8,
            9,
            6,
            8,
            7,
            1
        ],
        "text-top-10-question_score": [
            17.078125,
            16.21875,
            16.171875,
            15.3828125,
            14.4453125,
            14.2265625,
            13.8515625,
            13.625,
            13.5625,
            13.0546875
        ]
    },
    {
        "doc_id": "2004.01878.pdf",
        "q_uid": "5a23f436a7e0c33e4842425cf86d5fd8ba78ac92",
        "question": "How big is dataset used?",
        "answer": "553,451 documents",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            9,
            10,
            11,
            8,
            6,
            1,
            0,
            3,
            7
        ],
        "image-top-10-question_score": [
            11.881318092346191,
            11.626791954040527,
            11.331018447875977,
            11.301164627075195,
            11.263284683227539,
            11.246696472167969,
            11.150812149047852,
            11.133132934570312,
            11.118499755859375,
            11.032175064086914
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2004.01878.pdf",
        "text-top-10-question": [
            5,
            5,
            5,
            9,
            7,
            6,
            2,
            1,
            3,
            6
        ],
        "text-top-10-question_score": [
            14.453125,
            13.0859375,
            12.359375,
            9.7421875,
            9.703125,
            8.96875,
            8.9453125,
            8.921875,
            8.7734375,
            8.671875
        ]
    },
    {
        "doc_id": "1603.00968.pdf",
        "q_uid": "085147cd32153d46dd9901ab0f9195bfdbff6a85",
        "question": "What are the baseline models?",
        "answer": "MC-CNN\nMVCNN\nCNN",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            4,
            5,
            1,
            2,
            6
        ],
        "image-top-10-question_score": [
            12.013383865356445,
            11.586894989013672,
            11.415565490722656,
            10.771001815795898,
            10.642120361328125,
            10.621932983398438,
            10.273797988891602
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1603.00968.pdf",
        "text-top-10-question": [
            0,
            4,
            4,
            3,
            4,
            1,
            0,
            2,
            5,
            5
        ],
        "text-top-10-question_score": [
            21.6875,
            17.65625,
            17.515625,
            15.34375,
            13.75,
            12.78125,
            12.4921875,
            12.3046875,
            12.2265625,
            11.9765625
        ]
    },
    {
        "doc_id": "1603.00968.pdf",
        "q_uid": "c0035fb1c2b3de15146a7ce186ccd2e366fb4da2",
        "question": "By how much of MGNC-CNN out perform the baselines?",
        "answer": "In terms of Subj the Average MGNC-CNN is better than the average score of baselines by 0.5.  Similarly, Scores of SST-1, SST-2, and TREC where MGNC-CNN has similar improvements. \nIn case of Irony the difference is about 2.0. \n",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            4,
            2,
            3,
            1,
            5,
            6
        ],
        "image-top-10-question_score": [
            19.705795288085938,
            19.431055068969727,
            18.85572624206543,
            18.457889556884766,
            17.711875915527344,
            15.199097633361816,
            14.725293159484863
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1603.00968.pdf",
        "text-top-10-question": [
            4,
            4,
            0,
            4,
            3,
            4,
            2,
            3,
            3,
            2
        ],
        "text-top-10-question_score": [
            22.34375,
            21.21875,
            20.234375,
            20.1875,
            18.890625,
            18.75,
            17.875,
            17.578125,
            17.125,
            16.90625
        ]
    },
    {
        "doc_id": "1603.00968.pdf",
        "q_uid": "34dd0ee1374a3afd16cf8b0c803f4ef4c6fec8ac",
        "question": "What are the comparable alternative architectures?",
        "answer": "standard CNN, C-CNN, MVCNN ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            1,
            2,
            3,
            4,
            6
        ],
        "image-top-10-question_score": [
            12.337060928344727,
            10.744197845458984,
            10.502546310424805,
            10.307470321655273,
            10.174253463745117,
            10.159011840820312,
            10.011467933654785
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1603.00968.pdf",
        "text-top-10-question": [
            0,
            0,
            4,
            0,
            1,
            1,
            4,
            1,
            3,
            0
        ],
        "text-top-10-question_score": [
            20.09375,
            18.0625,
            15.46875,
            14.390625,
            13.625,
            11.7890625,
            11.765625,
            11.3515625,
            9.2578125,
            9.0625
        ]
    },
    {
        "doc_id": "2004.01980.pdf",
        "q_uid": "53377f1c5eda961e438424d71d16150e669f7072",
        "question": "Which state-of-the-art model is surpassed by 9.68% attraction score?",
        "answer": "pure summarization model NHG",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            6,
            1,
            8,
            7,
            5,
            4,
            3,
            10,
            9
        ],
        "image-top-10-question_score": [
            23.438337326049805,
            22.285850524902344,
            20.80999183654785,
            20.332256317138672,
            19.890628814697266,
            19.84699249267578,
            19.191383361816406,
            18.8848876953125,
            18.867250442504883,
            18.859188079833984
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2004.01980.pdf",
        "text-top-10-question": [
            0,
            6,
            6,
            8,
            6,
            8,
            5,
            6,
            4,
            6
        ],
        "text-top-10-question_score": [
            21.015625,
            18.78125,
            16.5,
            15.796875,
            15.375,
            15.2421875,
            14.96875,
            14.2578125,
            13.25,
            12.890625
        ]
    },
    {
        "doc_id": "2004.01980.pdf",
        "q_uid": "f37ed011e7eb259360170de027c1e8557371f002",
        "question": "What is increase in percentage of humor contained in headlines generated with TitleStylist method (w.r.t. baselines)?",
        "answer": "Humor in headlines (TitleStylist vs Multitask baseline):\nRelevance: +6.53% (5.87 vs 5.51)\nAttraction: +3.72% (8.93 vs 8.61)\nFluency: 1,98% (9.29 vs 9.11)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            8,
            4,
            1,
            6,
            5,
            0,
            2,
            10,
            9
        ],
        "image-top-10-question_score": [
            28.99102783203125,
            28.757883071899414,
            28.61099624633789,
            28.37435531616211,
            28.36313819885254,
            27.313865661621094,
            26.73065757751465,
            25.817230224609375,
            24.846134185791016,
            23.498271942138672
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2004.01980.pdf",
        "text-top-10-question": [
            7,
            6,
            8,
            7,
            0,
            0,
            6,
            1,
            6,
            8
        ],
        "text-top-10-question_score": [
            18.0625,
            17.90625,
            17.046875,
            16.859375,
            16.796875,
            16.703125,
            16.640625,
            16.0625,
            16.0625,
            15.96875
        ]
    },
    {
        "doc_id": "1804.08139.pdf",
        "q_uid": "0fd678d24c86122b9ab27b73ef20216bbd9847d1",
        "question": "What evaluation metrics are used?",
        "answer": "Accuracy on each dataset and the average accuracy on all datasets.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            5,
            4,
            2,
            6,
            1,
            0
        ],
        "image-top-10-question_score": [
            9.426494598388672,
            9.024438858032227,
            8.88804817199707,
            8.877885818481445,
            8.713376998901367,
            8.087634086608887,
            7.832019805908203
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1804.08139.pdf",
        "text-top-10-question": [
            4,
            3,
            2,
            2,
            3,
            5,
            2,
            5,
            4,
            2
        ],
        "text-top-10-question_score": [
            12.5390625,
            11.1171875,
            11.0078125,
            10.625,
            10.5390625,
            10.421875,
            10.3671875,
            10.1953125,
            9.8515625,
            9.828125
        ]
    },
    {
        "doc_id": "1911.03597.pdf",
        "q_uid": "b9c0049a7a5639c33efdb6178c2594b8efdefabb",
        "question": "How much better are results of proposed model compared to pivoting method?",
        "answer": "our method outperforms the baseline in both relevance and fluency significantly.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            0,
            6,
            1,
            7,
            3,
            2,
            4,
            8
        ],
        "image-top-10-question_score": [
            16.494585037231445,
            14.91729736328125,
            14.694268226623535,
            14.626413345336914,
            14.315513610839844,
            14.031725883483887,
            13.741905212402344,
            13.462843894958496,
            13.442428588867188
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.03597.pdf",
        "text-top-10-question": [
            7,
            0,
            5,
            1,
            1,
            0,
            6,
            5,
            7,
            5
        ],
        "text-top-10-question_score": [
            18.640625,
            18.359375,
            17.9375,
            17.828125,
            16.96875,
            16.296875,
            15.2734375,
            14.2734375,
            14.015625,
            13.609375
        ]
    },
    {
        "doc_id": "1909.07734.pdf",
        "q_uid": "d2fbf34cf4b5b1fd82394124728b03003884409c",
        "question": "Who was the top-scoring team?",
        "answer": "IDEA",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            1,
            0,
            2,
            5
        ],
        "image-top-10-question_score": [
            11.516724586486816,
            11.13460922241211,
            10.658679962158203,
            10.458812713623047,
            9.790940284729004,
            8.698892593383789
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.07734.pdf",
        "text-top-10-question": [
            0,
            3,
            3,
            4,
            0,
            2,
            3,
            4,
            1,
            0
        ],
        "text-top-10-question_score": [
            17.6875,
            14.3671875,
            13.796875,
            11.4609375,
            11.1953125,
            10.3515625,
            10.0078125,
            9.203125,
            9.1328125,
            9.0546875
        ]
    },
    {
        "doc_id": "2001.05970.pdf",
        "q_uid": "dd5c9a370652f6550b4fd13e2ac317eaf90973a8",
        "question": "How strong is the correlation between the prevalence of the #MeToo movement and official reports [of sexual harassment]?",
        "answer": "0.9098 correlation",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            3,
            1,
            5,
            2
        ],
        "image-top-10-question_score": [
            24.565290451049805,
            23.206052780151367,
            22.704620361328125,
            21.800758361816406,
            21.174768447875977,
            18.85111427307129
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.05970.pdf",
        "text-top-10-question": [
            4,
            3,
            0,
            0,
            3,
            1,
            4,
            2,
            0,
            4
        ],
        "text-top-10-question_score": [
            21.609375,
            20.59375,
            19.75,
            19.578125,
            17.59375,
            17.359375,
            17.28125,
            17.046875,
            16.734375,
            16.34375
        ]
    },
    {
        "doc_id": "1710.06700.pdf",
        "q_uid": "2fa0b9d0cb26e1be8eae7e782ada6820bc2c037f",
        "question": "What were their accuracy results on the task?",
        "answer": "97.32%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            0,
            3
        ],
        "image-top-10-question_score": [
            13.57091999053955,
            12.365610122680664,
            12.334526062011719,
            10.037603378295898
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1710.06700.pdf",
        "text-top-10-question": [
            2,
            1,
            0,
            1,
            1,
            0,
            2,
            2,
            2,
            2
        ],
        "text-top-10-question_score": [
            21.140625,
            18.6875,
            15.9140625,
            15.0703125,
            15.0078125,
            14.8203125,
            13.59375,
            13.015625,
            10.53125,
            8.140625
        ]
    },
    {
        "doc_id": "1912.10435.pdf",
        "q_uid": "707db46938d16647bf4b6407b2da84b5c7ab4a81",
        "question": "How much F1 was improved after adding skip connections?",
        "answer": "Simple Skip improves F1 from 74.34 to 74.81\nTransformer Skip improes F1 from 74.34 to 74.95 ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            0,
            3,
            6,
            7,
            4,
            1,
            2,
            8
        ],
        "image-top-10-question_score": [
            15.322598457336426,
            15.04580307006836,
            14.736242294311523,
            12.426634788513184,
            12.409530639648438,
            12.325909614562988,
            11.89840030670166,
            11.66573429107666,
            11.282712936401367
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.10435.pdf",
        "text-top-10-question": [
            0,
            0,
            5,
            3,
            5,
            5,
            5,
            4,
            6,
            4
        ],
        "text-top-10-question_score": [
            24.1875,
            21.828125,
            21.328125,
            20.40625,
            19.4375,
            18.515625,
            17.9375,
            15.5625,
            14.7734375,
            14.046875
        ]
    },
    {
        "doc_id": "1603.04513.pdf",
        "q_uid": "d8de12f5eff64d0e9c9e88f6ebdabc4cdf042c22",
        "question": "How much gain does the model achieve with pretraining MVCNN?",
        "answer": "0.8 points on Binary; 0.7 points on Fine-Grained; 0.6 points on Senti140; 0.7 points on Subj",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            1,
            5,
            2,
            6,
            0,
            3,
            4,
            8,
            9
        ],
        "image-top-10-question_score": [
            16.504804611206055,
            16.226125717163086,
            15.976351737976074,
            15.85525131225586,
            15.807921409606934,
            15.43541145324707,
            15.367094039916992,
            15.17319107055664,
            15.169473648071289,
            13.346780776977539
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1603.04513.pdf",
        "text-top-10-question": [
            1,
            2,
            0,
            7,
            6,
            7,
            4,
            2,
            8,
            3
        ],
        "text-top-10-question_score": [
            18.46875,
            17.6875,
            17.25,
            16.921875,
            16.765625,
            16.375,
            16.234375,
            15.7421875,
            14.953125,
            14.859375
        ]
    },
    {
        "doc_id": "1603.04513.pdf",
        "q_uid": "9cba2ee1f8e1560e48b3099d0d8cf6c854ddea2e",
        "question": "What are the effects of extracting features of multigranular phrases?",
        "answer": "The system benefits from filters of each size., features of multigranular phrases are extracted with variable-size convolution filters.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            8,
            3,
            5,
            2,
            10,
            9,
            4,
            7
        ],
        "image-top-10-question_score": [
            17.129104614257812,
            15.89111614227295,
            15.765081405639648,
            15.761604309082031,
            15.708166122436523,
            15.167970657348633,
            15.044905662536621,
            14.902621269226074,
            14.886897087097168,
            14.805505752563477
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1603.04513.pdf",
        "text-top-10-question": [
            8,
            0,
            8,
            2,
            1,
            3,
            5,
            0,
            3,
            1
        ],
        "text-top-10-question_score": [
            21.890625,
            19.046875,
            18.328125,
            15.515625,
            14.4921875,
            14.4453125,
            14.359375,
            14.1015625,
            13.8671875,
            13.0625
        ]
    },
    {
        "doc_id": "1603.04513.pdf",
        "q_uid": "7975c3e1f61344e3da3b38bb12e1ac6dcb153a18",
        "question": "What are the effects of diverse versions of pertained word embeddings? ",
        "answer": "each embedding version is crucial for good performance",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            0,
            1,
            7,
            2,
            6,
            4,
            5,
            9,
            3
        ],
        "image-top-10-question_score": [
            18.26089859008789,
            17.87869644165039,
            17.758502960205078,
            17.557601928710938,
            17.05199432373047,
            17.018146514892578,
            16.885805130004883,
            16.751022338867188,
            15.713227272033691,
            15.704242706298828
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1603.04513.pdf",
        "text-top-10-question": [
            8,
            0,
            8,
            8,
            1,
            1,
            4,
            2,
            1,
            2
        ],
        "text-top-10-question_score": [
            21.609375,
            19.59375,
            18.703125,
            18.703125,
            18.25,
            18.015625,
            17.59375,
            17.375,
            17.359375,
            17.21875
        ]
    },
    {
        "doc_id": "1607.06025.pdf",
        "q_uid": "ea6764a362bac95fb99969e9f8c773a61afd8f39",
        "question": "What is the highest accuracy score achieved?",
        "answer": "82.0%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            15,
            0,
            11,
            2,
            9,
            14,
            12,
            10,
            13,
            8
        ],
        "image-top-10-question_score": [
            14.352123260498047,
            13.85450553894043,
            13.740514755249023,
            13.550175666809082,
            13.507217407226562,
            13.3935546875,
            13.347208023071289,
            12.988042831420898,
            12.930068016052246,
            12.648090362548828
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1607.06025.pdf",
        "text-top-10-question": [
            9,
            12,
            0,
            15,
            2,
            9,
            12,
            0,
            9,
            2
        ],
        "text-top-10-question_score": [
            21.0,
            19.8125,
            19.53125,
            19.15625,
            18.96875,
            18.484375,
            16.765625,
            15.8984375,
            15.5703125,
            14.0703125
        ]
    },
    {
        "doc_id": "1909.00252.pdf",
        "q_uid": "2815bac42db32d8f988b380fed997af31601f129",
        "question": "What is improvement in accuracy for short Jokes in relation other types of jokes?",
        "answer": "It had the highest accuracy comparing to all datasets 0.986% and It had the highest improvement comparing to previous methods on the same dataset by 8%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            0,
            4,
            1
        ],
        "image-top-10-question_score": [
            19.82476806640625,
            19.19355010986328,
            18.95682144165039,
            18.487091064453125,
            18.410972595214844
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00252.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            2,
            4,
            3,
            0,
            0,
            0,
            3
        ],
        "text-top-10-question_score": [
            19.15625,
            19.140625,
            19.125,
            18.765625,
            18.265625,
            17.046875,
            16.640625,
            16.609375,
            16.09375,
            15.2734375
        ]
    },
    {
        "doc_id": "1808.09920.pdf",
        "q_uid": "63403ffc0232ff041f3da8fa6c30827cfd6404b7",
        "question": "What is the metric used with WIKIHOP?",
        "answer": "Accuracy",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            8,
            4,
            11,
            12,
            5,
            7,
            9,
            6
        ],
        "image-top-10-question_score": [
            15.417346954345703,
            15.375350952148438,
            15.252711296081543,
            14.819958686828613,
            14.668440818786621,
            14.540505409240723,
            14.142740249633789,
            13.84417724609375,
            13.150075912475586,
            12.511834144592285
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1808.09920.pdf",
        "text-top-10-question": [
            1,
            1,
            4,
            0,
            4,
            7,
            4,
            6,
            7,
            5
        ],
        "text-top-10-question_score": [
            18.296875,
            15.296875,
            15.1328125,
            14.03125,
            13.3828125,
            12.90625,
            12.7265625,
            12.3515625,
            11.8515625,
            11.7265625
        ]
    },
    {
        "doc_id": "1808.09920.pdf",
        "q_uid": "a25c1883f0a99d2b6471fed48c5121baccbbae82",
        "question": "What performance does the Entity-GCN get on WIKIHOP?",
        "answer": "During testing: 67.6 for single model without coreference, 66.4 for single model with coreference, 71.2 for ensemble of 5 models",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            11,
            5,
            4,
            6,
            12,
            8,
            0,
            7,
            3
        ],
        "image-top-10-question_score": [
            19.878990173339844,
            19.812976837158203,
            19.760602951049805,
            18.911026000976562,
            18.607393264770508,
            18.386821746826172,
            18.095605850219727,
            18.077083587646484,
            17.261608123779297,
            17.2540283203125
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1808.09920.pdf",
        "text-top-10-question": [
            11,
            1,
            1,
            6,
            0,
            7,
            6,
            5,
            6,
            11
        ],
        "text-top-10-question_score": [
            21.53125,
            21.09375,
            20.53125,
            20.5,
            20.0,
            19.65625,
            19.1875,
            19.125,
            19.0625,
            18.90625
        ]
    },
    {
        "doc_id": "2002.08899.pdf",
        "q_uid": "79ed71a3505cf6f5e8bf121fd7ec1518cab55cae",
        "question": "How do they damage different neural modules?",
        "answer": "Damage to neural modules is done by randomly initializing their weights, causing the loss of all learned information.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            0,
            5,
            4,
            2,
            1
        ],
        "image-top-10-question_score": [
            13.457722663879395,
            12.987974166870117,
            11.881682395935059,
            10.401861190795898,
            9.204643249511719,
            9.169445991516113
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.08899.pdf",
        "text-top-10-question": [
            3,
            0,
            0,
            0,
            5,
            0,
            2,
            2,
            4,
            5
        ],
        "text-top-10-question_score": [
            24.5,
            21.328125,
            18.953125,
            18.796875,
            14.765625,
            14.421875,
            13.125,
            12.96875,
            12.25,
            12.1875
        ]
    },
    {
        "doc_id": "1705.00108.pdf",
        "q_uid": "a5b67470a1c4779877f0d8b7724879bbb0a3b313",
        "question": "what metrics are used in evaluation?",
        "answer": "micro-averaged F1",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            6,
            7,
            4,
            0,
            5,
            9,
            8,
            2,
            1
        ],
        "image-top-10-question_score": [
            11.753270149230957,
            10.514506340026855,
            10.459620475769043,
            10.19830322265625,
            10.08556842803955,
            9.930745124816895,
            8.956609725952148,
            8.820684432983398,
            8.198729515075684,
            8.092680931091309
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1705.00108.pdf",
        "text-top-10-question": [
            3,
            7,
            3,
            6,
            0,
            0,
            3,
            6,
            4,
            4
        ],
        "text-top-10-question_score": [
            18.109375,
            15.5234375,
            15.421875,
            13.4921875,
            13.296875,
            12.6015625,
            12.6015625,
            12.1640625,
            11.03125,
            10.9921875
        ]
    },
    {
        "doc_id": "1705.00108.pdf",
        "q_uid": "4640793d82aa7db30ad7b88c0bf0a1030e636558",
        "question": "what previous systems were compared to?",
        "answer": "Chiu and Nichols (2016), Lample et al. (2016), Ma and Hovy (2016), Yang et al. (2017), Hashimoto et al. (2016), S\u00f8gaard and Goldberg (2016) ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            9,
            4,
            6,
            5,
            8,
            7,
            2,
            1
        ],
        "image-top-10-question_score": [
            11.96738052368164,
            11.808708190917969,
            11.603836059570312,
            11.282011032104492,
            11.231348037719727,
            11.21594524383545,
            11.18385124206543,
            11.090404510498047,
            10.818086624145508,
            10.71174144744873
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1705.00108.pdf",
        "text-top-10-question": [
            0,
            4,
            0,
            6,
            4,
            7,
            6,
            3,
            5,
            6
        ],
        "text-top-10-question_score": [
            17.546875,
            16.1875,
            14.953125,
            14.5390625,
            13.5234375,
            13.5078125,
            13.296875,
            13.2890625,
            13.0,
            12.7578125
        ]
    },
    {
        "doc_id": "1712.03547.pdf",
        "q_uid": "a4d8fdcaa8adf99bdd1d7224f1a85c610659a9d3",
        "question": "When they say \"comparable performance\", how much of a performance drop do these new embeddings result in?",
        "answer": "Performance was comparable, with the proposed method quite close and sometimes exceeding performance of baseline method.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            0,
            1,
            2,
            4
        ],
        "image-top-10-question_score": [
            20.756715774536133,
            19.38131332397461,
            19.04132652282715,
            18.352109909057617,
            17.662485122680664
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1712.03547.pdf",
        "text-top-10-question": [
            3,
            0,
            2,
            1,
            3,
            3,
            2,
            3,
            2,
            1
        ],
        "text-top-10-question_score": [
            14.2265625,
            13.8203125,
            13.640625,
            13.21875,
            12.8671875,
            11.84375,
            11.71875,
            11.65625,
            11.59375,
            11.5234375
        ]
    },
    {
        "doc_id": "1910.02339.pdf",
        "q_uid": "9c4a4dfa7b0b977173e76e2d2f08fa984af86f0e",
        "question": "How does TP-N2F compare to LSTM-based Seq2Seq in terms of training and inference speed?",
        "answer": "Full Testing Set accuracy: 84.02\nCleaned Testing Set accuracy: 93.48",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            10,
            8,
            5,
            4,
            14,
            2,
            13,
            0,
            3
        ],
        "image-top-10-question_score": [
            25.291257858276367,
            24.185054779052734,
            23.99941062927246,
            23.946380615234375,
            23.83720588684082,
            23.376649856567383,
            23.22250747680664,
            22.975173950195312,
            22.86663818359375,
            22.604999542236328
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.02339.pdf",
        "text-top-10-question": [
            6,
            7,
            7,
            12,
            10,
            10,
            7,
            0,
            5,
            5
        ],
        "text-top-10-question_score": [
            21.859375,
            21.6875,
            21.390625,
            19.828125,
            19.390625,
            19.21875,
            18.765625,
            18.65625,
            18.296875,
            16.84375
        ]
    },
    {
        "doc_id": "1910.02339.pdf",
        "q_uid": "4c7ac51a66c15593082e248451e8f6896e476ffb",
        "question": "What is the performance proposed model achieved on AlgoList benchmark?",
        "answer": "Full Testing Set Accuracy: 84.02\nCleaned Testing Set Accuracy: 93.48",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            10,
            8,
            14,
            1,
            6,
            9,
            0,
            12,
            13
        ],
        "image-top-10-question_score": [
            15.763650894165039,
            15.206092834472656,
            15.195830345153809,
            13.969587326049805,
            13.819622039794922,
            13.778376579284668,
            13.76849365234375,
            13.70415210723877,
            13.585147857666016,
            13.376398086547852
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.02339.pdf",
        "text-top-10-question": [
            8,
            7,
            6,
            10,
            7,
            6,
            8,
            10,
            0,
            1
        ],
        "text-top-10-question_score": [
            16.5625,
            16.53125,
            16.46875,
            16.21875,
            16.078125,
            15.8671875,
            15.328125,
            14.875,
            14.8359375,
            14.7734375
        ]
    },
    {
        "doc_id": "1910.02339.pdf",
        "q_uid": "05671d068679be259493df638d27c106e7dd36d0",
        "question": "What is the performance proposed model achieved on MathQA?",
        "answer": "Operation accuracy: 71.89\nExecution accuracy: 55.95",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            10,
            6,
            14,
            17,
            8,
            12,
            0,
            1,
            9
        ],
        "image-top-10-question_score": [
            15.8879976272583,
            15.45761775970459,
            14.638826370239258,
            14.512650489807129,
            14.503447532653809,
            14.145820617675781,
            13.901460647583008,
            13.827192306518555,
            13.12448501586914,
            13.070608139038086
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.02339.pdf",
        "text-top-10-question": [
            6,
            6,
            7,
            6,
            10,
            7,
            1,
            0,
            7,
            10
        ],
        "text-top-10-question_score": [
            23.5625,
            18.921875,
            16.65625,
            16.15625,
            16.125,
            15.9453125,
            15.875,
            15.484375,
            15.2421875,
            15.1796875
        ]
    },
    {
        "doc_id": "2003.06044.pdf",
        "q_uid": "a3a871ca2417b2ada9df1438d282c45e4b4ad668",
        "question": "How do previous methods perform on the Switchboard Dialogue Act and DailyDialog datasets?",
        "answer": "Table TABREF20 , Table TABREF22, Table TABREF23",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            6,
            1,
            7,
            0,
            8,
            3,
            5,
            9,
            2
        ],
        "image-top-10-question_score": [
            20.538015365600586,
            19.65038299560547,
            19.144386291503906,
            18.367115020751953,
            18.34471893310547,
            18.321731567382812,
            18.223312377929688,
            18.056446075439453,
            17.808429718017578,
            16.82394790649414
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.06044.pdf",
        "text-top-10-question": [
            0,
            0,
            4,
            8,
            4,
            1,
            7,
            6,
            4,
            8
        ],
        "text-top-10-question_score": [
            22.796875,
            21.84375,
            18.375,
            17.046875,
            16.609375,
            16.375,
            15.5546875,
            15.375,
            15.3203125,
            14.7734375
        ]
    },
    {
        "doc_id": "2003.06044.pdf",
        "q_uid": "0fcac64544842dd06d14151df8c72fc6de5d695c",
        "question": "What previous methods is the proposed method compared against?",
        "answer": "BLSTM+Attention+BLSTM\nHierarchical BLSTM-CRF\nCRF-ASN\nHierarchical CNN (window 4)\nmLSTM-RNN\nDRLM-Conditional\nLSTM-Softmax\nRCNN\nCNN\nCRF\nLSTM\nBERT",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            3,
            2,
            4,
            1,
            6,
            7,
            8,
            0,
            9
        ],
        "image-top-10-question_score": [
            14.937881469726562,
            14.901931762695312,
            14.834893226623535,
            14.541194915771484,
            13.989744186401367,
            13.955582618713379,
            13.590347290039062,
            13.563241958618164,
            13.053495407104492,
            12.541484832763672
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.06044.pdf",
        "text-top-10-question": [
            5,
            5,
            5,
            1,
            2,
            0,
            1,
            2,
            2,
            6
        ],
        "text-top-10-question_score": [
            18.0625,
            16.359375,
            15.6015625,
            14.6015625,
            14.40625,
            13.8203125,
            13.765625,
            13.078125,
            13.0625,
            12.8828125
        ]
    },
    {
        "doc_id": "2002.01359.pdf",
        "q_uid": "b43fa27270eeba3e80ff2a03754628b5459875d6",
        "question": "What domains are present in the data?",
        "answer": "Alarm, Banks, Buses, Calendar, Events, Flights, Homes, Hotels, Media, Messaging, Movies, Music, Payment, Rental Cars, Restaurants, Ride Sharing, Services, Train, Travel, Weather",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            4,
            1,
            5,
            6,
            7,
            0
        ],
        "image-top-10-question_score": [
            14.273002624511719,
            13.468189239501953,
            13.350208282470703,
            13.0148286819458,
            12.972049713134766,
            12.488635063171387,
            12.032745361328125,
            12.005085945129395
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.01359.pdf",
        "text-top-10-question": [
            3,
            4,
            4,
            3,
            6,
            3,
            6,
            2,
            1,
            1
        ],
        "text-top-10-question_score": [
            19.96875,
            18.609375,
            18.5,
            18.296875,
            17.953125,
            17.265625,
            16.578125,
            16.09375,
            15.8828125,
            15.84375
        ]
    },
    {
        "doc_id": "1612.05270.pdf",
        "q_uid": "458dbf217218fcab9153e33045aac08a2c8a38c6",
        "question": "How many texts/datapoints are in the SemEval, TASS and SENTIPOLC datasets?",
        "answer": "Total number of annotated data:\nSemeval'15: 10712\nSemeval'16: 28632\nTass'15: 69000\nSentipol'14: 6428",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            6,
            7,
            1,
            4,
            9,
            8,
            10,
            0,
            3
        ],
        "image-top-10-question_score": [
            24.737258911132812,
            23.901836395263672,
            23.751712799072266,
            23.44516372680664,
            23.001686096191406,
            21.809581756591797,
            21.77267837524414,
            21.579387664794922,
            21.45827293395996,
            20.20168685913086
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1612.05270.pdf",
        "text-top-10-question": [
            6,
            5,
            5,
            7,
            5,
            6,
            4,
            6,
            1,
            6
        ],
        "text-top-10-question_score": [
            18.40625,
            18.046875,
            17.5625,
            17.171875,
            16.640625,
            16.265625,
            16.125,
            15.5078125,
            15.3515625,
            15.1171875
        ]
    },
    {
        "doc_id": "1612.05270.pdf",
        "q_uid": "cebf3e07057339047326cb2f8863ee633a62f49f",
        "question": "In which languages did the approach outperform the reported results?",
        "answer": "Arabic, German, Portuguese, Russian, Swedish",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            7,
            1,
            0,
            4,
            8,
            6,
            10,
            3,
            9
        ],
        "image-top-10-question_score": [
            16.127887725830078,
            16.04940414428711,
            15.854267120361328,
            15.837850570678711,
            15.772785186767578,
            15.738680839538574,
            14.860795021057129,
            14.771535873413086,
            13.339828491210938,
            13.056611061096191
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1612.05270.pdf",
        "text-top-10-question": [
            0,
            8,
            1,
            5,
            1,
            0,
            5,
            5,
            6,
            8
        ],
        "text-top-10-question_score": [
            20.65625,
            18.953125,
            18.890625,
            16.53125,
            16.5,
            14.359375,
            13.90625,
            13.421875,
            13.25,
            12.90625
        ]
    },
    {
        "doc_id": "1910.08987.pdf",
        "q_uid": "f1831b2e96ff8ef65b8fde8b4c2ee3e04b7ac4bf",
        "question": "How close do clusters match to ground truth tone categories?",
        "answer": "NMI between cluster assignments and ground truth tones for all sylables is:\nMandarin: 0.641\nCantonese: 0.464",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            4,
            3,
            2,
            1,
            5,
            6
        ],
        "image-top-10-question_score": [
            16.044384002685547,
            15.975320816040039,
            15.386245727539062,
            15.336408615112305,
            15.028274536132812,
            14.286846160888672,
            13.029376029968262
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.08987.pdf",
        "text-top-10-question": [
            4,
            4,
            3,
            3,
            0,
            5,
            0,
            4,
            2,
            4
        ],
        "text-top-10-question_score": [
            21.609375,
            21.5625,
            21.5,
            20.125,
            19.21875,
            18.859375,
            17.1875,
            17.046875,
            15.78125,
            14.0546875
        ]
    },
    {
        "doc_id": "1701.09123.pdf",
        "q_uid": "20ec88c45c1d633adfd7bff7bbf3336d01fb6f37",
        "question": "what are the evaluation metrics?",
        "answer": "Precision, Recall, F1",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            20,
            13,
            21,
            14,
            16,
            0,
            15,
            24,
            3,
            25
        ],
        "image-top-10-question_score": [
            10.32012939453125,
            10.309764862060547,
            10.271218299865723,
            10.249223709106445,
            10.198005676269531,
            10.146806716918945,
            10.106939315795898,
            10.040874481201172,
            9.980498313903809,
            9.942394256591797
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1701.09123.pdf",
        "text-top-10-question": [
            24,
            3,
            4,
            13,
            1,
            15,
            13,
            21,
            3,
            0
        ],
        "text-top-10-question_score": [
            14.8359375,
            14.2734375,
            14.109375,
            14.109375,
            13.9375,
            13.8359375,
            13.6484375,
            13.6328125,
            13.6015625,
            13.53125
        ]
    },
    {
        "doc_id": "1701.09123.pdf",
        "q_uid": "a4fe5d182ddee24e5bbf222d6d6996b3925060c8",
        "question": "which datasets were used in evaluation?",
        "answer": "CoNLL 2003, GermEval 2014, CoNLL 2002, Egunkaria, MUC7, Wikigold, MEANTIME, SONAR-1, Ancora 2.0",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            13,
            4,
            21,
            18,
            2,
            14,
            15,
            16,
            12
        ],
        "image-top-10-question_score": [
            13.356307983398438,
            13.117755889892578,
            13.000629425048828,
            12.9036865234375,
            12.79058837890625,
            12.436880111694336,
            12.37771987915039,
            12.36910629272461,
            12.335184097290039,
            12.177176475524902
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1701.09123.pdf",
        "text-top-10-question": [
            4,
            13,
            3,
            13,
            18,
            22,
            21,
            2,
            12,
            18
        ],
        "text-top-10-question_score": [
            23.5,
            23.3125,
            22.6875,
            22.40625,
            22.171875,
            21.703125,
            21.5625,
            21.015625,
            20.890625,
            20.84375
        ]
    },
    {
        "doc_id": "1611.00514.pdf",
        "q_uid": "30803eefd7cdeb721f47c9ca72a5b1d750b8e03b",
        "question": "How well does their system perform on the development set of SRE?",
        "answer": "EER 16.04, Cmindet 0.6012, Cdet 0.6107",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            4,
            5,
            2,
            1,
            3,
            6
        ],
        "image-top-10-question_score": [
            18.22962760925293,
            16.851158142089844,
            16.54255485534668,
            15.885826110839844,
            15.54360580444336,
            15.350193977355957,
            15.2855224609375
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1611.00514.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            4,
            0,
            4,
            3,
            4,
            2,
            1
        ],
        "text-top-10-question_score": [
            21.109375,
            20.359375,
            18.359375,
            18.25,
            17.5625,
            15.96875,
            14.21875,
            13.2421875,
            12.9375,
            12.2578125
        ]
    },
    {
        "doc_id": "1704.08960.pdf",
        "q_uid": "25e4dbc7e211a1ebe02ee8dff675b846fb18fdc5",
        "question": "What external sources are used?",
        "answer": "Raw data from Gigaword, Automatically segmented text from Gigaword, Heterogenous training data from People's Daily, POS data from People's Daily",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            9,
            10,
            8,
            1,
            5,
            4,
            0,
            7,
            2,
            6
        ],
        "image-top-10-question_score": [
            10.953628540039062,
            10.717838287353516,
            10.354976654052734,
            10.319927215576172,
            10.071762084960938,
            10.000133514404297,
            9.980544090270996,
            9.939229965209961,
            8.960750579833984,
            8.856851577758789
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1704.08960.pdf",
        "text-top-10-question": [
            1,
            1,
            4,
            5,
            0,
            1,
            0,
            8,
            4,
            4
        ],
        "text-top-10-question_score": [
            19.46875,
            18.96875,
            17.359375,
            16.5,
            15.0390625,
            13.828125,
            13.765625,
            12.5625,
            11.8203125,
            11.4375
        ]
    },
    {
        "doc_id": "2002.05058.pdf",
        "q_uid": "75b69eef4a38ec16df63d60be9708a3c44a79c56",
        "question": "How much better peformance is achieved in human evaluation when model is trained considering proposed metric?",
        "answer": "Pearson correlation to human judgement - proposed vs next best metric\nSample level comparison:\n- Story generation: 0.387 vs 0.148\n- Dialogue: 0.472 vs 0.341\nModel level comparison:\n- Story generation:  0.631 vs 0.302\n- Dialogue: 0.783 vs 0.553",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            5,
            6,
            1,
            0,
            2,
            3,
            8,
            7
        ],
        "image-top-10-question_score": [
            20.18075942993164,
            20.032207489013672,
            19.983257293701172,
            19.611112594604492,
            19.15442657470703,
            17.95844268798828,
            17.899747848510742,
            16.812320709228516,
            16.734447479248047
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.05058.pdf",
        "text-top-10-question": [
            0,
            5,
            6,
            0,
            6,
            5,
            5,
            6,
            1,
            4
        ],
        "text-top-10-question_score": [
            22.671875,
            19.40625,
            19.40625,
            19.203125,
            19.046875,
            18.578125,
            18.484375,
            18.234375,
            18.15625,
            18.09375
        ]
    },
    {
        "doc_id": "2002.06675.pdf",
        "q_uid": "8a5254ca726a2914214a4c0b6b42811a007ecfc6",
        "question": "How much transcribed data is available for for Ainu language?",
        "answer": "Transcribed data is available for duration of 38h 54m 38s for 8 speakers.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            3,
            5,
            4,
            6,
            2
        ],
        "image-top-10-question_score": [
            17.338586807250977,
            16.03330421447754,
            15.515583992004395,
            14.752896308898926,
            13.521869659423828,
            12.59953498840332,
            12.194759368896484
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.06675.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            4,
            0,
            1,
            1,
            5,
            0,
            5
        ],
        "text-top-10-question_score": [
            18.65625,
            18.125,
            16.75,
            16.328125,
            15.984375,
            15.984375,
            15.4296875,
            15.3671875,
            15.21875,
            15.1875
        ]
    },
    {
        "doc_id": "1909.08041.pdf",
        "q_uid": "13d92cbc2c77134626e26166c64ca5c00aec0bf5",
        "question": "What baseline approaches do they compare against?",
        "answer": "HotspotQA: Yang, Ding, Muppet\nFever: Hanselowski, Yoneda, Nie",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            10,
            1,
            9,
            3,
            2,
            5,
            7,
            0,
            8
        ],
        "image-top-10-question_score": [
            12.71225357055664,
            12.348814010620117,
            12.270061492919922,
            12.24637508392334,
            11.990583419799805,
            11.89559555053711,
            11.824394226074219,
            11.810380935668945,
            11.804570198059082,
            11.574407577514648
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.08041.pdf",
        "text-top-10-question": [
            2,
            7,
            3,
            1,
            4,
            5,
            2,
            4,
            9,
            8
        ],
        "text-top-10-question_score": [
            10.3203125,
            10.21875,
            10.203125,
            9.828125,
            9.421875,
            9.3359375,
            8.9765625,
            8.8125,
            8.6796875,
            8.53125
        ]
    },
    {
        "doc_id": "1909.08041.pdf",
        "q_uid": "ac54a9c30c968e5225978a37032158a6ffd4ddb8",
        "question": "Retrieval at what level performs better, sentence level or paragraph level?",
        "answer": "This seems to indicate that the downstream QA module relies more on the upstream paragraph-level retrieval whereas the verification module relies more on the upstream sentence-level retrieval.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            6,
            8,
            5,
            9,
            1,
            10,
            3,
            7,
            0
        ],
        "image-top-10-question_score": [
            17.607276916503906,
            17.50396728515625,
            17.449626922607422,
            16.918954849243164,
            16.852872848510742,
            16.351829528808594,
            15.905244827270508,
            15.838626861572266,
            15.775360107421875,
            15.692336082458496
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.08041.pdf",
        "text-top-10-question": [
            5,
            8,
            5,
            6,
            0,
            5,
            1,
            5,
            0,
            6
        ],
        "text-top-10-question_score": [
            22.921875,
            22.1875,
            21.859375,
            21.625,
            21.359375,
            21.1875,
            21.125,
            21.0625,
            20.578125,
            20.5625
        ]
    },
    {
        "doc_id": "1909.09270.pdf",
        "q_uid": "a7510ec34eaec2c7ac2869962b69cc41031221e5",
        "question": "What was their F1 score on the Bengali NER corpus?",
        "answer": "52.0%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            6,
            8,
            0,
            4,
            5,
            9,
            3,
            2,
            10
        ],
        "image-top-10-question_score": [
            15.520215034484863,
            15.238621711730957,
            14.717456817626953,
            14.157042503356934,
            14.15619945526123,
            13.792101860046387,
            13.664717674255371,
            13.542858123779297,
            13.361262321472168,
            13.29601001739502
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.09270.pdf",
        "text-top-10-question": [
            8,
            7,
            0,
            7,
            6,
            8,
            6,
            7,
            0,
            7
        ],
        "text-top-10-question_score": [
            20.0,
            19.390625,
            17.796875,
            17.40625,
            16.15625,
            15.5546875,
            14.96875,
            14.265625,
            13.6328125,
            12.84375
        ]
    },
    {
        "doc_id": "1903.00172.pdf",
        "q_uid": "1fb73176394ef59adfaa8fc7827395525f9a5af7",
        "question": "Where did they get training data?",
        "answer": "AmazonQA and ConciergeQA datasets",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            5,
            6,
            8,
            7,
            2,
            1,
            10,
            12,
            11
        ],
        "image-top-10-question_score": [
            12.77059268951416,
            12.25365161895752,
            11.750499725341797,
            10.750153541564941,
            10.70770263671875,
            10.672253608703613,
            10.661300659179688,
            10.496980667114258,
            10.491066932678223,
            10.426164627075195
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1903.00172.pdf",
        "text-top-10-question": [
            4,
            4,
            6,
            5,
            4,
            0,
            5,
            4,
            9,
            0
        ],
        "text-top-10-question_score": [
            17.296875,
            17.015625,
            15.75,
            15.5390625,
            14.9609375,
            13.2109375,
            12.6171875,
            12.5078125,
            12.4609375,
            12.390625
        ]
    },
    {
        "doc_id": "1903.00172.pdf",
        "q_uid": "d70ba6053e245ee4179c26a5dabcad37561c6af0",
        "question": "Which datasets did they experiment on?",
        "answer": "ConciergeQA and AmazonQA",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            5,
            8,
            1,
            7,
            6,
            11,
            10,
            9,
            0
        ],
        "image-top-10-question_score": [
            13.697742462158203,
            12.689582824707031,
            12.414124488830566,
            12.405658721923828,
            12.119902610778809,
            12.098477363586426,
            11.830183029174805,
            11.509496688842773,
            11.358991622924805,
            11.284628868103027
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1903.00172.pdf",
        "text-top-10-question": [
            4,
            1,
            5,
            7,
            8,
            8,
            4,
            4,
            11,
            5
        ],
        "text-top-10-question_score": [
            20.4375,
            17.578125,
            16.828125,
            16.546875,
            15.390625,
            15.296875,
            14.9140625,
            14.6484375,
            14.546875,
            14.1171875
        ]
    },
    {
        "doc_id": "1705.08142.pdf",
        "q_uid": "a1c5b95e407127c6bb2f9a19b7d9b1f1bcd4a7a5",
        "question": "Do sluice networks outperform non-transfer learning approaches?",
        "answer": "Yes",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            4,
            6,
            1,
            5,
            0,
            3,
            7
        ],
        "image-top-10-question_score": [
            16.436038970947266,
            15.26954460144043,
            14.603959083557129,
            14.555302619934082,
            14.47084903717041,
            13.525691986083984,
            13.25229549407959,
            13.213679313659668
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1705.08142.pdf",
        "text-top-10-question": [
            4,
            5,
            0,
            4,
            6,
            1,
            6,
            4,
            2,
            2
        ],
        "text-top-10-question_score": [
            20.328125,
            19.5,
            19.484375,
            19.4375,
            17.84375,
            17.21875,
            16.9375,
            16.796875,
            16.546875,
            16.171875
        ]
    },
    {
        "doc_id": "1704.05907.pdf",
        "q_uid": "bde6fa2057fa21b38a91eeb2bb6a3ae7fb3a2c62",
        "question": "what state of the accuracy did they obtain?",
        "answer": "51.5",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            2,
            3,
            0,
            1,
            5
        ],
        "image-top-10-question_score": [
            14.741450309753418,
            14.706270217895508,
            12.906886100769043,
            12.4016695022583,
            8.489692687988281,
            8.444478988647461
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1704.05907.pdf",
        "text-top-10-question": [
            3,
            2,
            2,
            0,
            4,
            3,
            2,
            3,
            3,
            0
        ],
        "text-top-10-question_score": [
            21.140625,
            18.90625,
            17.140625,
            16.140625,
            15.3828125,
            12.9921875,
            11.96875,
            10.1640625,
            9.6328125,
            8.625
        ]
    },
    {
        "doc_id": "2001.08051.pdf",
        "q_uid": "9ebb2adf92a0f8db99efddcade02a20a219ca7d9",
        "question": "How is the proficiency score calculated?",
        "answer": "They used 6 indicators for proficiency (same for written and spoken) each marked by bad, medium or good by one expert.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            0,
            4,
            1,
            2,
            5,
            6,
            7
        ],
        "image-top-10-question_score": [
            12.365676879882812,
            11.735191345214844,
            11.117600440979004,
            11.067489624023438,
            10.992493629455566,
            10.886747360229492,
            10.155478477478027,
            8.581897735595703
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.08051.pdf",
        "text-top-10-question": [
            1,
            0,
            5,
            4,
            4,
            0,
            1,
            2,
            5,
            0
        ],
        "text-top-10-question_score": [
            18.453125,
            14.9765625,
            14.46875,
            14.3515625,
            13.421875,
            12.78125,
            12.7578125,
            12.65625,
            12.15625,
            11.9921875
        ]
    },
    {
        "doc_id": "2001.08051.pdf",
        "q_uid": "973f6284664675654cc9881745880a0e88f3280e",
        "question": "What proficiency indicators are used to the score the utterances?",
        "answer": "6 indicators:\n- lexical richness\n- pronunciation and fluency\n- syntactical correctness\n- fulfillment of delivery\n- coherence and cohesion\n- communicative, descriptive, narrative skills",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            0,
            1,
            2,
            4,
            3,
            6,
            7
        ],
        "image-top-10-question_score": [
            15.135274887084961,
            15.046842575073242,
            14.78483772277832,
            14.45406723022461,
            14.251094818115234,
            13.897354125976562,
            13.36117935180664,
            12.907999038696289
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.08051.pdf",
        "text-top-10-question": [
            1,
            2,
            0,
            5,
            0,
            4,
            5,
            0,
            1,
            7
        ],
        "text-top-10-question_score": [
            22.40625,
            19.40625,
            18.5625,
            17.859375,
            17.296875,
            16.984375,
            16.8125,
            15.8125,
            15.453125,
            15.046875
        ]
    },
    {
        "doc_id": "2001.08051.pdf",
        "q_uid": "0a3a8d1b0cbac559f7de845d845ebbfefb91135e",
        "question": "What accuracy is achieved by the speech recognition system?",
        "answer": "Accuracy not available: WER results are reported 42.6 German, 35.9 English",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            6,
            3,
            4,
            1,
            7,
            5,
            2
        ],
        "image-top-10-question_score": [
            14.843748092651367,
            14.264215469360352,
            13.964069366455078,
            13.851034164428711,
            13.782964706420898,
            13.782896041870117,
            13.770298957824707,
            13.685101509094238
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.08051.pdf",
        "text-top-10-question": [
            4,
            0,
            0,
            5,
            3,
            6,
            7,
            6,
            7,
            6
        ],
        "text-top-10-question_score": [
            20.171875,
            18.984375,
            17.765625,
            17.515625,
            17.171875,
            16.75,
            16.71875,
            16.34375,
            16.25,
            16.1875
        ]
    },
    {
        "doc_id": "2001.08051.pdf",
        "q_uid": "ec2b8c43f14227cf74f9b49573cceb137dd336e7",
        "question": "How is the speech recognition system evaluated?",
        "answer": "Speech recognition system is evaluated using WER metric.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            6,
            1,
            4,
            2,
            5,
            7,
            3
        ],
        "image-top-10-question_score": [
            13.532644271850586,
            13.0181884765625,
            12.9144868850708,
            12.674076080322266,
            12.599578857421875,
            12.50484848022461,
            12.373443603515625,
            12.31817626953125
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.08051.pdf",
        "text-top-10-question": [
            0,
            4,
            5,
            7,
            0,
            6,
            6,
            6,
            6,
            4
        ],
        "text-top-10-question_score": [
            21.390625,
            21.203125,
            20.421875,
            20.28125,
            19.96875,
            18.890625,
            18.734375,
            18.71875,
            18.5,
            18.390625
        ]
    },
    {
        "doc_id": "2001.08051.pdf",
        "q_uid": "5e5460ea955d8bce89526647dd7c4f19b173ab34",
        "question": "How many of the utterances are transcribed?",
        "answer": "Total number of transcribed utterances including Train and Test for both Eng and Ger language is 5562 (2188 cleaned)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            5,
            0,
            2,
            1,
            7,
            6
        ],
        "image-top-10-question_score": [
            13.803096771240234,
            13.484313011169434,
            13.319246292114258,
            13.183184623718262,
            12.912562370300293,
            12.582437515258789,
            11.9666109085083,
            11.592216491699219
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.08051.pdf",
        "text-top-10-question": [
            3,
            0,
            0,
            4,
            1,
            2,
            1,
            2,
            3,
            2
        ],
        "text-top-10-question_score": [
            21.8125,
            20.46875,
            20.078125,
            19.09375,
            18.671875,
            18.203125,
            17.59375,
            17.34375,
            16.984375,
            16.609375
        ]
    },
    {
        "doc_id": "2001.08051.pdf",
        "q_uid": "d7d611f622552142723e064f330d071f985e805c",
        "question": "How many utterances are in the corpus?",
        "answer": "Total number of utterances available is: 70607 (37344 ENG + 33263 GER)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            0,
            1,
            4,
            3,
            2,
            6,
            7
        ],
        "image-top-10-question_score": [
            13.178854942321777,
            13.149895668029785,
            12.728984832763672,
            12.600351333618164,
            12.599847793579102,
            12.552998542785645,
            11.134354591369629,
            10.73377513885498
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2001.08051.pdf",
        "text-top-10-question": [
            1,
            0,
            0,
            1,
            1,
            4,
            0,
            6,
            1,
            4
        ],
        "text-top-10-question_score": [
            21.875,
            20.390625,
            20.109375,
            19.875,
            18.875,
            17.453125,
            16.734375,
            16.296875,
            16.1875,
            15.96875
        ]
    },
    {
        "doc_id": "1611.03382.pdf",
        "q_uid": "9555aa8de322396a16a07a5423e6a79dcd76816a",
        "question": "By how much does their model outperform both the state-of-the-art systems?",
        "answer": "w.r.t Rouge-1 their model outperforms by 0.98% and w.r.t Rouge-L their model outperforms by 0.45%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            7,
            8,
            1,
            10,
            0,
            3,
            2,
            9,
            5
        ],
        "image-top-10-question_score": [
            21.126516342163086,
            20.442567825317383,
            20.097530364990234,
            19.696125030517578,
            19.16817855834961,
            19.152509689331055,
            18.676387786865234,
            18.580272674560547,
            18.277912139892578,
            18.189468383789062
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1611.03382.pdf",
        "text-top-10-question": [
            0,
            1,
            1,
            7,
            9,
            1,
            7,
            6,
            7,
            3
        ],
        "text-top-10-question_score": [
            15.5546875,
            15.1015625,
            14.4140625,
            14.1171875,
            13.828125,
            13.390625,
            13.109375,
            13.03125,
            13.0234375,
            12.96875
        ]
    },
    {
        "doc_id": "1909.06937.pdf",
        "q_uid": "fa3312ae4bbed11a5bebd77caf15d651962e0b26",
        "question": "What was the performance on the self-collected corpus?",
        "answer": "F1 scores of 86.16 on slot filling and 94.56 on intent detection",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            0,
            1,
            5,
            6,
            4,
            8,
            9,
            2,
            3
        ],
        "image-top-10-question_score": [
            15.742897987365723,
            15.740358352661133,
            14.626245498657227,
            14.074193954467773,
            14.071711540222168,
            13.861719131469727,
            13.367849349975586,
            13.101781845092773,
            12.818497657775879,
            12.780754089355469
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.06937.pdf",
        "text-top-10-question": [
            0,
            1,
            7,
            6,
            1,
            6,
            5,
            4,
            5,
            7
        ],
        "text-top-10-question_score": [
            21.203125,
            19.078125,
            16.015625,
            15.3359375,
            15.0859375,
            14.9609375,
            14.03125,
            13.734375,
            12.625,
            11.328125
        ]
    },
    {
        "doc_id": "1909.06937.pdf",
        "q_uid": "26c290584c97e22b25035f5458625944db181552",
        "question": "What is the size of their dataset?",
        "answer": "10,001 utterances",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            1,
            7,
            9,
            8,
            0,
            6,
            2,
            3
        ],
        "image-top-10-question_score": [
            13.89569091796875,
            13.89468765258789,
            12.971172332763672,
            12.933965682983398,
            12.770977020263672,
            12.696979522705078,
            12.650093078613281,
            12.453094482421875,
            12.384748458862305,
            12.298396110534668
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.06937.pdf",
        "text-top-10-question": [
            4,
            4,
            5,
            5,
            0,
            4,
            5,
            1,
            1,
            7
        ],
        "text-top-10-question_score": [
            20.171875,
            12.7734375,
            12.3984375,
            12.2578125,
            12.1171875,
            12.015625,
            11.9765625,
            11.5859375,
            11.4921875,
            11.2265625
        ]
    },
    {
        "doc_id": "1704.00939.pdf",
        "q_uid": "e2e31ab279d3092418159dfd24760f0f0566e9d3",
        "question": "What was their performance?",
        "answer": "beneficial impact of word-representations and basic pre-processing",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            2,
            5,
            4,
            1
        ],
        "image-top-10-question_score": [
            9.689173698425293,
            9.636026382446289,
            8.630609512329102,
            8.106988906860352,
            8.079901695251465,
            8.0678071975708
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1704.00939.pdf",
        "text-top-10-question": [
            3,
            3,
            0,
            0,
            2,
            1,
            2,
            2,
            3,
            2
        ],
        "text-top-10-question_score": [
            12.03125,
            10.8203125,
            9.9375,
            8.6640625,
            8.546875,
            7.79296875,
            6.2890625,
            6.09765625,
            5.94921875,
            5.6796875
        ]
    },
    {
        "doc_id": "1707.08559.pdf",
        "q_uid": "1a8b7d3d126935c09306cacca7ddb4b953ef68ab",
        "question": "What were their results?",
        "answer": "Best model achieved F-score 74.7 on NALCS and F-score of 70.0 on LMS on test set",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            2,
            0,
            6,
            1,
            5
        ],
        "image-top-10-question_score": [
            11.156110763549805,
            9.9757719039917,
            9.742524147033691,
            9.609439849853516,
            9.213679313659668,
            8.824010848999023,
            8.616024017333984
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1707.08559.pdf",
        "text-top-10-question": [
            4,
            4,
            4,
            4,
            2,
            3,
            1,
            2,
            4,
            0
        ],
        "text-top-10-question_score": [
            15.25,
            13.9765625,
            11.6484375,
            11.1171875,
            10.671875,
            10.328125,
            9.7109375,
            8.9296875,
            8.6484375,
            7.81640625
        ]
    },
    {
        "doc_id": "1912.10806.pdf",
        "q_uid": "2e1ededb7c8460169cf3c38e6cde6de402c1e720",
        "question": "What is the prediction accuracy of the model?",
        "answer": "mean prediction accuracy 0.99582651\nS&P 500 Accuracy 0.99582651",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            7,
            5,
            1,
            0,
            8,
            4,
            3,
            2
        ],
        "image-top-10-question_score": [
            14.881765365600586,
            14.869086265563965,
            14.191048622131348,
            13.949260711669922,
            13.875640869140625,
            12.460222244262695,
            12.43862247467041,
            12.229438781738281,
            11.880973815917969
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.10806.pdf",
        "text-top-10-question": [
            7,
            1,
            7,
            5,
            6,
            6,
            1,
            0,
            4,
            1
        ],
        "text-top-10-question_score": [
            22.296875,
            21.71875,
            21.4375,
            20.328125,
            19.375,
            19.3125,
            18.84375,
            18.71875,
            18.4375,
            17.953125
        ]
    },
    {
        "doc_id": "1902.09393.pdf",
        "q_uid": "af75ad21dda25ec72311c2be4589efed9df2f482",
        "question": "How much does this system outperform prior work?",
        "answer": "The system outperforms by 27.7% the LSTM model, 38.5% the RL-SPINN model and 41.6% the Gumbel Tree-LSTM",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            4,
            0,
            8,
            1,
            5,
            9,
            10,
            2,
            6
        ],
        "image-top-10-question_score": [
            13.740289688110352,
            13.126846313476562,
            13.086827278137207,
            12.951780319213867,
            12.949686050415039,
            12.861186981201172,
            12.509831428527832,
            12.461054801940918,
            12.452534675598145,
            12.202184677124023
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1902.09393.pdf",
        "text-top-10-question": [
            7,
            7,
            0,
            0,
            0,
            5,
            4,
            5,
            8,
            4
        ],
        "text-top-10-question_score": [
            15.6171875,
            15.6171875,
            10.78125,
            10.7421875,
            10.4296875,
            10.2265625,
            9.59375,
            9.4765625,
            9.296875,
            8.9140625
        ]
    },
    {
        "doc_id": "1902.09393.pdf",
        "q_uid": "de12e059088e4800d7d89e4214a3997994dbc0d9",
        "question": "What are the baseline systems that are compared against?",
        "answer": "The system is compared to baseline models: LSTM, RL-SPINN and Gumbel Tree-LSTM",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            3,
            4,
            7,
            0,
            1,
            6,
            10,
            9,
            8
        ],
        "image-top-10-question_score": [
            14.056214332580566,
            13.27524185180664,
            13.077392578125,
            13.038447380065918,
            12.642670631408691,
            12.515655517578125,
            12.438261032104492,
            12.431161880493164,
            12.371682167053223,
            12.365362167358398
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1902.09393.pdf",
        "text-top-10-question": [
            5,
            3,
            5,
            3,
            3,
            5,
            0,
            7,
            6,
            1
        ],
        "text-top-10-question_score": [
            14.6484375,
            13.921875,
            13.5078125,
            11.390625,
            10.5,
            10.4921875,
            9.4140625,
            9.234375,
            9.1171875,
            9.03125
        ]
    },
    {
        "doc_id": "1909.13695.pdf",
        "q_uid": "52e8f79814736fea96fd9b642881b476243e1698",
        "question": "What systems are tested?",
        "answer": "BULATS i-vector/PLDA\nBULATS x-vector/PLDA\nVoxCeleb x-vector/PLDA\nPLDA adaptation (X1)\n Extractor fine-tuning (X2) ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            3,
            5,
            2,
            0,
            1,
            6,
            7
        ],
        "image-top-10-question_score": [
            10.962860107421875,
            10.65553092956543,
            10.479330062866211,
            10.345378875732422,
            9.49458122253418,
            9.43424129486084,
            8.731173515319824,
            8.694074630737305
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.13695.pdf",
        "text-top-10-question": [
            2,
            0,
            2,
            3,
            3,
            3,
            2,
            3,
            0,
            5
        ],
        "text-top-10-question_score": [
            18.515625,
            17.8125,
            17.5,
            17.484375,
            17.09375,
            16.84375,
            16.65625,
            16.65625,
            16.5,
            16.328125
        ]
    },
    {
        "doc_id": "1909.11467.pdf",
        "q_uid": "3d6015d722de6e6297ba7bfe7cb0f8a67f660636",
        "question": "What are the 12 categories devised?",
        "answer": "Economics, Genocide, Geography, History, Human Rights, Kurdish, Kurdology, Philosophy, Physics, Theology, Sociology, Social Study",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            2,
            3
        ],
        "image-top-10-question_score": [
            13.259222030639648,
            12.873787879943848,
            12.33133316040039,
            11.812393188476562
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.11467.pdf",
        "text-top-10-question": [
            1,
            0,
            0,
            0,
            1,
            2,
            1,
            3,
            0,
            1
        ],
        "text-top-10-question_score": [
            11.484375,
            11.46875,
            10.9765625,
            10.140625,
            8.84375,
            8.1015625,
            7.46875,
            7.0546875,
            6.953125,
            6.05078125
        ]
    },
    {
        "doc_id": "1909.00361.pdf",
        "q_uid": "3fb4334e5a4702acd44bd24eb1831bb7e9b98d31",
        "question": "How big are the datasets used?",
        "answer": "Evaluation datasets used:\nCMRC 2018 - 18939 questions, 10 answers\nDRCD - 33953 questions, 5 answers\nNIST MT02/03/04/05/06/08 Chinese-English - Not specified\n\nSource language train data:\nSQuAD - Not specified",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            1,
            0,
            6,
            9,
            8,
            7,
            2,
            3,
            4
        ],
        "image-top-10-question_score": [
            13.743886947631836,
            12.994268417358398,
            12.543201446533203,
            12.29470443725586,
            11.923933982849121,
            11.797979354858398,
            11.734185218811035,
            11.37435245513916,
            11.138612747192383,
            10.944194793701172
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.00361.pdf",
        "text-top-10-question": [
            7,
            5,
            0,
            7,
            9,
            1,
            7,
            9,
            0,
            6
        ],
        "text-top-10-question_score": [
            15.7421875,
            13.515625,
            12.984375,
            12.8359375,
            12.7109375,
            12.546875,
            12.2890625,
            12.2421875,
            12.046875,
            12.0
        ]
    },
    {
        "doc_id": "1908.11546.pdf",
        "q_uid": "8a0a51382d186e8d92bf7e78277a1d48958758da",
        "question": "How better is gCAS approach compared to other approaches?",
        "answer": "For entity  F1 in the movie, taxi and restaurant domain it results in scores of 50.86, 64, and 60.35. For success, it results it outperforms in the movie and restaurant domain with scores of 77.95 and 71.52",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            3,
            1,
            6,
            2,
            5
        ],
        "image-top-10-question_score": [
            17.0256290435791,
            16.838661193847656,
            16.762292861938477,
            15.048168182373047,
            13.688408851623535,
            13.501653671264648,
            13.035134315490723
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.11546.pdf",
        "text-top-10-question": [
            4,
            4,
            3,
            4,
            3,
            0,
            0,
            4,
            3,
            1
        ],
        "text-top-10-question_score": [
            22.921875,
            22.5,
            20.328125,
            20.28125,
            20.09375,
            17.78125,
            17.6875,
            17.03125,
            15.921875,
            15.0546875
        ]
    },
    {
        "doc_id": "1905.07464.pdf",
        "q_uid": "4a4616e1a9807f32cca9b92ab05e65b05c2a1bf5",
        "question": "What were the sizes of the test sets?",
        "answer": "Test set 1 contained 57 drug labels and 8208 sentences and test set 2 contained 66 drug labels and 4224 sentences",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            8,
            0,
            5,
            7,
            6,
            9,
            10,
            3
        ],
        "image-top-10-question_score": [
            15.345422744750977,
            15.341753005981445,
            14.579158782958984,
            14.151517868041992,
            13.029019355773926,
            12.707178115844727,
            12.299302101135254,
            12.011770248413086,
            11.764623641967773,
            11.311279296875
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1905.07464.pdf",
        "text-top-10-question": [
            5,
            1,
            1,
            5,
            2,
            8,
            8,
            8,
            7,
            0
        ],
        "text-top-10-question_score": [
            20.515625,
            19.328125,
            19.28125,
            19.125,
            18.046875,
            17.140625,
            16.59375,
            16.125,
            13.6015625,
            13.328125
        ]
    },
    {
        "doc_id": "1901.09755.pdf",
        "q_uid": "93b299acfb6fad104b9ebf4d0585d42de4047051",
        "question": "Which datasets are used?",
        "answer": "ABSA SemEval 2014-2016 datasets\nYelp Academic Dataset\nWikipedia dumps",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            10,
            5,
            8,
            9,
            4,
            7,
            11,
            6,
            3,
            13
        ],
        "image-top-10-question_score": [
            11.956210136413574,
            11.799467086791992,
            11.7257080078125,
            11.53593635559082,
            11.408164978027344,
            11.308297157287598,
            11.144830703735352,
            11.073755264282227,
            11.01262092590332,
            10.971047401428223
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.09755.pdf",
        "text-top-10-question": [
            5,
            4,
            5,
            10,
            2,
            2,
            10,
            8,
            9,
            5
        ],
        "text-top-10-question_score": [
            19.34375,
            18.28125,
            17.421875,
            17.28125,
            17.1875,
            17.0625,
            17.03125,
            16.734375,
            16.453125,
            16.203125
        ]
    },
    {
        "doc_id": "2002.05829.pdf",
        "q_uid": "02417455c05f09d89c2658f39705ac1df1daa0cd",
        "question": "How much does it minimally cost to fine-tune some model according to benchmarking framework?",
        "answer": "$1,728",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            3,
            2,
            5,
            0,
            6
        ],
        "image-top-10-question_score": [
            19.612951278686523,
            19.58177947998047,
            19.264863967895508,
            18.778329849243164,
            18.29808807373047,
            17.65765380859375,
            15.953214645385742
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.05829.pdf",
        "text-top-10-question": [
            3,
            3,
            4,
            1,
            1,
            0,
            2,
            4,
            3,
            5
        ],
        "text-top-10-question_score": [
            16.390625,
            16.0,
            15.4453125,
            15.1875,
            15.078125,
            14.71875,
            14.4921875,
            14.4765625,
            14.4375,
            14.2734375
        ]
    },
    {
        "doc_id": "2002.05829.pdf",
        "q_uid": "6ce057d3b88addf97a30cb188795806239491154",
        "question": "What models are included in baseline benchmarking results?",
        "answer": "BERT, XLNET RoBERTa, ALBERT, DistilBERT",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            3,
            2,
            5,
            0,
            6
        ],
        "image-top-10-question_score": [
            14.401717185974121,
            14.321253776550293,
            14.175294876098633,
            13.74604606628418,
            13.679383277893066,
            13.659058570861816,
            11.928159713745117
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.05829.pdf",
        "text-top-10-question": [
            4,
            5,
            4,
            5,
            4,
            5,
            1,
            0,
            4,
            2
        ],
        "text-top-10-question_score": [
            20.921875,
            19.21875,
            18.234375,
            17.984375,
            17.734375,
            17.734375,
            17.4375,
            17.21875,
            16.953125,
            16.828125
        ]
    },
    {
        "doc_id": "1912.00864.pdf",
        "q_uid": "572458399a45fd392c3a4e07ce26dcff2ad5a07d",
        "question": "How much more accurate is the model than the baseline?",
        "answer": "For the Oshiete-goo dataset, the NAGM model's ROUGE-L score is higher than the highest performing conventional model, Trans, by 0.021, and its BLEU-4 score is higher than the highest performing model CLSTM by 0.037.  For the nfL6 dataset, the NAGM model's ROUGE-L score is higher than the highest performing conventional model, CLSTM, by 0.028, and its BLEU-4 score is higher than the highest performing model CLSTM by 0.040. Human evaluation of the NAGM's generated outputs for the Oshiete-goo dataset had 47% ratings of (1), the highest rating, while CLSTM only received 21% ratings of (1). For the nfL6 dataset, the comparison of (1)'s was NAGM's 50% to CLSTM's 30%. ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            4,
            3,
            1,
            2,
            7,
            6
        ],
        "image-top-10-question_score": [
            14.702847480773926,
            14.470348358154297,
            14.19744873046875,
            13.927530288696289,
            13.694172859191895,
            13.179357528686523,
            12.957883834838867,
            12.455946922302246
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.00864.pdf",
        "text-top-10-question": [
            0,
            5,
            5,
            3,
            4,
            4,
            7,
            5,
            2,
            5
        ],
        "text-top-10-question_score": [
            15.390625,
            14.8046875,
            14.640625,
            12.921875,
            12.46875,
            12.2109375,
            11.609375,
            11.421875,
            11.3828125,
            11.3203125
        ]
    },
    {
        "doc_id": "1910.11204.pdf",
        "q_uid": "33d864153822bd378a98a732ace720e2c06a6bc6",
        "question": "What is new state-of-the-art performance on CoNLL-2009 dataset?",
        "answer": "In closed setting 84.22 F1 and in open 87.35 F1.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            8,
            4,
            5,
            0,
            10,
            2,
            7,
            9,
            6
        ],
        "image-top-10-question_score": [
            25.587799072265625,
            24.734054565429688,
            24.456279754638672,
            24.310697555541992,
            24.189043045043945,
            23.26530647277832,
            22.68122100830078,
            22.53760528564453,
            21.807010650634766,
            20.916372299194336
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.11204.pdf",
        "text-top-10-question": [
            0,
            0,
            4,
            4,
            8,
            8,
            5,
            1,
            7,
            8
        ],
        "text-top-10-question_score": [
            20.75,
            19.296875,
            15.8359375,
            14.890625,
            14.890625,
            14.28125,
            14.171875,
            14.109375,
            13.921875,
            13.53125
        ]
    },
    {
        "doc_id": "1910.11204.pdf",
        "q_uid": "bab8c69e183bae6e30fc362009db9b46e720225e",
        "question": "What are two strong baseline methods authors refer to?",
        "answer": "Marcheggiani and Titov (2017) and Cai et al. (2018)",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            10,
            8,
            1,
            9,
            5,
            4,
            6,
            0,
            2
        ],
        "image-top-10-question_score": [
            13.279592514038086,
            13.126409530639648,
            13.116289138793945,
            13.094693183898926,
            12.946455955505371,
            12.880491256713867,
            12.777243614196777,
            12.766742706298828,
            12.703716278076172,
            12.637768745422363
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.11204.pdf",
        "text-top-10-question": [
            0,
            8,
            1,
            7,
            9,
            8,
            10,
            1,
            6,
            3
        ],
        "text-top-10-question_score": [
            12.6171875,
            10.4765625,
            10.1171875,
            10.1015625,
            10.0859375,
            10.078125,
            10.0625,
            9.9921875,
            9.5625,
            9.515625
        ]
    },
    {
        "doc_id": "1810.03459.pdf",
        "q_uid": "1adbdb5f08d67d8b05328ccc86d297ac01bf076c",
        "question": "What languages do they use?",
        "answer": "Train languages are: Cantonese, Bengali, Pashto, Turkish, Vietnamese, Haitian, Tamil, Kurdish, Tokpisin and Georgian, while Assamese, Tagalog, Swahili, Lao are used as target languages.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            4,
            3,
            6,
            0,
            5,
            1
        ],
        "image-top-10-question_score": [
            11.828312873840332,
            11.077638626098633,
            10.879075050354004,
            10.56682014465332,
            10.07699203491211,
            9.672380447387695,
            9.023038864135742
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.03459.pdf",
        "text-top-10-question": [
            4,
            2,
            2,
            5,
            2,
            0,
            4,
            3,
            4,
            4
        ],
        "text-top-10-question_score": [
            14.296875,
            13.6953125,
            13.1171875,
            12.734375,
            12.578125,
            12.265625,
            12.1171875,
            11.9765625,
            11.6328125,
            11.59375
        ]
    },
    {
        "doc_id": "2002.10361.pdf",
        "q_uid": "38c74ab8292a94fc5a82999400ee9c06be19f791",
        "question": "How large is the corpus?",
        "answer": "It contains 106,350 documents",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            5,
            2,
            3,
            8,
            7,
            4,
            6
        ],
        "image-top-10-question_score": [
            12.790410995483398,
            12.427864074707031,
            11.89349365234375,
            11.148645401000977,
            10.994473457336426,
            10.055745124816895,
            10.048213958740234,
            9.91529655456543,
            9.785908699035645
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.10361.pdf",
        "text-top-10-question": [
            3,
            1,
            1,
            0,
            3,
            5,
            8,
            2,
            0,
            1
        ],
        "text-top-10-question_score": [
            18.453125,
            15.5,
            15.4296875,
            15.0078125,
            14.8359375,
            14.3359375,
            14.3125,
            13.890625,
            13.5703125,
            12.7578125
        ]
    },
    {
        "doc_id": "2002.10361.pdf",
        "q_uid": "16af38f7c4774637cf8e04d4b239d6d72f0b0a3a",
        "question": "How large is the dataset?",
        "answer": "over 104k documents",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            5,
            3,
            2,
            6,
            0,
            8,
            7,
            4
        ],
        "image-top-10-question_score": [
            12.103806495666504,
            11.83841323852539,
            11.716462135314941,
            11.661368370056152,
            11.497037887573242,
            11.434720993041992,
            11.372942924499512,
            11.367347717285156,
            11.353607177734375
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.10361.pdf",
        "text-top-10-question": [
            5,
            7,
            1,
            1,
            0,
            5,
            2,
            8,
            1,
            5
        ],
        "text-top-10-question_score": [
            14.671875,
            14.5625,
            14.375,
            14.3359375,
            14.2890625,
            13.0859375,
            12.9296875,
            12.8828125,
            12.65625,
            12.234375
        ]
    },
    {
        "doc_id": "1810.10254.pdf",
        "q_uid": "657edbf39c500b2446edb9cca18de2912c628b7d",
        "question": "What was their perplexity score?",
        "answer": "Perplexity score 142.84 on dev and 138.91 on test",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            0,
            3,
            1,
            4
        ],
        "image-top-10-question_score": [
            13.704902648925781,
            12.277570724487305,
            10.002922058105469,
            9.83843994140625,
            9.574527740478516
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.10254.pdf",
        "text-top-10-question": [
            2,
            0,
            2,
            2,
            2,
            3,
            2,
            3,
            2,
            3
        ],
        "text-top-10-question_score": [
            18.5,
            15.9921875,
            14.6875,
            14.59375,
            14.3125,
            13.875,
            13.375,
            13.15625,
            10.7734375,
            9.9453125
        ]
    },
    {
        "doc_id": "1703.06492.pdf",
        "q_uid": "0c7823b27326b3f5dff51f32f45fc69c91a4e06d",
        "question": "In which setting they achieve the state of the art?",
        "answer": "in open-ended task esp. for counting-type questions ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            5,
            0,
            6,
            2,
            8,
            4,
            7,
            3
        ],
        "image-top-10-question_score": [
            15.11120891571045,
            14.620994567871094,
            14.31447982788086,
            14.295795440673828,
            13.855375289916992,
            13.782452583312988,
            13.731378555297852,
            13.221330642700195,
            13.049436569213867
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1703.06492.pdf",
        "text-top-10-question": [
            5,
            2,
            0,
            5,
            6,
            1,
            6,
            4,
            0,
            3
        ],
        "text-top-10-question_score": [
            14.6015625,
            14.3046875,
            14.203125,
            14.15625,
            13.90625,
            13.7109375,
            13.59375,
            13.4453125,
            10.96875,
            8.421875
        ]
    },
    {
        "doc_id": "1909.01958.pdf",
        "q_uid": "384d571e4017628ebb72f3debb2846efaf0cb0cb",
        "question": "On what dataset is Aristo system trained?",
        "answer": "Aristo Corpus\nRegents 4th\nRegents 8th\nRegents `12th\nARC-Easy\nARC-challenge ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            3,
            4,
            6,
            5,
            2,
            7,
            8,
            9
        ],
        "image-top-10-question_score": [
            14.606351852416992,
            14.571382522583008,
            14.404800415039062,
            14.22126293182373,
            14.139963150024414,
            14.121111869812012,
            13.947147369384766,
            13.197134017944336,
            11.999612808227539,
            11.889896392822266
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.01958.pdf",
        "text-top-10-question": [
            6,
            6,
            5,
            2,
            6,
            4,
            4,
            3,
            3,
            3
        ],
        "text-top-10-question_score": [
            23.375,
            22.53125,
            22.484375,
            22.296875,
            22.28125,
            22.015625,
            21.34375,
            20.890625,
            20.828125,
            20.6875
        ]
    },
    {
        "doc_id": "1806.07711.pdf",
        "q_uid": "0c09a0e8f9c5bdb678563be49f912ab6e3f97619",
        "question": "How many roles are proposed?",
        "answer": "12",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            1,
            5,
            4,
            6,
            0,
            7,
            8
        ],
        "image-top-10-question_score": [
            11.00782299041748,
            10.98530101776123,
            10.935495376586914,
            10.770365715026855,
            10.717927932739258,
            9.758052825927734,
            9.118749618530273,
            8.325386047363281,
            7.226496696472168
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1806.07711.pdf",
        "text-top-10-question": [
            6,
            3,
            2,
            1,
            2,
            5,
            0,
            6,
            3,
            6
        ],
        "text-top-10-question_score": [
            18.65625,
            15.859375,
            15.6640625,
            15.5703125,
            14.65625,
            14.375,
            14.0546875,
            13.984375,
            13.796875,
            13.1015625
        ]
    },
    {
        "doc_id": "1912.03457.pdf",
        "q_uid": "50716cc7f589b9b9f3aca806214228b063e9695b",
        "question": "What language technologies have been introduced in the past?",
        "answer": "- Font & Keyboard\n- Speech-to-Text\n- Text-to-Speech\n- Text Prediction\n- Spell Checker\n- Grammar Checker\n- Text Search\n- Machine Translation\n- Voice to Text Search\n- Voice to Speech Search",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            2,
            1,
            8,
            4,
            5,
            7,
            6
        ],
        "image-top-10-question_score": [
            16.675540924072266,
            16.659503936767578,
            15.691444396972656,
            15.615175247192383,
            15.068155288696289,
            14.486522674560547,
            14.429047584533691,
            14.117931365966797,
            11.706588745117188
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1912.03457.pdf",
        "text-top-10-question": [
            0,
            5,
            0,
            5,
            7,
            7,
            1,
            1,
            3,
            1
        ],
        "text-top-10-question_score": [
            21.734375,
            20.453125,
            20.359375,
            19.0625,
            18.84375,
            17.828125,
            17.15625,
            17.09375,
            16.453125,
            16.40625
        ]
    },
    {
        "doc_id": "1901.05280.pdf",
        "q_uid": "73bbe0b6457423f08d9297a0951381098bd89a2b",
        "question": "what were the baselines?",
        "answer": "2008 Punyakanok et al. \n2009 Zhao et al. + ME \n2008 Toutanova et al. \n2010 Bjorkelund et al.  \n2015 FitzGerald et al. \n2015 Zhou and Xu \n2016 Roth and Lapata \n2017 He et al. \n2017 Marcheggiani et al.\n2017 Marcheggiani and Titov \n2018 Tan et al. \n2018 He et al. \n2018 Strubell et al. \n2018 Cai et al. \n2018 He et al. \n2018 Li et al. \n",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            6,
            5,
            8,
            0,
            7,
            3,
            2
        ],
        "image-top-10-question_score": [
            10.673831939697266,
            10.587564468383789,
            10.561084747314453,
            9.841608047485352,
            9.779993057250977,
            9.560979843139648,
            9.546341896057129,
            9.262897491455078,
            9.176847457885742
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.05280.pdf",
        "text-top-10-question": [
            1,
            4,
            6,
            4,
            0,
            0,
            5,
            7,
            3,
            2
        ],
        "text-top-10-question_score": [
            7.78125,
            7.4765625,
            7.2109375,
            7.19921875,
            6.51171875,
            6.234375,
            5.7578125,
            5.75390625,
            5.6640625,
            5.63671875
        ]
    },
    {
        "doc_id": "1909.11297.pdf",
        "q_uid": "e292676c8c75dd3711efd0e008423c11077938b1",
        "question": "Which soft-selection approaches are evaluated?",
        "answer": "LSTM and BERT ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            0,
            4,
            1,
            7,
            6,
            3,
            9,
            8,
            5
        ],
        "image-top-10-question_score": [
            13.985282897949219,
            12.899633407592773,
            12.786103248596191,
            12.367995262145996,
            12.306270599365234,
            11.754228591918945,
            11.722342491149902,
            10.933502197265625,
            10.876140594482422,
            10.800070762634277
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.11297.pdf",
        "text-top-10-question": [
            6,
            4,
            2,
            5,
            5,
            0,
            7,
            2,
            0,
            1
        ],
        "text-top-10-question_score": [
            22.390625,
            21.828125,
            21.265625,
            21.21875,
            21.15625,
            21.0625,
            21.046875,
            20.84375,
            20.78125,
            20.4375
        ]
    },
    {
        "doc_id": "1911.01680.pdf",
        "q_uid": "2d47cdf2c1e0c64c73518aead1b94e0ee594b7a5",
        "question": "How big is slot filing dataset?",
        "answer": "Dataset has 1737 train, 497 dev and 559 test sentences.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            4,
            3,
            5,
            2
        ],
        "image-top-10-question_score": [
            11.91822338104248,
            11.844144821166992,
            10.073286056518555,
            10.062614440917969,
            9.743938446044922,
            9.46455192565918
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.01680.pdf",
        "text-top-10-question": [
            3,
            3,
            1,
            0,
            3,
            5,
            0,
            4,
            1,
            4
        ],
        "text-top-10-question_score": [
            17.46875,
            17.1875,
            14.3515625,
            13.0859375,
            12.6015625,
            12.03125,
            11.953125,
            11.46875,
            11.1796875,
            10.9140625
        ]
    },
    {
        "doc_id": "1809.08298.pdf",
        "q_uid": "dafa760e1466e9eaa73ad8cb39b229abd5babbda",
        "question": "How large is the dataset they generate?",
        "answer": "4.756 million sentences",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            4,
            1,
            0,
            5
        ],
        "image-top-10-question_score": [
            12.688369750976562,
            12.629928588867188,
            12.508729934692383,
            12.331079483032227,
            12.157083511352539,
            11.826471328735352
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1809.08298.pdf",
        "text-top-10-question": [
            3,
            2,
            2,
            2,
            4,
            3,
            3,
            2,
            3,
            3
        ],
        "text-top-10-question_score": [
            13.8359375,
            13.546875,
            12.59375,
            12.296875,
            11.875,
            11.84375,
            11.5,
            11.375,
            10.8671875,
            10.7421875
        ]
    },
    {
        "doc_id": "1805.04033.pdf",
        "q_uid": "bd99aba3309da96e96eab3e0f4c4c8c70b51980a",
        "question": "Which existing models does this approach outperform?",
        "answer": "RNN-context, SRB, CopyNet, RNN-distract, DRGD",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            10,
            0,
            4,
            7,
            2,
            3,
            9,
            1,
            13,
            11
        ],
        "image-top-10-question_score": [
            14.298805236816406,
            13.878469467163086,
            13.844474792480469,
            13.66629409790039,
            13.32339859008789,
            13.283935546875,
            13.051790237426758,
            12.823837280273438,
            12.823638916015625,
            12.805000305175781
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1805.04033.pdf",
        "text-top-10-question": [
            0,
            11,
            7,
            7,
            10,
            4,
            7,
            10,
            3,
            5
        ],
        "text-top-10-question_score": [
            21.5,
            17.34375,
            16.96875,
            16.203125,
            15.6015625,
            14.875,
            14.4921875,
            14.484375,
            14.46875,
            14.390625
        ]
    },
    {
        "doc_id": "1910.06748.pdf",
        "q_uid": "8ad815b29cc32c1861b77de938c7269c9259a064",
        "question": "What languages are represented in the dataset?",
        "answer": "EN, JA, ES, AR, PT, KO, TH, FR, TR, RU, IT, DE, PL, NL, EL, SV, FA, VI, FI, CS, UK, HI, DA, HU, NO, RO, SR, LV, BG, UR, TA, MR, BN, IN, KN, ET, SL, GU, CY, ZH, CKB, IS, LT, ML, SI, IW, NE, KM, MY, TL, KA, BO",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            1,
            6,
            2,
            0,
            7,
            4,
            8,
            5
        ],
        "image-top-10-question_score": [
            14.284646034240723,
            13.7935791015625,
            13.791197776794434,
            13.716443061828613,
            13.529180526733398,
            13.487215042114258,
            12.962886810302734,
            12.877113342285156,
            12.66607666015625
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.06748.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            6,
            8,
            3,
            0,
            3,
            2,
            0
        ],
        "text-top-10-question_score": [
            21.125,
            20.859375,
            20.765625,
            18.84375,
            18.5,
            18.375,
            18.34375,
            18.078125,
            17.96875,
            17.859375
        ]
    },
    {
        "doc_id": "1911.08673.pdf",
        "q_uid": "9aa52b898d029af615b95b18b79078e9bed3d766",
        "question": "How faster is training and decoding compared to former models?",
        "answer": "Proposed vs best baseline:\nDecoding: 8541 vs 8532 tokens/sec\nTraining: 8h vs 8h",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            4,
            1,
            0,
            7,
            8,
            5,
            3,
            2
        ],
        "image-top-10-question_score": [
            15.107596397399902,
            14.827967643737793,
            14.778865814208984,
            14.456002235412598,
            14.359272003173828,
            13.793910026550293,
            13.770917892456055,
            13.690896987915039,
            13.659675598144531
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.08673.pdf",
        "text-top-10-question": [
            6,
            6,
            6,
            1,
            1,
            4,
            6,
            0,
            7,
            3
        ],
        "text-top-10-question_score": [
            21.0,
            20.84375,
            18.609375,
            18.28125,
            16.65625,
            16.234375,
            15.5703125,
            15.46875,
            14.625,
            14.2890625
        ]
    },
    {
        "doc_id": "1611.04642.pdf",
        "q_uid": "b13d0e463d5eb6028cdaa0c36ac7de3b76b5e933",
        "question": "What datasets are used to evaluate the model?",
        "answer": "WN18 and FB15k",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            6,
            12,
            13,
            2,
            3,
            0,
            11,
            8,
            7
        ],
        "image-top-10-question_score": [
            14.968276977539062,
            14.356657028198242,
            14.210573196411133,
            13.962715148925781,
            13.754323959350586,
            13.65964126586914,
            13.402196884155273,
            12.889921188354492,
            12.720837593078613,
            12.671466827392578
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1611.04642.pdf",
        "text-top-10-question": [
            6,
            5,
            2,
            12,
            12,
            12,
            2,
            8,
            6,
            12
        ],
        "text-top-10-question_score": [
            21.640625,
            20.46875,
            18.625,
            18.609375,
            18.390625,
            17.59375,
            16.375,
            15.1328125,
            14.7265625,
            14.3359375
        ]
    },
    {
        "doc_id": "1909.03242.pdf",
        "q_uid": "e9ccc74b1f1b172224cf9f01e66b1fa9e34d2593",
        "question": "What metadata is included?",
        "answer": "besides claim, label and claim url, it also includes a claim ID, reason, category, speaker, checker, tags, claim entities, article title, publish data and claim date",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            6,
            1,
            4,
            3,
            7,
            2,
            0,
            10,
            11
        ],
        "image-top-10-question_score": [
            11.391792297363281,
            11.343168258666992,
            10.699625968933105,
            10.643550872802734,
            10.391365051269531,
            10.271881103515625,
            10.1546630859375,
            9.476448059082031,
            9.145618438720703,
            9.076976776123047
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.03242.pdf",
        "text-top-10-question": [
            6,
            4,
            8,
            2,
            2,
            6,
            2,
            7,
            1,
            2
        ],
        "text-top-10-question_score": [
            21.046875,
            18.953125,
            17.984375,
            17.5625,
            16.671875,
            16.671875,
            16.3125,
            16.28125,
            16.0625,
            15.5390625
        ]
    },
    {
        "doc_id": "1905.12260.pdf",
        "q_uid": "e8029ec69b0b273954b4249873a5070c2a0edb8a",
        "question": "How much important is the visual grounding in the learning of the multilingual representations?",
        "answer": "performance is significantly degraded without pixel data",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            7,
            8,
            0,
            5,
            3,
            2,
            4,
            6,
            9
        ],
        "image-top-10-question_score": [
            18.62824058532715,
            18.402240753173828,
            18.38572120666504,
            18.375930786132812,
            18.222736358642578,
            18.194168090820312,
            17.88031005859375,
            17.745849609375,
            17.537494659423828,
            16.8216552734375
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1905.12260.pdf",
        "text-top-10-question": [
            8,
            8,
            0,
            8,
            8,
            0,
            0,
            6,
            1,
            4
        ],
        "text-top-10-question_score": [
            18.390625,
            18.125,
            18.09375,
            18.0625,
            17.734375,
            17.5,
            17.28125,
            17.265625,
            17.03125,
            16.75
        ]
    },
    {
        "doc_id": "1804.08050.pdf",
        "q_uid": "5a9f94ae296dda06c8aec0fb389ce2f68940ea88",
        "question": "By how much does their method outperform the multi-head attention model?",
        "answer": "Their average improvement in Character Error Rate over the best MHA model was 0.33 percent points.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            0,
            3,
            1,
            4
        ],
        "image-top-10-question_score": [
            17.316923141479492,
            17.112794876098633,
            16.81174087524414,
            16.50648307800293,
            14.126306533813477
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1804.08050.pdf",
        "text-top-10-question": [
            3,
            0,
            3,
            0,
            0,
            0,
            2,
            0,
            2,
            2
        ],
        "text-top-10-question_score": [
            23.203125,
            22.890625,
            22.828125,
            21.765625,
            20.90625,
            20.78125,
            20.296875,
            19.234375,
            18.9375,
            17.9375
        ]
    },
    {
        "doc_id": "1804.08050.pdf",
        "q_uid": "85912b87b16b45cde79039447a70bd1f6f1f8361",
        "question": "How large is the corpus they use?",
        "answer": "449050",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            0,
            4,
            3,
            1
        ],
        "image-top-10-question_score": [
            11.441572189331055,
            11.254658699035645,
            11.209074974060059,
            10.838476181030273,
            10.478745460510254
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1804.08050.pdf",
        "text-top-10-question": [
            0,
            0,
            2,
            2,
            4,
            3,
            3,
            0,
            4,
            3
        ],
        "text-top-10-question_score": [
            13.5390625,
            13.1875,
            12.5703125,
            12.4375,
            11.8984375,
            11.5859375,
            11.5625,
            11.0078125,
            8.328125,
            8.109375
        ]
    },
    {
        "doc_id": "2002.06424.pdf",
        "q_uid": "58f50397a075f128b45c6b824edb7a955ee8cba1",
        "question": "How many shared layers are in the system?",
        "answer": "1",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            5,
            0,
            1,
            3,
            4,
            6
        ],
        "image-top-10-question_score": [
            15.240395545959473,
            14.298352241516113,
            14.023231506347656,
            13.674315452575684,
            13.26329517364502,
            12.647796630859375,
            10.888181686401367
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.06424.pdf",
        "text-top-10-question": [
            2,
            2,
            2,
            3,
            2,
            1,
            4,
            4,
            1,
            2
        ],
        "text-top-10-question_score": [
            19.78125,
            19.375,
            19.25,
            18.125,
            17.890625,
            17.8125,
            17.78125,
            17.65625,
            17.625,
            17.578125
        ]
    },
    {
        "doc_id": "2002.06424.pdf",
        "q_uid": "9adcc8c4a10fa0d58f235b740d8d495ee622d596",
        "question": "How many additional task-specific layers are introduced?",
        "answer": "2 for the ADE dataset and 3 for the CoNLL04 dataset",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            0,
            5,
            4,
            3,
            6
        ],
        "image-top-10-question_score": [
            15.569774627685547,
            14.991154670715332,
            14.907931327819824,
            14.488327980041504,
            14.133747100830078,
            13.360064506530762,
            12.04981803894043
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2002.06424.pdf",
        "text-top-10-question": [
            0,
            5,
            0,
            2,
            4,
            5,
            2,
            1,
            2,
            5
        ],
        "text-top-10-question_score": [
            18.734375,
            18.734375,
            17.765625,
            17.640625,
            17.421875,
            17.3125,
            17.171875,
            16.90625,
            16.546875,
            16.3125
        ]
    },
    {
        "doc_id": "1909.05246.pdf",
        "q_uid": "8568c82078495ab421ecbae38ddd692c867eac09",
        "question": "How many layers of self-attention does the model have?",
        "answer": "1, 4, 8, 16, 32, 64",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            5,
            2,
            0,
            1,
            7,
            3,
            4,
            8,
            9
        ],
        "image-top-10-question_score": [
            17.269859313964844,
            16.705596923828125,
            16.702781677246094,
            16.177120208740234,
            15.913049697875977,
            15.72494125366211,
            15.483386993408203,
            15.01750373840332,
            14.519641876220703,
            12.905966758728027
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.05246.pdf",
        "text-top-10-question": [
            6,
            6,
            0,
            6,
            5,
            0,
            6,
            5,
            2,
            6
        ],
        "text-top-10-question_score": [
            19.515625,
            18.875,
            18.296875,
            18.296875,
            18.0625,
            17.296875,
            17.21875,
            16.953125,
            16.9375,
            16.75
        ]
    },
    {
        "doc_id": "1606.04631.pdf",
        "q_uid": "b3fcab006a9e51a0178a1f64d1d084a895bd8d5c",
        "question": "what are the state of the art methods?",
        "answer": "S2VT, RGB (VGG), RGB (VGG)+Flow (AlexNet), LSTM-E (VGG), LSTM-E (C3D) and Yao et al.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            3,
            1,
            2
        ],
        "image-top-10-question_score": [
            14.307391166687012,
            14.140706062316895,
            13.646005630493164,
            12.988663673400879,
            12.591938972473145
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1606.04631.pdf",
        "text-top-10-question": [
            0,
            0,
            3,
            3,
            0,
            1,
            3,
            1,
            1,
            3
        ],
        "text-top-10-question_score": [
            19.890625,
            18.953125,
            18.390625,
            15.96875,
            14.578125,
            14.0,
            12.5625,
            10.96875,
            9.421875,
            8.9296875
        ]
    },
    {
        "doc_id": "2003.07996.pdf",
        "q_uid": "6baf5d7739758bdd79326ce8f50731c785029802",
        "question": "Which four languages do they experiment with?",
        "answer": "German, English, Italian, Chinese",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            6,
            3,
            5,
            2,
            0
        ],
        "image-top-10-question_score": [
            13.141912460327148,
            12.603021621704102,
            12.566872596740723,
            12.35684871673584,
            12.070091247558594,
            11.747089385986328,
            11.413871765136719
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2003.07996.pdf",
        "text-top-10-question": [
            4,
            4,
            1,
            4,
            3,
            0,
            1,
            1,
            1,
            2
        ],
        "text-top-10-question_score": [
            19.109375,
            18.46875,
            17.671875,
            17.640625,
            16.9375,
            16.421875,
            16.125,
            16.015625,
            15.921875,
            15.78125
        ]
    },
    {
        "doc_id": "1910.10288.pdf",
        "q_uid": "5c4c8e91d28935e1655a582568cc9d94149da2b2",
        "question": "Does DCA or GMM-based attention perform better in experiments?",
        "answer": "About the same performance",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            3,
            0,
            2,
            4
        ],
        "image-top-10-question_score": [
            17.853187561035156,
            17.583120346069336,
            17.384506225585938,
            15.395147323608398,
            13.762578010559082
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.10288.pdf",
        "text-top-10-question": [
            1,
            3,
            3,
            0,
            3,
            0,
            2,
            2,
            3,
            1
        ],
        "text-top-10-question_score": [
            22.234375,
            21.578125,
            21.015625,
            20.46875,
            19.34375,
            18.921875,
            18.6875,
            18.140625,
            18.015625,
            17.5
        ]
    },
    {
        "doc_id": "1908.06083.pdf",
        "q_uid": "3f326c003be29c8eac76b24d6bba9608c75aa7ea",
        "question": "What evaluation metric is used?",
        "answer": "F1 and Weighted-F1",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            6,
            12,
            10,
            2,
            7,
            8,
            3,
            11
        ],
        "image-top-10-question_score": [
            10.417349815368652,
            10.327699661254883,
            10.298524856567383,
            10.095117568969727,
            9.583060264587402,
            9.547542572021484,
            8.9136323928833,
            8.898594856262207,
            8.862909317016602,
            8.438972473144531
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.06083.pdf",
        "text-top-10-question": [
            2,
            6,
            4,
            1,
            3,
            5,
            1,
            3,
            3,
            5
        ],
        "text-top-10-question_score": [
            14.3515625,
            13.921875,
            13.546875,
            13.3359375,
            12.7265625,
            12.34375,
            12.21875,
            11.9609375,
            10.6484375,
            9.921875
        ]
    },
    {
        "doc_id": "1910.12129.pdf",
        "q_uid": "14e259a312e653f8fc0d52ca5325b43c3bdfb968",
        "question": "Is any data-to-text generation model trained on this new corpus, what are the results?",
        "answer": "Yes, Transformer based seq2seq is evaluated with average BLEU 0.519, METEOR 0.388, ROUGE 0.631 CIDEr 2.531 and SER 2.55%.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            3,
            2,
            8,
            4,
            1,
            5,
            6,
            7
        ],
        "image-top-10-question_score": [
            22.979312896728516,
            20.909238815307617,
            20.781150817871094,
            20.506935119628906,
            20.331371307373047,
            19.976490020751953,
            19.7819766998291,
            19.58670425415039,
            18.847965240478516
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.12129.pdf",
        "text-top-10-question": [
            0,
            0,
            1,
            5,
            4,
            4,
            1,
            5,
            5,
            5
        ],
        "text-top-10-question_score": [
            22.265625,
            19.703125,
            16.921875,
            15.5859375,
            14.8671875,
            14.6171875,
            14.3828125,
            14.3125,
            13.46875,
            13.34375
        ]
    },
    {
        "doc_id": "1911.02821.pdf",
        "q_uid": "34fab25d9ceb9c5942daf4ebdab6c5dd4ff9d3db",
        "question": "What dataset did they use?",
        "answer": "weibo-100k, Ontonotes, LCQMC and XNLI",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            1,
            2,
            6,
            5,
            0
        ],
        "image-top-10-question_score": [
            12.274749755859375,
            12.187311172485352,
            11.70359992980957,
            11.567354202270508,
            11.26060962677002,
            11.16787338256836,
            11.034255981445312
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.02821.pdf",
        "text-top-10-question": [
            3,
            4,
            2,
            3,
            3,
            4,
            6,
            3,
            3,
            4
        ],
        "text-top-10-question_score": [
            17.65625,
            16.5,
            16.4375,
            15.09375,
            13.8984375,
            13.7265625,
            13.2578125,
            13.2265625,
            13.1484375,
            12.8671875
        ]
    },
    {
        "doc_id": "1906.10551.pdf",
        "q_uid": "863d5c6305e5bb4b14882b85b6216fa11bcbf053",
        "question": "What are the 12 AV approaches which are examined?",
        "answer": "MOCC, OCCAV, COAV, AVeer, GLAD, DistAV, Unmasking, Caravel, GenIM, ImpGI, SPATIUM and NNCD",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            2,
            7,
            0,
            6,
            8,
            1,
            4,
            3,
            9
        ],
        "image-top-10-question_score": [
            17.528261184692383,
            17.377124786376953,
            17.305099487304688,
            17.170753479003906,
            17.132234573364258,
            16.997894287109375,
            16.84588623046875,
            16.26248550415039,
            15.271529197692871,
            14.249801635742188
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1906.10551.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            8,
            5,
            1,
            5,
            0,
            6,
            1
        ],
        "text-top-10-question_score": [
            23.109375,
            22.625,
            22.53125,
            22.390625,
            22.265625,
            22.09375,
            21.9375,
            21.890625,
            21.03125,
            20.96875
        ]
    },
    {
        "doc_id": "1808.03430.pdf",
        "q_uid": "01edeca7b902ae3fd66264366bf548acea1db364",
        "question": "What are the results achieved from the introduced method?",
        "answer": "Their model resulted in values of 0.476, 0.672 and 0.893 for recall at position 1,2 and 5 respectively in 10 candidates.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            5,
            4,
            0,
            3,
            1
        ],
        "image-top-10-question_score": [
            14.069778442382812,
            13.525921821594238,
            12.345439910888672,
            12.07281494140625,
            11.808979034423828,
            11.794673919677734
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1808.03430.pdf",
        "text-top-10-question": [
            4,
            2,
            1,
            2,
            0,
            0,
            1,
            4,
            2,
            4
        ],
        "text-top-10-question_score": [
            13.4765625,
            13.3515625,
            13.15625,
            12.8046875,
            11.71875,
            9.15625,
            8.765625,
            8.5859375,
            8.28125,
            8.0625
        ]
    },
    {
        "doc_id": "1911.05153.pdf",
        "q_uid": "234ccc1afcae4890e618ff2a7b06fc1e513ea640",
        "question": "How big is performance improvement proposed methods are used?",
        "answer": "Data augmentation (es)  improved Adv es by 20% comparing to baseline \nData augmentation (cs) improved Adv cs by 16.5% comparing to baseline\nData augmentation (cs+es) improved both Adv cs and Adv es by at least 10% comparing to baseline \nAll models show improvements over adversarial sets  \n",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            3,
            0,
            1,
            4,
            2,
            9,
            6,
            8,
            5
        ],
        "image-top-10-question_score": [
            12.644652366638184,
            12.393156051635742,
            12.29339599609375,
            12.285505294799805,
            12.261493682861328,
            12.162975311279297,
            12.063593864440918,
            11.664140701293945,
            11.597376823425293,
            10.926410675048828
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.05153.pdf",
        "text-top-10-question": [
            7,
            7,
            1,
            7,
            4,
            6,
            7,
            6,
            4,
            1
        ],
        "text-top-10-question_score": [
            16.84375,
            15.609375,
            14.640625,
            13.9375,
            13.7265625,
            13.5,
            12.9453125,
            12.90625,
            12.5625,
            11.7890625
        ]
    },
    {
        "doc_id": "1811.02906.pdf",
        "q_uid": "4704cbb35762d0172f5ac6c26b67550921567a65",
        "question": "By how much does transfer learning improve performance on this task?",
        "answer": "In task 1 best transfer learning strategy improves F1 score by 4.4% and accuracy score by 3.3%, in task 2 best transfer learning strategy improves F1 score by 2.9% and accuracy score by 1.7%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            5,
            4,
            7,
            1,
            0,
            2,
            3,
            8,
            9
        ],
        "image-top-10-question_score": [
            17.845977783203125,
            17.766141891479492,
            17.56418228149414,
            17.453866958618164,
            17.350605010986328,
            17.251296997070312,
            16.75804901123047,
            16.58664894104004,
            12.707270622253418,
            12.266018867492676
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1811.02906.pdf",
        "text-top-10-question": [
            5,
            6,
            6,
            6,
            5,
            1,
            2,
            1,
            0,
            7
        ],
        "text-top-10-question_score": [
            24.40625,
            23.296875,
            22.125,
            21.859375,
            21.828125,
            21.203125,
            20.859375,
            20.5,
            20.46875,
            20.46875
        ]
    },
    {
        "doc_id": "1903.09588.pdf",
        "q_uid": "e9d9bb87a5c4faa965ceddd98d8b80d4b99e339e",
        "question": "How much do they outperform previous state-of-the-art?",
        "answer": "On subtask 3 best proposed model has F1 score of 92.18 compared to best previous F1 score of 88.58.\nOn subtask 4 best proposed model has 85.9, 89.9 and 95.6 compared to best previous results of 82.9, 84.0 and 89.9 on 4-way, 3-way and binary aspect polarity.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            4,
            5,
            0,
            1,
            2
        ],
        "image-top-10-question_score": [
            17.352703094482422,
            16.79962730407715,
            16.735660552978516,
            16.72327423095703,
            16.57408905029297,
            16.464576721191406
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1903.09588.pdf",
        "text-top-10-question": [
            1,
            1,
            4,
            0,
            3,
            3,
            5,
            5,
            2,
            2
        ],
        "text-top-10-question_score": [
            13.109375,
            12.1015625,
            11.40625,
            10.078125,
            9.9140625,
            9.5,
            7.87109375,
            7.625,
            6.875,
            6.65625
        ]
    },
    {
        "doc_id": "1904.01608.pdf",
        "q_uid": "9349acbfce95cb5d6b4d09ac626b55a9cb90e55e",
        "question": "What are the citation intent labels in the datasets?",
        "answer": "Background, extends, uses, motivation, compare/contrast, and future work for the ACL-ARC dataset. Background, method, result comparison for the SciCite dataset.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            8,
            1,
            4,
            2,
            5,
            0,
            7,
            6,
            9
        ],
        "image-top-10-question_score": [
            16.07599639892578,
            15.946365356445312,
            15.68370532989502,
            15.597042083740234,
            15.466649055480957,
            15.431880950927734,
            14.948587417602539,
            14.5870361328125,
            14.242853164672852,
            14.06984806060791
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1904.01608.pdf",
        "text-top-10-question": [
            3,
            3,
            6,
            1,
            3,
            1,
            3,
            6,
            4,
            0
        ],
        "text-top-10-question_score": [
            21.953125,
            21.859375,
            21.421875,
            21.359375,
            21.328125,
            21.0,
            20.171875,
            19.609375,
            19.40625,
            19.359375
        ]
    },
    {
        "doc_id": "1911.13066.pdf",
        "q_uid": "160e6d2fc6e04bb0b4ee8d59c06715355dec4a17",
        "question": "What accuracy score do they obtain?",
        "answer": "the best performing model obtained an accuracy of 0.86",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            8,
            7,
            9,
            10,
            3,
            11,
            6,
            1,
            2,
            5
        ],
        "image-top-10-question_score": [
            13.190156936645508,
            10.118438720703125,
            10.027789115905762,
            10.027336120605469,
            8.892562866210938,
            8.877243041992188,
            8.79995346069336,
            8.68818473815918,
            8.344742774963379,
            8.297529220581055
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.13066.pdf",
        "text-top-10-question": [
            7,
            8,
            7,
            8,
            8,
            0,
            9,
            10,
            11,
            11
        ],
        "text-top-10-question_score": [
            17.546875,
            17.125,
            16.8125,
            15.3515625,
            14.0,
            11.4921875,
            11.234375,
            9.6875,
            9.453125,
            9.265625
        ]
    },
    {
        "doc_id": "1911.13066.pdf",
        "q_uid": "30dad5d9b4a03e56fa31f932c879aa56e11ed15b",
        "question": "What is the 12 class bilingual text?",
        "answer": "Appreciation, Satisfied, Peripheral complaint, Demanded inquiry, Corruption, Lagged response, Unresponsive, Medicine payment, Adverse behavior, Grievance ascribed and Obnoxious/irrelevant",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            1,
            10,
            3,
            6,
            2,
            4,
            8,
            11,
            5
        ],
        "image-top-10-question_score": [
            14.482954025268555,
            13.9528169631958,
            13.654609680175781,
            13.596960067749023,
            13.444189071655273,
            13.411226272583008,
            13.269062042236328,
            13.190385818481445,
            13.048052787780762,
            11.588468551635742
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.13066.pdf",
        "text-top-10-question": [
            0,
            0,
            6,
            1,
            4,
            3,
            1,
            1,
            10,
            2
        ],
        "text-top-10-question_score": [
            23.765625,
            19.1875,
            18.96875,
            18.328125,
            18.328125,
            18.171875,
            18.0,
            17.71875,
            17.703125,
            17.625
        ]
    },
    {
        "doc_id": "1910.13215.pdf",
        "q_uid": "98eb245c727c0bd050d7686d133fa7cd9d25a0fb",
        "question": "Was evaluation metrics and criteria were used to evaluate the output of the cascaded multimodal speech translation?",
        "answer": "BLEU scores",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            0,
            5,
            6,
            4,
            3,
            7,
            2,
            1
        ],
        "image-top-10-question_score": [
            19.91891860961914,
            19.911203384399414,
            18.41436767578125,
            18.38490104675293,
            17.827457427978516,
            17.60793113708496,
            17.42845916748047,
            17.26799774169922
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.13215.pdf",
        "text-top-10-question": [
            0,
            5,
            0,
            0,
            4,
            5,
            6,
            4,
            0,
            0
        ],
        "text-top-10-question_score": [
            19.359375,
            19.140625,
            19.109375,
            17.875,
            16.671875,
            16.03125,
            15.90625,
            15.8984375,
            15.8046875,
            15.765625
        ]
    },
    {
        "doc_id": "1909.05855.pdf",
        "q_uid": "6dcbe941a3b0d5193f950acbdc574f1cfb007845",
        "question": "What are the domains covered in the dataset?",
        "answer": "Alarm\nBank\nBus\nCalendar\nEvent\nFlight\nHome\nHotel\nMedia\nMovie\nMusic\nRentalCar\nRestaurant\nRideShare\nService\nTravel\nWeather",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            6,
            10,
            2,
            3,
            9,
            8,
            0,
            4,
            7
        ],
        "image-top-10-question_score": [
            14.780170440673828,
            14.680916786193848,
            14.513006210327148,
            14.108016967773438,
            14.041290283203125,
            13.909551620483398,
            13.673677444458008,
            13.629423141479492,
            13.38503360748291,
            12.96076774597168
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.05855.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            6,
            1,
            3,
            6,
            0,
            1,
            3
        ],
        "text-top-10-question_score": [
            20.015625,
            19.15625,
            18.3125,
            18.203125,
            18.140625,
            17.296875,
            16.453125,
            16.328125,
            15.9140625,
            15.703125
        ]
    },
    {
        "doc_id": "1703.02507.pdf",
        "q_uid": "37eba8c3cfe23778498d95a7dfddf8dfb725f8e2",
        "question": "Which other unsupervised models are used for comparison?",
        "answer": "Sequential (Denoising) Autoencoder, TF-IDF BOW, SkipThought, FastSent, Siamese C-BOW, C-BOW, C-PHRASE, ParagraphVector",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            1,
            6,
            7,
            3,
            5,
            0,
            12,
            2,
            8
        ],
        "image-top-10-question_score": [
            15.099390029907227,
            15.05485725402832,
            14.874595642089844,
            14.59334659576416,
            14.549494743347168,
            14.022632598876953,
            13.813148498535156,
            13.76108169555664,
            13.218524932861328,
            13.083501815795898
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1703.02507.pdf",
        "text-top-10-question": [
            7,
            5,
            12,
            1,
            6,
            5,
            7,
            5,
            8,
            5
        ],
        "text-top-10-question_score": [
            23.078125,
            21.84375,
            21.0,
            20.890625,
            20.875,
            20.65625,
            20.21875,
            20.109375,
            19.953125,
            19.78125
        ]
    },
    {
        "doc_id": "1710.09340.pdf",
        "q_uid": "11dde2be9a69a025f2fc29ce647201fb5a4df580",
        "question": "By how much does the new parser outperform the current state-of-the-art?",
        "answer": "Proposed method achieves 94.5 UAS and 92.4 LAS  compared to 94.3 and 92.2 of best state-of-the -art greedy based parser. Best state-of-the art parser overall achieves 95.8 UAS and 94.6 LAS.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            1,
            0,
            2,
            4,
            6,
            7,
            5
        ],
        "image-top-10-question_score": [
            22.099157333374023,
            21.487655639648438,
            21.458925247192383,
            21.451326370239258,
            21.420963287353516,
            21.131298065185547,
            20.140525817871094,
            18.82917022705078
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1710.09340.pdf",
        "text-top-10-question": [
            3,
            0,
            0,
            3,
            4,
            2,
            3,
            0,
            3,
            4
        ],
        "text-top-10-question_score": [
            17.65625,
            17.328125,
            15.671875,
            15.5625,
            15.546875,
            15.5078125,
            15.140625,
            15.0234375,
            14.578125,
            14.46875
        ]
    },
    {
        "doc_id": "1906.05474.pdf",
        "q_uid": "b540cd4fe9dc4394f64d5b76b0eaa4d9e30fb728",
        "question": "Could you tell me more about the metrics used for performance evaluation?",
        "answer": "BLUE utilizes different metrics for each of the tasks: Pearson correlation coefficient, F-1 scores, micro-averaging, and accuracy",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            2,
            3,
            0,
            5,
            7,
            1,
            6
        ],
        "image-top-10-question_score": [
            16.51321029663086,
            15.93712043762207,
            15.344883918762207,
            15.292282104492188,
            15.126676559448242,
            14.631776809692383,
            14.249667167663574,
            14.070405006408691
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1906.05474.pdf",
        "text-top-10-question": [
            2,
            2,
            5,
            2,
            5,
            0,
            2,
            4,
            0,
            4
        ],
        "text-top-10-question_score": [
            13.7109375,
            13.078125,
            12.6015625,
            12.5859375,
            12.53125,
            12.296875,
            11.8203125,
            11.515625,
            11.46875,
            11.3828125
        ]
    },
    {
        "doc_id": "1906.05474.pdf",
        "q_uid": "41173179efa6186eef17c96f7cbd8acb29105b0e",
        "question": "which tasks are used in BLUE benchmark?",
        "answer": "Inference task\nThe aim of the inference task is to predict whether the premise sentence entails or contradicts the hypothesis sentence, Document multilabel classification\nThe multilabel classification task predicts multiple labels from the texts., Relation extraction\nThe aim of the relation extraction task is to predict relations and their types between the two entities mentioned in the sentences., Named entity recognition\nThe aim of the named entity recognition task is to predict mention spans given in the text , Sentence similarity\nThe sentence similarity task is to predict similarity scores based on sentence pairs",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            4,
            0,
            2,
            3,
            5,
            7,
            6
        ],
        "image-top-10-question_score": [
            14.340021133422852,
            14.177813529968262,
            14.069597244262695,
            13.945270538330078,
            13.637081146240234,
            13.589776992797852,
            11.487608909606934,
            11.162650108337402
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1906.05474.pdf",
        "text-top-10-question": [
            0,
            0,
            1,
            0,
            5,
            1,
            0,
            3,
            4,
            2
        ],
        "text-top-10-question_score": [
            24.96875,
            21.0625,
            20.59375,
            20.46875,
            20.078125,
            19.453125,
            16.75,
            16.53125,
            16.015625,
            15.6171875
        ]
    },
    {
        "doc_id": "1906.11180.pdf",
        "q_uid": "a996b6aee9be88a3db3f4127f9f77a18ed10caba",
        "question": "What's the precision of the system?",
        "answer": "0.8320 on semantic typing, 0.7194 on entity matching",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            10,
            8,
            12,
            11,
            15,
            6,
            5,
            14,
            4,
            9
        ],
        "image-top-10-question_score": [
            11.417293548583984,
            11.409112930297852,
            11.40719985961914,
            10.529315948486328,
            10.385003089904785,
            10.276310920715332,
            10.275053024291992,
            10.13034725189209,
            10.078010559082031,
            9.83837890625
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1906.11180.pdf",
        "text-top-10-question": [
            12,
            8,
            12,
            11,
            8,
            10,
            11,
            11,
            12,
            8
        ],
        "text-top-10-question_score": [
            17.453125,
            16.1875,
            15.484375,
            15.46875,
            14.46875,
            14.4296875,
            14.34375,
            13.125,
            12.8359375,
            11.875
        ]
    },
    {
        "doc_id": "1908.06379.pdf",
        "q_uid": "a6665074b067abb2676d5464f36b2cb07f6919d3",
        "question": "What are the performances obtained for PTB and CTB?",
        "answer": ". On PTB, our model achieves 93.90 F1 score of constituent parsing and 95.91 UAS and 93.86 LAS of dependency parsing., On CTB, our model achieves a new state-of-the-art result on both constituent and dependency parsing.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            3,
            0,
            5,
            6,
            4,
            1
        ],
        "image-top-10-question_score": [
            16.461448669433594,
            16.434280395507812,
            15.765380859375,
            12.514190673828125,
            12.499364852905273,
            12.229742050170898,
            11.519725799560547
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.06379.pdf",
        "text-top-10-question": [
            3,
            0,
            3,
            0,
            2,
            3,
            2,
            3,
            2,
            2
        ],
        "text-top-10-question_score": [
            20.0625,
            19.453125,
            19.34375,
            18.78125,
            17.90625,
            17.5,
            16.375,
            15.8671875,
            14.75,
            14.2890625
        ]
    },
    {
        "doc_id": "1908.11365.pdf",
        "q_uid": "3288a50701a80303fd71c8c5ede81cbee14fa2c7",
        "question": "Is the proposed layer smaller in parameters than a Transformer?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            0,
            6,
            7,
            8,
            4,
            3,
            5,
            9
        ],
        "image-top-10-question_score": [
            16.151992797851562,
            15.947303771972656,
            15.709510803222656,
            15.54794692993164,
            15.494664192199707,
            15.31414794921875,
            15.28478717803955,
            15.251347541809082,
            14.106284141540527,
            12.699337005615234
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.11365.pdf",
        "text-top-10-question": [
            1,
            1,
            0,
            7,
            4,
            3,
            0,
            4,
            8,
            1
        ],
        "text-top-10-question_score": [
            22.203125,
            18.390625,
            18.265625,
            18.171875,
            17.796875,
            17.484375,
            17.125,
            17.109375,
            16.890625,
            16.8125
        ]
    },
    {
        "doc_id": "1708.09609.pdf",
        "q_uid": "ce807a42370bfca10fa322d6fa772e4a58a8dca1",
        "question": "What are the four forums the data comes from?",
        "answer": "Darkode,  Hack Forums, Blackhat and Nulled.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            8,
            0,
            7,
            5,
            3,
            4,
            6,
            9,
            2
        ],
        "image-top-10-question_score": [
            16.000133514404297,
            15.365078926086426,
            14.965999603271484,
            14.723304748535156,
            14.687417984008789,
            14.284106254577637,
            14.240065574645996,
            14.166380882263184,
            13.807331085205078,
            13.736583709716797
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1708.09609.pdf",
        "text-top-10-question": [
            0,
            0,
            0,
            7,
            1,
            7,
            1,
            5,
            0,
            7
        ],
        "text-top-10-question_score": [
            21.03125,
            17.625,
            17.0,
            16.828125,
            16.34375,
            15.484375,
            15.453125,
            15.4375,
            15.25,
            15.046875
        ]
    },
    {
        "doc_id": "1911.11951.pdf",
        "q_uid": "79620a2b4b121b6d3edd0f7b1d4a8cc7ada0b516",
        "question": "What are the state-of-the-art models for the task?",
        "answer": "To the best of our knowledge, our method achieves state-of-the-art results in weighted-accuracy and standard accuracy on the dataset",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            1,
            2,
            5,
            0,
            7,
            4,
            6
        ],
        "image-top-10-question_score": [
            19.243244171142578,
            18.70932388305664,
            18.510332107543945,
            18.426624298095703,
            18.40813636779785,
            17.994600296020508,
            17.78214454650879,
            17.036161422729492
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.11951.pdf",
        "text-top-10-question": [
            1,
            1,
            3,
            0,
            5,
            2,
            1,
            2,
            3,
            3
        ],
        "text-top-10-question_score": [
            18.859375,
            18.640625,
            17.25,
            16.984375,
            15.546875,
            15.2109375,
            13.3671875,
            13.1640625,
            12.0625,
            11.7109375
        ]
    },
    {
        "doc_id": "2004.03788.pdf",
        "q_uid": "1cbca15405632a2e9d0a7061855642d661e3b3a7",
        "question": "How much improvement do they get?",
        "answer": "Their GTRS approach got an improvement of 3.89% compared to SVM and 27.91% compared to Pawlak.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            10,
            0,
            9,
            7,
            11,
            4,
            6,
            8,
            5,
            3
        ],
        "image-top-10-question_score": [
            10.058566093444824,
            8.974458694458008,
            7.665361404418945,
            7.5030012130737305,
            7.255845546722412,
            7.088889122009277,
            7.081893444061279,
            7.047360420227051,
            6.977691650390625,
            6.713047981262207
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-2004.03788.pdf",
        "text-top-10-question": [
            10,
            10,
            7,
            8,
            6,
            9,
            9,
            5,
            6,
            9
        ],
        "text-top-10-question_score": [
            14.390625,
            12.6796875,
            8.125,
            7.73828125,
            6.90234375,
            6.89453125,
            6.48828125,
            5.88671875,
            5.84375,
            5.4375
        ]
    },
    {
        "doc_id": "1910.10869.pdf",
        "q_uid": "c54de73b36ab86534d18a295f3711591ce9e1784",
        "question": "Is this approach compared to some baseline?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            0,
            3,
            4
        ],
        "image-top-10-question_score": [
            13.004464149475098,
            12.192073822021484,
            11.67628002166748,
            11.629316329956055,
            10.78587532043457
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.10869.pdf",
        "text-top-10-question": [
            2,
            2,
            1,
            0,
            0,
            3,
            3,
            1,
            2,
            2
        ],
        "text-top-10-question_score": [
            12.2734375,
            11.0,
            10.7109375,
            10.046875,
            9.3125,
            8.875,
            8.7734375,
            8.7265625,
            8.1953125,
            8.1328125
        ]
    },
    {
        "doc_id": "1911.08962.pdf",
        "q_uid": "a379c380ac9f67f824506951444c873713405eed",
        "question": "What are the baselines?",
        "answer": "CNN, LSTM, BERT",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            2,
            0,
            4,
            1
        ],
        "image-top-10-question_score": [
            12.030815124511719,
            11.600647926330566,
            10.037233352661133,
            9.944282531738281,
            9.737619400024414
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.08962.pdf",
        "text-top-10-question": [
            3,
            2,
            0,
            0,
            2,
            3,
            4,
            3,
            4,
            2
        ],
        "text-top-10-question_score": [
            17.359375,
            16.25,
            13.03125,
            11.7890625,
            6.1953125,
            6.0078125,
            5.8046875,
            5.26953125,
            4.82421875,
            4.80078125
        ]
    },
    {
        "doc_id": "1810.12885.pdf",
        "q_uid": "a516b37ad9d977cb9d4da3897f942c1c494405fe",
        "question": "Which models do they try out?",
        "answer": "DocQA, SAN, QANet, ASReader, LM, Random Guess",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            6,
            5,
            8,
            12,
            1,
            3,
            7,
            4,
            11,
            0
        ],
        "image-top-10-question_score": [
            11.247004508972168,
            11.09456729888916,
            11.058904647827148,
            10.856111526489258,
            10.769248962402344,
            10.554180145263672,
            10.479923248291016,
            10.094449043273926,
            10.089832305908203,
            10.050918579101562
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.12885.pdf",
        "text-top-10-question": [
            6,
            7,
            8,
            12,
            5,
            6,
            3,
            8,
            6,
            3
        ],
        "text-top-10-question_score": [
            13.953125,
            13.8046875,
            13.3671875,
            12.9609375,
            12.9296875,
            12.671875,
            11.984375,
            11.6015625,
            11.5078125,
            11.4296875
        ]
    },
    {
        "doc_id": "1911.02086.pdf",
        "q_uid": "7f5ab9a53aef7ea1a1c2221967057ee71abb27cb",
        "question": "Do they compare executionttime of their model against other models?",
        "answer": "No",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            3,
            1,
            2,
            0,
            4
        ],
        "image-top-10-question_score": [
            16.625221252441406,
            16.485363006591797,
            16.02952003479004,
            15.55966567993164,
            13.962682723999023
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.02086.pdf",
        "text-top-10-question": [
            3,
            3,
            3,
            2,
            3,
            2,
            0,
            0,
            0,
            3
        ],
        "text-top-10-question_score": [
            15.578125,
            15.4375,
            15.3828125,
            13.40625,
            12.8671875,
            12.46875,
            12.328125,
            11.921875,
            11.6015625,
            11.0859375
        ]
    },
    {
        "doc_id": "1810.02100.pdf",
        "q_uid": "c38a48d65bb21c314194090d0cc3f1a45c549dd6",
        "question": "Which English domains do they evaluate on?",
        "answer": "Conll, Weblogs, Newsgroups, Reviews, Answers",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            121,
            126,
            134,
            129,
            95,
            125,
            139,
            124,
            115,
            15
        ],
        "image-top-10-question_score": [
            13.056711196899414,
            12.902547836303711,
            12.8126220703125,
            12.775386810302734,
            12.72555923461914,
            12.641886711120605,
            12.639232635498047,
            12.632635116577148,
            12.617403030395508,
            12.594938278198242
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1810.02100.pdf",
        "text-top-10-question": [
            2,
            46,
            47,
            138,
            48,
            120,
            120,
            95,
            95,
            48
        ],
        "text-top-10-question_score": [
            22.0,
            21.8125,
            21.734375,
            21.671875,
            21.1875,
            21.171875,
            21.125,
            20.421875,
            20.359375,
            20.296875
        ]
    },
    {
        "doc_id": "1910.11235.pdf",
        "q_uid": "12ac76b77f22ed3bcb6430bcd0b909441d79751b",
        "question": "What are the competing models?",
        "answer": "TEACHER FORCING (TF), SCHEDULED SAMPLING (SS),  SEQGAN, RANKGAN, LEAKGAN.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            3,
            1,
            4,
            0,
            2
        ],
        "image-top-10-question_score": [
            10.385726928710938,
            10.083003997802734,
            9.923744201660156,
            9.83570671081543,
            9.831952095031738,
            9.723170280456543
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1910.11235.pdf",
        "text-top-10-question": [
            3,
            0,
            3,
            0,
            1,
            1,
            3,
            3,
            2,
            1
        ],
        "text-top-10-question_score": [
            17.03125,
            17.0,
            12.9375,
            12.8515625,
            11.9921875,
            11.6015625,
            11.203125,
            11.03125,
            10.65625,
            10.5
        ]
    },
    {
        "doc_id": "1909.01247.pdf",
        "q_uid": "0d7de323fd191a793858386d7eb8692cc924b432",
        "question": "What writing styles are present in the corpus?",
        "answer": "current news, historical news, free time, sports, juridical news pieces, personal adverts, editorials.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            6,
            5,
            2,
            4,
            3,
            7
        ],
        "image-top-10-question_score": [
            14.576398849487305,
            14.275382995605469,
            13.840799331665039,
            13.339184761047363,
            12.525053024291992,
            12.132182121276855,
            11.97494888305664,
            11.830793380737305
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1909.01247.pdf",
        "text-top-10-question": [
            1,
            1,
            0,
            6,
            1,
            1,
            0,
            0,
            5,
            0
        ],
        "text-top-10-question_score": [
            20.09375,
            20.078125,
            17.03125,
            16.671875,
            16.609375,
            16.28125,
            15.8203125,
            15.6328125,
            15.5234375,
            15.3203125
        ]
    },
    {
        "doc_id": "1908.06151.pdf",
        "q_uid": "f9c5799091e7e35a8133eee4d95004e1b35aea00",
        "question": "What experiment result led to conclussion that reducing the number of layers of the decoder does not matter much?",
        "answer": "Exp. 5.1",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            2,
            7,
            5,
            6,
            1,
            0,
            3,
            8,
            9
        ],
        "image-top-10-question_score": [
            22.4871883392334,
            22.054887771606445,
            21.949554443359375,
            21.456737518310547,
            21.300037384033203,
            21.120277404785156,
            20.718921661376953,
            19.647977828979492,
            16.49176597595215,
            16.129594802856445
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.06151.pdf",
        "text-top-10-question": [
            6,
            0,
            0,
            4,
            4,
            3,
            6,
            1,
            6,
            1
        ],
        "text-top-10-question_score": [
            19.9375,
            18.84375,
            16.65625,
            15.1328125,
            14.7109375,
            14.546875,
            14.234375,
            13.546875,
            13.2890625,
            13.0625
        ]
    },
    {
        "doc_id": "1908.06151.pdf",
        "q_uid": "04012650a45d56c0013cf45fd9792f43916eaf83",
        "question": "How much is performance hurt when using too small amount of layers in encoder?",
        "answer": "comparing to the results from reducing the number of layers in the decoder, the BLEU score was 69.93 which is less than 1% in case of test2016 and in case of test2017 it was less by 0.2 %. In terms of TER it had higher score by 0.7 in case of test2016 and 0.1 in case of test2017. ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            0,
            2,
            4,
            1,
            5,
            6,
            3,
            9,
            8
        ],
        "image-top-10-question_score": [
            17.956071853637695,
            17.85049057006836,
            17.715120315551758,
            17.69858741760254,
            17.544750213623047,
            17.41817855834961,
            16.95844268798828,
            16.62013053894043,
            13.280994415283203,
            13.23668384552002
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1908.06151.pdf",
        "text-top-10-question": [
            0,
            0,
            6,
            4,
            4,
            7,
            6,
            3,
            6,
            1
        ],
        "text-top-10-question_score": [
            21.3125,
            21.03125,
            20.125,
            16.546875,
            14.8203125,
            14.796875,
            14.6953125,
            14.3125,
            13.7890625,
            13.28125
        ]
    },
    {
        "doc_id": "1901.03866.pdf",
        "q_uid": "efe49829725cfe54de01405c76149a4fe4d18747",
        "question": "How much does HAS-QA improve over baselines?",
        "answer": "For example, in QuasarT, it improves 16.8% in EM score and 20.4% in F1 score. , For example, in QuasarT, it improves 4.6% in EM score and 3.5% in F1 score.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            0,
            1,
            6,
            2,
            4,
            7,
            8,
            3
        ],
        "image-top-10-question_score": [
            17.69286346435547,
            17.255542755126953,
            17.124807357788086,
            16.954853057861328,
            16.48722267150879,
            15.860420227050781,
            12.884503364562988,
            12.384227752685547,
            12.09531021118164
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1901.03866.pdf",
        "text-top-10-question": [
            5,
            5,
            0,
            0,
            6,
            5,
            6,
            5,
            5,
            6
        ],
        "text-top-10-question_score": [
            22.140625,
            20.28125,
            18.296875,
            18.125,
            18.0,
            17.984375,
            17.328125,
            16.1875,
            16.0625,
            15.7109375
        ]
    },
    {
        "doc_id": "1606.00189.pdf",
        "q_uid": "a49832c89a2d7f95c1fe6132902d74e4e7a3f2d0",
        "question": "Which dataset do they evaluate grammatical error correction on?",
        "answer": "CoNLL 2014",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            1,
            0,
            6,
            5,
            3,
            4,
            2
        ],
        "image-top-10-question_score": [
            15.732074737548828,
            15.683854103088379,
            15.431955337524414,
            13.896580696105957,
            12.812957763671875,
            12.509078979492188,
            12.488822937011719
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1606.00189.pdf",
        "text-top-10-question": [
            5,
            0,
            6,
            0,
            6,
            0,
            1,
            6,
            0,
            6
        ],
        "text-top-10-question_score": [
            20.453125,
            20.203125,
            20.0625,
            19.953125,
            19.59375,
            19.25,
            19.1875,
            19.1875,
            19.171875,
            19.0625
        ]
    },
    {
        "doc_id": "1605.07683.pdf",
        "q_uid": "a02696d4ab728ddd591f84a352df9375faf7d1b4",
        "question": "How large is the Dialog State Tracking Dataset?",
        "answer": "1,618 training dialogs, 500 validation dialogs, and 1,117 test dialogs",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            5,
            2,
            14,
            6,
            3,
            7,
            0,
            9,
            8
        ],
        "image-top-10-question_score": [
            14.869443893432617,
            14.421547889709473,
            14.352921485900879,
            14.011573791503906,
            13.432258605957031,
            13.40560531616211,
            13.299695014953613,
            13.102154731750488,
            13.08676528930664,
            12.94727897644043
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1605.07683.pdf",
        "text-top-10-question": [
            9,
            2,
            4,
            2,
            9,
            14,
            5,
            5,
            14,
            7
        ],
        "text-top-10-question_score": [
            20.359375,
            20.328125,
            20.3125,
            20.015625,
            19.359375,
            19.140625,
            18.828125,
            18.59375,
            18.328125,
            18.21875
        ]
    },
    {
        "doc_id": "1711.00106.pdf",
        "q_uid": "1f63ccc379f01ecdccaa02ed0912970610c84b72",
        "question": "How much is the gap between using the proposed objective and using only cross-entropy objective?",
        "answer": "The mixed objective improves EM by 2.5% and F1 by 2.2%",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            4,
            0,
            6,
            3,
            1,
            5,
            7,
            2,
            8,
            9
        ],
        "image-top-10-question_score": [
            20.272075653076172,
            20.228816986083984,
            19.77468490600586,
            19.484163284301758,
            19.022947311401367,
            17.054473876953125,
            16.775699615478516,
            16.44135856628418,
            16.335018157958984,
            15.071464538574219
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1711.00106.pdf",
        "text-top-10-question": [
            6,
            0,
            4,
            6,
            0,
            4,
            3,
            3,
            7,
            0
        ],
        "text-top-10-question_score": [
            19.546875,
            19.46875,
            18.546875,
            18.140625,
            17.84375,
            17.78125,
            17.765625,
            16.90625,
            16.78125,
            16.453125
        ]
    },
    {
        "doc_id": "1911.08976.pdf",
        "q_uid": "dac2591f19f5bbac3d4a7fa038ff7aa09f6f0d96",
        "question": "what are the three methods presented in the paper?",
        "answer": "Optimized TF-IDF, iterated TF-IDF, BERT re-ranking.",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            2,
            1,
            4,
            0,
            3
        ],
        "image-top-10-question_score": [
            14.2862548828125,
            14.071850776672363,
            14.061511039733887,
            13.828204154968262,
            13.677392959594727
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1911.08976.pdf",
        "text-top-10-question": [
            1,
            2,
            0,
            2,
            4,
            3,
            1,
            0,
            2,
            2
        ],
        "text-top-10-question_score": [
            17.71875,
            15.84375,
            15.7734375,
            15.453125,
            14.6171875,
            13.8203125,
            13.265625,
            12.734375,
            12.53125,
            11.8359375
        ]
    },
    {
        "doc_id": "1812.01704.pdf",
        "q_uid": "f62c78be58983ef1d77049738785ec7ab9f2a3ee",
        "question": "what datasets did the authors use?",
        "answer": "Kaggle\nSubversive Kaggle\nWikipedia\nSubversive Wikipedia\nReddit\nSubversive Reddit ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            7,
            1,
            4,
            0,
            8,
            5,
            3,
            6,
            2
        ],
        "image-top-10-question_score": [
            12.654369354248047,
            12.62249755859375,
            12.540614128112793,
            12.288454055786133,
            12.166507720947266,
            11.919412612915039,
            11.904213905334473,
            11.719738006591797,
            11.404569625854492
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1812.01704.pdf",
        "text-top-10-question": [
            1,
            1,
            1,
            5,
            4,
            5,
            4,
            7,
            4,
            6
        ],
        "text-top-10-question_score": [
            20.984375,
            19.703125,
            18.21875,
            16.125,
            15.9765625,
            15.8359375,
            13.9765625,
            13.921875,
            13.5859375,
            13.34375
        ]
    },
    {
        "doc_id": "1712.03556.pdf",
        "q_uid": "39a450ac15688199575798e72a2cc016ef4316b5",
        "question": "How much performance improvements they achieve on SQuAD?",
        "answer": "Compared to baselines SAN (Table 1) shows  improvement of 1.096% on EM and 0.689% F1. Compared to other published SQuAD results (Table 2) SAN is ranked second. ",
        "answer_2": " ",
        "answer_3": " ",
        "image-top-10-question": [
            5,
            4,
            7,
            0,
            8,
            6,
            2,
            1,
            10,
            9
        ],
        "image-top-10-question_score": [
            15.221546173095703,
            15.095727920532227,
            14.925962448120117,
            14.123905181884766,
            13.941850662231445,
            13.638692855834961,
            12.18852424621582,
            11.914527893066406,
            11.182889938354492,
            10.95112133026123
        ],
        "text-index-path-question": ".ragatouille/colbert/indexes/PaperTab-question-1712.03556.pdf",
        "text-top-10-question": [
            5,
            0,
            5,
            5,
            6,
            8,
            4,
            6,
            6,
            7
        ],
        "text-top-10-question_score": [
            18.234375,
            17.546875,
            17.328125,
            17.296875,
            16.53125,
            15.984375,
            15.625,
            15.5078125,
            15.1015625,
            14.8125
        ]
    }
]